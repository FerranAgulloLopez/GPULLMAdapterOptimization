INFO 06-01 00:47:10 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:10 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 3.048349712975323,
    "estimated_duration": 3599.9729883200343,
    "input_throughput": 1800.0054503253225,
    "output_throughput": 1611.7254265031704,
    "total_throughput": 3411.730876828493,
    "itl": 23.773971926084926,
    "ttft": 69504.08811237894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.99655876669904,
    "arrivals": 26760,
    "finished_requests": 26465,
    "scheduler_time": 3.4261716579576773
}
#Debug simulation 
Total elapsed time: 3.0485042352229357. Arrivals time: 0.08568534534424543 Scheduler time: 2.5719781420193613 Scheduler overhead time: 0.14203097624704242 Adapter cache time: 0.04483732674270868 Engine time: 0.1378234182484448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 3.0298732491210103,
    "estimated_duration": 3599.9720040402904,
    "input_throughput": 1797.9812045026,
    "output_throughput": 1611.0594730989162,
    "total_throughput": 3409.040677601516,
    "itl": 23.765527575958938,
    "ttft": 71722.70851195368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.513704131456615,
    "arrivals": 26760,
    "finished_requests": 26447,
    "scheduler_time": 3.3974565515433723
}
#Debug simulation 
Total elapsed time: 3.0299840453080833. Arrivals time: 0.08308778936043382 Scheduler time: 2.560721074230969 Scheduler overhead time: 0.14014414697885513 Adapter cache time: 0.04452831670641899 Engine time: 0.13561047613620758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 135, 135, 135, 135, 1080, 135, 33, 1080, 33, 135, 135, 33, 1080, 1080, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 33, 135, 135, 1080, 135, 33, 33, 135, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 1080, 1080, 33, 135, 1080, 33, 135, 33, 135, 33, 33, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 135, 33, 33, 33, 33, 33, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 33, 135, 135, 1080, 33, 33, 33, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 135, 33, 1080, 135, 135, 135, 1080, 135, 33, 135, 1080, 1080, 135, 1080, 135, 33, 1080, 135, 33, 135, 135, 33, 135, 1080, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 135, 33, 33, 135, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 135, 33, 1080, 1080, 135, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 135, 135, 135, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 79872 . Total input tokens: 17789080 . Total output tokens: 15964667
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 3.0414219070225954,
    "estimated_duration": 3599.983915395924,
    "input_throughput": 1800.7408233897743,
    "output_throughput": 1611.3969218559714,
    "total_throughput": 3412.1377452457455,
    "itl": 23.769797791810795,
    "ttft": 68287.139188104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4851,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.22997199084494,
    "arrivals": 26760,
    "finished_requests": 26474,
    "scheduler_time": 3.433126443759974
}
#Debug simulation 
Total elapsed time: 3.041536259930581. Arrivals time: 0.08463213266804814 Scheduler time: 2.5679778358899057 Scheduler overhead time: 0.14167260052636266 Adapter cache time: 0.044385266955941916 Engine time: 0.13651888351887465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.7631447529420257,
    "estimated_duration": 3599.8846657728473,
    "input_throughput": 1719.3242491481947,
    "output_throughput": 1535.0516788886177,
    "total_throughput": 3254.375928036812,
    "itl": 23.49986102977576,
    "ttft": 50634.91792450366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4949,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.146353844721615,
    "arrivals": 25342,
    "finished_requests": 25151,
    "scheduler_time": 1.4381384640126027
}
#Debug simulation 
Total elapsed time: 2.7632411760278046. Arrivals time: 0.0787534131668508 Scheduler time: 2.29817480314523 Scheduler overhead time: 0.13888463377952576 Adapter cache time: 0.04476292384788394 Engine time: 0.13639240060001612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.755266317166388,
    "estimated_duration": 3599.8838577834003,
    "input_throughput": 1720.261331934506,
    "output_throughput": 1534.8961850681067,
    "total_throughput": 3255.1575170026126,
    "itl": 23.501380554336706,
    "ttft": 49744.33749352857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4935,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.058908675849604,
    "arrivals": 25342,
    "finished_requests": 25158,
    "scheduler_time": 1.4450198635044946
}
#Debug simulation 
Total elapsed time: 2.755387980956584. Arrivals time: 0.07923823688179255 Scheduler time: 2.292455113492906 Scheduler overhead time: 0.1382991266436875 Adapter cache time: 0.044882404152303934 Engine time: 0.1345796943642199 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.766695444006473,
    "estimated_duration": 3599.886032347956,
    "input_throughput": 1719.5016576573912,
    "output_throughput": 1535.1122092039186,
    "total_throughput": 3254.61386686131,
    "itl": 23.495744318779646,
    "ttft": 50191.76279345533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.1172269056537,
    "arrivals": 25342,
    "finished_requests": 25154,
    "scheduler_time": 1.4219761300636202
}
#Debug simulation 
Total elapsed time: 2.7667976021766663. Arrivals time: 0.07592374784871936 Scheduler time: 2.306067672558129 Scheduler overhead time: 0.13783614477142692 Adapter cache time: 0.04493843065574765 Engine time: 0.13627811567857862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.7995700296014547,
    "estimated_duration": 3599.883060959685,
    "input_throughput": 1718.8313884702866,
    "output_throughput": 1534.392619555666,
    "total_throughput": 3253.2240080259526,
    "itl": 23.49112334673133,
    "ttft": 52178.56160528599,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4939,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.435503156854706,
    "arrivals": 25342,
    "finished_requests": 25140,
    "scheduler_time": 1.4259672972907247
}
#Debug simulation 
Total elapsed time: 2.7996760099194944. Arrivals time: 0.08310786774381995 Scheduler time: 2.329501111060381 Scheduler overhead time: 0.13817630987614393 Adapter cache time: 0.045311964116990566 Engine time: 0.13737616688013077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.797750633675605,
    "estimated_duration": 3599.8685282761694,
    "input_throughput": 1718.7449906574298,
    "output_throughput": 1534.2721426120595,
    "total_throughput": 3253.0171332694895,
    "itl": 23.50149036961966,
    "ttft": 52774.40395358083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4927,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.264846268257717,
    "arrivals": 25342,
    "finished_requests": 25137,
    "scheduler_time": 1.4545697470327017
}
#Debug simulation 
Total elapsed time: 2.7978504127822816. Arrivals time: 0.08095413073897362 Scheduler time: 2.3308473033830523 Scheduler overhead time: 0.1387316333130002 Adapter cache time: 0.04522603563964367 Engine time: 0.1360756061039865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.8006760510616004,
    "estimated_duration": 3599.8768499325492,
    "input_throughput": 1719.3646499646154,
    "output_throughput": 1534.097478946669,
    "total_throughput": 3253.4621289112843,
    "itl": 23.493835379192227,
    "ttft": 52146.50026090171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.782808657997881,
    "arrivals": 25342,
    "finished_requests": 25141,
    "scheduler_time": 1.4487974917839948
}
#Debug simulation 
Total elapsed time: 2.8007734972052276. Arrivals time: 0.08273913990706205 Scheduler time: 2.330098323058337 Scheduler overhead time: 0.13872705167159438 Adapter cache time: 0.04532606899738312 Engine time: 0.1377985505387187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [64 64 64]
Adapter prompts. [1080, 33, 1080, 33, 1080, 33, 1080, 33, 33, 33, 66, 66, 66, 66, 1080, 66, 33, 1080, 33, 66, 66, 33, 1080, 1080, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 33, 66, 66, 1080, 66, 33, 33, 66, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 1080, 1080, 33, 66, 1080, 33, 66, 33, 66, 33, 33, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 1080, 66, 33, 33, 33, 33, 33, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 33, 66, 66, 1080, 33, 33, 33, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 66, 33, 1080, 66, 66, 66, 1080, 66, 33, 66, 1080, 1080, 66, 1080, 66, 33, 1080, 66, 33, 66, 66, 33, 66, 1080, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 66, 33, 33, 66, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 66, 33, 1080, 1080, 66, 1080, 33, 1080, 1080, 1080, 33, 1080, 1080, 1080, 66, 66, 66, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 75456 . Total input tokens: 16792402 . Total output tokens: 15073813
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.821669611148536,
    "estimated_duration": 3599.877346392999,
    "input_throughput": 1719.1813510538323,
    "output_throughput": 1534.8739605076523,
    "total_throughput": 3254.0553115614844,
    "itl": 23.50534426940519,
    "ttft": 50926.972606734584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.414169615729463,
    "arrivals": 25342,
    "finished_requests": 25151,
    "scheduler_time": 1.5010151022835314
}
#Debug simulation 
Total elapsed time: 2.821772085968405. Arrivals time: 0.08308870252221823 Scheduler time: 2.35128676565364 Scheduler overhead time: 0.1382168047130108 Adapter cache time: 0.045315280091017485 Engine time: 0.13773455983027816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.4835100392811,
    "estimated_duration": 3599.5098028927464,
    "input_throughput": 1389.8050773412665,
    "output_throughput": 1220.9106908024573,
    "total_throughput": 2610.715768143724,
    "itl": 22.62623301912319,
    "ttft": 77762.98788030875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.82199962518555,
    "arrivals": 20309,
    "finished_requests": 20075,
    "scheduler_time": 0.11948814147595027
}
#Debug simulation 
Total elapsed time: 2.483607013244182. Arrivals time: 0.07071957131847739 Scheduler time: 2.0113755092024803 Scheduler overhead time: 0.1415197066962719 Adapter cache time: 0.051034390926361084 Engine time: 0.1415573712438345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.4738661339506507,
    "estimated_duration": 3599.5022309055034,
    "input_throughput": 1389.87189868791,
    "output_throughput": 1221.005494110883,
    "total_throughput": 2610.877392798793,
    "itl": 22.636899731893198,
    "ttft": 77666.10103393442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.988963311265344,
    "arrivals": 20309,
    "finished_requests": 20076,
    "scheduler_time": 0.13953096572162443
}
#Debug simulation 
Total elapsed time: 2.4739966802299023. Arrivals time: 0.072173030115664 Scheduler time: 2.001885305158794 Scheduler overhead time: 0.14132512360811234 Adapter cache time: 0.05066503630951047 Engine time: 0.14035188499838114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.4923022598959506,
    "estimated_duration": 3599.4998114628565,
    "input_throughput": 1389.8728329053074,
    "output_throughput": 1221.006314822904,
    "total_throughput": 2610.879147728211,
    "itl": 22.63605292063109,
    "ttft": 77667.00343576113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6135,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.029746550171886,
    "arrivals": 20309,
    "finished_requests": 20076,
    "scheduler_time": 0.13942754639917876
}
#Debug simulation 
Total elapsed time: 2.492404135875404. Arrivals time: 0.07019489211961627 Scheduler time: 2.0224583954550326 Scheduler overhead time: 0.14081629365682602 Adapter cache time: 0.051057725213468075 Engine time: 0.14006236661225557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.5038438900373876,
    "estimated_duration": 3599.505943250713,
    "input_throughput": 1389.806567587478,
    "output_throughput": 1220.9119999482946,
    "total_throughput": 2610.7185675357723,
    "itl": 22.62865301381078,
    "ttft": 77681.16186415966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.266804868493075,
    "arrivals": 20309,
    "finished_requests": 20075,
    "scheduler_time": 0.12619619486685263
}
#Debug simulation 
Total elapsed time: 2.5039544738829136. Arrivals time: 0.07241010339930654 Scheduler time: 2.0319368420168757 Scheduler overhead time: 0.1409594244323671 Adapter cache time: 0.05119979940354824 Engine time: 0.1400118302553892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.4780848901718855,
    "estimated_duration": 3599.508793388853,
    "input_throughput": 1389.748514905098,
    "output_throughput": 1220.8832516457353,
    "total_throughput": 2610.631766550833,
    "itl": 22.634595291816478,
    "ttft": 77374.79601588812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.29209634499515,
    "arrivals": 20309,
    "finished_requests": 20078,
    "scheduler_time": 0.1393139492247463
}
#Debug simulation 
Total elapsed time: 2.4781884350813925. Arrivals time: 0.06613553734496236 Scheduler time: 2.0101445368491113 Scheduler overhead time: 0.14143549744039774 Adapter cache time: 0.050923686008900404 Engine time: 0.14197552017867565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.484026886988431,
    "estimated_duration": 3599.513212271494,
    "input_throughput": 1390.0082330417686,
    "output_throughput": 1220.7995195069616,
    "total_throughput": 2610.80775254873,
    "itl": 22.624418929648222,
    "ttft": 77437.56558896649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.382829213059626,
    "arrivals": 20309,
    "finished_requests": 20077,
    "scheduler_time": 0.12184265793684695
}
#Debug simulation 
Total elapsed time: 2.48418234474957. Arrivals time: 0.07102305814623833 Scheduler time: 2.0105647589080036 Scheduler overhead time: 0.14272373402491212 Adapter cache time: 0.05134433787316084 Engine time: 0.14056361420080066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_192_slots_16_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [64 64 64]
Adapter prompts. [540, 135, 540, 135, 540, 135, 540, 135, 135, 135, 270, 270, 270, 270, 540, 270, 135, 540, 135, 270, 270, 135, 540, 540, 135, 270, 135, 270, 135, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 135, 270, 270, 540, 270, 135, 135, 270, 540, 135, 270, 135, 540, 540, 270, 540, 540, 540, 135, 270, 540, 135, 270, 135, 270, 135, 135, 270, 540, 540, 135, 135, 135, 540, 540, 540, 270, 135, 135, 135, 135, 135, 540, 135, 270, 135, 540, 540, 135, 540, 135, 270, 270, 540, 135, 135, 135, 540, 540, 270, 540, 270, 540, 540, 270, 270, 135, 540, 270, 270, 270, 540, 270, 135, 270, 540, 540, 270, 540, 270, 135, 540, 270, 135, 270, 270, 135, 270, 540, 135, 270, 540, 135, 270, 540, 540, 270, 135, 540, 270, 135, 135, 270, 540, 540, 540, 135, 540, 135, 540, 135, 270, 135, 540, 540, 270, 540, 135, 540, 540, 540, 135, 540, 540, 540, 270, 270, 270, 270, 270, 270, 135, 540, 270, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 60480 . Total input tokens: 13415393 . Total output tokens: 12119019
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.495673951227218,
    "estimated_duration": 3599.5050194864793,
    "input_throughput": 1389.7499719874443,
    "output_throughput": 1220.8845316812335,
    "total_throughput": 2610.634503668678,
    "itl": 22.638921830373306,
    "ttft": 77377.62577716692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.550520376077202,
    "arrivals": 20309,
    "finished_requests": 20078,
    "scheduler_time": 0.13911290263123352
}
#Debug simulation 
Total elapsed time: 2.495775837916881. Arrivals time: 0.07059683417901397 Scheduler time: 2.0254253586754203 Scheduler overhead time: 0.14073853474110365 Adapter cache time: 0.05091237835586071 Engine time: 0.14072280516847968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.3153902501799166,
    "estimated_duration": 3599.9967989477777,
    "input_throughput": 1281.237250363152,
    "output_throughput": 1155.923805603463,
    "total_throughput": 2437.161055966615,
    "itl": 22.462442863407517,
    "ttft": 65154.800763024316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6359,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.461641563667705,
    "arrivals": 18908,
    "finished_requests": 18723,
    "scheduler_time": 0.008864995677166131
}
#Debug simulation 
Total elapsed time: 2.315493841189891. Arrivals time: 0.06757269380614161 Scheduler time: 1.8468199046328664 Scheduler overhead time: 0.13965481240302324 Adapter cache time: 0.05140947503969073 Engine time: 0.1421646699309349 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.28164132963866,
    "estimated_duration": 3600.011390376162,
    "input_throughput": 1280.792892024215,
    "output_throughput": 1156.062175560265,
    "total_throughput": 2436.85506758448,
    "itl": 22.472997007191935,
    "ttft": 66233.28982280302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.68302842253993,
    "arrivals": 18908,
    "finished_requests": 18718,
    "scheduler_time": 0.012250225810840329
}
#Debug simulation 
Total elapsed time: 2.2817424377426505. Arrivals time: 0.06530870078131557 Scheduler time: 1.8178197327069938 Scheduler overhead time: 0.1398199643008411 Adapter cache time: 0.05123610282316804 Engine time: 0.1400062758475542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.286434176377952,
    "estimated_duration": 3600.0119112549974,
    "input_throughput": 1280.7927067087421,
    "output_throughput": 1156.0620082918406,
    "total_throughput": 2436.854715000583,
    "itl": 22.47388375051399,
    "ttft": 66233.70436150243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.72694182585868,
    "arrivals": 18908,
    "finished_requests": 18718,
    "scheduler_time": 0.012257079257516264
}
#Debug simulation 
Total elapsed time: 2.2865369212813675. Arrivals time: 0.06706150015816092 Scheduler time: 1.8203434976749122 Scheduler overhead time: 0.1396543439477682 Adapter cache time: 0.05134230945259333 Engine time: 0.14050326542928815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.292446175124496,
    "estimated_duration": 3600.0119485539553,
    "input_throughput": 1280.9890816757893,
    "output_throughput": 1156.0956073136829,
    "total_throughput": 2437.0846889894724,
    "itl": 22.467620005149524,
    "ttft": 65076.20741624265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6360,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.85638325497287,
    "arrivals": 18908,
    "finished_requests": 18724,
    "scheduler_time": 0.012255698885456393
}
#Debug simulation 
Total elapsed time: 2.2925508432090282. Arrivals time: 0.0663977270014584 Scheduler time: 1.8268415392376482 Scheduler overhead time: 0.13977754767984152 Adapter cache time: 0.05143248476088047 Engine time: 0.14028644328936934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.2903047488071024,
    "estimated_duration": 3600.0135598969805,
    "input_throughput": 1280.4618436303647,
    "output_throughput": 1156.0389789529277,
    "total_throughput": 2436.5008225832926,
    "itl": 22.476173062188042,
    "ttft": 66413.77644060027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.99001874703805,
    "arrivals": 18908,
    "finished_requests": 18717,
    "scheduler_time": 0.01192533978265564
}
#Debug simulation 
Total elapsed time: 2.290410299785435. Arrivals time: 0.0637144478969276 Scheduler time: 1.82396702747792 Scheduler overhead time: 0.14249054016545415 Adapter cache time: 0.051155393943190575 Engine time: 0.14071007166057825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.289549225009978,
    "estimated_duration": 3600.005270512324,
    "input_throughput": 1280.2470145673144,
    "output_throughput": 1155.9719187321546,
    "total_throughput": 2436.218933299469,
    "itl": 22.462557004714018,
    "ttft": 66822.27679600462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.05260047911749,
    "arrivals": 18908,
    "finished_requests": 18714,
    "scheduler_time": 0.009190342930835338
}
#Debug simulation 
Total elapsed time: 2.289656341075897. Arrivals time: 0.06501201773062348 Scheduler time: 1.8237777869217098 Scheduler overhead time: 0.14060999918729067 Adapter cache time: 0.05126076005399227 Engine time: 0.14107193984091282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_192_slots_16_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 270, 270, 270, 270, 540, 270, 66, 540, 66, 270, 270, 66, 540, 540, 66, 270, 66, 270, 66, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 66, 270, 270, 540, 270, 66, 66, 270, 540, 66, 270, 66, 540, 540, 270, 540, 540, 540, 66, 270, 540, 66, 270, 66, 270, 66, 66, 270, 540, 540, 66, 66, 66, 540, 540, 540, 270, 66, 66, 66, 66, 66, 540, 66, 270, 66, 540, 540, 66, 540, 66, 270, 270, 540, 66, 66, 66, 540, 540, 270, 540, 270, 540, 540, 270, 270, 66, 540, 270, 270, 270, 540, 270, 66, 270, 540, 540, 270, 540, 270, 66, 540, 270, 66, 270, 270, 66, 270, 540, 66, 270, 540, 66, 270, 540, 540, 270, 66, 540, 270, 66, 66, 270, 540, 540, 540, 66, 540, 66, 540, 66, 270, 66, 540, 540, 270, 540, 66, 540, 540, 540, 66, 540, 540, 540, 270, 270, 270, 270, 270, 270, 66, 540, 270, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 56064 . Total input tokens: 12438405 . Total output tokens: 11244593
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.294654596131295,
    "estimated_duration": 3600.0112607829647,
    "input_throughput": 1280.7929381301947,
    "output_throughput": 1156.0622171761886,
    "total_throughput": 2436.8551553063835,
    "itl": 22.47937315933373,
    "ttft": 66242.25262765899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.24806551676078,
    "arrivals": 18908,
    "finished_requests": 18718,
    "scheduler_time": 0.012275841304370134
}
#Debug simulation 
Total elapsed time: 2.2947558308951557. Arrivals time: 0.06561177968978882 Scheduler time: 1.8311165827326477 Scheduler overhead time: 0.13911357801407576 Adapter cache time: 0.051053994335234165 Engine time: 0.14033101266250014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.1296503809280694,
    "estimated_duration": 3599.6232639154796,
    "input_throughput": 1253.0944683065345,
    "output_throughput": 1099.5625680268233,
    "total_throughput": 2352.6570363333576,
    "itl": 22.27823678774283,
    "ttft": 50377.55552129981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.743985928375945,
    "arrivals": 18247,
    "finished_requests": 18110,
    "scheduler_time": 0.0017492528276405886
}
#Debug simulation 
Total elapsed time: 2.129749253857881. Arrivals time: 0.06021819356828928 Scheduler time: 1.6701717963442206 Scheduler overhead time: 0.1398311322554946 Adapter cache time: 0.05265028029680252 Engine time: 0.13892663083970547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.137878078967333,
    "estimated_duration": 3599.6292673441985,
    "input_throughput": 1252.9620872117252,
    "output_throughput": 1099.4243312506048,
    "total_throughput": 2352.38641846233,
    "itl": 22.285491738054095,
    "ttft": 50620.14850559344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.002108776053756,
    "arrivals": 18247,
    "finished_requests": 18109,
    "scheduler_time": 0.0012550376066824353
}
#Debug simulation 
Total elapsed time: 2.13798168534413. Arrivals time: 0.0630887346342206 Scheduler time: 1.6738676275126636 Scheduler overhead time: 0.14038353692740202 Adapter cache time: 0.052636418491601944 Engine time: 0.1396568277850747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.1223117178305984,
    "estimated_duration": 3599.6302170605622,
    "input_throughput": 1252.9617566337142,
    "output_throughput": 1099.4240411815658,
    "total_throughput": 2352.38579781528,
    "itl": 22.286096189207832,
    "ttft": 50619.07038636531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.068243566825643,
    "arrivals": 18247,
    "finished_requests": 18109,
    "scheduler_time": 0.0012690689480069977
}
#Debug simulation 
Total elapsed time: 2.1223956658504903. Arrivals time: 0.05719973612576723 Scheduler time: 1.6651095123961568 Scheduler overhead time: 0.13933191308751702 Adapter cache time: 0.05269887484610081 Engine time: 0.14015863090753555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 2.1295793768949807,
    "estimated_duration": 3599.633526112229,
    "input_throughput": 1252.9606048177977,
    "output_throughput": 1099.423030508971,
    "total_throughput": 2352.383635326769,
    "itl": 22.27846727003355,
    "ttft": 50625.70325443363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6755,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.09302208476669,
    "arrivals": 18247,
    "finished_requests": 18109,
    "scheduler_time": 0.0008995324388761806
}
#Debug simulation 
Total elapsed time: 2.1296686977148056. Arrivals time: 0.057332743890583515 Scheduler time: 1.672604416962713 Scheduler overhead time: 0.13938308088108897 Adapter cache time: 0.052352693397551775 Engine time: 0.14016736345365644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 2.1163254734128714,
    "estimated_duration": 3599.639447048847,
    "input_throughput": 1252.9585438612949,
    "output_throughput": 1099.4212221017192,
    "total_throughput": 2352.379765963014,
    "itl": 22.28683187439438,
    "ttft": 50675.35561285258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.294756279568077,
    "arrivals": 18247,
    "finished_requests": 18109,
    "scheduler_time": 0.0013030192626370214
}
#Debug simulation 
Total elapsed time: 2.1164031960070133. Arrivals time: 0.056832537055015564 Scheduler time: 1.6598971923813224 Scheduler overhead time: 0.13923413958400488 Adapter cache time: 0.05258293775841594 Engine time: 0.13996645715087652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 2.1386259379796684,
    "estimated_duration": 3599.6390910969885,
    "input_throughput": 1253.0889586003957,
    "output_throughput": 1099.5577333820424,
    "total_throughput": 2352.646691982438,
    "itl": 22.27666718670182,
    "ttft": 50371.34480556778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6775,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.257590747962666,
    "arrivals": 18247,
    "finished_requests": 18110,
    "scheduler_time": 0.0017775681658039454
}
#Debug simulation 
Total elapsed time: 2.138704815879464. Arrivals time: 0.05680489959195256 Scheduler time: 1.6825604103505611 Scheduler overhead time: 0.13951919740065932 Adapter cache time: 0.052635328844189644 Engine time: 0.13912955159321427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 270, 270, 270, 270, 540, 270, 33, 540, 33, 270, 270, 33, 540, 540, 33, 270, 33, 270, 33, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 33, 270, 270, 540, 270, 33, 33, 270, 540, 33, 270, 33, 540, 540, 270, 540, 540, 540, 33, 270, 540, 33, 270, 33, 270, 33, 33, 270, 540, 540, 33, 33, 33, 540, 540, 540, 270, 33, 33, 33, 33, 33, 540, 33, 270, 33, 540, 540, 33, 540, 33, 270, 270, 540, 33, 33, 33, 540, 540, 270, 540, 270, 540, 540, 270, 270, 33, 540, 270, 270, 270, 540, 270, 33, 270, 540, 540, 270, 540, 270, 33, 540, 270, 33, 270, 270, 33, 270, 540, 33, 270, 540, 33, 270, 540, 540, 270, 33, 540, 270, 33, 33, 270, 540, 540, 540, 33, 540, 33, 540, 33, 270, 33, 540, 540, 270, 540, 33, 540, 540, 540, 33, 540, 540, 540, 270, 270, 270, 270, 270, 270, 33, 540, 270, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 53952 . Total input tokens: 11959790 . Total output tokens: 10819341
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 2.120036080945283,
    "estimated_duration": 3599.632734118367,
    "input_throughput": 1252.9608804951185,
    "output_throughput": 1099.423272404841,
    "total_throughput": 2352.3841528999596,
    "itl": 22.288199697877243,
    "ttft": 50679.69112291296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.571037348320775,
    "arrivals": 18247,
    "finished_requests": 18109,
    "scheduler_time": 0.00130532595399246
}
#Debug simulation 
Total elapsed time: 2.1201348211616278. Arrivals time: 0.06122135743498802 Scheduler time: 1.6593934297561646 Scheduler overhead time: 0.13934988202527165 Adapter cache time: 0.052357029635459185 Engine time: 0.1400102605111897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.8932725060731173,
    "estimated_duration": 3600.0187783002384,
    "input_throughput": 1097.2981651682232,
    "output_throughput": 986.1259672862537,
    "total_throughput": 2083.424132454477,
    "itl": 22.00619016480402,
    "ttft": 47866.15694148418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.64148832961487,
    "arrivals": 16073,
    "finished_requests": 15938,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8933710842393339. Arrivals time: 0.056049864273518324 Scheduler time: 1.4333406803198159 Scheduler overhead time: 0.14019184466451406 Adapter cache time: 0.05458481656387448 Engine time: 0.14090078277513385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.9023613967001438,
    "estimated_duration": 3600.0151898072218,
    "input_throughput": 1097.2992589543867,
    "output_throughput": 986.1269502560359,
    "total_throughput": 2083.4262092104227,
    "itl": 22.01386708372607,
    "ttft": 47874.98859576065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.09347992831193,
    "arrivals": 16073,
    "finished_requests": 15938,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.9024581178091466. Arrivals time: 0.05570650612935424 Scheduler time: 1.442675728816539 Scheduler overhead time: 0.1404617284424603 Adapter cache time: 0.05511195678263903 Engine time: 0.1399060534313321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8911201967857778,
    "estimated_duration": 3600.001649315084,
    "input_throughput": 1097.3033861669371,
    "output_throughput": 986.1306593221747,
    "total_throughput": 2083.4340454891117,
    "itl": 22.017280597320458,
    "ttft": 47872.25822572317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.145557210948358,
    "arrivals": 16073,
    "finished_requests": 15938,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8912281156517565. Arrivals time: 0.055492434184998274 Scheduler time: 1.425328356679529 Scheduler overhead time: 0.1436179936863482 Adapter cache time: 0.055233560502529144 Engine time: 0.14201280241832137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.9398692976683378,
    "estimated_duration": 3600.004736658173,
    "input_throughput": 1097.302445125946,
    "output_throughput": 986.1298136222663,
    "total_throughput": 2083.432258748212,
    "itl": 22.009030089674813,
    "ttft": 47863.66845406514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.128228956969828,
    "arrivals": 16073,
    "finished_requests": 15938,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.939973069820553. Arrivals time: 0.056741037871688604 Scheduler time: 1.4767794962972403 Scheduler overhead time: 0.1399234072305262 Adapter cache time: 0.05532274302095175 Engine time: 0.14292892487719655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.892762128263712,
    "estimated_duration": 3600.0061238843873,
    "input_throughput": 1097.302022291466,
    "output_throughput": 986.1294336270438,
    "total_throughput": 2083.4314559185095,
    "itl": 22.01929877228313,
    "ttft": 47842.35139672904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7404,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.45402750521804,
    "arrivals": 16073,
    "finished_requests": 15938,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8928899383172393. Arrivals time: 0.05642603849992156 Scheduler time: 1.4348094915039837 Scheduler overhead time: 0.13947076722979546 Adapter cache time: 0.05468859197571874 Engine time: 0.13913869066163898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.9051085249520838,
    "estimated_duration": 3599.9974096979463,
    "input_throughput": 1097.3046784307116,
    "output_throughput": 986.1318206609112,
    "total_throughput": 2083.436499091623,
    "itl": 22.00278214023203,
    "ttft": 47858.48792094759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.123382131981003,
    "arrivals": 16073,
    "finished_requests": 15938,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.9052093429490924. Arrivals time: 0.05687024537473917 Scheduler time: 1.443246693816036 Scheduler overhead time: 0.14175630221143365 Adapter cache time: 0.05479454807937145 Engine time: 0.14014720916748047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_192_slots_16_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [64 64 64]
Adapter prompts. [540, 66, 540, 66, 540, 66, 540, 66, 66, 66, 135, 135, 135, 135, 540, 135, 66, 540, 66, 135, 135, 66, 540, 540, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 66, 135, 135, 540, 135, 66, 66, 135, 540, 66, 135, 66, 540, 540, 135, 540, 540, 540, 66, 135, 540, 66, 135, 66, 135, 66, 66, 135, 540, 540, 66, 66, 66, 540, 540, 540, 135, 66, 66, 66, 66, 66, 540, 66, 135, 66, 540, 540, 66, 540, 66, 135, 135, 540, 66, 66, 66, 540, 540, 135, 540, 135, 540, 540, 135, 135, 66, 540, 135, 135, 135, 540, 135, 66, 135, 540, 540, 135, 540, 135, 66, 540, 135, 66, 135, 135, 66, 135, 540, 66, 135, 540, 66, 135, 540, 540, 135, 66, 540, 135, 66, 66, 135, 540, 540, 540, 66, 540, 66, 540, 66, 135, 66, 540, 540, 135, 540, 66, 540, 540, 540, 66, 540, 540, 540, 135, 135, 135, 135, 135, 135, 66, 540, 135, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 47424 . Total input tokens: 10486917 . Total output tokens: 9511922
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.8988416530191898,
    "estimated_duration": 3600.0082614836924,
    "input_throughput": 1097.3013707396167,
    "output_throughput": 986.1288480868342,
    "total_throughput": 2083.430218826451,
    "itl": 22.019782364715187,
    "ttft": 47847.504377702026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7404,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.75986071377792,
    "arrivals": 16073,
    "finished_requests": 15938,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.8989385217428207. Arrivals time: 0.056712884455919266 Scheduler time: 1.4387163142673671 Scheduler overhead time: 0.13999340077862144 Adapter cache time: 0.05540289217606187 Engine time: 0.13956713071092963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.8057242250069976,
    "estimated_duration": 3599.9925340387335,
    "input_throughput": 1034.7596459653992,
    "output_throughput": 940.5508394767046,
    "total_throughput": 1975.3104854421038,
    "itl": 21.956353569462276,
    "ttft": 31593.9910147507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.76162684389462,
    "arrivals": 15374,
    "finished_requests": 15296,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.805842636153102. Arrivals time: 0.05248545203357935 Scheduler time: 1.3424637890420854 Scheduler overhead time: 0.14238998759537935 Adapter cache time: 0.056560683995485306 Engine time: 0.14219478610903025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7904522521421313,
    "estimated_duration": 3600.000725081227,
    "input_throughput": 1034.7572915880316,
    "output_throughput": 940.5486994516098,
    "total_throughput": 1975.3059910396412,
    "itl": 21.96157118370647,
    "ttft": 31610.419717618497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.267105828023148,
    "arrivals": 15374,
    "finished_requests": 15296,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7905326578766108. Arrivals time: 0.05050407536327839 Scheduler time: 1.3335609077475965 Scheduler overhead time: 0.1401831661351025 Adapter cache time: 0.0565142622217536 Engine time: 0.14122424041852355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7851560516282916,
    "estimated_duration": 3599.9958940599445,
    "input_throughput": 1034.7586801825314,
    "output_throughput": 940.5499616227115,
    "total_throughput": 1975.3086418052428,
    "itl": 21.96355904531261,
    "ttft": 31605.818836453695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.321867604684325,
    "arrivals": 15374,
    "finished_requests": 15296,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7852568179368973. Arrivals time: 0.053942215628921986 Scheduler time: 1.3263704599812627 Scheduler overhead time: 0.13998204190284014 Adapter cache time: 0.05611746804788709 Engine time: 0.14041530899703503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.7876419289968908,
    "estimated_duration": 3599.995187836354,
    "input_throughput": 1034.7588831747444,
    "output_throughput": 940.5501461336723,
    "total_throughput": 1975.3090293084167,
    "itl": 21.957873238225684,
    "ttft": 31597.036844574817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.263614672055446,
    "arrivals": 15374,
    "finished_requests": 15296,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7877383138984442. Arrivals time: 0.05402486817911267 Scheduler time: 1.328041995409876 Scheduler overhead time: 0.14224779093638062 Adapter cache time: 0.05602764105424285 Engine time: 0.138688076287508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.7853648280724883,
    "estimated_duration": 3599.9867301785107,
    "input_throughput": 1034.6315914934796,
    "output_throughput": 940.5090223296766,
    "total_throughput": 1975.140613823156,
    "itl": 21.965810813701285,
    "ttft": 31867.85906764482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.60187791868958,
    "arrivals": 15374,
    "finished_requests": 15295,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7854624460451305. Arrivals time: 0.05460535688325763 Scheduler time: 1.3251235717907548 Scheduler overhead time: 0.14128648163750768 Adapter cache time: 0.056245462503284216 Engine time: 0.13925361772999167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.7838455713354051,
    "estimated_duration": 3600.005109306936,
    "input_throughput": 1034.7560314205089,
    "output_throughput": 940.5475540149607,
    "total_throughput": 1975.3035854354696,
    "itl": 21.953656325559887,
    "ttft": 31557.88638993883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.22970074109444,
    "arrivals": 15374,
    "finished_requests": 15296,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7839482203125954. Arrivals time: 0.054815417155623436 Scheduler time: 1.3219929444603622 Scheduler overhead time: 0.14095205953344703 Adapter cache time: 0.05644196877256036 Engine time: 0.14107875572517514 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 135, 135, 135, 135, 540, 135, 33, 540, 33, 135, 135, 33, 540, 540, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 33, 135, 135, 540, 135, 33, 33, 135, 540, 33, 135, 33, 540, 540, 135, 540, 540, 540, 33, 135, 540, 33, 135, 33, 135, 33, 33, 135, 540, 540, 33, 33, 33, 540, 540, 540, 135, 33, 33, 33, 33, 33, 540, 33, 135, 33, 540, 540, 33, 540, 33, 135, 135, 540, 33, 33, 33, 540, 540, 135, 540, 135, 540, 540, 135, 135, 33, 540, 135, 135, 135, 540, 135, 33, 135, 540, 540, 135, 540, 135, 33, 540, 135, 33, 135, 135, 33, 135, 540, 33, 135, 540, 33, 135, 540, 540, 135, 33, 540, 135, 33, 33, 135, 540, 540, 540, 33, 540, 33, 540, 33, 135, 33, 540, 540, 135, 540, 33, 540, 540, 540, 33, 540, 540, 540, 135, 135, 135, 135, 135, 135, 33, 540, 135, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 45312 . Total input tokens: 10004990 . Total output tokens: 9089958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.7678826828487217,
    "estimated_duration": 3600.0052805062837,
    "input_throughput": 1034.7559822123706,
    "output_throughput": 940.5475092869353,
    "total_throughput": 1975.303491499306,
    "itl": 21.96815669613321,
    "ttft": 31631.903579922047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.9212671082073,
    "arrivals": 15374,
    "finished_requests": 15296,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.767977678682655. Arrivals time: 0.05135721154510975 Scheduler time: 1.31299241585657 Scheduler overhead time: 0.1404897030442953 Adapter cache time: 0.05564259039238095 Engine time: 0.1387237529270351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.6127706193365157,
    "estimated_duration": 3599.9102009870635,
    "input_throughput": 933.9210736640488,
    "output_throughput": 851.8970831992208,
    "total_throughput": 1785.8181568632695,
    "itl": 21.67676901191091,
    "ttft": 18482.032184117368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8433,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.8090931445863,
    "arrivals": 13872,
    "finished_requests": 13827,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6128540229983628. Arrivals time: 0.04668580833822489 Scheduler time: 1.1450162730179727 Scheduler overhead time: 0.15002429531887174 Adapter cache time: 0.058553495444357395 Engine time: 0.1411105957813561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.571777714882046,
    "estimated_duration": 3599.912825750099,
    "input_throughput": 933.9203927249175,
    "output_throughput": 851.8964620652984,
    "total_throughput": 1785.816854790216,
    "itl": 21.687003684891412,
    "ttft": 18480.123024704586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8436,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.434156365235577,
    "arrivals": 13872,
    "finished_requests": 13827,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5719042005948722. Arrivals time: 0.04818465048447251 Scheduler time: 1.1170676071196795 Scheduler overhead time: 0.13986484287306666 Adapter cache time: 0.05844750348478556 Engine time: 0.139204453676939 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5588000752031803,
    "estimated_duration": 3599.9116503301416,
    "input_throughput": 933.9206976625868,
    "output_throughput": 851.8967402210423,
    "total_throughput": 1785.817437883629,
    "itl": 21.688103065250573,
    "ttft": 18480.39702037335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.496253187265825,
    "arrivals": 13872,
    "finished_requests": 13827,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5588933029212058. Arrivals time: 0.04653506353497505 Scheduler time: 1.1086154063232243 Scheduler overhead time: 0.1413084277883172 Adapter cache time: 0.057587023824453354 Engine time: 0.13581731170415878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.5975731029175222,
    "estimated_duration": 3599.912500937409,
    "input_throughput": 933.920476990631,
    "output_throughput": 851.8965389301615,
    "total_throughput": 1785.8170159207923,
    "itl": 21.68156073396424,
    "ttft": 18489.851560224502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.37238490791775,
    "arrivals": 13872,
    "finished_requests": 13827,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.597661754116416. Arrivals time: 0.04754605842754245 Scheduler time: 1.1405708189122379 Scheduler overhead time: 0.14121923688799143 Adapter cache time: 0.05827078316360712 Engine time: 0.1411695471033454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5965767572633922,
    "estimated_duration": 3599.90030598271,
    "input_throughput": 933.9236407221072,
    "output_throughput": 851.8994247988848,
    "total_throughput": 1785.8230655209918,
    "itl": 21.688755055957763,
    "ttft": 18482.225664227353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.81809714056474,
    "arrivals": 13872,
    "finished_requests": 13827,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5966748879291117. Arrivals time: 0.04894162807613611 Scheduler time: 1.1402961304411292 Scheduler overhead time: 0.1417463286779821 Adapter cache time: 0.057902312371879816 Engine time: 0.13886576844379306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.5937842158600688,
    "estimated_duration": 3599.8968401907982,
    "input_throughput": 933.9245398548168,
    "output_throughput": 851.9002449629804,
    "total_throughput": 1785.824784817797,
    "itl": 21.671949219282023,
    "ttft": 18480.755037011837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8434,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.218084187203726,
    "arrivals": 13872,
    "finished_requests": 13827,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5938810417428613. Arrivals time: 0.049419351387768984 Scheduler time: 1.13665451714769 Scheduler overhead time: 0.14034410007297993 Adapter cache time: 0.058378728572279215 Engine time: 0.1401297291740775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [64 64 64]
Adapter prompts. [540, 33, 540, 33, 540, 33, 540, 33, 33, 33, 66, 66, 66, 66, 540, 66, 33, 540, 33, 66, 66, 33, 540, 540, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 33, 66, 66, 540, 66, 33, 33, 66, 540, 33, 66, 33, 540, 540, 66, 540, 540, 540, 33, 66, 540, 33, 66, 33, 66, 33, 33, 66, 540, 540, 33, 33, 33, 540, 540, 540, 66, 33, 33, 33, 33, 33, 540, 33, 66, 33, 540, 540, 33, 540, 33, 66, 66, 540, 33, 33, 33, 540, 540, 66, 540, 66, 540, 540, 66, 66, 33, 540, 66, 66, 66, 540, 66, 33, 66, 540, 540, 66, 540, 66, 33, 540, 66, 33, 66, 66, 33, 66, 540, 33, 66, 540, 33, 66, 540, 540, 66, 33, 540, 66, 33, 33, 66, 540, 540, 540, 33, 540, 33, 540, 33, 66, 33, 540, 540, 66, 540, 33, 540, 540, 540, 33, 540, 540, 540, 66, 66, 66, 66, 66, 66, 33, 540, 66, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 40896 . Total input tokens: 9009721 . Total output tokens: 8220936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.5875902813859284,
    "estimated_duration": 3599.908570636039,
    "input_throughput": 933.9214966245628,
    "output_throughput": 851.8974690121534,
    "total_throughput": 1785.818965636716,
    "itl": 21.693085150449566,
    "ttft": 18506.964220229464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.16242933746191,
    "arrivals": 13872,
    "finished_requests": 13827,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.58769939141348. Arrivals time: 0.04792133625596762 Scheduler time: 1.131668227724731 Scheduler overhead time: 0.1403602883219719 Adapter cache time: 0.05830298410728574 Engine time: 0.14048514980822802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.2499681669287384,
    "estimated_duration": 3599.233711344102,
    "input_throughput": 696.3598924127717,
    "output_throughput": 615.3754320035174,
    "total_throughput": 1311.7353244162891,
    "itl": 20.829611279825496,
    "ttft": 5150.610137559432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.373002381736445,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.250048064161092. Arrivals time: 0.04051580000668764 Scheduler time: 0.792187824845314 Scheduler overhead time: 0.14320177771151066 Adapter cache time: 0.05928001692518592 Engine time: 0.14385221153497696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.2522210679017007,
    "estimated_duration": 3599.231665921911,
    "input_throughput": 696.3602881500037,
    "output_throughput": 615.3757817177568,
    "total_throughput": 1311.7360698677605,
    "itl": 20.843575708956873,
    "ttft": 5153.516141956557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.12049611253997,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2523149531334639. Arrivals time: 0.04070564266294241 Scheduler time: 0.7942932778969407 Scheduler overhead time: 0.14332074206322432 Adapter cache time: 0.05953484680503607 Engine time: 0.14381445292383432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.2424679738469422,
    "estimated_duration": 3599.241820606501,
    "input_throughput": 696.3583234809319,
    "output_throughput": 615.374045533505,
    "total_throughput": 1311.732369014437,
    "itl": 20.844638743094638,
    "ttft": 5153.688727491093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.18603648651496,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.242738293018192. Arrivals time: 0.039430342614650726 Scheduler time: 0.7859811061061919 Scheduler overhead time: 0.14260640367865562 Adapter cache time: 0.05910435505211353 Engine time: 0.14152017049491405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.2278085290454328,
    "estimated_duration": 3599.2250734122,
    "input_throughput": 696.3615636362177,
    "output_throughput": 615.3769088689446,
    "total_throughput": 1311.7384725051625,
    "itl": 20.836122956610787,
    "ttft": 5151.543762440822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8944,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.95367776614109,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2279580468311906. Arrivals time: 0.0380185442045331 Scheduler time: 0.7788694524206221 Scheduler overhead time: 0.1422049910761416 Adapter cache time: 0.05877355160191655 Engine time: 0.13936872174963355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.2316355360671878,
    "estimated_duration": 3599.2328710519296,
    "input_throughput": 696.3600549879059,
    "output_throughput": 615.3755756716758,
    "total_throughput": 1311.7356306595818,
    "itl": 20.84512534724278,
    "ttft": 5154.455719495199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.53977104561338,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2317302310839295. Arrivals time: 0.03982473025098443 Scheduler time: 0.7801697258837521 Scheduler overhead time: 0.14244738966226578 Adapter cache time: 0.05848156940191984 Engine time: 0.1404103017412126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.2417624206282198,
    "estimated_duration": 3599.224402473796,
    "input_throughput": 696.3616934463278,
    "output_throughput": 615.3770235825482,
    "total_throughput": 1311.738717028876,
    "itl": 20.827992892328336,
    "ttft": 5149.34691737811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8942,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.737029737013525,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2418777579441667. Arrivals time: 0.03941177297383547 Scheduler time: 0.7876004073768854 Scheduler overhead time: 0.14480079244822264 Adapter cache time: 0.05840594368055463 Engine time: 0.14061758061870933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [64 64 64]
Adapter prompts. [270, 66, 270, 66, 270, 66, 270, 66, 66, 66, 135, 135, 135, 135, 270, 135, 66, 270, 66, 135, 135, 66, 270, 270, 66, 135, 66, 135, 66, 66, 135, 66, 66, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 66, 135, 135, 270, 135, 66, 66, 135, 270, 66, 135, 66, 270, 270, 135, 270, 270, 270, 66, 135, 270, 66, 135, 66, 135, 66, 66, 135, 270, 270, 66, 66, 66, 270, 270, 270, 135, 66, 66, 66, 66, 66, 270, 66, 135, 66, 270, 270, 66, 270, 66, 135, 135, 270, 66, 66, 66, 270, 270, 135, 270, 135, 270, 270, 135, 135, 66, 270, 135, 135, 135, 270, 135, 66, 135, 270, 270, 135, 270, 135, 66, 270, 135, 66, 135, 135, 66, 135, 270, 66, 135, 270, 66, 135, 270, 270, 135, 66, 270, 135, 66, 66, 135, 270, 270, 270, 66, 270, 66, 270, 66, 135, 66, 270, 270, 135, 270, 66, 270, 270, 270, 66, 270, 270, 270, 135, 135, 135, 135, 135, 135, 66, 270, 135, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 30144 . Total input tokens: 6607829 . Total output tokens: 6040768
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.250681693200022,
    "estimated_duration": 3599.2324845986927,
    "input_throughput": 696.3601297567902,
    "output_throughput": 615.3756417451747,
    "total_throughput": 1311.7357715019648,
    "itl": 20.849464649556943,
    "ttft": 5154.918982403995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8943,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.915634527315664,
    "arrivals": 10170,
    "finished_requests": 10157,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2507438999600708. Arrivals time: 0.0385378310456872 Scheduler time: 0.7963043977506459 Scheduler overhead time: 0.1426610262133181 Adapter cache time: 0.0595377036370337 Engine time: 0.14330005319789052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1873191627673805,
    "estimated_duration": 3599.768871846768,
    "input_throughput": 641.2272793546887,
    "output_throughput": 572.6464874236369,
    "total_throughput": 1213.8737667783257,
    "itl": 20.616869213509055,
    "ttft": 5224.330746827656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.249023887446423,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1874399539083242. Arrivals time: 0.04041963303461671 Scheduler time: 0.7344973818399012 Scheduler overhead time: 0.14382368698716164 Adapter cache time: 0.055804342962801456 Engine time: 0.14183501014485955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1810829099267721,
    "estimated_duration": 3599.768947266938,
    "input_throughput": 641.2272659200846,
    "output_throughput": 572.6464754258959,
    "total_throughput": 1213.8737413459805,
    "itl": 20.626444428656463,
    "ttft": 5225.972306932104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8249,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.839469167384774,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1811657208018005. Arrivals time: 0.03839685022830963 Scheduler time: 0.730967232491821 Scheduler overhead time: 0.1427653105929494 Adapter cache time: 0.0559231243096292 Engine time: 0.14229999156668782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.1863959128968418,
    "estimated_duration": 3599.7777259151594,
    "input_throughput": 641.225702182258,
    "output_throughput": 572.6450789335718,
    "total_throughput": 1213.8707811158297,
    "itl": 20.628578801353974,
    "ttft": 5226.013574783104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.903861668222095,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1864829449914396. Arrivals time: 0.03790341969579458 Scheduler time: 0.7343468191102147 Scheduler overhead time: 0.14355135802179575 Adapter cache time: 0.05614542309194803 Engine time: 0.1431457158178091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.1776239471510053,
    "estimated_duration": 3599.7807054571676,
    "input_throughput": 641.2251714391176,
    "output_throughput": 572.6446049546803,
    "total_throughput": 1213.8697763937978,
    "itl": 20.61984586490765,
    "ttft": 5224.898059739251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.769617794522002,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1777216531336308. Arrivals time: 0.036915825214236975 Scheduler time: 0.7250238922424614 Scheduler overhead time: 0.14694755198433995 Adapter cache time: 0.05544550949707627 Engine time: 0.14152361592277884 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.1916063730604947,
    "estimated_duration": 3599.770399787285,
    "input_throughput": 641.2270071825689,
    "output_throughput": 572.6462443609765,
    "total_throughput": 1213.8732515435454,
    "itl": 20.62987959846955,
    "ttft": 5226.377203000604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8251,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.238603661767257,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1917056497186422. Arrivals time: 0.03852232871577144 Scheduler time: 0.738240844104439 Scheduler overhead time: 0.1423215833492577 Adapter cache time: 0.05668717110529542 Engine time: 0.1448409166187048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.1776509787887335,
    "estimated_duration": 3599.7724128640107,
    "input_throughput": 641.2266485934648,
    "output_throughput": 572.6459241238354,
    "total_throughput": 1213.8725727173003,
    "itl": 20.612968438640788,
    "ttft": 5223.906467015887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8250,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.66791493294191,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1777457599528134. Arrivals time: 0.03780083078891039 Scheduler time: 0.7287340047769248 Scheduler overhead time: 0.14406941691413522 Adapter cache time: 0.05535390740260482 Engine time: 0.14048066176474094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 135, 135, 135, 135, 270, 135, 33, 270, 33, 135, 135, 33, 270, 270, 33, 135, 33, 135, 33, 33, 135, 33, 33, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 33, 135, 135, 270, 135, 33, 33, 135, 270, 33, 135, 33, 270, 270, 135, 270, 270, 270, 33, 135, 270, 33, 135, 33, 135, 33, 33, 135, 270, 270, 33, 33, 33, 270, 270, 270, 135, 33, 33, 33, 33, 33, 270, 33, 135, 33, 270, 270, 33, 270, 33, 135, 135, 270, 33, 33, 33, 270, 270, 135, 270, 135, 270, 270, 135, 135, 33, 270, 135, 135, 135, 270, 135, 33, 135, 270, 270, 135, 270, 135, 33, 270, 135, 33, 135, 135, 33, 135, 270, 33, 135, 270, 33, 135, 270, 270, 135, 33, 270, 135, 33, 33, 135, 270, 270, 270, 33, 270, 33, 270, 33, 135, 33, 270, 270, 135, 270, 33, 270, 270, 270, 33, 270, 270, 270, 135, 135, 135, 135, 135, 135, 33, 270, 135, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 28032 . Total input tokens: 6152033 . Total output tokens: 5608060
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.175876713823527,
    "estimated_duration": 3599.7697326827133,
    "input_throughput": 641.2271260139107,
    "output_throughput": 572.6463504830222,
    "total_throughput": 1213.8734764969329,
    "itl": 20.63162901538076,
    "ttft": 5226.583452562886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.580136359778724,
    "arrivals": 9452,
    "finished_requests": 9439,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.175970482174307. Arrivals time: 0.03720319317653775 Scheduler time: 0.7302064690738916 Scheduler overhead time: 0.1424526427872479 Adapter cache time: 0.05547935236245394 Engine time: 0.13980814814567566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.0869089062325656,
    "estimated_duration": 3598.8104180215005,
    "input_throughput": 543.7202221604522,
    "output_throughput": 487.030934228425,
    "total_throughput": 1030.7511563888772,
    "itl": 19.916231683673185,
    "ttft": 6355.528461171792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.071458116976856,
    "arrivals": 8047,
    "finished_requests": 8033,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0869644889608026. Arrivals time: 0.03303378680720925 Scheduler time: 0.6357806795276701 Scheduler overhead time: 0.1457821079529822 Adapter cache time: 0.05076653603464365 Engine time: 0.14907428622245789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.075951256789267,
    "estimated_duration": 3598.797140453933,
    "input_throughput": 543.7222281868287,
    "output_throughput": 487.0327311027372,
    "total_throughput": 1030.754959289566,
    "itl": 19.92524861000421,
    "ttft": 6356.0780521138695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.420810547944804,
    "arrivals": 8047,
    "finished_requests": 8033,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0762837789952755. Arrivals time: 0.03403560956940055 Scheduler time: 0.6319747730158269 Scheduler overhead time: 0.14444949198514223 Adapter cache time: 0.05049588903784752 Engine time: 0.14259492279961705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0824644910171628,
    "estimated_duration": 3598.8127540883165,
    "input_throughput": 543.7198692199535,
    "output_throughput": 487.0306180861632,
    "total_throughput": 1030.7504873061166,
    "itl": 19.92447932203974,
    "ttft": 6356.19071863215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.4695513105949,
    "arrivals": 8047,
    "finished_requests": 8033,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0825839331373572. Arrivals time: 0.03412667661905289 Scheduler time: 0.6356445793062449 Scheduler overhead time: 0.14453131007030606 Adapter cache time: 0.050579851027578115 Engine time: 0.14351704623550177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 1.075060567818582,
    "estimated_duration": 3598.8044666296414,
    "input_throughput": 543.7211213179735,
    "output_throughput": 487.0317396381003,
    "total_throughput": 1030.7528609560738,
    "itl": 19.918655632411383,
    "ttft": 6355.586086140236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.537984893982742,
    "arrivals": 8047,
    "finished_requests": 8033,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0751240607351065. Arrivals time: 0.03258819133043289 Scheduler time: 0.6319560669362545 Scheduler overhead time: 0.14465305721387267 Adapter cache time: 0.05040552141144872 Engine time: 0.1430653459392488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 1.072226065210998,
    "estimated_duration": 3598.8142914710706,
    "input_throughput": 543.7196369474652,
    "output_throughput": 487.03041003083933,
    "total_throughput": 1030.7500469783047,
    "itl": 19.9269296735027,
    "ttft": 6356.006309527516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.73591241611069,
    "arrivals": 8047,
    "finished_requests": 8033,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0723786130547523. Arrivals time: 0.03290623985230923 Scheduler time: 0.6308552171103656 Scheduler overhead time: 0.14439647225663066 Adapter cache time: 0.05011070752516389 Engine time: 0.14166807103902102 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 1.0817821598611772,
    "estimated_duration": 3598.7997870846107,
    "input_throughput": 543.7218283224255,
    "output_throughput": 487.032372928945,
    "total_throughput": 1030.7542012513704,
    "itl": 19.912582164048075,
    "ttft": 6355.4989408089305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.589486330696698,
    "arrivals": 8047,
    "finished_requests": 8033,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0818666638806462. Arrivals time: 0.032825314439833164 Scheduler time: 0.6332853003405035 Scheduler overhead time: 0.14553679386153817 Adapter cache time: 0.05068177776411176 Engine time: 0.14679957553744316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [64 64 64]
Adapter prompts. [270, 33, 270, 33, 270, 33, 270, 33, 33, 33, 66, 66, 66, 66, 270, 66, 33, 270, 33, 66, 66, 33, 270, 270, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 33, 66, 66, 270, 66, 33, 33, 66, 270, 33, 66, 33, 270, 270, 66, 270, 270, 270, 33, 66, 270, 33, 66, 33, 66, 33, 33, 66, 270, 270, 33, 33, 33, 270, 270, 270, 66, 33, 33, 33, 33, 33, 270, 33, 66, 33, 270, 270, 33, 270, 33, 66, 66, 270, 33, 33, 33, 270, 270, 66, 270, 66, 270, 270, 66, 66, 33, 270, 66, 66, 66, 270, 66, 33, 66, 270, 270, 66, 270, 66, 33, 270, 66, 33, 66, 66, 33, 66, 270, 33, 66, 270, 33, 66, 270, 270, 66, 33, 270, 66, 33, 33, 66, 270, 270, 270, 33, 270, 33, 270, 33, 66, 33, 270, 270, 66, 270, 33, 270, 270, 270, 33, 270, 270, 270, 66, 66, 66, 66, 66, 66, 33, 270, 66, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 23616 . Total input tokens: 5190960 . Total output tokens: 4735188
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 1.0804808381944895,
    "estimated_duration": 3598.8074335924434,
    "input_throughput": 543.7206730582732,
    "output_throughput": 487.0313381147953,
    "total_throughput": 1030.7520111730685,
    "itl": 19.929479297647553,
    "ttft": 6356.402209791206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.03284253381009,
    "arrivals": 8047,
    "finished_requests": 8033,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0805553360842168. Arrivals time: 0.0347773302346468 Scheduler time: 0.6343962955288589 Scheduler overhead time: 0.14498812099918723 Adapter cache time: 0.050291466526687145 Engine time: 0.14376923441886902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 0.8892594086937606,
    "estimated_duration": 3599.942414428684,
    "input_throughput": 340.3234993675398,
    "output_throughput": 312.1602710909869,
    "total_throughput": 652.4837704585267,
    "itl": 19.013969099115986,
    "ttft": 7825.838797515488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.876251430989846,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8893210329115391. Arrivals time: 0.026527983136475086 Scheduler time: 0.45093671698123217 Scheduler overhead time: 0.14795879507437348 Adapter cache time: 0.04080140171572566 Engine time: 0.14818784454837441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.9086962859146297,
    "estimated_duration": 3599.9398996021228,
    "input_throughput": 340.3237371088909,
    "output_throughput": 312.1604891582222,
    "total_throughput": 652.4842262671132,
    "itl": 19.018038769974616,
    "ttft": 7825.905631050911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.753533841733306,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9087726292200387. Arrivals time: 0.026774662546813488 Scheduler time: 0.4604021762497723 Scheduler overhead time: 0.1518120588734746 Adapter cache time: 0.041746378876268864 Engine time: 0.1521388180553913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8899453887715936,
    "estimated_duration": 3599.9420811240984,
    "input_throughput": 340.3235308767642,
    "output_throughput": 312.16029999268795,
    "total_throughput": 652.4838308694522,
    "itl": 19.018181542681777,
    "ttft": 7825.844562320191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.786429585403475,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8900232138112187. Arrivals time: 0.026462897192686796 Scheduler time: 0.45217091171070933 Scheduler overhead time: 0.14771802257746458 Adapter cache time: 0.04059324460104108 Engine time: 0.14840597845613956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 0.899325517937541,
    "estimated_duration": 3599.9294542159946,
    "input_throughput": 340.32472457625323,
    "output_throughput": 312.1613949084278,
    "total_throughput": 652.486119484681,
    "itl": 19.016533432314684,
    "ttft": 7825.777415137701,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.163930797224062,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8993937629275024. Arrivals time: 0.02686307020485401 Scheduler time: 0.4566366239450872 Scheduler overhead time: 0.14898105012252927 Adapter cache time: 0.040969496592879295 Engine time: 0.15070879785344005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 0.9054351272061467,
    "estimated_duration": 3599.9304921850903,
    "input_throughput": 340.3246264503179,
    "output_throughput": 312.1613049028342,
    "total_throughput": 652.4859313531522,
    "itl": 19.020958504738523,
    "ttft": 7825.804643508508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.970935818048906,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9055315000005066. Arrivals time: 0.02682429738342762 Scheduler time: 0.46017293399199843 Scheduler overhead time: 0.15048570884391665 Adapter cache time: 0.04086236655712128 Engine time: 0.15173406107351184 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 0.8914222200401127,
    "estimated_duration": 3599.9488172017564,
    "input_throughput": 340.32289407722925,
    "output_throughput": 312.15971589104396,
    "total_throughput": 652.4826099682732,
    "itl": 19.0116967090767,
    "ttft": 7825.634995999569,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.556888037087669,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8916539717465639. Arrivals time: 0.02651816187426448 Scheduler time: 0.4527768213301897 Scheduler overhead time: 0.14778558118268847 Adapter cache time: 0.041066829580813646 Engine time: 0.14860343467444181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_192_slots_16_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [64 64 64]
Adapter prompts. [135, 33, 135, 33, 135, 33, 135, 33, 33, 33, 66, 66, 66, 66, 135, 66, 33, 135, 33, 66, 66, 33, 135, 135, 33, 66, 33, 66, 33, 33, 66, 33, 33, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 33, 66, 66, 135, 66, 33, 33, 66, 135, 33, 66, 33, 135, 135, 66, 135, 135, 135, 33, 66, 135, 33, 66, 33, 66, 33, 33, 66, 135, 135, 33, 33, 33, 135, 135, 135, 66, 33, 33, 33, 33, 33, 135, 33, 66, 33, 135, 135, 33, 135, 33, 66, 66, 135, 33, 33, 33, 135, 135, 66, 135, 66, 135, 135, 66, 66, 33, 135, 66, 66, 66, 135, 66, 33, 66, 135, 135, 66, 135, 66, 33, 135, 66, 33, 66, 66, 33, 66, 135, 33, 66, 135, 33, 66, 135, 135, 66, 33, 135, 66, 33, 33, 66, 135, 135, 135, 33, 135, 33, 135, 33, 66, 33, 135, 135, 66, 135, 33, 135, 135, 135, 33, 135, 135, 135, 66, 66, 66, 66, 66, 66, 33, 135, 66, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 14976 . Total input tokens: 3282180 . Total output tokens: 3038664
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 0.8897988721728325,
    "estimated_duration": 3599.936978717205,
    "input_throughput": 340.3240132377445,
    "output_throughput": 312.1607424362296,
    "total_throughput": 652.4847556739741,
    "itl": 19.02144275959326,
    "ttft": 7825.897323030968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.158686221166391,
    "arrivals": 5084,
    "finished_requests": 5073,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8898932179436088. Arrivals time: 0.026267658919095993 Scheduler time: 0.4523650393821299 Scheduler overhead time: 0.14782016817480326 Adapter cache time: 0.04079923825338483 Engine time: 0.1480752588249743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 105.04089093068615,
    "estimated_duration": 3600.1430905265215,
    "input_throughput": 7443.448031417236,
    "output_throughput": 6582.039214595333,
    "total_throughput": 14025.487246012568,
    "itl": 123.33228925591037,
    "ttft": 2005222.6393102005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.224195097573108,
    "arrivals": 1289329,
    "finished_requests": 108375,
    "scheduler_time": 217.7987296592075
}
#Debug simulation 
Total elapsed time: 105.04106759605929. Arrivals time: 0.7397171105258167 Scheduler time: 104.09739326313138 Scheduler overhead time: 0.08020661072805524 Adapter cache time: 0.018450985196977854 Engine time: 0.07701712753623724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.52144858334213,
    "estimated_duration": 3600.0245670780414,
    "input_throughput": 7470.5995747770085,
    "output_throughput": 6613.919032037495,
    "total_throughput": 14084.518606814503,
    "itl": 123.92920208612132,
    "ttft": 2002377.705872108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2374208679702192,
    "arrivals": 1289329,
    "finished_requests": 108818,
    "scheduler_time": 216.63967201197335
}
#Debug simulation 
Total elapsed time: 107.52162900334224. Arrivals time: 0.7388957221992314 Scheduler time: 106.57089866744354 Scheduler overhead time: 0.0832135402597487 Adapter cache time: 0.019254176411777735 Engine time: 0.08020931854844093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.68743218109012,
    "estimated_duration": 3600.026644353635,
    "input_throughput": 7470.595264116088,
    "output_throughput": 6613.915215695578,
    "total_throughput": 14084.510479811666,
    "itl": 123.92926427777682,
    "ttft": 2002378.6818184478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2394917547889124,
    "arrivals": 1289329,
    "finished_requests": 108818,
    "scheduler_time": 216.63967840073286
}
#Debug simulation 
Total elapsed time: 107.68761700810865. Arrivals time: 0.7632868094369769 Scheduler time: 106.71019974630326 Scheduler overhead time: 0.08377180527895689 Adapter cache time: 0.019244006369262934 Engine time: 0.0823720833286643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 105.02644556807354,
    "estimated_duration": 3600.1132975836026,
    "input_throughput": 7450.746069020651,
    "output_throughput": 6592.519467631796,
    "total_throughput": 14043.265536652447,
    "itl": 123.03114321627318,
    "ttft": 2004523.131516123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2200541970459748,
    "arrivals": 1289329,
    "finished_requests": 108525,
    "scheduler_time": 217.87924857763574
}
#Debug simulation 
Total elapsed time: 105.02660834603012. Arrivals time: 0.6089855651371181 Scheduler time: 104.21847156621516 Scheduler overhead time: 0.07817812729626894 Adapter cache time: 0.017875445540994406 Engine time: 0.07432032562792301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 109.17424014909193,
    "estimated_duration": 3600.041671767336,
    "input_throughput": 7470.564080108829,
    "output_throughput": 6613.887607670674,
    "total_throughput": 14084.451687779503,
    "itl": 123.92944886816467,
    "ttft": 2002384.8843686427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2557139932364274,
    "arrivals": 1289329,
    "finished_requests": 108818,
    "scheduler_time": 216.63972773134168
}
#Debug simulation 
Total elapsed time: 109.17442198796198. Arrivals time: 0.7457580333575606 Scheduler time: 108.21795384865254 Scheduler overhead time: 0.08290067501366138 Adapter cache time: 0.019594074226915836 Engine time: 0.07911422848701477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 106.34567470801994,
    "estimated_duration": 3600.1137521096334,
    "input_throughput": 7443.508690328722,
    "output_throughput": 6582.092853625582,
    "total_throughput": 14025.601543954304,
    "itl": 123.33143678968818,
    "ttft": 2005209.960025623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1960201179608647,
    "arrivals": 1289329,
    "finished_requests": 108375,
    "scheduler_time": 217.7982448520645
}
#Debug simulation 
Total elapsed time: 106.34585396992043. Arrivals time: 0.7409198568202555 Scheduler time: 105.39674232294783 Scheduler overhead time: 0.08172368770465255 Adapter cache time: 0.018877402879297733 Engine time: 0.07922948198392987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 110.21189106209204,
    "estimated_duration": 3600.0575461709686,
    "input_throughput": 7470.531138760517,
    "output_throughput": 6613.858443825341,
    "total_throughput": 14084.389582585858,
    "itl": 123.92986051680508,
    "ttft": 2002391.8255578403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 379,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2715589703246974,
    "arrivals": 1289329,
    "finished_requests": 108818,
    "scheduler_time": 216.63987026293105
}
#Debug simulation 
Total elapsed time: 110.2120658531785. Arrivals time: 0.7596195046789944 Scheduler time: 109.23629370564595 Scheduler overhead time: 0.08580386266112328 Adapter cache time: 0.019862523768097162 Engine time: 0.08171911910176277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 111.19048094702885,
    "estimated_duration": 3600.096227410153,
    "input_throughput": 7501.385878073443,
    "output_throughput": 6595.465093187591,
    "total_throughput": 14096.850971261034,
    "itl": 122.97040224449884,
    "ttft": 1994055.9214486722,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2333765608049065,
    "arrivals": 1197398,
    "finished_requests": 108505,
    "scheduler_time": 217.0680033147508
}
#Debug simulation 
Total elapsed time: 111.19064845889807. Arrivals time: 0.7402931451797485 Scheduler time: 110.23885020148009 Scheduler overhead time: 0.0838011559098959 Adapter cache time: 0.019327987916767597 Engine time: 0.07983628055080771 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 110.90938173793256,
    "estimated_duration": 3600.036903312371,
    "input_throughput": 7501.46810304982,
    "output_throughput": 6595.34183612223,
    "total_throughput": 14096.80993917205,
    "itl": 122.97264290123593,
    "ttft": 1994058.2719223765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.314493814187596,
    "arrivals": 1197398,
    "finished_requests": 108503,
    "scheduler_time": 217.0611291884918
}
#Debug simulation 
Total elapsed time: 110.90954849403352. Arrivals time: 0.6923085893504322 Scheduler time: 110.0033098300919 Scheduler overhead time: 0.08422658778727055 Adapter cache time: 0.01975073665380478 Engine time: 0.08129846258088946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 111.18987058568746,
    "estimated_duration": 3600.0391113212045,
    "input_throughput": 7501.463502180962,
    "output_throughput": 6595.337791007001,
    "total_throughput": 14096.801293187962,
    "itl": 122.97268659072735,
    "ttft": 1994059.1884814324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3169204245880322,
    "arrivals": 1197398,
    "finished_requests": 108503,
    "scheduler_time": 217.06113679697057
}
#Debug simulation 
Total elapsed time: 111.1900346558541. Arrivals time: 0.7790886759757996 Scheduler time: 110.19354001618922 Scheduler overhead time: 0.08527384232729673 Adapter cache time: 0.020449189003556967 Engine time: 0.08261556318029761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 109.61871036328375,
    "estimated_duration": 3600.1223062175936,
    "input_throughput": 7501.331539031263,
    "output_throughput": 6595.417316515157,
    "total_throughput": 14096.748855546419,
    "itl": 122.97105558709353,
    "ttft": 1994066.8076969618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2589248508797015,
    "arrivals": 1197398,
    "finished_requests": 108505,
    "scheduler_time": 217.06819451697802
}
#Debug simulation 
Total elapsed time: 109.61888422211632. Arrivals time: 0.7368397801183164 Scheduler time: 108.67182057490572 Scheduler overhead time: 0.0819872859865427 Adapter cache time: 0.020187258254736662 Engine time: 0.07938770297914743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 110.50703851692379,
    "estimated_duration": 3600.0572629294165,
    "input_throughput": 7501.425679552996,
    "output_throughput": 6595.304537094948,
    "total_throughput": 14096.730216647944,
    "itl": 122.97318911242513,
    "ttft": 1994066.8127176156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3340229395404501,
    "arrivals": 1197398,
    "finished_requests": 108503,
    "scheduler_time": 217.06128104999485
}
#Debug simulation 
Total elapsed time: 110.50721435714513. Arrivals time: 0.7807326540350914 Scheduler time: 109.51010662643239 Scheduler overhead time: 0.08514224551618099 Adapter cache time: 0.020491044968366623 Engine time: 0.08139141369611025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 110.0286879609339,
    "estimated_duration": 3600.067537964245,
    "input_throughput": 7501.4456576753855,
    "output_throughput": 6595.517653379042,
    "total_throughput": 14096.963311054427,
    "itl": 122.96965679101478,
    "ttft": 1994044.1182592697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.204990268845571,
    "arrivals": 1197398,
    "finished_requests": 108505,
    "scheduler_time": 217.06781326577217
}
#Debug simulation 
Total elapsed time: 110.02885983511806. Arrivals time: 0.7509687854908407 Scheduler time: 109.0637329495512 Scheduler overhead time: 0.0844167759642005 Adapter cache time: 0.019914086908102036 Engine time: 0.08022979600355029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.24354668706656,
    "estimated_duration": 3600.0735603026715,
    "input_throughput": 7501.39172093182,
    "output_throughput": 6595.274680443974,
    "total_throughput": 14096.666401375793,
    "itl": 122.97367105757363,
    "ttft": 1994073.2924620037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3506224393472088,
    "arrivals": 1197398,
    "finished_requests": 108503,
    "scheduler_time": 217.06143134358268
}
#Debug simulation 
Total elapsed time: 105.24371692165732. Arrivals time: 0.6154433996416628 Scheduler time: 104.42923214612529 Scheduler overhead time: 0.07816673861816525 Adapter cache time: 0.017886499408632517 Engine time: 0.07490664627403021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 113.93645503697917,
    "estimated_duration": 3600.0621045257876,
    "input_throughput": 7441.336905361185,
    "output_throughput": 6590.387696415933,
    "total_throughput": 14031.724601777118,
    "itl": 124.26106841375255,
    "ttft": 1988744.6855187025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0405658329371363,
    "arrivals": 1127741,
    "finished_requests": 108749,
    "scheduler_time": 217.17092198534363
}
#Debug simulation 
Total elapsed time: 113.93663710076362. Arrivals time: 0.7358556152321398 Scheduler time: 112.98724174825475 Scheduler overhead time: 0.08485887385904789 Adapter cache time: 0.019296918995678425 Engine time: 0.08067609602585435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 111.37125089904293,
    "estimated_duration": 3600.0075387788415,
    "input_throughput": 7421.153625990018,
    "output_throughput": 6577.175115592056,
    "total_throughput": 13998.328741582074,
    "itl": 123.83253037990261,
    "ttft": 1990132.9982314324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1085510469158233,
    "arrivals": 1127741,
    "finished_requests": 108507,
    "scheduler_time": 218.08435876723308
}
#Debug simulation 
Total elapsed time: 111.3714352780953. Arrivals time: 0.7437565578147769 Scheduler time: 110.41503595886752 Scheduler overhead time: 0.08439230686053634 Adapter cache time: 0.019031439907848835 Engine time: 0.07984840823337436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 111.39221650455147,
    "estimated_duration": 3600.0102929243294,
    "input_throughput": 7421.147948523813,
    "output_throughput": 6577.170083801674,
    "total_throughput": 13998.318032325487,
    "itl": 123.83257872484036,
    "ttft": 1990134.424702682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 340,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1106770948506952,
    "arrivals": 1127741,
    "finished_requests": 108507,
    "scheduler_time": 218.08442133962222
}
#Debug simulation 
Total elapsed time: 111.3924008179456. Arrivals time: 0.9081653580069542 Scheduler time: 110.26907411823049 Scheduler overhead time: 0.08583473693579435 Adapter cache time: 0.01920923264697194 Engine time: 0.08115380816161633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 109.54967953357846,
    "estimated_duration": 3600.087997595998,
    "input_throughput": 7399.354409611116,
    "output_throughput": 6546.043878854268,
    "total_throughput": 13945.398288465383,
    "itl": 122.9136972421812,
    "ttft": 1987136.3626961973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1088649116293545,
    "arrivals": 1127741,
    "finished_requests": 108062,
    "scheduler_time": 219.4136618428959
}
#Debug simulation 
Total elapsed time: 109.54984509199858. Arrivals time: 0.6842279131524265 Scheduler time: 108.65731364348903 Scheduler overhead time: 0.08210928039625287 Adapter cache time: 0.018865318968892097 Engine time: 0.07850993378087878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 118.26199226127937,
    "estimated_duration": 3600.1268722367086,
    "input_throughput": 7402.642169508445,
    "output_throughput": 6552.154920402774,
    "total_throughput": 13954.797089911219,
    "itl": 122.7877899723123,
    "ttft": 1986837.6011654467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1439486345835082,
    "arrivals": 1127741,
    "finished_requests": 108060,
    "scheduler_time": 219.98809138978777
}
#Debug simulation 
Total elapsed time: 118.26217798702419. Arrivals time: 0.8975066379643977 Scheduler time: 117.1275223265402 Scheduler overhead time: 0.09443053416907787 Adapter cache time: 0.021889984607696533 Engine time: 0.09023051848635077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 117.90956272324547,
    "estimated_duration": 3600.063054880144,
    "input_throughput": 7428.77377210005,
    "output_throughput": 6568.364953481976,
    "total_throughput": 13997.138725582026,
    "itl": 123.65929549850988,
    "ttft": 1991112.990842153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0285773014463488,
    "arrivals": 1127741,
    "finished_requests": 108453,
    "scheduler_time": 218.4505665889751
}
#Debug simulation 
Total elapsed time: 117.90974298492074. Arrivals time: 0.9657572880387306 Scheduler time: 116.71520363772288 Scheduler overhead time: 0.09129247162491083 Adapter cache time: 0.02110647363588214 Engine time: 0.0860575195401907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.27101873932406,
    "estimated_duration": 3600.0208977772236,
    "input_throughput": 7409.226989895824,
    "output_throughput": 6555.468612577039,
    "total_throughput": 13964.695602472862,
    "itl": 123.38974220026984,
    "ttft": 1991661.486837908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 357,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.19534153003246,
    "arrivals": 1127741,
    "finished_requests": 108247,
    "scheduler_time": 218.96725141064718
}
#Debug simulation 
Total elapsed time: 108.27120464714244. Arrivals time: 0.8863615244626999 Scheduler time: 107.17450016457587 Scheduler overhead time: 0.08354877633973956 Adapter cache time: 0.019419866614043713 Engine time: 0.07852373691275716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 113.3344194511883,
    "estimated_duration": 3600.134929900441,
    "input_throughput": 7503.366269871176,
    "output_throughput": 6587.80364119738,
    "total_throughput": 14091.169911068557,
    "itl": 124.00460999738249,
    "ttft": 1986316.8298888428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0191424187296063,
    "arrivals": 1116016,
    "finished_requests": 108741,
    "scheduler_time": 217.59336594098153
}
#Debug simulation 
Total elapsed time: 113.33459368906915. Arrivals time: 0.7339396276511252 Scheduler time: 112.38328868895769 Scheduler overhead time: 0.0867851641960442 Adapter cache time: 0.01909745391458273 Engine time: 0.0818501440808177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.53445041971281,
    "estimated_duration": 3600.073500798699,
    "input_throughput": 7474.6618351069765,
    "output_throughput": 6566.326491599541,
    "total_throughput": 14040.988326706518,
    "itl": 123.71589571630217,
    "ttft": 1986698.9794639987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0949564644624536,
    "arrivals": 1116016,
    "finished_requests": 108383,
    "scheduler_time": 218.5334326201732
}
#Debug simulation 
Total elapsed time: 108.53463158477098. Arrivals time: 0.6489475928246975 Scheduler time: 107.67579208407551 Scheduler overhead time: 0.08265364496037364 Adapter cache time: 0.018301742617040873 Engine time: 0.08044050261378288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.52889722771943,
    "estimated_duration": 3600.0757551324145,
    "input_throughput": 7474.657154543751,
    "output_throughput": 6566.3223798274,
    "total_throughput": 14040.97953437115,
    "itl": 123.71592137505827,
    "ttft": 1986700.238063221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0971540294773936,
    "arrivals": 1116016,
    "finished_requests": 108383,
    "scheduler_time": 218.5334893888651
}
#Debug simulation 
Total elapsed time: 108.52906309301034. Arrivals time: 0.7268477883189917 Scheduler time: 107.58995527401567 Scheduler overhead time: 0.08410104410722852 Adapter cache time: 0.018894311506301165 Engine time: 0.08065827377140522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 112.58095457591116,
    "estimated_duration": 3600.0150516602134,
    "input_throughput": 7503.09585165297,
    "output_throughput": 6587.659956883535,
    "total_throughput": 14090.755808536505,
    "itl": 124.00529754002277,
    "ttft": 1986255.7253319465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 333,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0394064472755442,
    "arrivals": 1116016,
    "finished_requests": 108736,
    "scheduler_time": 217.58543363673087
}
#Debug simulation 
Total elapsed time: 112.58113969210535. Arrivals time: 0.7302080322988331 Scheduler time: 111.63615673454478 Scheduler overhead time: 0.08537728432565928 Adapter cache time: 0.019390592351555824 Engine time: 0.08112033782526851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 109.15565505810082,
    "estimated_duration": 3600.0622988555237,
    "input_throughput": 7474.6850932425805,
    "output_throughput": 6566.346923361584,
    "total_throughput": 14041.032016604166,
    "itl": 123.7171378157874,
    "ttft": 1986685.864813388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1111126997694423,
    "arrivals": 1116016,
    "finished_requests": 108383,
    "scheduler_time": 218.5299297863537
}
#Debug simulation 
Total elapsed time: 109.15583893982694. Arrivals time: 0.7385534630157053 Scheduler time: 108.20427916478366 Scheduler overhead time: 0.08464873349294066 Adapter cache time: 0.019159914925694466 Engine time: 0.07994144130498171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 105.19632416591048,
    "estimated_duration": 3600.069769908883,
    "input_throughput": 7496.236107858275,
    "output_throughput": 6585.18376453577,
    "total_throughput": 14081.419872394044,
    "itl": 124.02594334524382,
    "ttft": 1986081.4897012315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9867165973177193,
    "arrivals": 1116016,
    "finished_requests": 108644,
    "scheduler_time": 217.70214394669276
}
#Debug simulation 
Total elapsed time: 105.19650327088311. Arrivals time: 0.5922643453814089 Scheduler time: 104.40611412888393 Scheduler overhead time: 0.07841994240880013 Adapter cache time: 0.01697805756703019 Engine time: 0.07446110434830189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 106.80505576264113,
    "estimated_duration": 3600.074915590578,
    "input_throughput": 7474.658897642866,
    "output_throughput": 6566.323911101743,
    "total_throughput": 14040.982808744608,
    "itl": 123.7173822041902,
    "ttft": 1986690.9338400848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1249456162750764,
    "arrivals": 1116016,
    "finished_requests": 108383,
    "scheduler_time": 218.52995776025205
}
#Debug simulation 
Total elapsed time: 106.80522308498621. Arrivals time: 0.6622240031138062 Scheduler time: 105.93707025144249 Scheduler overhead time: 0.08124488918110728 Adapter cache time: 0.018071667291224003 Engine time: 0.07809232641011477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743711985 . Total output tokens: 667230169
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 110.97755581373349,
    "estimated_duration": 3600.0056878875994,
    "input_throughput": 7468.961254829972,
    "output_throughput": 6557.263528617247,
    "total_throughput": 14026.224783447218,
    "itl": 122.7640291049025,
    "ttft": 1984758.7706622386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1293199775111893,
    "arrivals": 1110264,
    "finished_requests": 108413,
    "scheduler_time": 218.77775139593328
}
#Debug simulation 
Total elapsed time: 110.97772819874808. Arrivals time: 0.837237951811403 Scheduler time: 109.92347818613052 Scheduler overhead time: 0.08454952947795391 Adapter cache time: 0.02185526303946972 Engine time: 0.08181322691962123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743711985 . Total output tokens: 667230169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 109.76665547210723,
    "estimated_duration": 3600.0959513643234,
    "input_throughput": 7511.802286756128,
    "output_throughput": 6610.656027370862,
    "total_throughput": 14122.458314126989,
    "itl": 124.32751954758093,
    "ttft": 1985458.804900004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2497896644682682,
    "arrivals": 1110264,
    "finished_requests": 109179,
    "scheduler_time": 216.2921664124507
}
#Debug simulation 
Total elapsed time: 109.76683230232447. Arrivals time: 0.7394226491451263 Scheduler time: 108.81100347125903 Scheduler overhead time: 0.08513079024851322 Adapter cache time: 0.019690824206918478 Engine time: 0.08239409234374762 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743711985 . Total output tokens: 667230169
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 110.53493479872122,
    "estimated_duration": 3600.0981735392743,
    "input_throughput": 7511.797650066217,
    "output_throughput": 6610.651946917073,
    "total_throughput": 14122.44959698329,
    "itl": 124.32757626627959,
    "ttft": 1985459.7320090374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2520030776783895,
    "arrivals": 1110264,
    "finished_requests": 109179,
    "scheduler_time": 216.29217517417808
}
#Debug simulation 
Total elapsed time: 110.53509586770087. Arrivals time: 0.8468213244341314 Scheduler time: 109.47321428405121 Scheduler overhead time: 0.08466324117034674 Adapter cache time: 0.019463380333036184 Engine time: 0.08175610145553946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743711985 . Total output tokens: 667230169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 111.7136543202214,
    "estimated_duration": 3600.00289980322,
    "input_throughput": 7468.967039295925,
    "output_throughput": 6557.268607003161,
    "total_throughput": 14026.235646299087,
    "itl": 122.76603757293044,
    "ttft": 1984747.9731118008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 369,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.155220164260828,
    "arrivals": 1110264,
    "finished_requests": 108413,
    "scheduler_time": 218.7735970996151
}
#Debug simulation 
Total elapsed time: 111.71382145630196. Arrivals time: 0.7907752972096205 Scheduler time: 110.70988372759894 Scheduler overhead time: 0.08464151434600353 Adapter cache time: 0.019320106133818626 Engine time: 0.08061253605410457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743711985 . Total output tokens: 667230169
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 107.90197491133586,
    "estimated_duration": 3600.1141300663344,
    "input_throughput": 7511.764356065487,
    "output_throughput": 6610.622646999663,
    "total_throughput": 14122.38700306515,
    "itl": 124.3279940966938,
    "ttft": 1985466.0331874741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2680995623394893,
    "arrivals": 1110264,
    "finished_requests": 109179,
    "scheduler_time": 216.29226142665087
}
#Debug simulation 
Total elapsed time: 107.90213916730136. Arrivals time: 0.7501711151562631 Scheduler time: 106.93691161740571 Scheduler overhead time: 0.08570894366130233 Adapter cache time: 0.01957837911322713 Engine time: 0.08078200835734606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743711985 . Total output tokens: 667230169
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 108.9357054810971,
    "estimated_duration": 3600.1317272796937,
    "input_throughput": 7503.202395433183,
    "output_throughput": 6595.242562955073,
    "total_throughput": 14098.444958388256,
    "itl": 124.12065312987176,
    "ttft": 1987165.2448045062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.169109665306746,
    "arrivals": 1110264,
    "finished_requests": 108903,
    "scheduler_time": 217.09807153795546
}
#Debug simulation 
Total elapsed time: 108.93587683001533. Arrivals time: 0.9352122414857149 Scheduler time: 107.78624029643834 Scheduler overhead time: 0.08441920951008797 Adapter cache time: 0.01977267535403371 Engine time: 0.08151439111679792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 17280, 17280, 17280, 17280, 34560, 17280, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 270, 270, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 34560, 34560, 270, 17280, 34560, 270, 17280, 270, 17280, 270, 270, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 17280, 270, 270, 270, 270, 270, 34560, 270, 17280, 270, 34560, 34560, 270, 34560, 270, 17280, 17280, 34560, 270, 270, 270, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 270, 34560, 17280, 17280, 17280, 34560, 17280, 270, 17280, 34560, 34560, 17280, 34560, 17280, 270, 34560, 17280, 270, 17280, 17280, 270, 17280, 34560, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 17280, 270, 34560, 34560, 17280, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 3335040 . Total input tokens: 743711985 . Total output tokens: 667230169
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.23402143316343,
    "estimated_duration": 3600.130115828168,
    "input_throughput": 7511.73100136105,
    "output_throughput": 6610.593293660809,
    "total_throughput": 14122.32429502186,
    "itl": 124.32834404658813,
    "ttft": 1985472.5187234308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 383,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2841960470005895,
    "arrivals": 1110264,
    "finished_requests": 109179,
    "scheduler_time": 216.29237691389787
}
#Debug simulation 
Total elapsed time: 108.23418967612088. Arrivals time: 0.7291346793062985 Scheduler time: 107.29315455863252 Scheduler overhead time: 0.0835796887986362 Adapter cache time: 0.019475391134619713 Engine time: 0.080330615863204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741778155 . Total output tokens: 665499970
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 101.8479827651754,
    "estimated_duration": 3600.0487058760914,
    "input_throughput": 7450.798083986594,
    "output_throughput": 6604.194538033096,
    "total_throughput": 14054.99262201969,
    "itl": 124.95378752486572,
    "ttft": 1981076.6114433657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0619892471446664,
    "arrivals": 1107343,
    "finished_requests": 108789,
    "scheduler_time": 216.5112668219767
}
#Debug simulation 
Total elapsed time: 101.84815761307254. Arrivals time: 0.5924649951048195 Scheduler time: 101.06374441226944 Scheduler overhead time: 0.0757242701947689 Adapter cache time: 0.016362959519028664 Engine time: 0.07246708450838923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741778155 . Total output tokens: 665499970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.64334906684235,
    "estimated_duration": 3600.135771946226,
    "input_throughput": 7435.500129910055,
    "output_throughput": 6593.979367385532,
    "total_throughput": 14029.479497295586,
    "itl": 124.83348396016396,
    "ttft": 1979946.3377906359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1826339428382984,
    "arrivals": 1107343,
    "finished_requests": 108575,
    "scheduler_time": 217.14715350955768
}
#Debug simulation 
Total elapsed time: 105.64352212985978. Arrivals time: 0.6845356123521924 Scheduler time: 104.75317168841138 Scheduler overhead time: 0.08048493415117264 Adapter cache time: 0.01870181318372488 Engine time: 0.07843111082911491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741778155 . Total output tokens: 665499970
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.10439733602107,
    "estimated_duration": 3600.1388367434038,
    "input_throughput": 7435.493800070889,
    "output_throughput": 6593.973753932754,
    "total_throughput": 14029.467554003642,
    "itl": 124.83353578303462,
    "ttft": 1979947.9695894385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1850622458010978,
    "arrivals": 1107343,
    "finished_requests": 108575,
    "scheduler_time": 217.14722447860223
}
#Debug simulation 
Total elapsed time: 107.10455682594329. Arrivals time: 0.7287158644758165 Scheduler time: 106.16539503028616 Scheduler overhead time: 0.08407689724117517 Adapter cache time: 0.01875710440799594 Engine time: 0.07896160334348679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741778155 . Total output tokens: 665499970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 106.31604203395545,
    "estimated_duration": 3600.0724125480206,
    "input_throughput": 7450.749020077443,
    "output_throughput": 6604.151049054174,
    "total_throughput": 14054.900069131616,
    "itl": 124.95422349197526,
    "ttft": 1981086.9780701948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0841273186332565,
    "arrivals": 1107343,
    "finished_requests": 108789,
    "scheduler_time": 216.5115912670363
}
#Debug simulation 
Total elapsed time: 106.31621348205954. Arrivals time: 0.7171871075406671 Scheduler time: 105.39285172661766 Scheduler overhead time: 0.08157962141558528 Adapter cache time: 0.0177827225998044 Engine time: 0.07865329179912806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741778155 . Total output tokens: 665499970
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 101.83709497191012,
    "estimated_duration": 3600.0110468047733,
    "input_throughput": 7435.262740028909,
    "output_throughput": 6594.007821467479,
    "total_throughput": 14029.270561496387,
    "itl": 124.83323590879932,
    "ttft": 1979914.9100199942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2002784539572942,
    "arrivals": 1107343,
    "finished_requests": 108571,
    "scheduler_time": 217.13891660707534
}
#Debug simulation 
Total elapsed time: 101.83724993700162. Arrivals time: 0.608700358774513 Scheduler time: 101.03410882782191 Scheduler overhead time: 0.07725037960335612 Adapter cache time: 0.01653078803792596 Engine time: 0.07351417513564229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741778155 . Total output tokens: 665499970
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 102.51817885506898,
    "estimated_duration": 3600.024136085338,
    "input_throughput": 7450.848934909519,
    "output_throughput": 6604.239610974766,
    "total_throughput": 14055.088545884284,
    "itl": 124.95333030785518,
    "ttft": 1981066.4524116153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.037547452331055,
    "arrivals": 1107343,
    "finished_requests": 108789,
    "scheduler_time": 216.51102572095448
}
#Debug simulation 
Total elapsed time: 102.51833269698545. Arrivals time: 0.5399233447387815 Scheduler time: 101.79649309953675 Scheduler overhead time: 0.07112083723768592 Adapter cache time: 0.015388063620775938 Engine time: 0.06912163831293583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 17280, 17280, 17280, 17280, 34560, 17280, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 135, 135, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 34560, 34560, 135, 17280, 34560, 135, 17280, 135, 17280, 135, 135, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 17280, 135, 135, 135, 135, 135, 34560, 135, 17280, 135, 34560, 34560, 135, 34560, 135, 17280, 17280, 34560, 135, 135, 135, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 135, 34560, 17280, 17280, 17280, 34560, 17280, 135, 17280, 34560, 34560, 17280, 34560, 17280, 135, 34560, 17280, 135, 17280, 17280, 135, 17280, 34560, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 17280, 135, 34560, 34560, 17280, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 3326400 . Total input tokens: 741778155 . Total output tokens: 665499970
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 102.81086738081649,
    "estimated_duration": 3600.024598212051,
    "input_throughput": 7435.234751810813,
    "output_throughput": 6593.982999946641,
    "total_throughput": 14029.217751757455,
    "itl": 124.83345831425048,
    "ttft": 1979920.3037618927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2149916469678315,
    "arrivals": 1107343,
    "finished_requests": 108571,
    "scheduler_time": 217.13899897669774
}
#Debug simulation 
Total elapsed time: 102.81102977972478. Arrivals time: 0.5724672181531787 Scheduler time: 102.0543748093769 Scheduler overhead time: 0.07106573972851038 Adapter cache time: 0.01601092191413045 Engine time: 0.07043455308303237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740786661 . Total output tokens: 664621116
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 108.16948078619316,
    "estimated_duration": 3600.0336264591083,
    "input_throughput": 7507.800705346274,
    "output_throughput": 6619.9489984876955,
    "total_throughput": 14127.74970383397,
    "itl": 124.6552084461095,
    "ttft": 1985123.3800934905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0160819309856735,
    "arrivals": 1105914,
    "finished_requests": 109264,
    "scheduler_time": 215.85303422059707
}
#Debug simulation 
Total elapsed time: 108.1696433890611. Arrivals time: 0.5721433395519853 Scheduler time: 107.40712579805404 Scheduler overhead time: 0.07429148722440004 Adapter cache time: 0.015897095203399658 Engine time: 0.07315409276634455 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740786661 . Total output tokens: 664621116
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 102.3047462538816,
    "estimated_duration": 3600.0068774127053,
    "input_throughput": 7484.632368081738,
    "output_throughput": 6608.997651998772,
    "total_throughput": 14093.63002008051,
    "itl": 124.16435161045608,
    "ttft": 1983205.3931927169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1107239065738452,
    "arrivals": 1105914,
    "finished_requests": 109008,
    "scheduler_time": 216.6207433528846
}
#Debug simulation 
Total elapsed time: 102.30489617213607. Arrivals time: 0.518410206772387 Scheduler time: 101.60628538671881 Scheduler overhead time: 0.07001059735193849 Adapter cache time: 0.014826495666056871 Engine time: 0.0688047893345356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740786661 . Total output tokens: 664621116
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.1275502089411,
    "estimated_duration": 3600.010051617526,
    "input_throughput": 7484.625768723457,
    "output_throughput": 6608.991824706096,
    "total_throughput": 14093.617593429553,
    "itl": 124.16442646111273,
    "ttft": 1983207.1283119065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.113046118710196,
    "arrivals": 1105914,
    "finished_requests": 109008,
    "scheduler_time": 216.62080361033858
}
#Debug simulation 
Total elapsed time: 107.12770953169093. Arrivals time: 0.5756984641775489 Scheduler time: 106.36137614957988 Scheduler overhead time: 0.07398841576650739 Adapter cache time: 0.016477582044899464 Engine time: 0.07259908737614751 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740786661 . Total output tokens: 664621116
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 107.85430593276396,
    "estimated_duration": 3600.0588056060456,
    "input_throughput": 7507.748195088153,
    "output_throughput": 6619.90269794719,
    "total_throughput": 14127.650893035343,
    "itl": 124.6560858160943,
    "ttft": 1985132.285876482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.039276564209725,
    "arrivals": 1105914,
    "finished_requests": 109264,
    "scheduler_time": 215.85388768396288
}
#Debug simulation 
Total elapsed time: 107.85445813182741. Arrivals time: 0.6001310385763645 Scheduler time: 107.06365328514948 Scheduler overhead time: 0.07328275684267282 Adapter cache time: 0.015856547746807337 Engine time: 0.07469099247828126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740786661 . Total output tokens: 664621116
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 108.8746000630781,
    "estimated_duration": 3600.0238408966748,
    "input_throughput": 7484.59710013719,
    "output_throughput": 6608.966510086751,
    "total_throughput": 14093.563610223942,
    "itl": 124.16475709259213,
    "ttft": 1983212.9584049308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.126627527643,
    "arrivals": 1105914,
    "finished_requests": 109008,
    "scheduler_time": 216.62089837553208
}
#Debug simulation 
Total elapsed time: 108.87476228689775. Arrivals time: 0.5878614205867052 Scheduler time: 108.09502055635676 Scheduler overhead time: 0.07415575301274657 Adapter cache time: 0.016657827887684107 Engine time: 0.07433905964717269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740786661 . Total output tokens: 664621116
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 104.59919772529975,
    "estimated_duration": 3600.0102210705913,
    "input_throughput": 7507.849517150026,
    "output_throughput": 6619.992037942796,
    "total_throughput": 14127.841555092822,
    "itl": 124.65472608012257,
    "ttft": 1985113.7709799288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9926966979075237,
    "arrivals": 1105914,
    "finished_requests": 109264,
    "scheduler_time": 215.85278785504747
}
#Debug simulation 
Total elapsed time: 104.59933463018388. Arrivals time: 0.5414085472002625 Scheduler time: 103.87300296965986 Scheduler overhead time: 0.07168302265927196 Adapter cache time: 0.015648746863007545 Engine time: 0.07083572167903185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 17280, 17280, 17280, 17280, 34560, 17280, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 66, 66, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 34560, 34560, 66, 17280, 34560, 66, 17280, 66, 17280, 66, 66, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 17280, 66, 66, 66, 66, 66, 34560, 66, 17280, 66, 34560, 34560, 66, 34560, 66, 17280, 17280, 34560, 66, 66, 66, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 66, 34560, 17280, 17280, 17280, 34560, 17280, 66, 17280, 34560, 34560, 17280, 34560, 17280, 66, 34560, 17280, 66, 17280, 17280, 66, 17280, 34560, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 17280, 66, 34560, 34560, 17280, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 3321984 . Total input tokens: 740786661 . Total output tokens: 664621116
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.01415141997859,
    "estimated_duration": 3600.0398488651385,
    "input_throughput": 7484.56381906271,
    "output_throughput": 6608.937122598859,
    "total_throughput": 14093.500941661569,
    "itl": 124.16537131069938,
    "ttft": 1983219.5480089982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.141089213080708,
    "arrivals": 1105914,
    "finished_requests": 109008,
    "scheduler_time": 216.62142671328894
}
#Debug simulation 
Total elapsed time: 108.01429660292342. Arrivals time: 0.5414070328697562 Scheduler time: 107.28487922018394 Scheduler overhead time: 0.07246618485078216 Adapter cache time: 0.01619765628129244 Engine time: 0.07230775523930788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740314272 . Total output tokens: 664208977
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 104.7829157426022,
    "estimated_duration": 3600.037875253388,
    "input_throughput": 7440.515607940559,
    "output_throughput": 6655.32303554268,
    "total_throughput": 14095.83864348324,
    "itl": 125.84480488203548,
    "ttft": 1988405.585180028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9273277864116232,
    "arrivals": 1105156,
    "finished_requests": 108807,
    "scheduler_time": 214.21267120113592
}
#Debug simulation 
Total elapsed time: 104.78307105088606. Arrivals time: 0.5797013794071972 Scheduler time: 104.01667151181027 Scheduler overhead time: 0.07202650560066104 Adapter cache time: 0.015638697426766157 Engine time: 0.07230960810557008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740314272 . Total output tokens: 664208977
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 104.18034498998895,
    "estimated_duration": 3600.1043125029673,
    "input_throughput": 7427.346454139157,
    "output_throughput": 6638.495422757365,
    "total_throughput": 14065.841876896522,
    "itl": 125.81020750332206,
    "ttft": 1987021.3247431768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9227214410714852,
    "arrivals": 1105156,
    "finished_requests": 108574,
    "scheduler_time": 214.94594736169486
}
#Debug simulation 
Total elapsed time: 104.18050116114318. Arrivals time: 0.5761478268541396 Scheduler time: 103.41657099779695 Scheduler overhead time: 0.07369580445811152 Adapter cache time: 0.014903966803103685 Engine time: 0.07236573612317443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740314272 . Total output tokens: 664208977
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.55039121489972,
    "estimated_duration": 3600.106909342603,
    "input_throughput": 7427.341096623909,
    "output_throughput": 6638.490634258448,
    "total_throughput": 14065.831730882357,
    "itl": 125.81026672928783,
    "ttft": 1987022.6648757418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9250639020651625,
    "arrivals": 1105156,
    "finished_requests": 108574,
    "scheduler_time": 214.9459755302695
}
#Debug simulation 
Total elapsed time: 105.55052619008347. Arrivals time: 0.5848952638916671 Scheduler time: 104.77566986531019 Scheduler overhead time: 0.07360453344881535 Adapter cache time: 0.015412046574056149 Engine time: 0.07394481869414449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740314272 . Total output tokens: 664208977
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 101.5227509373799,
    "estimated_duration": 3600.05393945513,
    "input_throughput": 7440.482406786965,
    "output_throughput": 6655.293338084337,
    "total_throughput": 14095.775744871302,
    "itl": 125.84515334135004,
    "ttft": 1988413.1210108758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9435760086518742,
    "arrivals": 1105156,
    "finished_requests": 108807,
    "scheduler_time": 214.21288127947844
}
#Debug simulation 
Total elapsed time: 101.52290667919442. Arrivals time: 0.5152586246840656 Scheduler time: 100.82702034711838 Scheduler overhead time: 0.07039433717727661 Adapter cache time: 0.01467225281521678 Engine time: 0.0694623994641006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740314272 . Total output tokens: 664208977
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 106.92075941106305,
    "estimated_duration": 3600.1194356623064,
    "input_throughput": 7427.315253800974,
    "output_throughput": 6638.467536175866,
    "total_throughput": 14065.78278997684,
    "itl": 125.81053021449377,
    "ttft": 1987028.9525298432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9368847579881597,
    "arrivals": 1105156,
    "finished_requests": 108574,
    "scheduler_time": 214.94611546890073
}
#Debug simulation 
Total elapsed time: 106.92091734567657. Arrivals time: 0.6732626091688871 Scheduler time: 106.05669402703643 Scheduler overhead time: 0.07443349435925484 Adapter cache time: 0.015635596588253975 Engine time: 0.07343609211966395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740314272 . Total output tokens: 664208977
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 105.94887309707701,
    "estimated_duration": 3600.0571052086807,
    "input_throughput": 7427.443848408076,
    "output_throughput": 6638.582472878484,
    "total_throughput": 14066.02632128656,
    "itl": 125.80751914245455,
    "ttft": 1987005.6347859756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.849174283752219,
    "arrivals": 1105156,
    "finished_requests": 108574,
    "scheduler_time": 214.94849020130488
}
#Debug simulation 
Total elapsed time: 105.94901592982933. Arrivals time: 0.575061506126076 Scheduler time: 105.18310192646459 Scheduler overhead time: 0.07507833885028958 Adapter cache time: 0.015369309578090906 Engine time: 0.07355254190042615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_192_slots_32_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 17280, 17280, 17280, 17280, 34560, 17280, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 33, 33, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 34560, 34560, 33, 17280, 34560, 33, 17280, 33, 17280, 33, 33, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 17280, 33, 33, 33, 33, 33, 34560, 33, 17280, 33, 34560, 34560, 33, 34560, 33, 17280, 17280, 34560, 33, 33, 33, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 33, 34560, 17280, 17280, 17280, 34560, 17280, 33, 17280, 34560, 34560, 17280, 34560, 17280, 33, 34560, 17280, 33, 17280, 17280, 33, 17280, 34560, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 17280, 33, 34560, 34560, 17280, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 3319872 . Total input tokens: 740314272 . Total output tokens: 664208977
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 106.05222032219172,
    "estimated_duration": 3600.12957135684,
    "input_throughput": 7427.294343165085,
    "output_throughput": 6638.448846437681,
    "total_throughput": 14065.743189602767,
    "itl": 125.81069519606066,
    "ttft": 1987033.7212733908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.947699583619838,
    "arrivals": 1105156,
    "finished_requests": 108574,
    "scheduler_time": 214.94622807302628
}
#Debug simulation 
Total elapsed time: 106.05237285792828. Arrivals time: 0.6032976456917822 Scheduler time: 105.25792391970754 Scheduler overhead time: 0.07479477766901255 Adapter cache time: 0.015956758055835962 Engine time: 0.07289506308734417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678338410 . Total output tokens: 608620142
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 104.05919487215579,
    "estimated_duration": 3600.034421776785,
    "input_throughput": 7493.972512264152,
    "output_throughput": 6597.020533008824,
    "total_throughput": 14090.993045272977,
    "itl": 123.51408573665236,
    "ttft": 1971662.4892065949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2119531465973765,
    "arrivals": 1012546,
    "finished_requests": 108573,
    "scheduler_time": 216.54649068931977
}
#Debug simulation 
Total elapsed time: 104.05933409184217. Arrivals time: 0.5025784047320485 Scheduler time: 103.3759635137394 Scheduler overhead time: 0.06987187080085278 Adapter cache time: 0.015930939465761185 Engine time: 0.06871542008593678 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678338410 . Total output tokens: 608620142
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 111.26843059482053,
    "estimated_duration": 3600.030096704996,
    "input_throughput": 7470.783376121289,
    "output_throughput": 6580.860538272711,
    "total_throughput": 14051.643914393999,
    "itl": 122.69373121227989,
    "ttft": 1974514.5314336126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1221456293691936,
    "arrivals": 1012546,
    "finished_requests": 108225,
    "scheduler_time": 217.76407811756363
}
#Debug simulation 
Total elapsed time: 111.26857763715088. Arrivals time: 0.5580439483746886 Scheduler time: 110.52083744620904 Scheduler overhead time: 0.07357740309089422 Adapter cache time: 0.01607475522905588 Engine time: 0.0727583090774715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678338410 . Total output tokens: 608620142
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 116.86508049722761,
    "estimated_duration": 3600.0321570770097,
    "input_throughput": 7470.779100439207,
    "output_throughput": 6580.856771911665,
    "total_throughput": 14051.635872350873,
    "itl": 122.69378185490822,
    "ttft": 1974515.3814764353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1242001602239968,
    "arrivals": 1012546,
    "finished_requests": 108225,
    "scheduler_time": 217.7640839587152
}
#Debug simulation 
Total elapsed time: 116.86522314324975. Arrivals time: 0.6183767090551555 Scheduler time: 116.04659089446068 Scheduler overhead time: 0.07884552935138345 Adapter cache time: 0.017502709291875362 Engine time: 0.07637424441054463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678338410 . Total output tokens: 608620142
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 108.44313151109964,
    "estimated_duration": 3600.059728898312,
    "input_throughput": 7493.919832340104,
    "output_throughput": 6596.974158333703,
    "total_throughput": 14090.893990673807,
    "itl": 123.51460759153777,
    "ttft": 1971673.138997894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2375859034969463,
    "arrivals": 1012546,
    "finished_requests": 108573,
    "scheduler_time": 216.5467305790608
}
#Debug simulation 
Total elapsed time: 108.4432828957215. Arrivals time: 0.6220652996562421 Scheduler time: 107.6283820499666 Scheduler overhead time: 0.07511720480397344 Adapter cache time: 0.017690347973257303 Engine time: 0.0735132284462452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678338410 . Total output tokens: 608620142
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 115.55626299092546,
    "estimated_duration": 3600.0462908983286,
    "input_throughput": 7470.749770078321,
    "output_throughput": 6580.830935395626,
    "total_throughput": 14051.580705473947,
    "itl": 122.69404648006368,
    "ttft": 1974521.697637995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1386618456617048,
    "arrivals": 1012546,
    "finished_requests": 108225,
    "scheduler_time": 217.76420851472886
}
#Debug simulation 
Total elapsed time: 115.55640372214839. Arrivals time: 0.6282901717349887 Scheduler time: 114.7307793283835 Scheduler overhead time: 0.07729894062504172 Adapter cache time: 0.017284048721194267 Engine time: 0.07580082304775715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678338410 . Total output tokens: 608620142
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 106.91089400136843,
    "estimated_duration": 3600.0052392746584,
    "input_throughput": 7494.033260194848,
    "output_throughput": 6597.074010032588,
    "total_throughput": 14091.107270227436,
    "itl": 123.51339262763177,
    "ttft": 1971650.0744902382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 396,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1840599167812564,
    "arrivals": 1012546,
    "finished_requests": 108573,
    "scheduler_time": 216.54621936223234
}
#Debug simulation 
Total elapsed time: 106.91104977810755. Arrivals time: 0.5388905997388065 Scheduler time: 106.18319764733315 Scheduler overhead time: 0.0735016530379653 Adapter cache time: 0.016560350079089403 Engine time: 0.07209015032276511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 8640, 34560, 8640, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 34560, 4320, 8640, 4320, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 4320, 34560, 4320, 8640, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 4320, 34560, 8640, 8640, 8640, 34560, 8640, 4320, 8640, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 8640, 4320, 8640, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 8640, 4320, 34560, 34560, 8640, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 3041280 . Total input tokens: 678338410 . Total output tokens: 608620142
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 114.6871679527685,
    "estimated_duration": 3600.0653821959963,
    "input_throughput": 7470.710152379052,
    "output_throughput": 6580.79603697325,
    "total_throughput": 14051.506189352302,
    "itl": 122.69559390011098,
    "ttft": 1974511.6977242962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1529977773129982,
    "arrivals": 1012546,
    "finished_requests": 108225,
    "scheduler_time": 217.76500520466732
}
#Debug simulation 
Total elapsed time: 114.68730282085016. Arrivals time: 0.6170507688075304 Scheduler time: 113.87220613472164 Scheduler overhead time: 0.07726815855130553 Adapter cache time: 0.016913109924644232 Engine time: 0.07584261056035757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 632185017 . Total output tokens: 567029397
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 110.5028021177277,
    "estimated_duration": 3600.0126101498336,
    "input_throughput": 7474.719095186735,
    "output_throughput": 6623.670687366718,
    "total_throughput": 14098.389782553453,
    "itl": 124.3611544779415,
    "ttft": 1962511.5288235203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9579326638509507,
    "arrivals": 943308,
    "finished_requests": 108742,
    "scheduler_time": 215.3889495037203
}
#Debug simulation 
Total elapsed time: 110.50295430794358. Arrivals time: 0.5916465758346021 Scheduler time: 109.72017615567893 Scheduler overhead time: 0.0739847356453538 Adapter cache time: 0.0163278691470623 Engine time: 0.07390432199463248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 632185017 . Total output tokens: 567029397
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 110.4176558139734,
    "estimated_duration": 3600.080103800917,
    "input_throughput": 7384.82262434408,
    "output_throughput": 6553.689451268034,
    "total_throughput": 13938.512075612114,
    "itl": 122.39597150263008,
    "ttft": 1962337.53271882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9996645042230433,
    "arrivals": 943308,
    "finished_requests": 107449,
    "scheduler_time": 218.91768437166078
}
#Debug simulation 
Total elapsed time: 110.41780733782798. Arrivals time: 0.5756066865287721 Scheduler time: 109.64734077546746 Scheduler overhead time: 0.07578016351908445 Adapter cache time: 0.016277711372822523 Engine time: 0.07514799712225795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 632185017 . Total output tokens: 567029397
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 106.27312081307173,
    "estimated_duration": 3600.083202709129,
    "input_throughput": 7384.81626757781,
    "output_throughput": 6553.683809931177,
    "total_throughput": 13938.500077508987,
    "itl": 122.39606096934871,
    "ttft": 1962339.0906623662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0018097854778223,
    "arrivals": 943308,
    "finished_requests": 107449,
    "scheduler_time": 218.91773315836394
}
#Debug simulation 
Total elapsed time: 106.27325805928558. Arrivals time: 0.5053737438283861 Scheduler time: 105.58418387547135 Scheduler overhead time: 0.07166296243667603 Adapter cache time: 0.014905286021530628 Engine time: 0.0703408820554614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 632185017 . Total output tokens: 567029397
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 112.47683209413663,
    "estimated_duration": 3600.0319436030795,
    "input_throughput": 7474.678953283991,
    "output_throughput": 6623.635115896921,
    "total_throughput": 14098.314069180911,
    "itl": 124.36144842620021,
    "ttft": 1962520.123386405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9767452741484192,
    "arrivals": 943308,
    "finished_requests": 108742,
    "scheduler_time": 215.38913103154022
}
#Debug simulation 
Total elapsed time: 112.47698865784332. Arrivals time: 0.6091247764416039 Scheduler time: 111.66881908010691 Scheduler overhead time: 0.07727708155289292 Adapter cache time: 0.016840494703501463 Engine time: 0.077050706371665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 632185017 . Total output tokens: 567029397
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 111.74731799727306,
    "estimated_duration": 3600.0108529140707,
    "input_throughput": 7464.441108072797,
    "output_throughput": 6615.540056142288,
    "total_throughput": 14079.981164215085,
    "itl": 124.0174502945584,
    "ttft": 1964286.63954909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0218612056598122,
    "arrivals": 943308,
    "finished_requests": 108639,
    "scheduler_time": 215.69275507527692
}
#Debug simulation 
Total elapsed time: 111.74746632529423. Arrivals time: 0.6107093207538128 Scheduler time: 110.938612007536 Scheduler overhead time: 0.07741766702383757 Adapter cache time: 0.017057348042726517 Engine time: 0.0762517862021923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 632185017 . Total output tokens: 567029397
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 111.49224796099588,
    "estimated_duration": 3600.1313248712254,
    "input_throughput": 7474.52816904187,
    "output_throughput": 6623.581710829104,
    "total_throughput": 14098.109879870974,
    "itl": 124.3608004549438,
    "ttft": 1962530.372691753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9358857423043823,
    "arrivals": 943308,
    "finished_requests": 108744,
    "scheduler_time": 215.3970487619283
}
#Debug simulation 
Total elapsed time: 111.49240063177422. Arrivals time: 0.6193944620899856 Scheduler time: 110.6768664191477 Scheduler overhead time: 0.07598580652847886 Adapter cache time: 0.017122605815529823 Engine time: 0.07548895617946982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 8640, 34560, 8640, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 34560, 1080, 8640, 1080, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 1080, 34560, 1080, 8640, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 1080, 34560, 8640, 8640, 8640, 34560, 8640, 1080, 8640, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 8640, 1080, 8640, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 8640, 1080, 34560, 34560, 8640, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2833920 . Total input tokens: 632185017 . Total output tokens: 567029397
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 104.02132132090628,
    "estimated_duration": 3600.0244870603906,
    "input_throughput": 7464.412838464456,
    "output_throughput": 6615.515001523512,
    "total_throughput": 14079.92783998797,
    "itl": 124.0177014354429,
    "ttft": 1964292.92603574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.034436584301298,
    "arrivals": 943308,
    "finished_requests": 108639,
    "scheduler_time": 215.6929090027085
}
#Debug simulation 
Total elapsed time: 104.02146674087271. Arrivals time: 0.5480273156426847 Scheduler time: 103.28822875069454 Scheduler overhead time: 0.07199574960395694 Adapter cache time: 0.0151946977712214 Engine time: 0.07135600270703435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624454548 . Total output tokens: 560131340
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 109.79798448877409,
    "estimated_duration": 3600.092228564253,
    "input_throughput": 7543.010921925701,
    "output_throughput": 6640.084887362311,
    "total_throughput": 14183.095809288012,
    "itl": 125.1262322909126,
    "ttft": 1957739.3799044434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9579326638509507,
    "arrivals": 932003,
    "finished_requests": 109648,
    "scheduler_time": 214.5321941619743
}
#Debug simulation 
Total elapsed time: 109.79813872789964. Arrivals time: 0.6031859214417636 Scheduler time: 108.99946383666247 Scheduler overhead time: 0.07694362942129374 Adapter cache time: 0.01618174323812127 Engine time: 0.07536276988685131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624454548 . Total output tokens: 560131340
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.43972696410492,
    "estimated_duration": 3600.1270158992284,
    "input_throughput": 7545.117680581394,
    "output_throughput": 6638.344395754773,
    "total_throughput": 14183.462076336167,
    "itl": 124.83503419055504,
    "ttft": 1956969.1843612173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0558070983761048,
    "arrivals": 932003,
    "finished_requests": 109660,
    "scheduler_time": 214.89323516911568
}
#Debug simulation 
Total elapsed time: 108.43986740428954. Arrivals time: 0.6373145594261587 Scheduler time: 107.6020831214264 Scheduler overhead time: 0.07757982285693288 Adapter cache time: 0.016791169997304678 Engine time: 0.07879176968708634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624454548 . Total output tokens: 560131340
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 104.72652459098026,
    "estimated_duration": 3600.1291630682235,
    "input_throughput": 7545.113180564307,
    "output_throughput": 6638.340436550362,
    "total_throughput": 14183.453617114668,
    "itl": 124.83508677825594,
    "ttft": 1956970.2166215216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0579338233359215,
    "arrivals": 932003,
    "finished_requests": 109660,
    "scheduler_time": 214.8932556131462
}
#Debug simulation 
Total elapsed time: 104.72673717467114. Arrivals time: 0.6030053282156587 Scheduler time: 103.93353099841624 Scheduler overhead time: 0.0739496354945004 Adapter cache time: 0.016289451625198126 Engine time: 0.07304454129189253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624454548 . Total output tokens: 560131340
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 108.14216246409342,
    "estimated_duration": 3600.1139730036307,
    "input_throughput": 7542.965362661482,
    "output_throughput": 6640.044781708885,
    "total_throughput": 14183.010144370368,
    "itl": 125.12682265382833,
    "ttft": 1957748.3809900635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9796054413775018,
    "arrivals": 932003,
    "finished_requests": 109648,
    "scheduler_time": 214.53226582379142
}
#Debug simulation 
Total elapsed time: 108.14230036502704. Arrivals time: 0.6081236968748271 Scheduler time: 107.34020781889558 Scheduler overhead time: 0.07498258305713534 Adapter cache time: 0.016840401105582714 Engine time: 0.0743057020008564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624454548 . Total output tokens: 560131340
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 106.96757619315758,
    "estimated_duration": 3600.142388793305,
    "input_throughput": 7545.085462329343,
    "output_throughput": 6638.316049496704,
    "total_throughput": 14183.401511826047,
    "itl": 124.83531537361708,
    "ttft": 1956976.017295719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0711379709094815,
    "arrivals": 932003,
    "finished_requests": 109660,
    "scheduler_time": 214.89339029568816
}
#Debug simulation 
Total elapsed time: 106.96771339187399. Arrivals time: 0.6751700574532151 Scheduler time: 106.10040996130556 Scheduler overhead time: 0.07497792784124613 Adapter cache time: 0.01627467293292284 Engine time: 0.07373073417693377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624454548 . Total output tokens: 560131340
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 113.50794476503506,
    "estimated_duration": 3600.1269788889326,
    "input_throughput": 7533.988984013772,
    "output_throughput": 6632.003298774924,
    "total_throughput": 14165.992282788695,
    "itl": 124.74871098762036,
    "ttft": 1958047.3501066838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9089752896502626,
    "arrivals": 932003,
    "finished_requests": 109461,
    "scheduler_time": 215.28102464445226
}
#Debug simulation 
Total elapsed time: 113.50808986509219. Arrivals time: 0.6232152604497969 Scheduler time: 112.68750922754407 Scheduler overhead time: 0.07720719510689378 Adapter cache time: 0.016403577756136656 Engine time: 0.07639746880158782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 8640, 8640, 8640, 8640, 34560, 8640, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 540, 540, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 34560, 34560, 540, 8640, 34560, 540, 8640, 540, 8640, 540, 540, 8640, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 8640, 540, 540, 540, 540, 540, 34560, 540, 8640, 540, 34560, 34560, 540, 34560, 540, 8640, 8640, 34560, 540, 540, 540, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 540, 34560, 8640, 8640, 8640, 34560, 8640, 540, 8640, 34560, 34560, 8640, 34560, 8640, 540, 34560, 8640, 540, 8640, 8640, 540, 8640, 34560, 540, 8640, 34560, 540, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 8640, 540, 34560, 34560, 8640, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 540, 34560, 8640, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2799360 . Total input tokens: 624454548 . Total output tokens: 560131340
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 112.4110539611429,
    "estimated_duration": 3600.0303570612496,
    "input_throughput": 7534.910628404596,
    "output_throughput": 6624.401084069597,
    "total_throughput": 14159.311712474193,
    "itl": 124.62957414414089,
    "ttft": 1957914.1455197695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 303,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.016175471208995,
    "arrivals": 932003,
    "finished_requests": 109491,
    "scheduler_time": 215.28835764187244
}
#Debug simulation 
Total elapsed time: 112.41120899328962. Arrivals time: 0.7254916271194816 Scheduler time: 111.48715406982228 Scheduler overhead time: 0.07652815198525786 Adapter cache time: 0.01709654927253723 Engine time: 0.07700465153902769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620620174 . Total output tokens: 556713099
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 104.53279043221846,
    "estimated_duration": 3600.1165647145544,
    "input_throughput": 7498.287212303181,
    "output_throughput": 6631.014182701274,
    "total_throughput": 14129.301395004455,
    "itl": 125.00640368943911,
    "ttft": 1952389.4869278616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9854770535463454,
    "arrivals": 926191,
    "finished_requests": 109292,
    "scheduler_time": 214.92918379973398
}
#Debug simulation 
Total elapsed time: 104.53298757923767. Arrivals time: 0.6226050993427634 Scheduler time: 103.71886029280722 Scheduler overhead time: 0.0737608247436583 Adapter cache time: 0.016465538181364536 Engine time: 0.07398571399971843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620620174 . Total output tokens: 556713099
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 104.18239560397342,
    "estimated_duration": 3600.0703809255056,
    "input_throughput": 7503.288586556929,
    "output_throughput": 6627.185436820961,
    "total_throughput": 14130.47402337789,
    "itl": 124.93068251174984,
    "ttft": 1956431.407363319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.124318489027215,
    "arrivals": 926191,
    "finished_requests": 109204,
    "scheduler_time": 215.17935745324337
}
#Debug simulation 
Total elapsed time: 104.18256047880277. Arrivals time: 0.5062279850244522 Scheduler time: 103.49533692514524 Scheduler overhead time: 0.07000544667243958 Adapter cache time: 0.01515077706426382 Engine time: 0.06898229382932186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620620174 . Total output tokens: 556713099
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.89588973205537,
    "estimated_duration": 3600.072339705386,
    "input_throughput": 7503.284504058208,
    "output_throughput": 6627.181831005223,
    "total_throughput": 14130.466335063431,
    "itl": 124.93057119240484,
    "ttft": 1956432.2853505826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1265691840834977,
    "arrivals": 926191,
    "finished_requests": 109204,
    "scheduler_time": 215.17939410182007
}
#Debug simulation 
Total elapsed time: 108.89604482008144. Arrivals time: 0.6320311119779944 Scheduler time: 108.07162075582892 Scheduler overhead time: 0.07369789713993669 Adapter cache time: 0.0172317111864686 Engine time: 0.07468839874491096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620620174 . Total output tokens: 556713099
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 106.5468889111653,
    "estimated_duration": 3600.1358107687092,
    "input_throughput": 7509.768914586356,
    "output_throughput": 6641.073075211279,
    "total_throughput": 14150.841989797635,
    "itl": 125.49438462542653,
    "ttft": 1953366.5682719972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0069244893500615,
    "arrivals": 926191,
    "finished_requests": 109459,
    "scheduler_time": 214.4005902630437
}
#Debug simulation 
Total elapsed time: 106.54703018208966. Arrivals time: 0.5901424502953887 Scheduler time: 105.76310442155227 Scheduler overhead time: 0.07545927166938782 Adapter cache time: 0.01633446989580989 Engine time: 0.07500119879841805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620620174 . Total output tokens: 556713099
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 107.74700869899243,
    "estimated_duration": 3600.130756393001,
    "input_throughput": 7506.026260855656,
    "output_throughput": 6634.329866376859,
    "total_throughput": 14140.356127232515,
    "itl": 125.1940803747272,
    "ttft": 1953336.7590537195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0919255841150932,
    "arrivals": 926191,
    "finished_requests": 109316,
    "scheduler_time": 214.80970432413446
}
#Debug simulation 
Total elapsed time: 107.74714646674693. Arrivals time: 0.6031031017191708 Scheduler time: 106.94866083841771 Scheduler overhead time: 0.07622941862791777 Adapter cache time: 0.016485178377479315 Engine time: 0.07513199979439378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620620174 . Total output tokens: 556713099
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 100.2309640608728,
    "estimated_duration": 3600.093625657809,
    "input_throughput": 7498.334989848362,
    "output_throughput": 6631.05643416094,
    "total_throughput": 14129.391424009302,
    "itl": 125.00553663720059,
    "ttft": 1952379.7741749017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 322,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9627961949585019,
    "arrivals": 926191,
    "finished_requests": 109292,
    "scheduler_time": 214.92844126391788
}
#Debug simulation 
Total elapsed time: 100.23114981688559. Arrivals time: 0.4993136031553149 Scheduler time: 99.55342249013484 Scheduler overhead time: 0.06914450135082006 Adapter cache time: 0.014833578374236822 Engine time: 0.06827751826494932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [64 64 64]
Adapter prompts. [34560, 270, 34560, 270, 34560, 270, 34560, 270, 270, 270, 8640, 8640, 8640, 8640, 34560, 8640, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 270, 270, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 34560, 34560, 270, 8640, 34560, 270, 8640, 270, 8640, 270, 270, 8640, 34560, 34560, 270, 270, 270, 34560, 34560, 34560, 8640, 270, 270, 270, 270, 270, 34560, 270, 8640, 270, 34560, 34560, 270, 34560, 270, 8640, 8640, 34560, 270, 270, 270, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 270, 34560, 8640, 8640, 8640, 34560, 8640, 270, 8640, 34560, 34560, 8640, 34560, 8640, 270, 34560, 8640, 270, 8640, 8640, 270, 8640, 34560, 270, 8640, 34560, 270, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 34560, 34560, 270, 34560, 270, 34560, 270, 8640, 270, 34560, 34560, 8640, 34560, 270, 34560, 34560, 34560, 270, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 270, 34560, 8640, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2782080 . Total input tokens: 620620174 . Total output tokens: 556713099
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 103.74632623326033,
    "estimated_duration": 3600.0062433892454,
    "input_throughput": 7505.97364924579,
    "output_throughput": 6634.352660876097,
    "total_throughput": 14140.326310121885,
    "itl": 125.19436628322181,
    "ttft": 1953317.6821971238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.105758500620727,
    "arrivals": 926191,
    "finished_requests": 109313,
    "scheduler_time": 214.80198489800114
}
#Debug simulation 
Total elapsed time: 103.74646377423778. Arrivals time: 0.5634931023232639 Scheduler time: 102.997060819529 Scheduler overhead time: 0.07154434360563755 Adapter cache time: 0.015633403323590755 Engine time: 0.07128713000565767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618725733 . Total output tokens: 554986694
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 108.37433726293966,
    "estimated_duration": 3600.013629626737,
    "input_throughput": 7512.80655645858,
    "output_throughput": 6637.5137592125,
    "total_throughput": 14150.32031567108,
    "itl": 125.22156222689968,
    "ttft": 1955081.130780419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0069004677538749,
    "arrivals": 923294,
    "finished_requests": 109292,
    "scheduler_time": 214.73764056310407
}
#Debug simulation 
Total elapsed time: 108.37449441291392. Arrivals time: 0.6133405305445194 Scheduler time: 107.5650588190183 Scheduler overhead time: 0.07589987386018038 Adapter cache time: 0.01720444578677416 Engine time: 0.07548610307276249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618725733 . Total output tokens: 554986694
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.40710490802303,
    "estimated_duration": 3600.0126923940707,
    "input_throughput": 7480.635292452492,
    "output_throughput": 6615.041399802156,
    "total_throughput": 14095.676692254647,
    "itl": 124.62316276189208,
    "ttft": 1953711.9460860947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0532256433996428,
    "arrivals": 923294,
    "finished_requests": 108929,
    "scheduler_time": 215.8297878117029
}
#Debug simulation 
Total elapsed time: 105.40725675178692. Arrivals time: 0.6261703562922776 Scheduler time: 104.589453720022 Scheduler overhead time: 0.07453570561483502 Adapter cache time: 0.016334800515323877 Engine time: 0.0736620151437819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618725733 . Total output tokens: 554986694
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 104.17462342092767,
    "estimated_duration": 3600.01470105649,
    "input_throughput": 7480.631118560929,
    "output_throughput": 6615.037708876933,
    "total_throughput": 14095.668827437861,
    "itl": 124.62322071156301,
    "ttft": 1953712.7888106685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0552275519818124,
    "arrivals": 923294,
    "finished_requests": 108929,
    "scheduler_time": 215.8297945655344
}
#Debug simulation 
Total elapsed time: 104.17476909607649. Arrivals time: 0.5898979976773262 Scheduler time: 103.39486092096195 Scheduler overhead time: 0.0739404116757214 Adapter cache time: 0.016154487151652575 Engine time: 0.07298763236030936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618725733 . Total output tokens: 554986694
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 106.80679359706119,
    "estimated_duration": 3600.1134580849057,
    "input_throughput": 7480.67062706579,
    "output_throughput": 6615.002909566177,
    "total_throughput": 14095.673536631966,
    "itl": 124.62188265011366,
    "ttft": 1953720.4397515424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0107317302818446,
    "arrivals": 923294,
    "finished_requests": 108932,
    "scheduler_time": 215.83755740518308
}
#Debug simulation 
Total elapsed time: 106.80697135208175. Arrivals time: 0.5680194059386849 Scheduler time: 106.04748773993924 Scheduler overhead time: 0.07418234786018729 Adapter cache time: 0.01639249362051487 Engine time: 0.0737894531339407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618725733 . Total output tokens: 554986694
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 107.8280799118802,
    "estimated_duration": 3600.028349174567,
    "input_throughput": 7480.6027586351465,
    "output_throughput": 6615.012630514492,
    "total_throughput": 14095.61538914964,
    "itl": 124.62354422789394,
    "ttft": 1953718.7815807317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0683059457689577,
    "arrivals": 923294,
    "finished_requests": 108929,
    "scheduler_time": 215.82991186970327
}
#Debug simulation 
Total elapsed time: 107.82821588497609. Arrivals time: 0.612844608258456 Scheduler time: 107.0170888826251 Scheduler overhead time: 0.07784912548959255 Adapter cache time: 0.01677951915189624 Engine time: 0.0763646294362843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618725733 . Total output tokens: 554986694
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 109.55263117328286,
    "estimated_duration": 3600.127093371989,
    "input_throughput": 7492.004671073166,
    "output_throughput": 6621.137915904407,
    "total_throughput": 14113.142586977572,
    "itl": 124.36302782501011,
    "ttft": 1952012.6041828492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 318,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9508359937788932,
    "arrivals": 923294,
    "finished_requests": 108952,
    "scheduler_time": 215.56508967215206
}
#Debug simulation 
Total elapsed time: 109.55278231203556. Arrivals time: 0.6221972643397748 Scheduler time: 108.7390015013516 Scheduler overhead time: 0.07428708020597696 Adapter cache time: 0.01693811919540167 Engine time: 0.07281355420127511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [64 64 64]
Adapter prompts. [34560, 135, 34560, 135, 34560, 135, 34560, 135, 135, 135, 8640, 8640, 8640, 8640, 34560, 8640, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 135, 135, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 34560, 34560, 135, 8640, 34560, 135, 8640, 135, 8640, 135, 135, 8640, 34560, 34560, 135, 135, 135, 34560, 34560, 34560, 8640, 135, 135, 135, 135, 135, 34560, 135, 8640, 135, 34560, 34560, 135, 34560, 135, 8640, 8640, 34560, 135, 135, 135, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 135, 34560, 8640, 8640, 8640, 34560, 8640, 135, 8640, 34560, 34560, 8640, 34560, 8640, 135, 34560, 8640, 135, 8640, 8640, 135, 8640, 34560, 135, 8640, 34560, 135, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 34560, 34560, 135, 34560, 135, 34560, 135, 8640, 135, 34560, 34560, 8640, 34560, 135, 34560, 34560, 34560, 135, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 135, 34560, 8640, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2773440 . Total input tokens: 618725733 . Total output tokens: 554986694
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 104.9612993169576,
    "estimated_duration": 3600.0421748278923,
    "input_throughput": 7480.574030021597,
    "output_throughput": 6614.987226125619,
    "total_throughput": 14095.561256147215,
    "itl": 124.62388861590338,
    "ttft": 1953724.4570527272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 323,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.082138862274592,
    "arrivals": 923294,
    "finished_requests": 108929,
    "scheduler_time": 215.83001771155932
}
#Debug simulation 
Total elapsed time: 104.961453251075. Arrivals time: 0.6273411735892296 Scheduler time: 104.13900851551443 Scheduler overhead time: 0.07617874816060066 Adapter cache time: 0.016857899259775877 Engine time: 0.07510992372408509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617742491 . Total output tokens: 554114417
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 97.40251885075122,
    "estimated_duration": 3600.034507722541,
    "input_throughput": 7512.121048280881,
    "output_throughput": 6663.68112542795,
    "total_throughput": 14175.802173708831,
    "itl": 126.12771095065634,
    "ttft": 1957070.8952143632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9946585167781437,
    "arrivals": 921863,
    "finished_requests": 109358,
    "scheduler_time": 213.3789593023175
}
#Debug simulation 
Total elapsed time: 97.40266967471689. Arrivals time: 0.6548636252991855 Scheduler time: 96.56608995981514 Scheduler overhead time: 0.07096881233155727 Adapter cache time: 0.015135128051042557 Engine time: 0.06885890197008848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617742491 . Total output tokens: 554114417
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.90849944809452,
    "estimated_duration": 3600.1261622089623,
    "input_throughput": 7492.1618811964345,
    "output_throughput": 6659.762163803958,
    "total_throughput": 14151.924045000393,
    "itl": 125.85359099013185,
    "ttft": 1955801.807211617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.018421996629337,
    "arrivals": 921863,
    "finished_requests": 109219,
    "scheduler_time": 213.6631105642577
}
#Debug simulation 
Total elapsed time: 105.90871140686795. Arrivals time: 0.7086981404572725 Scheduler time: 105.00744206085801 Scheduler overhead time: 0.07487532822415233 Adapter cache time: 0.016297374852001667 Engine time: 0.07422081148251891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617742491 . Total output tokens: 554114417
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 108.33961562206969,
    "estimated_duration": 3600.129103298895,
    "input_throughput": 7492.155760548743,
    "output_throughput": 6659.756723177,
    "total_throughput": 14151.912483725742,
    "itl": 125.85365123428888,
    "ttft": 1955803.3560190015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.020745393559342,
    "arrivals": 921863,
    "finished_requests": 109219,
    "scheduler_time": 213.66316273209557
}
#Debug simulation 
Total elapsed time: 108.33977277530357. Arrivals time: 0.7269432134926319 Scheduler time: 107.41514754947275 Scheduler overhead time: 0.07650129124522209 Adapter cache time: 0.01718096435070038 Engine time: 0.07650218810886145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617742491 . Total output tokens: 554114417
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 113.08769551571459,
    "estimated_duration": 3600.1151990197363,
    "input_throughput": 7512.126558440093,
    "output_throughput": 6666.063909992242,
    "total_throughput": 14178.190468432334,
    "itl": 126.15907843410484,
    "ttft": 1955612.099283695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.892745153638537,
    "arrivals": 921863,
    "finished_requests": 109530,
    "scheduler_time": 213.1857120875206
}
#Debug simulation 
Total elapsed time: 113.08785456372425. Arrivals time: 0.7514040833339095 Scheduler time: 112.13870923314244 Scheduler overhead time: 0.0773074678145349 Adapter cache time: 0.016601139213889837 Engine time: 0.07657710229977965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617742491 . Total output tokens: 554114417
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 107.0764987221919,
    "estimated_duration": 3600.0011445174623,
    "input_throughput": 7492.272340267632,
    "output_throughput": 6659.73149383917,
    "total_throughput": 14152.003834106801,
    "itl": 125.85356993712485,
    "ttft": 1955782.8266365384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0331950184144134,
    "arrivals": 921863,
    "finished_requests": 109216,
    "scheduler_time": 213.6549642903761
}
#Debug simulation 
Total elapsed time: 107.07665357505903. Arrivals time: 0.7591605740599334 Scheduler time: 106.1230941163376 Scheduler overhead time: 0.07469311216846108 Adapter cache time: 0.017382522113621235 Engine time: 0.07522710366174579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617742491 . Total output tokens: 554114417
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 97.09399953391403,
    "estimated_duration": 3600.010270096459,
    "input_throughput": 7512.171624797999,
    "output_throughput": 6663.72598969203,
    "total_throughput": 14175.89761449003,
    "itl": 126.12704179880862,
    "ttft": 1957062.0594933513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 325,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9717663458432084,
    "arrivals": 921863,
    "finished_requests": 109358,
    "scheduler_time": 213.37874489744155
}
#Debug simulation 
Total elapsed time: 97.09414792712778. Arrivals time: 0.6237360397353768 Scheduler time: 96.29040447296575 Scheduler overhead time: 0.06953056994825602 Adapter cache time: 0.014907110016793013 Engine time: 0.06974471220746636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_192_slots_32_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [64 64 64]
Adapter prompts. [34560, 66, 34560, 66, 34560, 66, 34560, 66, 66, 66, 8640, 8640, 8640, 8640, 34560, 8640, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 66, 66, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 34560, 34560, 66, 8640, 34560, 66, 8640, 66, 8640, 66, 66, 8640, 34560, 34560, 66, 66, 66, 34560, 34560, 34560, 8640, 66, 66, 66, 66, 66, 34560, 66, 8640, 66, 34560, 34560, 66, 34560, 66, 8640, 8640, 34560, 66, 66, 66, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 66, 34560, 8640, 8640, 8640, 34560, 8640, 66, 8640, 34560, 34560, 8640, 34560, 8640, 66, 34560, 8640, 66, 8640, 8640, 66, 8640, 34560, 66, 8640, 34560, 66, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 34560, 34560, 66, 34560, 66, 34560, 66, 8640, 66, 34560, 34560, 8640, 34560, 66, 34560, 34560, 34560, 66, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 66, 34560, 8640, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2769024 . Total input tokens: 617742491 . Total output tokens: 554114417
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.97121577290818,
    "estimated_duration": 3600.014632747517,
    "input_throughput": 7492.24426885591,
    "output_throughput": 6659.70654172101,
    "total_throughput": 14151.95081057692,
    "itl": 125.85394878675041,
    "ttft": 1955788.5542564564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0461476584151437,
    "arrivals": 921863,
    "finished_requests": 109216,
    "scheduler_time": 213.65504746031544
}
#Debug simulation 
Total elapsed time: 105.9714111238718. Arrivals time: 0.753600035328418 Scheduler time: 105.02516481792554 Scheduler overhead time: 0.07414562441408634 Adapter cache time: 0.016937216743826866 Engine time: 0.0746041564270854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617284907 . Total output tokens: 553676923
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 106.31537333223969,
    "estimated_duration": 3600.053160550499,
    "input_throughput": 7525.945254613122,
    "output_throughput": 6621.295280082749,
    "total_throughput": 14147.240534695871,
    "itl": 124.6316607707373,
    "ttft": 1955465.1060135996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8691785192769009,
    "arrivals": 921076,
    "finished_requests": 109053,
    "scheduler_time": 215.51842020760554
}
#Debug simulation 
Total elapsed time: 106.31552307587117. Arrivals time: 0.7063998156227171 Scheduler time: 105.41606558859348 Scheduler overhead time: 0.07472545327618718 Adapter cache time: 0.016081116162240505 Engine time: 0.07522499235346913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617284907 . Total output tokens: 553676923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 103.75022466899827,
    "estimated_duration": 3600.0231620852564,
    "input_throughput": 7543.807297136729,
    "output_throughput": 6637.120908455461,
    "total_throughput": 14180.92820559219,
    "itl": 124.8973934457648,
    "ttft": 1956283.7698435676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9640436668158558,
    "arrivals": 921076,
    "finished_requests": 109327,
    "scheduler_time": 214.72693938274313
}
#Debug simulation 
Total elapsed time: 103.75038836104795. Arrivals time: 0.7365929652005434 Scheduler time: 102.82417873339728 Scheduler overhead time: 0.07352028368040919 Adapter cache time: 0.016283181961625814 Engine time: 0.07267603278160095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617284907 . Total output tokens: 553676923
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 99.1758132618852,
    "estimated_duration": 3600.0268233788497,
    "input_throughput": 7543.799624945748,
    "output_throughput": 6637.11415838124,
    "total_throughput": 14180.913783326987,
    "itl": 124.89739218348615,
    "ttft": 1956285.7427498368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9666531320661356,
    "arrivals": 921076,
    "finished_requests": 109327,
    "scheduler_time": 214.72700599994033
}
#Debug simulation 
Total elapsed time: 99.17595326295123. Arrivals time: 0.518532685469836 Scheduler time: 98.47829213738441 Scheduler overhead time: 0.06966685596853495 Adapter cache time: 0.014693665783852339 Engine time: 0.0686750179156661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617284907 . Total output tokens: 553676923
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 104.7623342317529,
    "estimated_duration": 3600.069310451841,
    "input_throughput": 7525.9114932427465,
    "output_throughput": 6621.26557696975,
    "total_throughput": 14147.177070212498,
    "itl": 124.63202273993673,
    "ttft": 1955472.4576166396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.885947862411852,
    "arrivals": 921076,
    "finished_requests": 109053,
    "scheduler_time": 215.51859250099878
}
#Debug simulation 
Total elapsed time: 104.76248569786549. Arrivals time: 0.7288333550095558 Scheduler time: 103.83482349617407 Scheduler overhead time: 0.07733806082978845 Adapter cache time: 0.016328189056366682 Engine time: 0.07767004752531648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617284907 . Total output tokens: 553676923
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 106.93318845285103,
    "estimated_duration": 3600.0382847176634,
    "input_throughput": 7543.775607966871,
    "output_throughput": 6637.093027990922,
    "total_throughput": 14180.868635957791,
    "itl": 124.89762305029056,
    "ttft": 1956290.5843548374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9780967266298881,
    "arrivals": 921076,
    "finished_requests": 109327,
    "scheduler_time": 214.72713684922653
}
#Debug simulation 
Total elapsed time: 106.93338441988453. Arrivals time: 0.6108318287879229 Scheduler time: 106.12702038371935 Scheduler overhead time: 0.07596106687560678 Adapter cache time: 0.016957541927695274 Engine time: 0.07558696903288364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_192_slots_32_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [64 64 64]
Adapter prompts. [34560, 33, 34560, 33, 34560, 33, 34560, 33, 33, 33, 8640, 8640, 8640, 8640, 34560, 8640, 33, 34560, 33, 8640, 8640, 33, 34560, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 33, 33, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 33, 8640, 8640, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 34560, 34560, 33, 8640, 34560, 33, 8640, 33, 8640, 33, 33, 8640, 34560, 34560, 33, 33, 33, 34560, 34560, 34560, 8640, 33, 33, 33, 33, 33, 34560, 33, 8640, 33, 34560, 34560, 33, 34560, 33, 8640, 8640, 34560, 33, 33, 33, 34560, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 33, 34560, 8640, 8640, 8640, 34560, 8640, 33, 8640, 34560, 34560, 8640, 34560, 8640, 33, 34560, 8640, 33, 8640, 8640, 33, 8640, 34560, 33, 8640, 34560, 33, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 34560, 34560, 33, 34560, 33, 34560, 33, 8640, 33, 34560, 34560, 8640, 34560, 33, 34560, 34560, 34560, 33, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 8640, 33, 34560, 8640, 34560, 33, 34560, 8640, 33, 8640, 33, 33, 8640, 8640, 8640, 34560, 8640, 33, 33]
Prompts retrieved: 2766912 . Total input tokens: 617284907 . Total output tokens: 553676923
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.1850108448416,
    "estimated_duration": 3600.0315341057426,
    "input_throughput": 7525.990465172459,
    "output_throughput": 6621.335056144495,
    "total_throughput": 14147.325521316954,
    "itl": 124.63126252975103,
    "ttft": 1955454.9630897562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 284,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.849174283752219,
    "arrivals": 921076,
    "finished_requests": 109053,
    "scheduler_time": 215.51817424458227
}
#Debug simulation 
Total elapsed time: 107.18514517694712. Arrivals time: 0.7102633798494935 Scheduler time: 106.2790361600928 Scheduler overhead time: 0.07648758171126246 Adapter cache time: 0.016341472044587135 Engine time: 0.07592291524633765 
