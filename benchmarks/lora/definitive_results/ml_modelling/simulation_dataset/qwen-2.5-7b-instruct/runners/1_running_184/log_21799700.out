INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:00 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 34560, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 211410 . Total input tokens: 47026792 . Total output tokens: 42361865
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.020625906065106,
    "estimated_duration": 3600.0300231867227,
    "input_throughput": 4910.750156564195,
    "output_throughput": 4330.947491987434,
    "total_throughput": 9241.697648551628,
    "itl": 31.921981491045226,
    "ttft": 7278.503502792214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 70747,
    "finished_requests": 70605,
    "scheduler_time": 42.953694349517455
}
#Debug simulation 
Total elapsed time: 5.020775048993528. Arrivals time: 0.179650554433465 Scheduler time: 4.536954389885068 Scheduler overhead time: 0.11411207029595971 Adapter cache time: 0.02076601656153798 Engine time: 0.11482008034363389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 34560, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 211410 . Total input tokens: 47026792 . Total output tokens: 42361865
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 4.991920716129243,
    "estimated_duration": 3600.0237283517504,
    "input_throughput": 4910.758743274771,
    "output_throughput": 4330.95506488189,
    "total_throughput": 9241.713808156663,
    "itl": 31.92188310065693,
    "ttft": 7278.59888701638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 70747,
    "finished_requests": 70605,
    "scheduler_time": 42.95358097196715
}
#Debug simulation 
Total elapsed time: 4.9920339728705585. Arrivals time: 0.17534576449543238 Scheduler time: 4.517933139111847 Scheduler overhead time: 0.1117887869477272 Adapter cache time: 0.020763013046234846 Engine time: 0.11322342371568084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 34560, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 211410 . Total input tokens: 47026792 . Total output tokens: 42361865
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.007904853671789,
    "estimated_duration": 3600.030269843645,
    "input_throughput": 4910.74982010299,
    "output_throughput": 4330.947195251546,
    "total_throughput": 9241.697015354537,
    "itl": 31.921961516579245,
    "ttft": 7278.515015904713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 70747,
    "finished_requests": 70605,
    "scheduler_time": 42.95369434951749
}
#Debug simulation 
Total elapsed time: 5.008005467709154. Arrivals time: 0.17802301235496998 Scheduler time: 4.5310477335006 Scheduler overhead time: 0.1124034384265542 Adapter cache time: 0.020532864145934582 Engine time: 0.112928647082299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 34560, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 211410 . Total input tokens: 47026792 . Total output tokens: 42361865
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.004838462918997,
    "estimated_duration": 3600.0229736069023,
    "input_throughput": 4910.759772815385,
    "output_throughput": 4330.955972866658,
    "total_throughput": 9241.715745682044,
    "itl": 31.921889059435298,
    "ttft": 7278.582202125267,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 70747,
    "finished_requests": 70605,
    "scheduler_time": 42.95360524081566
}
#Debug simulation 
Total elapsed time: 5.0049592279829085. Arrivals time: 0.17633107490837574 Scheduler time: 4.529531482607126 Scheduler overhead time: 0.11157278250902891 Adapter cache time: 0.020392336882650852 Engine time: 0.11389710614457726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 34560, 270, 34560, 270, 540, 540, 270, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 211410 . Total input tokens: 47026792 . Total output tokens: 42361865
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 4.993759615812451,
    "estimated_duration": 3599.9996706324027,
    "input_throughput": 4910.791560404338,
    "output_throughput": 4330.984007357166,
    "total_throughput": 9241.775567761504,
    "itl": 31.921968783024912,
    "ttft": 7278.542054912921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 70747,
    "finished_requests": 70605,
    "scheduler_time": 42.95336184127235
}
#Debug simulation 
Total elapsed time: 4.993880225811154. Arrivals time: 0.17483336152508855 Scheduler time: 4.52267668582499 Scheduler overhead time: 0.11205553309991956 Adapter cache time: 0.020461306907236576 Engine time: 0.11116181826218963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 34560, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210735 . Total input tokens: 46877334 . Total output tokens: 42224200
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 4.95913405623287,
    "estimated_duration": 3599.9934467260555,
    "input_throughput": 4894.155575761726,
    "output_throughput": 4315.115355036951,
    "total_throughput": 9209.270930798677,
    "itl": 31.607459068883077,
    "ttft": 8472.645792955991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 70543,
    "finished_requests": 70378,
    "scheduler_time": 42.538821188439684
}
#Debug simulation 
Total elapsed time: 4.959260671399534. Arrivals time: 0.17560516949743032 Scheduler time: 4.4854044718667865 Scheduler overhead time: 0.11282757855951786 Adapter cache time: 0.02011771034449339 Engine time: 0.11162273352965713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 34560, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210735 . Total input tokens: 46877334 . Total output tokens: 42224200
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 4.970839974936098,
    "estimated_duration": 3599.9957608324994,
    "input_throughput": 4894.152429758868,
    "output_throughput": 4315.112581245838,
    "total_throughput": 9209.265011004705,
    "itl": 31.607423847486793,
    "ttft": 8472.61510899637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 70543,
    "finished_requests": 70378,
    "scheduler_time": 42.53879283380795
}
#Debug simulation 
Total elapsed time: 4.970939594786614. Arrivals time: 0.1729868263937533 Scheduler time: 4.4982820665463805 Scheduler overhead time: 0.11223147995769978 Adapter cache time: 0.020270196720957756 Engine time: 0.11384546477347612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 34560, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210735 . Total input tokens: 46877334 . Total output tokens: 42224200
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 4.969896471127868,
    "estimated_duration": 3599.995799285389,
    "input_throughput": 4894.152377482612,
    "output_throughput": 4315.112535154521,
    "total_throughput": 9209.264912637133,
    "itl": 31.607429108563775,
    "ttft": 8472.61229028503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.052406024020165184,
    "arrivals": 70543,
    "finished_requests": 70378,
    "scheduler_time": 42.538788788999874
}
#Debug simulation 
Total elapsed time: 4.970021286047995. Arrivals time: 0.17732379166409373 Scheduler time: 4.4923299313522875 Scheduler overhead time: 0.11333544924855232 Adapter cache time: 0.020192946773022413 Engine time: 0.1131011014804244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 34560, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210735 . Total input tokens: 46877334 . Total output tokens: 42224200
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 4.9636202291585505,
    "estimated_duration": 3599.9937337995234,
    "input_throughput": 4894.15518548821,
    "output_throughput": 4315.115010937705,
    "total_throughput": 9209.270196425916,
    "itl": 31.607408050223427,
    "ttft": 8472.611198736398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 70543,
    "finished_requests": 70378,
    "scheduler_time": 42.53878074035911
}
#Debug simulation 
Total elapsed time: 4.963727854192257. Arrivals time: 0.17640621634200215 Scheduler time: 4.488790408242494 Scheduler overhead time: 0.11268588760867715 Adapter cache time: 0.020179031416773796 Engine time: 0.1120814811438322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 34560, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210735 . Total input tokens: 46877334 . Total output tokens: 42224200
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 4.968169217929244,
    "estimated_duration": 3599.998791871476,
    "input_throughput": 4894.148309100048,
    "output_throughput": 4315.108948112835,
    "total_throughput": 9209.257257212883,
    "itl": 31.60742845270881,
    "ttft": 8472.620279077608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 70543,
    "finished_requests": 70378,
    "scheduler_time": 42.53884137150442
}
#Debug simulation 
Total elapsed time: 4.968273606151342. Arrivals time: 0.17326087271794677 Scheduler time: 4.49699084693566 Scheduler overhead time: 0.11267179111018777 Adapter cache time: 0.020152222365140915 Engine time: 0.11179649317637086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 34560, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210735 . Total input tokens: 46877334 . Total output tokens: 42224200
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 4.997855296824127,
    "estimated_duration": 3599.993406718384,
    "input_throughput": 4894.155630151762,
    "output_throughput": 4315.115402991961,
    "total_throughput": 9209.271033143723,
    "itl": 31.607470971564133,
    "ttft": 8472.635266599775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 70543,
    "finished_requests": 70378,
    "scheduler_time": 42.53884137150498
}
#Debug simulation 
Total elapsed time: 4.997950496617705. Arrivals time: 0.17447604332119226 Scheduler time: 4.524388978257775 Scheduler overhead time: 0.11381430411711335 Adapter cache time: 0.020203109364956617 Engine time: 0.11186504503712058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 34560, 135, 34560, 135, 540, 540, 135, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210735 . Total input tokens: 46877334 . Total output tokens: 42224200
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 4.9577435329556465,
    "estimated_duration": 3599.998560175968,
    "input_throughput": 4894.14862408689,
    "output_throughput": 4315.109225832768,
    "total_throughput": 9209.257849919657,
    "itl": 31.607456432563076,
    "ttft": 8472.6278846347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 70543,
    "finished_requests": 70378,
    "scheduler_time": 42.53882110648911
}
#Debug simulation 
Total elapsed time: 4.957841041032225. Arrivals time: 0.1778360465541482 Scheduler time: 4.481091409921646 Scheduler overhead time: 0.11296251742169261 Adapter cache time: 0.020212105009704828 Engine time: 0.11250784574076533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 34560, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210390 . Total input tokens: 46805687 . Total output tokens: 42157471
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.073680134955794,
    "estimated_duration": 3600.0187749534593,
    "input_throughput": 4868.367943505122,
    "output_throughput": 4310.610574579745,
    "total_throughput": 9178.978518084867,
    "itl": 31.501452602339622,
    "ttft": 7159.183018712203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 70411,
    "finished_requests": 70270,
    "scheduler_time": 42.37143423000159
}
#Debug simulation 
Total elapsed time: 5.07378538325429. Arrivals time: 0.17305083107203245 Scheduler time: 4.599968388676643 Scheduler overhead time: 0.1130297239869833 Adapter cache time: 0.01970305060967803 Engine time: 0.11433272901922464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 34560, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210390 . Total input tokens: 46805687 . Total output tokens: 42157471
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.098617119248956,
    "estimated_duration": 3600.0238018441823,
    "input_throughput": 4868.361145562942,
    "output_throughput": 4310.604555461678,
    "total_throughput": 9178.96570102462,
    "itl": 31.50156516523968,
    "ttft": 7159.217289140998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 70411,
    "finished_requests": 70270,
    "scheduler_time": 42.37149486114715
}
#Debug simulation 
Total elapsed time: 5.098738907370716. Arrivals time: 0.1755210175178945 Scheduler time: 4.622073520440608 Scheduler overhead time: 0.11302106827497482 Adapter cache time: 0.019675026647746563 Engine time: 0.11483515333384275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 34560, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210390 . Total input tokens: 46805687 . Total output tokens: 42157471
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0385031583718956,
    "estimated_duration": 3600.0240088162736,
    "input_throughput": 4868.360865671784,
    "output_throughput": 4310.604307636986,
    "total_throughput": 9178.96517330877,
    "itl": 31.501553204370563,
    "ttft": 7159.207179222168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 70411,
    "finished_requests": 70270,
    "scheduler_time": 42.371502950763315
}
#Debug simulation 
Total elapsed time: 5.038600135128945. Arrivals time: 0.17785308603197336 Scheduler time: 4.5608167527243495 Scheduler overhead time: 0.11367997387424111 Adapter cache time: 0.02005788078531623 Engine time: 0.11234799912199378 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 34560, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210390 . Total input tokens: 46805687 . Total output tokens: 42157471
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.0600656257011,
    "estimated_duration": 3600.0189895682806,
    "input_throughput": 4868.367653277787,
    "output_throughput": 4310.610317603067,
    "total_throughput": 9178.977970880855,
    "itl": 31.501436278515165,
    "ttft": 7159.161140651463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 70411,
    "finished_requests": 70270,
    "scheduler_time": 42.371434230001576
}
#Debug simulation 
Total elapsed time: 5.060176195111126. Arrivals time: 0.1773004555143416 Scheduler time: 4.580357330385596 Scheduler overhead time: 0.11474272236227989 Adapter cache time: 0.02012390922755003 Engine time: 0.11382269905880094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 34560, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210390 . Total input tokens: 46805687 . Total output tokens: 42157471
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.10302077839151,
    "estimated_duration": 3600.024014620592,
    "input_throughput": 4868.360857822527,
    "output_throughput": 4310.6043006869995,
    "total_throughput": 9178.965158509525,
    "itl": 31.501551876698716,
    "ttft": 7159.215805706988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 70411,
    "finished_requests": 70270,
    "scheduler_time": 42.37150295076334
}
#Debug simulation 
Total elapsed time: 5.103119278326631. Arrivals time: 0.17688616691157222 Scheduler time: 4.626604016404599 Scheduler overhead time: 0.1131687075830996 Adapter cache time: 0.01971789076924324 Engine time: 0.11315220221877098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 34560, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210390 . Total input tokens: 46805687 . Total output tokens: 42157471
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.075721412431449,
    "estimated_duration": 3600.0172295391826,
    "input_throughput": 4868.370033396598,
    "output_throughput": 4310.612425037311,
    "total_throughput": 9178.98245843391,
    "itl": 31.50139223684246,
    "ttft": 7159.142276028185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 70411,
    "finished_requests": 70270,
    "scheduler_time": 42.3714220955776
}
#Debug simulation 
Total elapsed time: 5.075845779385418. Arrivals time: 0.1789866997860372 Scheduler time: 4.5957485269755125 Scheduler overhead time: 0.11329353554174304 Adapter cache time: 0.019796657375991344 Engine time: 0.1142938625998795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 34560, 66, 34560, 66, 540, 540, 66, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210390 . Total input tokens: 46805687 . Total output tokens: 42157471
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.061993831768632,
    "estimated_duration": 3600.0240657461854,
    "input_throughput": 4868.3607886847,
    "output_throughput": 4310.60423947013,
    "total_throughput": 9178.96502815483,
    "itl": 31.501566939531664,
    "ttft": 7159.191812735898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 70411,
    "finished_requests": 70270,
    "scheduler_time": 42.37149077536422
}
#Debug simulation 
Total elapsed time: 5.062089721672237. Arrivals time: 0.18035159958526492 Scheduler time: 4.57917662197724 Scheduler overhead time: 0.11386667657643557 Adapter cache time: 0.020111979451030493 Engine time: 0.1145473551005125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 34560, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210225 . Total input tokens: 46762856 . Total output tokens: 42126485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.086814013775438,
    "estimated_duration": 3599.9462037348503,
    "input_throughput": 4848.6121770073005,
    "output_throughput": 4324.683236612801,
    "total_throughput": 9173.295413620102,
    "itl": 31.531471140617448,
    "ttft": 8340.970512655027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 70360,
    "finished_requests": 70198,
    "scheduler_time": 42.6261562696623
}
#Debug simulation 
Total elapsed time: 5.086945903021842. Arrivals time: 0.1734746266156435 Scheduler time: 4.61431296216324 Scheduler overhead time: 0.11251633055508137 Adapter cache time: 0.019572108052670956 Engine time: 0.11322074430063367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 34560, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210225 . Total input tokens: 46762856 . Total output tokens: 42126485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.099958491977304,
    "estimated_duration": 3599.912257075609,
    "input_throughput": 4848.6576209441755,
    "output_throughput": 4324.685683491372,
    "total_throughput": 9173.343304435548,
    "itl": 31.531417252568264,
    "ttft": 8392.089183405787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 70360,
    "finished_requests": 70197,
    "scheduler_time": 42.625714674524815
}
#Debug simulation 
Total elapsed time: 5.100069941021502. Arrivals time: 0.1746560255996883 Scheduler time: 4.62637547403574 Scheduler overhead time: 0.11260208394378424 Adapter cache time: 0.019485304597765207 Engine time: 0.1136270402930677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 34560, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210225 . Total input tokens: 46762856 . Total output tokens: 42126485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.077811014838517,
    "estimated_duration": 3599.912954655729,
    "input_throughput": 4848.656681386134,
    "output_throughput": 4324.68484546701,
    "total_throughput": 9173.341526853144,
    "itl": 31.531407882326537,
    "ttft": 8392.072202835097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0524060240201652,
    "arrivals": 70360,
    "finished_requests": 70197,
    "scheduler_time": 42.625738902398304
}
#Debug simulation 
Total elapsed time: 5.077904797159135. Arrivals time: 0.17804923932999372 Scheduler time: 4.599449408240616 Scheduler overhead time: 0.1128368005156517 Adapter cache time: 0.019651720765978098 Engine time: 0.11443911539390683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 34560, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210225 . Total input tokens: 46762856 . Total output tokens: 42126485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.096505089662969,
    "estimated_duration": 3599.9456268772756,
    "input_throughput": 4848.612953951997,
    "output_throughput": 4324.683929602791,
    "total_throughput": 9173.296883554787,
    "itl": 31.531450161313924,
    "ttft": 8340.971727605118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 70360,
    "finished_requests": 70198,
    "scheduler_time": 42.62614013140504
}
#Debug simulation 
Total elapsed time: 5.0966096026822925. Arrivals time: 0.17504908563569188 Scheduler time: 4.623441428411752 Scheduler overhead time: 0.11244658846408129 Adapter cache time: 0.019393321126699448 Engine time: 0.11264962563291192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 34560, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210225 . Total input tokens: 46762856 . Total output tokens: 42126485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.081249459180981,
    "estimated_duration": 3599.921496808699,
    "input_throughput": 4848.645176144392,
    "output_throughput": 4324.674583543374,
    "total_throughput": 9173.319759687767,
    "itl": 31.531479387358807,
    "ttft": 8392.094971120214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 70360,
    "finished_requests": 70197,
    "scheduler_time": 42.62590077666976
}
#Debug simulation 
Total elapsed time: 5.0813445071689785. Arrivals time: 0.17562634032219648 Scheduler time: 4.606749368365854 Scheduler overhead time: 0.11291976971551776 Adapter cache time: 0.019628445152193308 Engine time: 0.11283970158547163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 34560, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210225 . Total input tokens: 46762856 . Total output tokens: 42126485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.092575469985604,
    "estimated_duration": 3599.944961958858,
    "input_throughput": 4848.61384950237,
    "output_throughput": 4324.684728382224,
    "total_throughput": 9173.298577884594,
    "itl": 31.531487296409097,
    "ttft": 8340.971614640963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 70360,
    "finished_requests": 70198,
    "scheduler_time": 42.62616031447037
}
#Debug simulation 
Total elapsed time: 5.092695462983102. Arrivals time: 0.17761385813355446 Scheduler time: 4.613732324913144 Scheduler overhead time: 0.11265068175271153 Adapter cache time: 0.01967206923291087 Engine time: 0.11527177784591913 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 34560, 33, 34560, 33, 540, 540, 33, 540, 34560, 34560, 34560, 34560]
Prompts retrieved: 210225 . Total input tokens: 46762856 . Total output tokens: 42126485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.111716170329601,
    "estimated_duration": 3599.9218011822272,
    "input_throughput": 4848.644766191254,
    "output_throughput": 4324.674217891969,
    "total_throughput": 9173.318984083224,
    "itl": 31.531427862729785,
    "ttft": 8392.058499508514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 70360,
    "finished_requests": 70197,
    "scheduler_time": 42.625876507821545
}
#Debug simulation 
Total elapsed time: 5.111813326366246. Arrivals time: 0.1782795898616314 Scheduler time: 4.633397804107517 Scheduler overhead time: 0.11315287416800857 Adapter cache time: 0.019665186293423176 Engine time: 0.11366980755701661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 34560, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209385 . Total input tokens: 46575963 . Total output tokens: 41948242
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.032084202859551,
    "estimated_duration": 3599.9666596051343,
    "input_throughput": 4842.025120841522,
    "output_throughput": 4298.41119742406,
    "total_throughput": 9140.436318265582,
    "itl": 31.20990673463783,
    "ttft": 7754.818536430529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 70101,
    "finished_requests": 69951,
    "scheduler_time": 41.993687026637254
}
#Debug simulation 
Total elapsed time: 5.032206865027547. Arrivals time: 0.1732145920395851 Scheduler time: 4.5576384286396205 Scheduler overhead time: 0.11418659472838044 Adapter cache time: 0.019552598241716623 Engine time: 0.1132703572511673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 34560, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209385 . Total input tokens: 46575963 . Total output tokens: 41948242
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.058545647189021,
    "estimated_duration": 3599.9752729061543,
    "input_throughput": 4842.098536395811,
    "output_throughput": 4298.457024541733,
    "total_throughput": 9140.555560937544,
    "itl": 31.209987842080235,
    "ttft": 7703.482516301033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 70101,
    "finished_requests": 69952,
    "scheduler_time": 41.99387300585762
}
#Debug simulation 
Total elapsed time: 5.058657679241151. Arrivals time: 0.1762728556059301 Scheduler time: 4.580334150232375 Scheduler overhead time: 0.11361992219462991 Adapter cache time: 0.019573344383388758 Engine time: 0.11431426927447319 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 34560, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209385 . Total input tokens: 46575963 . Total output tokens: 41948242
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 4.98008249187842,
    "estimated_duration": 3599.975262321395,
    "input_throughput": 4842.0985506327,
    "output_throughput": 4298.45703718019,
    "total_throughput": 9140.55558781289,
    "itl": 31.209985375969033,
    "ttft": 7703.476722083062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 70101,
    "finished_requests": 69952,
    "scheduler_time": 41.993873005857616
}
#Debug simulation 
Total elapsed time: 4.980194887146354. Arrivals time: 0.17810054682195187 Scheduler time: 4.5007183640263975 Scheduler overhead time: 0.11372192017734051 Adapter cache time: 0.019414333160966635 Engine time: 0.11414647614583373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 34560, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209385 . Total input tokens: 46575963 . Total output tokens: 41948242
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.016563639976084,
    "estimated_duration": 3599.967962021724,
    "input_throughput": 4842.023369066531,
    "output_throughput": 4298.409642320762,
    "total_throughput": 9140.433011387293,
    "itl": 31.209974671063712,
    "ttft": 7754.756334096503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 70101,
    "finished_requests": 69951,
    "scheduler_time": 41.99371938510167
}
#Debug simulation 
Total elapsed time: 5.016686759889126. Arrivals time: 0.1747649642638862 Scheduler time: 4.539952008519322 Scheduler overhead time: 0.11382454633712769 Adapter cache time: 0.019642024766653776 Engine time: 0.11426535621285439 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 34560, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209385 . Total input tokens: 46575963 . Total output tokens: 41948242
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.0720673580653965,
    "estimated_duration": 3599.9752999726647,
    "input_throughput": 4842.098499990364,
    "output_throughput": 4298.456992223669,
    "total_throughput": 9140.555492214033,
    "itl": 31.209998915591136,
    "ttft": 7703.4848737174425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 70101,
    "finished_requests": 69952,
    "scheduler_time": 41.993868920074675
}
#Debug simulation 
Total elapsed time: 5.072225654032081. Arrivals time: 0.17503980407491326 Scheduler time: 4.595868235919625 Scheduler overhead time: 0.11420331476256251 Adapter cache time: 0.019474186934530735 Engine time: 0.11350187379866838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 34560, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209385 . Total input tokens: 46575963 . Total output tokens: 41948242
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 4.997029105667025,
    "estimated_duration": 3600.0002322987953,
    "input_throughput": 4842.159409770056,
    "output_throughput": 4298.501111517603,
    "total_throughput": 9140.660521287658,
    "itl": 31.20995201507541,
    "ttft": 7652.092883092453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 70101,
    "finished_requests": 69953,
    "scheduler_time": 41.99410443487675
}
#Debug simulation 
Total elapsed time: 4.997119200881571. Arrivals time: 0.16085362900048494 Scheduler time: 4.534292094875127 Scheduler overhead time: 0.11460901983082294 Adapter cache time: 0.019615672063082457 Engine time: 0.11381507851183414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 34560, 135, 34560, 135, 270, 270, 135, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209385 . Total input tokens: 46575963 . Total output tokens: 41948242
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.013776978012174,
    "estimated_duration": 3599.9762353117635,
    "input_throughput": 4842.097241925379,
    "output_throughput": 4298.455875406605,
    "total_throughput": 9140.553117331983,
    "itl": 31.2099800704459,
    "ttft": 7703.468815697459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 70101,
    "finished_requests": 69952,
    "scheduler_time": 41.99386892007462
}
#Debug simulation 
Total elapsed time: 5.013870758004487. Arrivals time: 0.16186764743179083 Scheduler time: 4.548933741636574 Scheduler overhead time: 0.11426563560962677 Adapter cache time: 0.01941727427765727 Engine time: 0.11534567782655358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 34560, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209040 . Total input tokens: 46497896 . Total output tokens: 41881751
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.03289641905576,
    "estimated_duration": 3600.0187823663814,
    "input_throughput": 4844.316670074843,
    "output_throughput": 4270.173554454385,
    "total_throughput": 9114.490224529229,
    "itl": 30.9596637149527,
    "ttft": 7354.160450189708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 69999,
    "finished_requests": 69857,
    "scheduler_time": 41.45400856296109
}
#Debug simulation 
Total elapsed time: 5.032990716863424. Arrivals time: 0.1681628949008882 Scheduler time: 4.561903805471957 Scheduler overhead time: 0.11484515713527799 Adapter cache time: 0.019411650486290455 Engine time: 0.11446122312918305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 34560, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209040 . Total input tokens: 46497896 . Total output tokens: 41881751
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.023318627849221,
    "estimated_duration": 3600.024015763201,
    "input_throughput": 4844.309627835307,
    "output_throughput": 4270.16734685338,
    "total_throughput": 9114.476974688687,
    "itl": 30.959690064521826,
    "ttft": 7354.14182755836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 69999,
    "finished_requests": 69857,
    "scheduler_time": 41.454081410481024
}
#Debug simulation 
Total elapsed time: 5.023418013937771. Arrivals time: 0.17412452585995197 Scheduler time: 4.546404873020947 Scheduler overhead time: 0.11438328446820378 Adapter cache time: 0.019410233944654465 Engine time: 0.11467794515192509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 34560, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209040 . Total input tokens: 46497896 . Total output tokens: 41881751
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.030432765837759,
    "estimated_duration": 3600.023769643448,
    "input_throughput": 4844.30995902209,
    "output_throughput": 4270.167638788268,
    "total_throughput": 9114.477597810357,
    "itl": 30.959680436521015,
    "ttft": 7354.151744939931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 69999,
    "finished_requests": 69857,
    "scheduler_time": 41.45408141048104
}
#Debug simulation 
Total elapsed time: 5.03054768498987. Arrivals time: 0.17820619139820337 Scheduler time: 4.5502950036898255 Scheduler overhead time: 0.11419837782159448 Adapter cache time: 0.019616831094026566 Engine time: 0.11404037941247225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 34560, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209040 . Total input tokens: 46497896 . Total output tokens: 41881751
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.032777820248157,
    "estimated_duration": 3600.0205857359747,
    "input_throughput": 4844.314243396113,
    "output_throughput": 4270.171415382965,
    "total_throughput": 9114.485658779078,
    "itl": 30.959620800980932,
    "ttft": 7354.181282721527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 69999,
    "finished_requests": 69857,
    "scheduler_time": 41.454036917592575
}
#Debug simulation 
Total elapsed time: 5.032876749988645. Arrivals time: 0.17550609819591045 Scheduler time: 4.555006082635373 Scheduler overhead time: 0.11394150741398335 Adapter cache time: 0.019286558497697115 Engine time: 0.11461346410214901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 34560, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209040 . Total input tokens: 46497896 . Total output tokens: 41881751
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.083737403154373,
    "estimated_duration": 3600.023772988918,
    "input_throughput": 4844.309954520315,
    "output_throughput": 4270.167634820039,
    "total_throughput": 9114.477589340353,
    "itl": 30.959678210852704,
    "ttft": 7354.188961358948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 69999,
    "finished_requests": 69857,
    "scheduler_time": 41.4540895000971
}
#Debug simulation 
Total elapsed time: 5.083851743955165. Arrivals time: 0.17743070889264345 Scheduler time: 4.602016000077128 Scheduler overhead time: 0.1149949417449534 Adapter cache time: 0.01935449242591858 Engine time: 0.11525424150750041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 34560, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209040 . Total input tokens: 46497896 . Total output tokens: 41881751
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.016077573876828,
    "estimated_duration": 3600.0148876048856,
    "input_throughput": 4844.321911013736,
    "output_throughput": 4270.178174242931,
    "total_throughput": 9114.500085256666,
    "itl": 30.959566246646613,
    "ttft": 7354.1842103000035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 69999,
    "finished_requests": 69857,
    "scheduler_time": 41.45391557335112
}
#Debug simulation 
Total elapsed time: 5.016182533930987. Arrivals time: 0.1769714974798262 Scheduler time: 4.537042115814984 Scheduler overhead time: 0.11424392042681575 Adapter cache time: 0.01935359602794051 Engine time: 0.11414720909669995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 34560, 66, 34560, 66, 270, 270, 66, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 209040 . Total input tokens: 46497896 . Total output tokens: 41881751
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.056155824102461,
    "estimated_duration": 3600.024225011073,
    "input_throughput": 4844.309346264568,
    "output_throughput": 4270.167098654098,
    "total_throughput": 9114.476444918666,
    "itl": 30.95968956920156,
    "ttft": 7354.190078317001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 69999,
    "finished_requests": 69857,
    "scheduler_time": 41.454089500097005
}
#Debug simulation 
Total elapsed time: 5.05628455709666. Arrivals time: 0.17521955398842692 Scheduler time: 4.577955244574696 Scheduler overhead time: 0.1143205757252872 Adapter cache time: 0.019333111122250557 Engine time: 0.11514052376151085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 34560, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 208875 . Total input tokens: 46460653 . Total output tokens: 41848388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.012589629273862,
    "estimated_duration": 3600.008079618975,
    "input_throughput": 4828.4766632634255,
    "output_throughput": 4278.995118708291,
    "total_throughput": 9107.471781971715,
    "itl": 30.927659680009246,
    "ttft": 8181.3240757687245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 69963,
    "finished_requests": 69804,
    "scheduler_time": 41.55494795615958
}
#Debug simulation 
Total elapsed time: 5.012687379028648. Arrivals time: 0.1752498298883438 Scheduler time: 4.53474434511736 Scheduler overhead time: 0.11474072933197021 Adapter cache time: 0.018958517350256443 Engine time: 0.1146674957126379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 34560, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 208875 . Total input tokens: 46460653 . Total output tokens: 41848388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.032347488217056,
    "estimated_duration": 3600.01356685097,
    "input_throughput": 4828.469303576818,
    "output_throughput": 4278.988596555391,
    "total_throughput": 9107.457900132209,
    "itl": 30.927644977458254,
    "ttft": 8181.258097044127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 69963,
    "finished_requests": 69804,
    "scheduler_time": 41.55501263211349
}
#Debug simulation 
Total elapsed time: 5.032463217154145. Arrivals time: 0.1834157556295395 Scheduler time: 4.544162461999804 Scheduler overhead time: 0.11640075081959367 Adapter cache time: 0.019106403458863497 Engine time: 0.11480544321238995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 34560, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 208875 . Total input tokens: 46460653 . Total output tokens: 41848388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.019023159984499,
    "estimated_duration": 3600.0138130224136,
    "input_throughput": 4828.468973402735,
    "output_throughput": 4278.9883039551805,
    "total_throughput": 9107.457277357917,
    "itl": 30.927637529347237,
    "ttft": 8181.250451589678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 69963,
    "finished_requests": 69804,
    "scheduler_time": 41.55502072172965
}
#Debug simulation 
Total elapsed time: 5.019122750964016. Arrivals time: 0.1734499610029161 Scheduler time: 4.5407506031915545 Scheduler overhead time: 0.11431910702958703 Adapter cache time: 0.019110011868178844 Engine time: 0.11698341928422451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 34560, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 208875 . Total input tokens: 46460653 . Total output tokens: 41848388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.009637134149671,
    "estimated_duration": 3600.008328539263,
    "input_throughput": 4828.476329401475,
    "output_throughput": 4278.994822839893,
    "total_throughput": 9107.471152241367,
    "itl": 30.92759306793248,
    "ttft": 8181.355967711651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 69963,
    "finished_requests": 69804,
    "scheduler_time": 41.55493986654358
}
#Debug simulation 
Total elapsed time: 5.009757581166923. Arrivals time: 0.17711631674319506 Scheduler time: 4.527423873078078 Scheduler overhead time: 0.11438102647662163 Adapter cache time: 0.0189438508823514 Engine time: 0.11750411475077271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 34560, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 208875 . Total input tokens: 46460653 . Total output tokens: 41848388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.0185708976350725,
    "estimated_duration": 3600.014114054313,
    "input_throughput": 4828.468569647878,
    "output_throughput": 4278.987946147701,
    "total_throughput": 9107.456515795579,
    "itl": 30.92762859164676,
    "ttft": 8181.2680059876575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 69963,
    "finished_requests": 69804,
    "scheduler_time": 41.555012632113566
}
#Debug simulation 
Total elapsed time: 5.018667765893042. Arrivals time: 0.17650126898661256 Scheduler time: 4.537078723311424 Scheduler overhead time: 0.1149235600605607 Adapter cache time: 0.019035127013921738 Engine time: 0.11626749951392412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 34560, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 208875 . Total input tokens: 46460653 . Total output tokens: 41848388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.002216593828052,
    "estimated_duration": 3600.0056566131375,
    "input_throughput": 4828.479913099191,
    "output_throughput": 4278.9979987121405,
    "total_throughput": 9107.477911811331,
    "itl": 30.92761543203382,
    "ttft": 8181.2885185513815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 69963,
    "finished_requests": 69804,
    "scheduler_time": 41.5549074671044
}
#Debug simulation 
Total elapsed time: 5.00235840678215. Arrivals time: 0.1750070652924478 Scheduler time: 4.525464850012213 Scheduler overhead time: 0.1139564379118383 Adapter cache time: 0.019153472036123276 Engine time: 0.11428019450977445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 34560, 33, 34560, 33, 270, 270, 33, 270, 34560, 34560, 34560, 34560]
Prompts retrieved: 208875 . Total input tokens: 46460653 . Total output tokens: 41848388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.005917413160205,
    "estimated_duration": 3600.015150692978,
    "input_throughput": 4828.467179271171,
    "output_throughput": 4278.9867139961225,
    "total_throughput": 9107.453893267293,
    "itl": 30.927630410780655,
    "ttft": 8181.282189105543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 69963,
    "finished_requests": 69804,
    "scheduler_time": 41.555024848487385
}
#Debug simulation 
Total elapsed time: 5.006010465323925. Arrivals time: 0.1775345611386001 Scheduler time: 4.527176143601537 Scheduler overhead time: 0.11427750997245312 Adapter cache time: 0.01902806293219328 Engine time: 0.11362225143238902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 34560, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208365 . Total input tokens: 46352741 . Total output tokens: 41742568
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.061597982421517,
    "estimated_duration": 3599.9861617019537,
    "input_throughput": 4811.24071649528,
    "output_throughput": 4272.01197704861,
    "total_throughput": 9083.25269354389,
    "itl": 30.77591008096982,
    "ttft": 8252.237270380829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 69793,
    "finished_requests": 69634,
    "scheduler_time": 41.352821351702225
}
#Debug simulation 
Total elapsed time: 5.061755949165672. Arrivals time: 0.17806121706962585 Scheduler time: 4.57799214636907 Scheduler overhead time: 0.1152177038602531 Adapter cache time: 0.01930288504809141 Engine time: 0.11631284654140472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 34560, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208365 . Total input tokens: 46352741 . Total output tokens: 41742568
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.023186455946416,
    "estimated_duration": 3599.9921729385765,
    "input_throughput": 4811.232682726037,
    "output_throughput": 4272.004843678976,
    "total_throughput": 9083.237526405012,
    "itl": 30.77587499050728,
    "ttft": 8252.246946260022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 69793,
    "finished_requests": 69634,
    "scheduler_time": 41.35292243092803
}
#Debug simulation 
Total elapsed time: 5.023282086942345. Arrivals time: 0.17652455531060696 Scheduler time: 4.541299937758595 Scheduler overhead time: 0.11543518677353859 Adapter cache time: 0.01924235001206398 Engine time: 0.11595518980175257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 34560, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208365 . Total input tokens: 46352741 . Total output tokens: 41742568
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.036435274872929,
    "estimated_duration": 3599.9923485094137,
    "input_throughput": 4811.232448083274,
    "output_throughput": 4272.004635334237,
    "total_throughput": 9083.23708341751,
    "itl": 30.77588283854096,
    "ttft": 8252.250410562021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 69793,
    "finished_requests": 69634,
    "scheduler_time": 41.35292647573604
}
#Debug simulation 
Total elapsed time: 5.036562371067703. Arrivals time: 0.1785450461320579 Scheduler time: 4.552616880275309 Scheduler overhead time: 0.11451763287186623 Adapter cache time: 0.01915808394551277 Engine time: 0.11674557952210307 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 34560, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208365 . Total input tokens: 46352741 . Total output tokens: 41742568
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.024726124014705,
    "estimated_duration": 3599.989605425809,
    "input_throughput": 4811.236114097427,
    "output_throughput": 4272.007890473045,
    "total_throughput": 9083.244004570473,
    "itl": 30.775898171701634,
    "ttft": 8252.295824532905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 69793,
    "finished_requests": 69634,
    "scheduler_time": 41.35291033747898
}
#Debug simulation 
Total elapsed time: 5.024817555677146. Arrivals time: 0.17721620248630643 Scheduler time: 4.544819527771324 Scheduler overhead time: 0.11434235284104943 Adapter cache time: 0.019200443755835295 Engine time: 0.11480269860476255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 34560, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208365 . Total input tokens: 46352741 . Total output tokens: 41742568
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.032000734936446,
    "estimated_duration": 3599.9932054132455,
    "input_throughput": 4811.231302869023,
    "output_throughput": 4272.003618472,
    "total_throughput": 9083.234921341023,
    "itl": 30.775876375400834,
    "ttft": 8252.230521988946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 69793,
    "finished_requests": 69634,
    "scheduler_time": 41.35293861016011
}
#Debug simulation 
Total elapsed time: 5.032098046969622. Arrivals time: 0.1757940393872559 Scheduler time: 4.551230174489319 Scheduler overhead time: 0.11573724867776036 Adapter cache time: 0.01926677767187357 Engine time: 0.11512357834726572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 34560, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208365 . Total input tokens: 46352741 . Total output tokens: 41742568
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.013508388306946,
    "estimated_duration": 3599.9844415563175,
    "input_throughput": 4811.243015403749,
    "output_throughput": 4272.014018302643,
    "total_throughput": 9083.257033706392,
    "itl": 30.775837903129055,
    "ttft": 8252.270461922133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 69793,
    "finished_requests": 69634,
    "scheduler_time": 41.35281326208592
}
#Debug simulation 
Total elapsed time: 5.013607207220048. Arrivals time: 0.17839906178414822 Scheduler time: 4.529848190024495 Scheduler overhead time: 0.1153758536092937 Adapter cache time: 0.01938445633277297 Engine time: 0.11600958509370685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 34560, 66, 34560, 66, 135, 135, 66, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208365 . Total input tokens: 46352741 . Total output tokens: 41742568
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0515030096285045,
    "estimated_duration": 3599.995658443284,
    "input_throughput": 4811.228024505373,
    "output_throughput": 4272.000707537045,
    "total_throughput": 9083.228732042418,
    "itl": 30.77586409743927,
    "ttft": 8252.26058012596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 69793,
    "finished_requests": 69634,
    "scheduler_time": 41.35298314402368
}
#Debug simulation 
Total elapsed time: 5.051602108869702. Arrivals time: 0.17847492918372154 Scheduler time: 4.570607907604426 Scheduler overhead time: 0.11484876647591591 Adapter cache time: 0.01915027853101492 Engine time: 0.11389443930238485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 34560, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208200 . Total input tokens: 46312517 . Total output tokens: 41708970
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.036059758160263,
    "estimated_duration": 3600.0300565330613,
    "input_throughput": 4824.599441463161,
    "output_throughput": 4266.902153253989,
    "total_throughput": 9091.50159471715,
    "itl": 30.662575946194686,
    "ttft": 6453.966398086631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 69715,
    "finished_requests": 69591,
    "scheduler_time": 41.18326404249209
}
#Debug simulation 
Total elapsed time: 5.036215799860656. Arrivals time: 0.17347379121929407 Scheduler time: 4.5583579507656395 Scheduler overhead time: 0.11507902154698968 Adapter cache time: 0.018880336545407772 Engine time: 0.11532044457271695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 34560, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208200 . Total input tokens: 46312517 . Total output tokens: 41708970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0660096113570035,
    "estimated_duration": 3600.0042249726066,
    "input_throughput": 4824.634060014794,
    "output_throughput": 4266.932770090537,
    "total_throughput": 9091.56683010533,
    "itl": 30.66269849046082,
    "ttft": 6402.318605253895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 69715,
    "finished_requests": 69591,
    "scheduler_time": 41.18302856866466
}
#Debug simulation 
Total elapsed time: 5.066116247326136. Arrivals time: 0.17794727766886353 Scheduler time: 4.583483656868339 Scheduler overhead time: 0.11526831146329641 Adapter cache time: 0.01880365377292037 Engine time: 0.11556409718468785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 34560, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208200 . Total input tokens: 46312517 . Total output tokens: 41708970
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.054183195810765,
    "estimated_duration": 3600.004316876385,
    "input_throughput": 4824.633936847692,
    "output_throughput": 4266.932661160878,
    "total_throughput": 9091.566598008569,
    "itl": 30.66268680513538,
    "ttft": 6402.319360369827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 69715,
    "finished_requests": 69591,
    "scheduler_time": 41.18302856866467
}
#Debug simulation 
Total elapsed time: 5.054288446903229. Arrivals time: 0.17932726629078388 Scheduler time: 4.566971725784242 Scheduler overhead time: 0.1153459451161325 Adapter cache time: 0.01876519015058875 Engine time: 0.11931233387440443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 34560, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208200 . Total input tokens: 46312517 . Total output tokens: 41708970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.03819576324895,
    "estimated_duration": 3600.001554600418,
    "input_throughput": 4824.637638782308,
    "output_throughput": 4266.935935172114,
    "total_throughput": 9091.573573954423,
    "itl": 30.662711951097297,
    "ttft": 6402.349040229119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 69715,
    "finished_requests": 69591,
    "scheduler_time": 41.18300834462453
}
#Debug simulation 
Total elapsed time: 5.03831990621984. Arrivals time: 0.1731392377987504 Scheduler time: 4.56119011901319 Scheduler overhead time: 0.11545217828825116 Adapter cache time: 0.018660156056284904 Engine time: 0.11499082343652844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 34560, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208200 . Total input tokens: 46312517 . Total output tokens: 41708970
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.068449187092483,
    "estimated_duration": 3600.0050926810045,
    "input_throughput": 4824.632897134358,
    "output_throughput": 4266.931741632714,
    "total_throughput": 9091.564638767073,
    "itl": 30.662671285311923,
    "ttft": 6402.351876600325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 69715,
    "finished_requests": 69591,
    "scheduler_time": 41.183028609639564
}
#Debug simulation 
Total elapsed time: 5.068541957065463. Arrivals time: 0.1756236245855689 Scheduler time: 4.585886520799249 Scheduler overhead time: 0.1159529029391706 Adapter cache time: 0.018969228491187096 Engine time: 0.11644093040376902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 34560, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208200 . Total input tokens: 46312517 . Total output tokens: 41708970
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.050704220775515,
    "estimated_duration": 3600.0289582714017,
    "input_throughput": 4824.600913304819,
    "output_throughput": 4266.903454958808,
    "total_throughput": 9091.504368263626,
    "itl": 30.662606655190434,
    "ttft": 6453.972257821753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 69715,
    "finished_requests": 69591,
    "scheduler_time": 41.18327597204174
}
#Debug simulation 
Total elapsed time: 5.050829804036766. Arrivals time: 0.17692007683217525 Scheduler time: 4.568560344632715 Scheduler overhead time: 0.11564404098317027 Adapter cache time: 0.018920170608907938 Engine time: 0.11622093059122562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 34560, 33, 34560, 33, 135, 135, 33, 135, 34560, 34560, 34560, 34560]
Prompts retrieved: 208200 . Total input tokens: 46312517 . Total output tokens: 41708970
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.058627592865378,
    "estimated_duration": 3600.006830055235,
    "input_throughput": 4824.630568751869,
    "output_throughput": 4266.929682398496,
    "total_throughput": 9091.560251150366,
    "itl": 30.66270861103872,
    "ttft": 6402.328889948662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 69715,
    "finished_requests": 69591,
    "scheduler_time": 41.18306905772004
}
#Debug simulation 
Total elapsed time: 5.058730530086905. Arrivals time: 0.17651419527828693 Scheduler time: 4.577142871916294 Scheduler overhead time: 0.11540508922189474 Adapter cache time: 0.018961566034704447 Engine time: 0.1160211218520999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 34560, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 34560]
Prompts retrieved: 207855 . Total input tokens: 46229692 . Total output tokens: 41647429
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.0587655352428555,
    "estimated_duration": 3600.01095980351,
    "input_throughput": 4782.4626625413675,
    "output_throughput": 4283.770014089545,
    "total_throughput": 9066.232676630912,
    "itl": 30.65318881652176,
    "ttft": 7807.8440415435925,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 69614,
    "finished_requests": 69463,
    "scheduler_time": 41.417597876362
}
#Debug simulation 
Total elapsed time: 5.0588617650792. Arrivals time: 0.1787632037885487 Scheduler time: 4.573581958655268 Scheduler overhead time: 0.11558610200881958 Adapter cache time: 0.018951193429529667 Engine time: 0.11716081807389855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 34560, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 34560]
Prompts retrieved: 207855 . Total input tokens: 46229692 . Total output tokens: 41647429
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.0244657513685524,
    "estimated_duration": 3600.0170137126947,
    "input_throughput": 4782.482397838477,
    "output_throughput": 4283.763365911344,
    "total_throughput": 9066.245763749821,
    "itl": 30.652988394103048,
    "ttft": 7756.140115074766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 69614,
    "finished_requests": 69464,
    "scheduler_time": 41.417674727714164
}
#Debug simulation 
Total elapsed time: 5.024586453102529. Arrivals time: 0.17555321287363768 Scheduler time: 4.54171885875985 Scheduler overhead time: 0.11537287617102265 Adapter cache time: 0.018965830095112324 Engine time: 0.11768206162378192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 34560, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 34560]
Prompts retrieved: 207855 . Total input tokens: 46229692 . Total output tokens: 41647429
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.033579993061721,
    "estimated_duration": 3600.0170786669228,
    "input_throughput": 4782.482311549315,
    "output_throughput": 4283.763288620449,
    "total_throughput": 9066.245600169765,
    "itl": 30.652987051325955,
    "ttft": 7756.128343902067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 69614,
    "finished_requests": 69464,
    "scheduler_time": 41.41767472771411
}
#Debug simulation 
Total elapsed time: 5.033672069199383. Arrivals time: 0.16080083046108484 Scheduler time: 4.567665835376829 Scheduler overhead time: 0.11604170920327306 Adapter cache time: 0.018906314857304096 Engine time: 0.11521538067609072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 34560, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 34560]
Prompts retrieved: 207855 . Total input tokens: 46229692 . Total output tokens: 41647429
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 5.0171371810138226,
    "estimated_duration": 3600.013073548635,
    "input_throughput": 4782.459854521805,
    "output_throughput": 4283.767498877018,
    "total_throughput": 9066.227353398823,
    "itl": 30.653157613923746,
    "ttft": 7807.825718065894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 69614,
    "finished_requests": 69463,
    "scheduler_time": 41.41761409656897
}
#Debug simulation 
Total elapsed time: 5.017230290919542. Arrivals time: 0.162407701369375 Scheduler time: 4.549667039886117 Scheduler overhead time: 0.11505092587321997 Adapter cache time: 0.018886596895754337 Engine time: 0.1163257509469986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 34560, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 34560]
Prompts retrieved: 207855 . Total input tokens: 46229692 . Total output tokens: 41647429
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 5.054972150828689,
    "estimated_duration": 3600.018053578215,
    "input_throughput": 4782.48101641803,
    "output_throughput": 4283.762128545933,
    "total_throughput": 9066.243144963963,
    "itl": 30.652988476873695,
    "ttft": 7756.1517394197535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 69614,
    "finished_requests": 69464,
    "scheduler_time": 41.41769094792116
}
#Debug simulation 
Total elapsed time: 5.055064043030143. Arrivals time: 0.16143419407308102 Scheduler time: 4.587045245803893 Scheduler overhead time: 0.11592847621068358 Adapter cache time: 0.018834753427654505 Engine time: 0.11692608799785376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 34560, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 34560]
Prompts retrieved: 207855 . Total input tokens: 46229692 . Total output tokens: 41647429
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 5.054154724813998,
    "estimated_duration": 3600.009709896946,
    "input_throughput": 4782.464322990077,
    "output_throughput": 4283.771501394495,
    "total_throughput": 9066.235824384572,
    "itl": 30.653156571201045,
    "ttft": 7807.86185094152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 69614,
    "finished_requests": 69463,
    "scheduler_time": 41.41759379057939
}
#Debug simulation 
Total elapsed time: 5.05425790278241. Arrivals time: 0.17639161460101604 Scheduler time: 4.571761288680136 Scheduler overhead time: 0.11600626586005092 Adapter cache time: 0.018960665445774794 Engine time: 0.11608532909303904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 34560, 33, 34560, 33, 66, 66, 33, 66, 34560, 34560, 34560, 34560]
Prompts retrieved: 207855 . Total input tokens: 46229692 . Total output tokens: 41647429
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 5.070302908308804,
    "estimated_duration": 3600.0190129601106,
    "input_throughput": 4782.479741917621,
    "output_throughput": 4283.760986950898,
    "total_throughput": 9066.240728868519,
    "itl": 30.653005468589477,
    "ttft": 7756.159467477734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 69614,
    "finished_requests": 69464,
    "scheduler_time": 41.41769899656225
}
#Debug simulation 
Total elapsed time: 5.070412594359368. Arrivals time: 0.1797877843491733 Scheduler time: 4.581859217956662 Scheduler overhead time: 0.11742872232571244 Adapter cache time: 0.019018865656107664 Engine time: 0.11734205763787031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 168480 . Total input tokens: 37447136 . Total output tokens: 33744076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 4.231493417173624,
    "estimated_duration": 3600.030245247509,
    "input_throughput": 3876.107712823015,
    "output_throughput": 3482.7407399011977,
    "total_throughput": 7358.848452724213,
    "itl": 30.651646299862048,
    "ttft": 8015.211495186439,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 56500,
    "finished_requests": 56375,
    "scheduler_time": 29.70714527260411
}
#Debug simulation 
Total elapsed time: 4.231645619962364. Arrivals time: 0.14898598147556186 Scheduler time: 3.784702120348811 Scheduler overhead time: 0.1125748329795897 Adapter cache time: 0.01923932135105133 Engine time: 0.11219291528686881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 168480 . Total input tokens: 37447136 . Total output tokens: 33744076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 4.239529339130968,
    "estimated_duration": 3600.0009004820104,
    "input_throughput": 3875.9715304881565,
    "output_throughput": 3482.6566288695435,
    "total_throughput": 7358.6281593577005,
    "itl": 30.65158957480761,
    "ttft": 8142.60421836738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 56500,
    "finished_requests": 56373,
    "scheduler_time": 29.70685004259217
}
#Debug simulation 
Total elapsed time: 4.239658005069941. Arrivals time: 0.15140037890523672 Scheduler time: 3.788877431768924 Scheduler overhead time: 0.1133743398822844 Adapter cache time: 0.019439157098531723 Engine time: 0.11253738263621926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 168480 . Total input tokens: 37447136 . Total output tokens: 33744076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 4.217296939808875,
    "estimated_duration": 3600.0028460429853,
    "input_throughput": 3875.9694357845488,
    "output_throughput": 3482.6547467263576,
    "total_throughput": 7358.624182510906,
    "itl": 30.651599298524406,
    "ttft": 8142.633019244908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 56500,
    "finished_requests": 56373,
    "scheduler_time": 29.70687026663234
}
#Debug simulation 
Total elapsed time: 4.217389353085309. Arrivals time: 0.1498487493954599 Scheduler time: 3.770083785522729 Scheduler overhead time: 0.11230347538366914 Adapter cache time: 0.019138493575155735 Engine time: 0.11202993150800467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 168480 . Total input tokens: 37447136 . Total output tokens: 33744076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 4.214711971115321,
    "estimated_duration": 3599.9985859230983,
    "input_throughput": 3875.9740224792604,
    "output_throughput": 3482.6588679854062,
    "total_throughput": 7358.632890464666,
    "itl": 30.651592997232797,
    "ttft": 8142.617237831177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 56500,
    "finished_requests": 56373,
    "scheduler_time": 29.706841078014882
}
#Debug simulation 
Total elapsed time: 4.214831079822034. Arrivals time: 0.14714507944881916 Scheduler time: 3.771904102060944 Scheduler overhead time: 0.11269743461161852 Adapter cache time: 0.019137129187583923 Engine time: 0.11062515852972865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 168480 . Total input tokens: 37447136 . Total output tokens: 33744076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 4.200729071162641,
    "estimated_duration": 3600.003064631384,
    "input_throughput": 3875.9692004397625,
    "output_throughput": 3482.6545352632256,
    "total_throughput": 7358.623735702988,
    "itl": 30.651589101633824,
    "ttft": 8142.629796465071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 56500,
    "finished_requests": 56373,
    "scheduler_time": 29.7068581322083
}
#Debug simulation 
Total elapsed time: 4.2008176618255675. Arrivals time: 0.15026913164183497 Scheduler time: 3.7547848974354565 Scheduler overhead time: 0.11232707230374217 Adapter cache time: 0.01921100215986371 Engine time: 0.11076543154194951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 168480 . Total input tokens: 37447136 . Total output tokens: 33744076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 4.189265510067344,
    "estimated_duration": 3600.029350932859,
    "input_throughput": 3876.108675720696,
    "output_throughput": 3482.741605079162,
    "total_throughput": 7358.850280799858,
    "itl": 30.651660145728734,
    "ttft": 8015.201737142139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 56500,
    "finished_requests": 56375,
    "scheduler_time": 29.70713309720513
}
#Debug simulation 
Total elapsed time: 4.189359048847109. Arrivals time: 0.14883032254874706 Scheduler time: 3.7444394854828715 Scheduler overhead time: 0.11199290445074439 Adapter cache time: 0.01925017824396491 Engine time: 0.11121443752199411 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 4320, 4320, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 4320, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 168480 . Total input tokens: 37447136 . Total output tokens: 33744076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 4.170667042024434,
    "estimated_duration": 3600.008931093845,
    "input_throughput": 3875.962884281039,
    "output_throughput": 3482.648860037834,
    "total_throughput": 7358.611744318872,
    "itl": 30.651629447566812,
    "ttft": 8142.638325958366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 56500,
    "finished_requests": 56373,
    "scheduler_time": 29.70692280816202
}
#Debug simulation 
Total elapsed time: 4.170764161273837. Arrivals time: 0.14727592654526234 Scheduler time: 3.7280879165045917 Scheduler overhead time: 0.11270689778029919 Adapter cache time: 0.01904080482199788 Engine time: 0.11009910237044096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 152280 . Total input tokens: 33836170 . Total output tokens: 30528295
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.726135095115751,
    "estimated_duration": 3600.0137444106094,
    "input_throughput": 3504.7346748576533,
    "output_throughput": 3099.230667472537,
    "total_throughput": 6603.96534233019,
    "itl": 28.03465074415152,
    "ttft": 6823.322620756414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 50997,
    "finished_requests": 50900,
    "scheduler_time": 22.165216637713073
}
#Debug simulation 
Total elapsed time: 3.7262401059269905. Arrivals time: 0.13129072217270732 Scheduler time: 3.281749552115798 Scheduler overhead time: 0.11795789794996381 Adapter cache time: 0.021387893240898848 Engine time: 0.11700760992243886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 152280 . Total input tokens: 33836170 . Total output tokens: 30528295
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.7275158520787954,
    "estimated_duration": 3600.02345701227,
    "input_throughput": 3504.7252193382024,
    "output_throughput": 3099.2223059734283,
    "total_throughput": 6603.947525311631,
    "itl": 28.034747032606987,
    "ttft": 6893.747294362401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 50997,
    "finished_requests": 50900,
    "scheduler_time": 22.16532989233837
}
#Debug simulation 
Total elapsed time: 3.7276083077304065. Arrivals time: 0.13130964944139123 Scheduler time: 3.2840389078482985 Scheduler overhead time: 0.11728771543130279 Adapter cache time: 0.021516060922294855 Engine time: 0.11664720764383674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 152280 . Total input tokens: 33836170 . Total output tokens: 30528295
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.741186172235757,
    "estimated_duration": 3600.020300041662,
    "input_throughput": 3504.7282927415677,
    "output_throughput": 3099.225023778583,
    "total_throughput": 6603.95331652015,
    "itl": 28.034703647615277,
    "ttft": 6893.743787097118,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 50997,
    "finished_requests": 50900,
    "scheduler_time": 22.16529348906594
}
#Debug simulation 
Total elapsed time: 3.7413011733442545. Arrivals time: 0.13408226100727916 Scheduler time: 3.2947683772072196 Scheduler overhead time: 0.11753503186628222 Adapter cache time: 0.021626146510243416 Engine time: 0.11637227097526193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 152280 . Total input tokens: 33836170 . Total output tokens: 30528295
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.7409023200161755,
    "estimated_duration": 3600.014765489979,
    "input_throughput": 3504.7336808027662,
    "output_throughput": 3099.2297884315603,
    "total_throughput": 6603.963469234326,
    "itl": 28.034639129766006,
    "ttft": 6823.338380416845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 50997,
    "finished_requests": 50900,
    "scheduler_time": 22.165192368864876
}
#Debug simulation 
Total elapsed time: 3.7410020460374653. Arrivals time: 0.13150686351582408 Scheduler time: 3.297256793361157 Scheduler overhead time: 0.11795784020796418 Adapter cache time: 0.02136257803067565 Engine time: 0.11603463627398014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 152280 . Total input tokens: 33836170 . Total output tokens: 30528295
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.7229468640871346,
    "estimated_duration": 3600.0269236427584,
    "input_throughput": 3504.721844478081,
    "output_throughput": 3099.2193215905986,
    "total_throughput": 6603.94116606868,
    "itl": 28.034804754163876,
    "ttft": 6893.715324932618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 50997,
    "finished_requests": 50900,
    "scheduler_time": 22.165366295610642
}
#Debug simulation 
Total elapsed time: 3.723040542099625. Arrivals time: 0.13144329097121954 Scheduler time: 3.278722697403282 Scheduler overhead time: 0.11780178407207131 Adapter cache time: 0.021517178043723106 Engine time: 0.11683086957782507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 152280 . Total input tokens: 33836170 . Total output tokens: 30528295
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.7512994091957808,
    "estimated_duration": 3600.0142143597545,
    "input_throughput": 3504.7342173463862,
    "output_throughput": 3099.230262896134,
    "total_throughput": 6603.96448024252,
    "itl": 28.034655846089354,
    "ttft": 6823.305913928751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 50997,
    "finished_requests": 50900,
    "scheduler_time": 22.165216637713094
}
#Debug simulation 
Total elapsed time: 3.7514016539789736. Arrivals time: 0.13444466749206185 Scheduler time: 3.300839328672737 Scheduler overhead time: 0.11883630370721221 Adapter cache time: 0.021452005486935377 Engine time: 0.11820316314697266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [5 5 6]
Adapter prompts. [8640, 1080, 1080, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 1080, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 152280 . Total input tokens: 33836170 . Total output tokens: 30528295
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.739643592853099,
    "estimated_duration": 3600.0269181682593,
    "input_throughput": 3504.7218498076513,
    "output_throughput": 3099.2193263035283,
    "total_throughput": 6603.94117611118,
    "itl": 28.034789436013266,
    "ttft": 6893.720377239234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 50997,
    "finished_requests": 50900,
    "scheduler_time": 22.16535903998057
}
#Debug simulation 
Total elapsed time: 3.7397390487603843. Arrivals time: 0.13088149018585682 Scheduler time: 3.2952621458098292 Scheduler overhead time: 0.11702415021136403 Adapter cache time: 0.02160434192046523 Engine time: 0.11787329148501158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 17280, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 149580 . Total input tokens: 33255814 . Total output tokens: 29979130
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.6763044740073383,
    "estimated_duration": 3599.902269910901,
    "input_throughput": 3439.421148593139,
    "output_throughput": 3059.083045682949,
    "total_throughput": 6498.504194276088,
    "itl": 27.485836389259845,
    "ttft": 7226.9061047980085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 50129,
    "finished_requests": 50029,
    "scheduler_time": 21.116286712898276
}
#Debug simulation 
Total elapsed time: 3.676419819239527. Arrivals time: 0.1264669317752123 Scheduler time: 3.237296599894762 Scheduler overhead time: 0.11834614165127277 Adapter cache time: 0.02094638580456376 Engine time: 0.11503451969474554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 17280, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 149580 . Total input tokens: 33255814 . Total output tokens: 29979130
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.696170412003994,
    "estimated_duration": 3599.908975618163,
    "input_throughput": 3439.4147418335438,
    "output_throughput": 3059.077347395705,
    "total_throughput": 6498.492089229248,
    "itl": 27.48579708512459,
    "ttft": 7226.880986153234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 50129,
    "finished_requests": 50029,
    "scheduler_time": 21.116347344043977
}
#Debug simulation 
Total elapsed time: 3.6963133551180363. Arrivals time: 0.12917482666671276 Scheduler time: 3.2527954494580626 Scheduler overhead time: 0.11866300040856004 Adapter cache time: 0.02111778547987342 Engine time: 0.11711421282961965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 17280, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 149580 . Total input tokens: 33255814 . Total output tokens: 29979130
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.697282699868083,
    "estimated_duration": 3599.909043060807,
    "input_throughput": 3439.4146773976863,
    "output_throughput": 3059.0772900852944,
    "total_throughput": 6498.491967482981,
    "itl": 27.485798617027278,
    "ttft": 7226.890687366256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 50129,
    "finished_requests": 50029,
    "scheduler_time": 21.116343299235954
}
#Debug simulation 
Total elapsed time: 3.6973768728785217. Arrivals time: 0.12840727344155312 Scheduler time: 3.25268812244758 Scheduler overhead time: 0.11909757787361741 Adapter cache time: 0.021105837542563677 Engine time: 0.11821709759533405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 17280, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 149580 . Total input tokens: 33255814 . Total output tokens: 29979130
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6915825624018908,
    "estimated_duration": 3599.9031695559847,
    "input_throughput": 3439.4202890538177,
    "output_throughput": 3059.082281193213,
    "total_throughput": 6498.502570247031,
    "itl": 27.485801806486897,
    "ttft": 7226.8776317316815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 50129,
    "finished_requests": 50029,
    "scheduler_time": 21.1162867128983
}
#Debug simulation 
Total elapsed time: 3.6916936561465263. Arrivals time: 0.12700116354972124 Scheduler time: 3.249638147652149 Scheduler overhead time: 0.11911115795373917 Adapter cache time: 0.021196499932557344 Engine time: 0.11694812355563045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 17280, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 149580 . Total input tokens: 33255814 . Total output tokens: 29979130
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.685838826932013,
    "estimated_duration": 3599.9098523072325,
    "input_throughput": 3439.413904229983,
    "output_throughput": 3059.07660241603,
    "total_throughput": 6498.490506646012,
    "itl": 27.485797362370008,
    "ttft": 7226.909826126829,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 50129,
    "finished_requests": 50029,
    "scheduler_time": 21.11634329923601
}
#Debug simulation 
Total elapsed time: 3.6859407611191273. Arrivals time: 0.12692585168406367 Scheduler time: 3.246773248538375 Scheduler overhead time: 0.11875772895291448 Adapter cache time: 0.020920221228152514 Engine time: 0.11488199280574918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 17280, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 149580 . Total input tokens: 33255814 . Total output tokens: 29979130
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.7013394413515925,
    "estimated_duration": 3599.9014849505,
    "input_throughput": 3439.4218985607185,
    "output_throughput": 3059.0837127176064,
    "total_throughput": 6498.505611278325,
    "itl": 27.485829047845865,
    "ttft": 7226.859136757109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 50129,
    "finished_requests": 50029,
    "scheduler_time": 21.116286712898297
}
#Debug simulation 
Total elapsed time: 3.701431707944721. Arrivals time: 0.1286715492606163 Scheduler time: 3.259650924708694 Scheduler overhead time: 0.11871116235852242 Adapter cache time: 0.02089904574677348 Engine time: 0.11583236092701554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [5 5 6]
Adapter prompts. [8640, 540, 540, 8640, 17280, 540, 17280, 540, 8640, 8640, 540, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 149580 . Total input tokens: 33255814 . Total output tokens: 29979130
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.7088320697657764,
    "estimated_duration": 3599.9123331098704,
    "input_throughput": 3439.411534031407,
    "output_throughput": 3059.0744943187756,
    "total_throughput": 6498.486028350182,
    "itl": 27.485890010333584,
    "ttft": 7226.9018775968125,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 50129,
    "finished_requests": 50029,
    "scheduler_time": 21.116375657700402
}
#Debug simulation 
Total elapsed time: 3.7089210860431194. Arrivals time: 0.12710238387808204 Scheduler time: 3.2647019485011697 Scheduler overhead time: 0.11997471563518047 Adapter cache time: 0.020920658018440008 Engine time: 0.11824919562786818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 17280, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 148230 . Total input tokens: 32967431 . Total output tokens: 29691931
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.690851639956236,
    "estimated_duration": 3599.9728107726473,
    "input_throughput": 3415.5505183832165,
    "output_throughput": 3060.972562633035,
    "total_throughput": 6476.523081016251,
    "itl": 27.299999184486463,
    "ttft": 6926.437332521384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 49700,
    "finished_requests": 49605,
    "scheduler_time": 20.98031870314076
}
#Debug simulation 
Total elapsed time: 3.690968464128673. Arrivals time: 0.12710233172401786 Scheduler time: 3.2476643659174442 Scheduler overhead time: 0.11889396980404854 Adapter cache time: 0.02028849022462964 Engine time: 0.11891871364787221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 17280, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 148230 . Total input tokens: 32967431 . Total output tokens: 29691931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.6989330276846886,
    "estimated_duration": 3599.9794107424773,
    "input_throughput": 3415.5442565334106,
    "output_throughput": 3060.966950843561,
    "total_throughput": 6476.5112073769715,
    "itl": 27.300038540056665,
    "ttft": 6926.304318931628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 49700,
    "finished_requests": 49605,
    "scheduler_time": 20.980391468710675
}
#Debug simulation 
Total elapsed time: 3.6990222870372236. Arrivals time: 0.12598948646336794 Scheduler time: 3.259200554341078 Scheduler overhead time: 0.11954810889437795 Adapter cache time: 0.020041198004037142 Engine time: 0.11618262017145753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 17280, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 148230 . Total input tokens: 32967431 . Total output tokens: 29691931
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.6793313561938703,
    "estimated_duration": 3599.979168378537,
    "input_throughput": 3415.544486480509,
    "output_throughput": 3060.967156919201,
    "total_throughput": 6476.51164339971,
    "itl": 27.300055958508462,
    "ttft": 6926.316648665675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 49700,
    "finished_requests": 49605,
    "scheduler_time": 20.980387464877577
}
#Debug simulation 
Total elapsed time: 3.6794229359366. Arrivals time: 0.12357748672366142 Scheduler time: 3.2426448771730065 Scheduler overhead time: 0.11938232509419322 Adapter cache time: 0.020125060342252254 Engine time: 0.11587940994650126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 17280, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 148230 . Total input tokens: 32967431 . Total output tokens: 29691931
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6901062303222716,
    "estimated_duration": 3599.9744774378755,
    "input_throughput": 3415.548937099982,
    "output_throughput": 3060.971145507284,
    "total_throughput": 6476.520082607266,
    "itl": 27.30002749196643,
    "ttft": 6926.396637553812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 49700,
    "finished_requests": 49605,
    "scheduler_time": 20.980322706973897
}
#Debug simulation 
Total elapsed time: 3.6902080760337412. Arrivals time: 0.12754908669739962 Scheduler time: 3.2474344237707555 Scheduler overhead time: 0.11906795995309949 Adapter cache time: 0.020077593624591827 Engine time: 0.11840162193402648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 17280, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 148230 . Total input tokens: 32967431 . Total output tokens: 29691931
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.7141626933589578,
    "estimated_duration": 3599.9802612626886,
    "input_throughput": 3415.5434495874797,
    "output_throughput": 3060.9662276689687,
    "total_throughput": 6476.509677256448,
    "itl": 27.30007357405401,
    "ttft": 6926.311550997469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 49700,
    "finished_requests": 49605,
    "scheduler_time": 20.98039555449363
}
#Debug simulation 
Total elapsed time: 3.7142612230964005. Arrivals time: 0.12712750723585486 Scheduler time: 3.267366567160934 Scheduler overhead time: 0.11877446202561259 Adapter cache time: 0.02009694091975689 Engine time: 0.1229453613050282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 17280, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 148230 . Total input tokens: 32967431 . Total output tokens: 29691931
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.6964223366230726,
    "estimated_duration": 3599.9715955397905,
    "input_throughput": 3415.55167136154,
    "output_throughput": 3060.9735959174186,
    "total_throughput": 6476.525267278958,
    "itl": 27.300007017497723,
    "ttft": 6926.442100312043,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 49700,
    "finished_requests": 49605,
    "scheduler_time": 20.980305734730578
}
#Debug simulation 
Total elapsed time: 3.6965147317387164. Arrivals time: 0.12438784120604396 Scheduler time: 3.2562621319666505 Scheduler overhead time: 0.12005035392940044 Adapter cache time: 0.020058443769812584 Engine time: 0.11737247370183468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [5 5 6]
Adapter prompts. [8640, 270, 270, 8640, 17280, 270, 17280, 270, 8640, 8640, 270, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 148230 . Total input tokens: 32967431 . Total output tokens: 29691931
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.6882154936902225,
    "estimated_duration": 3599.981492188893,
    "input_throughput": 3415.542281725383,
    "output_throughput": 3060.9651810459377,
    "total_throughput": 6476.507462771321,
    "itl": 27.30009503167623,
    "ttft": 6926.307346318633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 49700,
    "finished_requests": 49605,
    "scheduler_time": 20.980399599301684
}
#Debug simulation 
Total elapsed time: 3.688307709991932. Arrivals time: 0.12723669549450278 Scheduler time: 3.2465424360707402 Scheduler overhead time: 0.11935394816100597 Adapter cache time: 0.02026444161310792 Engine time: 0.1169349867850542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 17280, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147555 . Total input tokens: 32829816 . Total output tokens: 29546879
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.611516857985407,
    "estimated_duration": 3599.911456823675,
    "input_throughput": 3397.0407735500544,
    "output_throughput": 3005.2939161858694,
    "total_throughput": 6402.334689735923,
    "itl": 26.924063500617752,
    "ttft": 6956.036452006668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 49483,
    "finished_requests": 49388,
    "scheduler_time": 19.88241878262859
}
#Debug simulation 
Total elapsed time: 3.6116083110682666. Arrivals time: 0.12589764315634966 Scheduler time: 3.169884036295116 Scheduler overhead time: 0.11941700102761388 Adapter cache time: 0.019934857729822397 Engine time: 0.11834694817662239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 17280, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147555 . Total input tokens: 32829816 . Total output tokens: 29546879
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.639030239544809,
    "estimated_duration": 3599.9143516928434,
    "input_throughput": 3397.0380418215636,
    "output_throughput": 3005.291499480401,
    "total_throughput": 6402.329541301964,
    "itl": 26.924072736554656,
    "ttft": 6955.934355575186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 49483,
    "finished_requests": 49388,
    "scheduler_time": 19.88243500283579
}
#Debug simulation 
Total elapsed time: 3.639146520756185. Arrivals time: 0.12486078683286905 Scheduler time: 3.1951038180850446 Scheduler overhead time: 0.12113825976848602 Adapter cache time: 0.019785425625741482 Engine time: 0.119424132630229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 17280, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147555 . Total input tokens: 32829816 . Total output tokens: 29546879
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.63732697814703,
    "estimated_duration": 3599.9145174638466,
    "input_throughput": 3397.037885392737,
    "output_throughput": 3005.291361090952,
    "total_throughput": 6402.329246483689,
    "itl": 26.924075948669987,
    "ttft": 6955.94866858146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 49483,
    "finished_requests": 49388,
    "scheduler_time": 19.882439047643835
}
#Debug simulation 
Total elapsed time: 3.6374196242541075. Arrivals time: 0.127658287063241 Scheduler time: 3.1919041513465345 Scheduler overhead time: 0.12054979894310236 Adapter cache time: 0.019965967629104853 Engine time: 0.11890941020101309 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 17280, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147555 . Total input tokens: 32829816 . Total output tokens: 29546879
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6334029119461775,
    "estimated_duration": 3599.912786773726,
    "input_throughput": 3397.0395185489424,
    "output_throughput": 3005.292805911528,
    "total_throughput": 6402.332324460471,
    "itl": 26.924065394208824,
    "ttft": 6955.957319189424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 49483,
    "finished_requests": 49388,
    "scheduler_time": 19.882422868411602
}
#Debug simulation 
Total elapsed time: 3.633494430221617. Arrivals time: 0.12690237816423178 Scheduler time: 3.1891867318190634 Scheduler overhead time: 0.12052080873399973 Adapter cache time: 0.019933687523007393 Engine time: 0.1186641794629395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 17280, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147555 . Total input tokens: 32829816 . Total output tokens: 29546879
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.634487869683653,
    "estimated_duration": 3599.914963732883,
    "input_throughput": 3397.037464273672,
    "output_throughput": 3005.2909885353515,
    "total_throughput": 6402.3284528090235,
    "itl": 26.924047065276376,
    "ttft": 6955.960387183291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 49483,
    "finished_requests": 49388,
    "scheduler_time": 19.88245118206793
}
#Debug simulation 
Total elapsed time: 3.6346065108664334. Arrivals time: 0.1233210926875472 Scheduler time: 3.1969396038912237 Scheduler overhead time: 0.12061817245557904 Adapter cache time: 0.019930037669837475 Engine time: 0.1152733638882637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 17280, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147555 . Total input tokens: 32829816 . Total output tokens: 29546879
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.617392087355256,
    "estimated_duration": 3599.9111122215286,
    "input_throughput": 3397.0410987324008,
    "output_throughput": 3005.2942038681763,
    "total_throughput": 6402.335302600577,
    "itl": 26.924062781518327,
    "ttft": 6956.05220489699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 49483,
    "finished_requests": 49388,
    "scheduler_time": 19.88243496186078
}
#Debug simulation 
Total elapsed time: 3.617481917142868. Arrivals time: 0.1252687182277441 Scheduler time: 3.175921962596476 Scheduler overhead time: 0.12135948473587632 Adapter cache time: 0.019822360016405582 Engine time: 0.11625747615471482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [5 5 6]
Adapter prompts. [8640, 135, 135, 8640, 17280, 135, 17280, 135, 8640, 8640, 135, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147555 . Total input tokens: 32829816 . Total output tokens: 29546879
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.6143732741475105,
    "estimated_duration": 3599.9160281416116,
    "input_throughput": 3397.036459851263,
    "output_throughput": 3005.290099942969,
    "total_throughput": 6402.326559794232,
    "itl": 26.924018217785562,
    "ttft": 6955.9450912123275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 49483,
    "finished_requests": 49388,
    "scheduler_time": 19.882447137259902
}
#Debug simulation 
Total elapsed time: 3.614468422252685. Arrivals time: 0.12578315194696188 Scheduler time: 3.1715832417830825 Scheduler overhead time: 0.11991797341033816 Adapter cache time: 0.020015867426991463 Engine time: 0.11870355298742652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 17280, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147210 . Total input tokens: 32754165 . Total output tokens: 29476559
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.6646543899551034,
    "estimated_duration": 3600.0058302166303,
    "input_throughput": 3381.295079532554,
    "output_throughput": 3030.902591439252,
    "total_throughput": 6412.1976709718065,
    "itl": 26.9925857000176,
    "ttft": 6242.382871137647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 49372,
    "finished_requests": 49287,
    "scheduler_time": 20.249096351286966
}
#Debug simulation 
Total elapsed time: 3.664749220944941. Arrivals time: 0.1237975019030273 Scheduler time: 3.2247496051713824 Scheduler overhead time: 0.1201241142116487 Adapter cache time: 0.019501590635627508 Engine time: 0.11783752357587218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 17280, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147210 . Total input tokens: 32754165 . Total output tokens: 29476559
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.657123695127666,
    "estimated_duration": 3600.010320648834,
    "input_throughput": 3381.290861912336,
    "output_throughput": 3030.898810877145,
    "total_throughput": 6412.189672789481,
    "itl": 26.992598873385457,
    "ttft": 6242.384008236493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 49372,
    "finished_requests": 49287,
    "scheduler_time": 20.24914889281661
}
#Debug simulation 
Total elapsed time: 3.6572174951434135. Arrivals time: 0.12552566220983863 Scheduler time: 3.2138568870723248 Scheduler overhead time: 0.12091277679428458 Adapter cache time: 0.019351222552359104 Engine time: 0.1187543566338718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 17280, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147210 . Total input tokens: 32754165 . Total output tokens: 29476559
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.6395645779557526,
    "estimated_duration": 3600.010394586241,
    "input_throughput": 3381.2907924670144,
    "output_throughput": 3030.8987486282135,
    "total_throughput": 6412.189541095228,
    "itl": 26.99260190364463,
    "ttft": 6242.39100904066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 49372,
    "finished_requests": 49287,
    "scheduler_time": 20.249148892816578
}
#Debug simulation 
Total elapsed time: 3.6396489017643034. Arrivals time: 0.11448743753135204 Scheduler time: 3.210335344541818 Scheduler overhead time: 0.11975063476711512 Adapter cache time: 0.0192623483017087 Engine time: 0.11730564944446087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 17280, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147210 . Total input tokens: 32754165 . Total output tokens: 29476559
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.6321793030947447,
    "estimated_duration": 3600.0068931421033,
    "input_throughput": 3381.294081183168,
    "output_throughput": 3030.901696545529,
    "total_throughput": 6412.195777728697,
    "itl": 26.992586161996705,
    "ttft": 6242.416612620144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 49372,
    "finished_requests": 49287,
    "scheduler_time": 20.2491084857111
}
#Debug simulation 
Total elapsed time: 3.6322625149041414. Arrivals time: 0.11421863315626979 Scheduler time: 3.200532532297075 Scheduler overhead time: 0.11971856094896793 Adapter cache time: 0.01921761780977249 Engine time: 0.11985313845798373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 17280, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147210 . Total input tokens: 32754165 . Total output tokens: 29476559
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.6466034813784063,
    "estimated_duration": 3600.0107752019458,
    "input_throughput": 3381.2904349757573,
    "output_throughput": 3030.8984281825997,
    "total_throughput": 6412.188863158357,
    "itl": 26.992619142978015,
    "ttft": 6242.383046374212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 49372,
    "finished_requests": 49287,
    "scheduler_time": 20.249144848008505
}
#Debug simulation 
Total elapsed time: 3.6466876682825387. Arrivals time: 0.11356273991987109 Scheduler time: 3.218059895094484 Scheduler overhead time: 0.11999888392165303 Adapter cache time: 0.019464150071144104 Engine time: 0.11711590783670545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 17280, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147210 . Total input tokens: 32754165 . Total output tokens: 29476559
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.657540406100452,
    "estimated_duration": 3600.004584393325,
    "input_throughput": 3381.296249668901,
    "output_throughput": 3030.9036403182176,
    "total_throughput": 6412.199889987119,
    "itl": 26.992606577677062,
    "ttft": 6242.374194230732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 49372,
    "finished_requests": 49287,
    "scheduler_time": 20.24909226550407
}
#Debug simulation 
Total elapsed time: 3.6576274503022432. Arrivals time: 0.11445871042087674 Scheduler time: 3.2265304885804653 Scheduler overhead time: 0.12043547118082643 Adapter cache time: 0.019334242679178715 Engine time: 0.11859779478982091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [5 5 6]
Adapter prompts. [8640, 66, 66, 8640, 17280, 66, 17280, 66, 8640, 8640, 66, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147210 . Total input tokens: 32754165 . Total output tokens: 29476559
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.6540036080405116,
    "estimated_duration": 3600.0119970181745,
    "input_throughput": 3381.289287391935,
    "output_throughput": 3030.8973995191145,
    "total_throughput": 6412.18668691105,
    "itl": 26.992608235989955,
    "ttft": 6242.415869731975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 49372,
    "finished_requests": 49287,
    "scheduler_time": 20.249165031073815
}
#Debug simulation 
Total elapsed time: 3.6540841278620064. Arrivals time: 0.11375122703611851 Scheduler time: 3.224059844855219 Scheduler overhead time: 0.12031870894134045 Adapter cache time: 0.01935426238924265 Engine time: 0.11790278367698193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 17280, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147045 . Total input tokens: 32716093 . Total output tokens: 29443940
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.651088884100318,
    "estimated_duration": 3599.984411468801,
    "input_throughput": 3369.3187563140423,
    "output_throughput": 3037.2831518842145,
    "total_throughput": 6406.601908198257,
    "itl": 27.004460827015997,
    "ttft": 6981.141028500661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 49304,
    "finished_requests": 49209,
    "scheduler_time": 20.36927406122182
}
#Debug simulation 
Total elapsed time: 3.651177118998021. Arrivals time: 0.11981673305854201 Scheduler time: 3.215742639731616 Scheduler overhead time: 0.11989912111312151 Adapter cache time: 0.019084662199020386 Engine time: 0.11836030753329396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 17280, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147045 . Total input tokens: 32716093 . Total output tokens: 29443940
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.6579625750891864,
    "estimated_duration": 3599.9869998994664,
    "input_throughput": 3369.3163337364076,
    "output_throughput": 3037.2809680438704,
    "total_throughput": 6406.597301780278,
    "itl": 27.004480156345878,
    "ttft": 6981.133763800055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 49304,
    "finished_requests": 49209,
    "scheduler_time": 20.369278106029974
}
#Debug simulation 
Total elapsed time: 3.658047219272703. Arrivals time: 0.11502041853964329 Scheduler time: 3.2264613616280258 Scheduler overhead time: 0.12056320440024137 Adapter cache time: 0.019213948398828506 Engine time: 0.11834990372881293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 17280, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147045 . Total input tokens: 32716093 . Total output tokens: 29443940
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.661022508982569,
    "estimated_duration": 3599.987080370104,
    "input_throughput": 3369.3162584219613,
    "output_throughput": 3037.280900151422,
    "total_throughput": 6406.597158573383,
    "itl": 27.004481411624372,
    "ttft": 6981.122011794135,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 49304,
    "finished_requests": 49209,
    "scheduler_time": 20.369278106029967
}
#Debug simulation 
Total elapsed time: 3.661106426268816. Arrivals time: 0.11497507011517882 Scheduler time: 3.2296432638540864 Scheduler overhead time: 0.12022116733714938 Adapter cache time: 0.019359620288014412 Engine time: 0.11867507081478834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 17280, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147045 . Total input tokens: 32716093 . Total output tokens: 29443940
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.646699249278754,
    "estimated_duration": 3599.985757710975,
    "input_throughput": 3369.3174963315555,
    "output_throughput": 3037.2820160689785,
    "total_throughput": 6406.599512400534,
    "itl": 27.004499618740255,
    "ttft": 6981.145358743194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 49304,
    "finished_requests": 49209,
    "scheduler_time": 20.36927810602996
}
#Debug simulation 
Total elapsed time: 3.6467829369939864. Arrivals time: 0.11408872716128826 Scheduler time: 3.2193217743188143 Scheduler overhead time: 0.1202944959513843 Adapter cache time: 0.01921900687739253 Engine time: 0.11537985038012266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 17280, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147045 . Total input tokens: 32716093 . Total output tokens: 29443940
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.666028599254787,
    "estimated_duration": 3599.9879409887462,
    "input_throughput": 3369.3154529480457,
    "output_throughput": 3037.2801740543887,
    "total_throughput": 6406.595627002434,
    "itl": 27.004495330741904,
    "ttft": 6981.0788030412405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 49304,
    "finished_requests": 49209,
    "scheduler_time": 20.36928619564608
}
#Debug simulation 
Total elapsed time: 3.666120419278741. Arrivals time: 0.12712621875107288 Scheduler time: 3.222563966643065 Scheduler overhead time: 0.12105868384242058 Adapter cache time: 0.019366200547665358 Engine time: 0.11750637833029032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 17280, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147045 . Total input tokens: 32716093 . Total output tokens: 29443940
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.669299394823611,
    "estimated_duration": 3600.0127581350566,
    "input_throughput": 3369.4788921481177,
    "output_throughput": 3037.2945138295518,
    "total_throughput": 6406.773405977669,
    "itl": 27.004275052721006,
    "ttft": 6835.109574271216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 49304,
    "finished_requests": 49211,
    "scheduler_time": 20.3694528667617
}
#Debug simulation 
Total elapsed time: 3.669416958000511. Arrivals time: 0.12713584676384926 Scheduler time: 3.222587263677269 Scheduler overhead time: 0.12074683699756861 Adapter cache time: 0.01928694359958172 Engine time: 0.12108759675174952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [5 5 6]
Adapter prompts. [8640, 33, 33, 8640, 17280, 33, 17280, 33, 8640, 8640, 33, 8640, 17280, 17280, 17280, 17280]
Prompts retrieved: 147045 . Total input tokens: 32716093 . Total output tokens: 29443940
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.641784079372883,
    "estimated_duration": 3599.9883919322947,
    "input_throughput": 3369.3150308991662,
    "output_throughput": 3037.279793597079,
    "total_throughput": 6406.594824496246,
    "itl": 27.004479835730045,
    "ttft": 6981.0542333301355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 49304,
    "finished_requests": 49209,
    "scheduler_time": 20.369278106030013
}
#Debug simulation 
Total elapsed time: 3.6419039661996067. Arrivals time: 0.12335492810234427 Scheduler time: 3.204646456055343 Scheduler overhead time: 0.11981110787019134 Adapter cache time: 0.01921042986214161 Engine time: 0.11652120156213641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 130680 . Total input tokens: 29073814 . Total output tokens: 26166608
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.2880470491945744,
    "estimated_duration": 3599.9374844093995,
    "input_throughput": 3006.0185897298593,
    "output_throughput": 2658.4019976585937,
    "total_throughput": 5664.420587388453,
    "itl": 26.103450906043914,
    "ttft": 5388.415651029865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 43777,
    "finished_requests": 43712,
    "scheduler_time": 14.007466057317554
}
#Debug simulation 
Total elapsed time: 3.2881445977836847. Arrivals time: 0.11299637146294117 Scheduler time: 2.846447927877307 Scheduler overhead time: 0.12348432093858719 Adapter cache time: 0.023986111860722303 Engine time: 0.12115917634218931 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 130680 . Total input tokens: 29073814 . Total output tokens: 26166608
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.26242035580799,
    "estimated_duration": 3599.945228051776,
    "input_throughput": 3006.01212365011,
    "output_throughput": 2658.3962793176024,
    "total_throughput": 5664.408402967712,
    "itl": 26.10345888184516,
    "ttft": 5388.446627027039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 43777,
    "finished_requests": 43712,
    "scheduler_time": 14.007509048331011
}
#Debug simulation 
Total elapsed time: 3.2625234499573708. Arrivals time: 0.11355923861265182 Scheduler time: 2.823061839211732 Scheduler overhead time: 0.12205641157925129 Adapter cache time: 0.02378949662670493 Engine time: 0.12029705382883549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 130680 . Total input tokens: 29073814 . Total output tokens: 26166608
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.285541143734008,
    "estimated_duration": 3599.9450562859156,
    "input_throughput": 3006.0122670773712,
    "output_throughput": 2658.3964061589063,
    "total_throughput": 5664.4086732362775,
    "itl": 26.103462615436037,
    "ttft": 5388.441533159585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 43777,
    "finished_requests": 43712,
    "scheduler_time": 14.007505003522967
}
#Debug simulation 
Total elapsed time: 3.285653730854392. Arrivals time: 0.11193637177348137 Scheduler time: 2.847116561140865 Scheduler overhead time: 0.12244250532239676 Adapter cache time: 0.024057744070887566 Engine time: 0.12038844916969538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 130680 . Total input tokens: 29073814 . Total output tokens: 26166608
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.2835133289918303,
    "estimated_duration": 3599.936439536582,
    "input_throughput": 3006.0194622194617,
    "output_throughput": 2658.4027692533236,
    "total_throughput": 5664.422231472786,
    "itl": 26.103449234837814,
    "ttft": 5388.427719725665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 43777,
    "finished_requests": 43712,
    "scheduler_time": 14.007442622455324
}
#Debug simulation 
Total elapsed time: 3.2836027909070253. Arrivals time: 0.11224860930815339 Scheduler time: 2.846490108408034 Scheduler overhead time: 0.12216955795884132 Adapter cache time: 0.023779327049851418 Engine time: 0.1191091570071876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 130680 . Total input tokens: 29073814 . Total output tokens: 26166608
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.2886572489514947,
    "estimated_duration": 3599.944402087579,
    "input_throughput": 3006.012813343648,
    "output_throughput": 2658.3968892548414,
    "total_throughput": 5664.409702598489,
    "itl": 26.10344568631002,
    "ttft": 5388.453229770113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 43777,
    "finished_requests": 43712,
    "scheduler_time": 14.00749286909886
}
#Debug simulation 
Total elapsed time: 3.288760480005294. Arrivals time: 0.11542216408997774 Scheduler time: 2.845277321059257 Scheduler overhead time: 0.12213656632229686 Adapter cache time: 0.023736764676868916 Engine time: 0.1219864240847528 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 130680 . Total input tokens: 29073814 . Total output tokens: 26166608
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.264619041234255,
    "estimated_duration": 3599.9365255432067,
    "input_throughput": 3006.019390402199,
    "output_throughput": 2658.4027057410235,
    "total_throughput": 5664.422096143222,
    "itl": 26.10339549657991,
    "ttft": 5388.47938345268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 43777,
    "finished_requests": 43712,
    "scheduler_time": 14.007462012509542
}
#Debug simulation 
Total elapsed time: 3.2647066791541874. Arrivals time: 0.1129919895902276 Scheduler time: 2.8285906272940338 Scheduler overhead time: 0.1216422040015459 Adapter cache time: 0.023671027272939682 Engine time: 0.11794560728594661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.1_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 1.6]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 17280, 1080, 17280, 1080, 4320, 4320, 1080, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 130680 . Total input tokens: 29073814 . Total output tokens: 26166608
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.2725839470513165,
    "estimated_duration": 3599.945417773723,
    "input_throughput": 3006.0119652292437,
    "output_throughput": 2658.396139216557,
    "total_throughput": 5664.408104445801,
    "itl": 26.1034349221794,
    "ttft": 5388.3834304770435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 43777,
    "finished_requests": 43712,
    "scheduler_time": 14.007517137947149
}
#Debug simulation 
Total elapsed time: 3.2727011716924608. Arrivals time: 0.11099362978711724 Scheduler time: 2.8354210290126503 Scheduler overhead time: 0.12250622268766165 Adapter cache time: 0.023832260631024837 Engine time: 0.12046748120337725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 17280, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 127980 . Total input tokens: 28471683 . Total output tokens: 25626535
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.253644571173936,
    "estimated_duration": 3600.0234301859787,
    "input_throughput": 2947.0785970556603,
    "output_throughput": 2642.4903016557737,
    "total_throughput": 5589.5688987114345,
    "itl": 25.774428307606964,
    "ttft": 6501.6042033022595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 42918,
    "finished_requests": 42840,
    "scheduler_time": 13.478930205268703
}
#Debug simulation 
Total elapsed time: 3.2537337793037295. Arrivals time: 0.11023075506091118 Scheduler time: 2.815539874602109 Scheduler overhead time: 0.12360344920307398 Adapter cache time: 0.022732575424015522 Engine time: 0.121469481382519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 17280, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 127980 . Total input tokens: 28471683 . Total output tokens: 25626535
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.24383190786466,
    "estimated_duration": 3600.0242432985697,
    "input_throughput": 2947.077931419389,
    "output_throughput": 2642.4897048147554,
    "total_throughput": 5589.567636234145,
    "itl": 25.774395300281235,
    "ttft": 6501.547400219458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 42918,
    "finished_requests": 42840,
    "scheduler_time": 13.478922949638644
}
#Debug simulation 
Total elapsed time: 3.2439249670132995. Arrivals time: 0.11298112757503986 Scheduler time: 2.8017414403147995 Scheduler overhead time: 0.12409670371562243 Adapter cache time: 0.022782356943935156 Engine time: 0.12190016638487577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 17280, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 127980 . Total input tokens: 28471683 . Total output tokens: 25626535
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.2367484271526337,
    "estimated_duration": 3600.0247833942817,
    "input_throughput": 2947.07748928239,
    "output_throughput": 2642.489308373774,
    "total_throughput": 5589.5667976561635,
    "itl": 25.77439655100213,
    "ttft": 6501.557383951107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 42918,
    "finished_requests": 42840,
    "scheduler_time": 13.478931039254729
}
#Debug simulation 
Total elapsed time: 3.2368413181975484. Arrivals time: 0.10991232423111796 Scheduler time: 2.802601759787649 Scheduler overhead time: 0.12309836223721504 Adapter cache time: 0.022723595146089792 Engine time: 0.11831309786066413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 17280, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 127980 . Total input tokens: 28471683 . Total output tokens: 25626535
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.2432233639992774,
    "estimated_duration": 3600.02415814125,
    "input_throughput": 2947.078001131493,
    "output_throughput": 2642.4897673219302,
    "total_throughput": 5589.567768453423,
    "itl": 25.774430743147043,
    "ttft": 6501.5480485006165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 42918,
    "finished_requests": 42840,
    "scheduler_time": 13.478925451596684
}
#Debug simulation 
Total elapsed time: 3.2433429388329387. Arrivals time: 0.10900528728961945 Scheduler time: 2.806056962814182 Scheduler overhead time: 0.12334427190944552 Adapter cache time: 0.022631130646914244 Engine time: 0.1221132162027061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 17280, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 127980 . Total input tokens: 28471683 . Total output tokens: 25626535
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.2532976921647787,
    "estimated_duration": 3600.024769669805,
    "input_throughput": 2947.077500517617,
    "output_throughput": 2642.4893184478105,
    "total_throughput": 5589.566818965428,
    "itl": 25.77439787825095,
    "ttft": 6501.558162529886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 42918,
    "finished_requests": 42840,
    "scheduler_time": 13.478931039254727
}
#Debug simulation 
Total elapsed time: 3.2533871098421514. Arrivals time: 0.1107467282563448 Scheduler time: 2.814879945013672 Scheduler overhead time: 0.12434334680438042 Adapter cache time: 0.022581748198717833 Engine time: 0.12054843036457896 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 17280, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 127980 . Total input tokens: 28471683 . Total output tokens: 25626535
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.257903437130153,
    "estimated_duration": 3600.0190993685824,
    "input_throughput": 2947.0821423866446,
    "output_throughput": 2642.4934805675107,
    "total_throughput": 5589.575622954155,
    "itl": 25.7743495666747,
    "ttft": 6501.607997217517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 42918,
    "finished_requests": 42840,
    "scheduler_time": 13.478897137940379
}
#Debug simulation 
Total elapsed time: 3.2580550932325423. Arrivals time: 0.11307018902152777 Scheduler time: 2.815484249033034 Scheduler overhead time: 0.12481912644580007 Adapter cache time: 0.02264541294425726 Engine time: 0.12113619921728969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.05_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  1.6 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 17280, 540, 17280, 540, 4320, 4320, 540, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 127980 . Total input tokens: 28471683 . Total output tokens: 25626535
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.2519514872692525,
    "estimated_duration": 3600.0247877840006,
    "input_throughput": 2947.0774856888474,
    "output_throughput": 2642.4893051516333,
    "total_throughput": 5589.566790840481,
    "itl": 25.774398549870693,
    "ttft": 6501.5392251818985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 42918,
    "finished_requests": 42840,
    "scheduler_time": 13.478931039254729
}
#Debug simulation 
Total elapsed time: 3.252046230249107. Arrivals time: 0.10862731514498591 Scheduler time: 2.816473518963903 Scheduler overhead time: 0.12394633563235402 Adapter cache time: 0.022676675114780664 Engine time: 0.11973378667607903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 17280, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 126630 . Total input tokens: 28173045 . Total output tokens: 25353481
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.216759856790304,
    "estimated_duration": 3600.0082194531615,
    "input_throughput": 2901.6364305931297,
    "output_throughput": 2611.9995918865825,
    "total_throughput": 5513.636022479712,
    "itl": 25.485207456253562,
    "ttft": 7170.84682135989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 42420,
    "finished_requests": 42336,
    "scheduler_time": 12.737756625478514
}
#Debug simulation 
Total elapsed time: 3.21687432564795. Arrivals time: 0.1084023080766201 Scheduler time: 2.7789464280940592 Scheduler overhead time: 0.12482944782823324 Adapter cache time: 0.02207612246274948 Engine time: 0.12212048377841711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 17280, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 126630 . Total input tokens: 28173045 . Total output tokens: 25353481
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.190418252721429,
    "estimated_duration": 3600.02028356021,
    "input_throughput": 2901.626706855551,
    "output_throughput": 2611.9908387573764,
    "total_throughput": 5513.617545612928,
    "itl": 25.485143512503857,
    "ttft": 7170.771849408568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 42420,
    "finished_requests": 42336,
    "scheduler_time": 12.737886059335894
}
#Debug simulation 
Total elapsed time: 3.190515099093318. Arrivals time: 0.10998674063012004 Scheduler time: 2.753468668088317 Scheduler overhead time: 0.12432896951213479 Adapter cache time: 0.02194152493029833 Engine time: 0.12013749359175563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 17280, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 126630 . Total input tokens: 28173045 . Total output tokens: 25353481
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.2337957839481533,
    "estimated_duration": 3600.020791759088,
    "input_throughput": 2901.626297245851,
    "output_throughput": 2611.99047003428,
    "total_throughput": 5513.616767280131,
    "itl": 25.485143547298684,
    "ttft": 7170.76529091654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 42420,
    "finished_requests": 42336,
    "scheduler_time": 12.737906283376125
}
#Debug simulation 
Total elapsed time: 3.233895010780543. Arrivals time: 0.11024919338524342 Scheduler time: 2.79262163862586 Scheduler overhead time: 0.12496831500902772 Adapter cache time: 0.022234464064240456 Engine time: 0.12261021742597222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 17280, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 126630 . Total input tokens: 28173045 . Total output tokens: 25353481
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.2319815629161894,
    "estimated_duration": 3600.010284829848,
    "input_throughput": 2901.6347658833756,
    "output_throughput": 2611.9980933455686,
    "total_throughput": 5513.632859228944,
    "itl": 25.485169065837717,
    "ttft": 7170.802628905622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 42420,
    "finished_requests": 42336,
    "scheduler_time": 12.7377808943268
}
#Debug simulation 
Total elapsed time: 3.232091045938432. Arrivals time: 0.10906596342101693 Scheduler time: 2.791994533035904 Scheduler overhead time: 0.12482485547661781 Adapter cache time: 0.022383004426956177 Engine time: 0.12288029445335269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 17280, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 126630 . Total input tokens: 28173045 . Total output tokens: 25353481
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.222351476084441,
    "estimated_duration": 3600.0209941297953,
    "input_throughput": 2901.626134134534,
    "output_throughput": 2611.990323204481,
    "total_throughput": 5513.616457339015,
    "itl": 25.485078820232403,
    "ttft": 7170.766597677825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 42420,
    "finished_requests": 42336,
    "scheduler_time": 12.737882014527907
}
#Debug simulation 
Total elapsed time: 3.222470642067492. Arrivals time: 0.10837384220212698 Scheduler time: 2.7841919362545013 Scheduler overhead time: 0.12468183552846313 Adapter cache time: 0.022018393501639366 Engine time: 0.12235449301078916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 17280, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 126630 . Total input tokens: 28173045 . Total output tokens: 25353481
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.2252453761175275,
    "estimated_duration": 3600.0082068462507,
    "input_throughput": 2901.6364407544042,
    "output_throughput": 2611.9996010335744,
    "total_throughput": 5513.636041787979,
    "itl": 25.485208923028146,
    "ttft": 7170.853511701136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 42420,
    "finished_requests": 42336,
    "scheduler_time": 12.737759836300535
}
#Debug simulation 
Total elapsed time: 3.225336034782231. Arrivals time: 0.11075553530827165 Scheduler time: 2.7833004775457084 Scheduler overhead time: 0.12479216838255525 Adapter cache time: 0.022011070977896452 Engine time: 0.12389188818633556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.025_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   1.6  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 17280, 270, 17280, 270, 4320, 4320, 270, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 126630 . Total input tokens: 28173045 . Total output tokens: 25353481
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.2373465429991484,
    "estimated_duration": 3600.021423798111,
    "input_throughput": 2901.6257878208135,
    "output_throughput": 2611.9900114592574,
    "total_throughput": 5513.615799280071,
    "itl": 25.48506599272421,
    "ttft": 7170.8032614287795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 42420,
    "finished_requests": 42336,
    "scheduler_time": 12.737883682499925
}
#Debug simulation 
Total elapsed time: 3.2374471961520612. Arrivals time: 0.10817311052232981 Scheduler time: 2.8010680051520467 Scheduler overhead time: 0.1233403580263257 Adapter cache time: 0.022136915009468794 Engine time: 0.12182894675061107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 17280, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125955 . Total input tokens: 28021340 . Total output tokens: 25219513
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.187856179662049,
    "estimated_duration": 3599.9943395524438,
    "input_throughput": 2919.579035034448,
    "output_throughput": 2578.809054781503,
    "total_throughput": 5498.388089815951,
    "itl": 25.215484896241957,
    "ttft": 5075.311794070594,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 42197,
    "finished_requests": 42138,
    "scheduler_time": 12.037482098371813
}
#Debug simulation 
Total elapsed time: 3.187955915927887. Arrivals time: 0.10707577178254724 Scheduler time: 2.750377642456442 Scheduler overhead time: 0.12540454929694533 Adapter cache time: 0.02220734814181924 Engine time: 0.12167300144210458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 17280, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125955 . Total input tokens: 28021340 . Total output tokens: 25219513
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.181901217903942,
    "estimated_duration": 3599.9914149311912,
    "input_throughput": 2919.5814068909085,
    "output_throughput": 2578.811149797546,
    "total_throughput": 5498.3925566884545,
    "itl": 25.217901160241667,
    "ttft": 5075.304835213816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 42197,
    "finished_requests": 42138,
    "scheduler_time": 12.040012104867516
}
#Debug simulation 
Total elapsed time: 3.1820142618380487. Arrivals time: 0.10934911342337728 Scheduler time: 2.7430036747828126 Scheduler overhead time: 0.1254968186840415 Adapter cache time: 0.022071142215281725 Engine time: 0.12103900546208024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 17280, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125955 . Total input tokens: 28021340 . Total output tokens: 25219513
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.189953289926052,
    "estimated_duration": 3599.9898270775698,
    "input_throughput": 2919.5826946356337,
    "output_throughput": 2578.8122872381555,
    "total_throughput": 5498.394981873789,
    "itl": 25.21792861554383,
    "ttft": 5075.297267947949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 42197,
    "finished_requests": 42138,
    "scheduler_time": 12.040004015251457
}
#Debug simulation 
Total elapsed time: 3.19005091721192. Arrivals time: 0.10965175786986947 Scheduler time: 2.74939938634634 Scheduler overhead time: 0.12495805649086833 Adapter cache time: 0.022026163525879383 Engine time: 0.12306644907221198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 17280, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125955 . Total input tokens: 28021340 . Total output tokens: 25219513
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.2119006300345063,
    "estimated_duration": 3599.995143437225,
    "input_throughput": 2919.5783830876926,
    "output_throughput": 2578.8084789292398,
    "total_throughput": 5498.386862016932,
    "itl": 25.215449964539875,
    "ttft": 5075.298011731871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 42197,
    "finished_requests": 42138,
    "scheduler_time": 12.037503865262012
}
#Debug simulation 
Total elapsed time: 3.212010638322681. Arrivals time: 0.10852340050041676 Scheduler time: 2.7674426026642323 Scheduler overhead time: 0.12536798743531108 Adapter cache time: 0.02201194642111659 Engine time: 0.1270737429149449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 17280, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125955 . Total input tokens: 28021340 . Total output tokens: 25219513
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.191592187155038,
    "estimated_duration": 3599.991654908101,
    "input_throughput": 2919.5812122704233,
    "output_throughput": 2578.8109778929447,
    "total_throughput": 5498.392190163368,
    "itl": 25.217931355164094,
    "ttft": 5075.300642354421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 42197,
    "finished_requests": 42138,
    "scheduler_time": 12.03999675962138
}
#Debug simulation 
Total elapsed time: 3.191681439988315. Arrivals time: 0.10834904899820685 Scheduler time: 2.750337701756507 Scheduler overhead time: 0.12403599359095097 Adapter cache time: 0.021977297496050596 Engine time: 0.12546271365135908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 17280, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125955 . Total input tokens: 28021340 . Total output tokens: 25219513
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.1938854521140456,
    "estimated_duration": 3599.9930058949185,
    "input_throughput": 2919.5801166250358,
    "output_throughput": 2578.8100101300543,
    "total_throughput": 5498.39012675509,
    "itl": 25.215500774753828,
    "ttft": 5075.312057278022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 42197,
    "finished_requests": 42138,
    "scheduler_time": 12.03752492328831
}
#Debug simulation 
Total elapsed time: 3.1939972480759025. Arrivals time: 0.11022978415712714 Scheduler time: 2.750243849121034 Scheduler overhead time: 0.12679137662053108 Adapter cache time: 0.021983670070767403 Engine time: 0.12314759846776724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    1.6   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 17280, 135, 17280, 135, 4320, 4320, 135, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125955 . Total input tokens: 28021340 . Total output tokens: 25219513
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.178224645089358,
    "estimated_duration": 3599.993107541996,
    "input_throughput": 2919.5800341896597,
    "output_throughput": 2578.8099373164428,
    "total_throughput": 5498.3899715061025,
    "itl": 25.217953098570383,
    "ttft": 5075.287713407486,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 42197,
    "finished_requests": 42138,
    "scheduler_time": 12.039997593607385
}
#Debug simulation 
Total elapsed time: 3.1783106210641563. Arrivals time: 0.10903989477083087 Scheduler time: 2.7379822032526135 Scheduler overhead time: 0.12522065034136176 Adapter cache time: 0.021813178900629282 Engine time: 0.12319805100560188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 17280, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125610 . Total input tokens: 27948859 . Total output tokens: 25148147
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.1967956200242043,
    "estimated_duration": 3600.008882538167,
    "input_throughput": 2901.0145087855285,
    "output_throughput": 2576.905030706309,
    "total_throughput": 5477.919539491837,
    "itl": 25.167906691944264,
    "ttft": 5860.527870976553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 42071,
    "finished_requests": 42002,
    "scheduler_time": 11.965944457316894
}
#Debug simulation 
Total elapsed time: 3.196886762045324. Arrivals time: 0.1080035986378789 Scheduler time: 2.7545104580931365 Scheduler overhead time: 0.12651038076728582 Adapter cache time: 0.021876841317862272 Engine time: 0.12465897342190146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 17280, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125610 . Total input tokens: 27948859 . Total output tokens: 25148147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.1965703261084855,
    "estimated_duration": 3600.0124383403586,
    "input_throughput": 2901.0116433971652,
    "output_throughput": 2576.902485447171,
    "total_throughput": 5477.914128844336,
    "itl": 25.167945241626473,
    "ttft": 5860.557183651962,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 42071,
    "finished_requests": 42002,
    "scheduler_time": 11.966025937219639
}
#Debug simulation 
Total elapsed time: 3.1966605628840625. Arrivals time: 0.10887114936485887 Scheduler time: 2.7566888737492263 Scheduler overhead time: 0.1257584299892187 Adapter cache time: 0.021708321757614613 Engine time: 0.12173289712518454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 17280, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125610 . Total input tokens: 27948859 . Total output tokens: 25148147
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.1978497859090567,
    "estimated_duration": 3600.012542691344,
    "input_throughput": 2901.0115593076184,
    "output_throughput": 2576.9024107523437,
    "total_throughput": 5477.913970059963,
    "itl": 25.16796592856561,
    "ttft": 5860.5461854829655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 42071,
    "finished_requests": 42002,
    "scheduler_time": 11.966003336343386
}
#Debug simulation 
Total elapsed time: 3.197969888802618. Arrivals time: 0.10977931506931782 Scheduler time: 2.756699392106384 Scheduler overhead time: 0.12635467294603586 Adapter cache time: 0.021742537152022123 Engine time: 0.12174700293689966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 17280, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125610 . Total input tokens: 27948859 . Total output tokens: 25148147
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.1757087013684213,
    "estimated_duration": 3600.0120636721495,
    "input_throughput": 2901.011945317497,
    "output_throughput": 2576.9027536361164,
    "total_throughput": 5477.914698953614,
    "itl": 25.167959876219015,
    "ttft": 5860.5402210520815,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 42071,
    "finished_requests": 42002,
    "scheduler_time": 11.965994537863317
}
#Debug simulation 
Total elapsed time: 3.1757995863445103. Arrivals time: 0.10715877637267113 Scheduler time: 2.739447634201497 Scheduler overhead time: 0.12507194699719548 Adapter cache time: 0.02166566625237465 Engine time: 0.12164432974532247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 17280, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125610 . Total input tokens: 27948859 . Total output tokens: 25148147
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.190820476040244,
    "estimated_duration": 3600.0159808364906,
    "input_throughput": 2901.0087887369136,
    "output_throughput": 2576.8999497175696,
    "total_throughput": 5477.908738454484,
    "itl": 25.167959166730597,
    "ttft": 5860.510280790201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 42071,
    "finished_requests": 42002,
    "scheduler_time": 11.966059129669915
}
#Debug simulation 
Total elapsed time: 3.190913636237383. Arrivals time: 0.10817054193466902 Scheduler time: 2.7487861244007945 Scheduler overhead time: 0.12587701110169291 Adapter cache time: 0.021839167922735214 Engine time: 0.1243846626020968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 17280, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125610 . Total input tokens: 27948859 . Total output tokens: 25148147
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.1803568778559566,
    "estimated_duration": 3600.0082869281764,
    "input_throughput": 2901.014988749208,
    "output_throughput": 2576.9054570471,
    "total_throughput": 5477.920445796308,
    "itl": 25.16792420737948,
    "ttft": 5860.5153331705715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 42071,
    "finished_requests": 42002,
    "scheduler_time": 11.96595421490502
}
#Debug simulation 
Total elapsed time: 3.1804484170861542. Arrivals time: 0.1102464315481484 Scheduler time: 2.737054361961782 Scheduler overhead time: 0.1265638116747141 Adapter cache time: 0.02196464128792286 Engine time: 0.12314771860837936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     1.6    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 17280, 66, 17280, 66, 4320, 4320, 66, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125610 . Total input tokens: 27948859 . Total output tokens: 25148147
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.1915994551964104,
    "estimated_duration": 3600.018757968261,
    "input_throughput": 2901.114883605303,
    "output_throughput": 2577.006294610477,
    "total_throughput": 5478.12117821578,
    "itl": 25.168084083878203,
    "ttft": 5774.953800064177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 42071,
    "finished_requests": 42003,
    "scheduler_time": 11.966101245722353
}
#Debug simulation 
Total elapsed time: 3.191690959967673. Arrivals time: 0.11019982537254691 Scheduler time: 2.7474317546002567 Scheduler overhead time: 0.12558171711862087 Adapter cache time: 0.02201854158192873 Engine time: 0.12504761293530464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 17280, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125445 . Total input tokens: 27917658 . Total output tokens: 25112075
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.1845171661116183,
    "estimated_duration": 3600.0189980932832,
    "input_throughput": 2902.6582930630498,
    "output_throughput": 2558.847885213661,
    "total_throughput": 5461.506178276711,
    "itl": 25.05327941114678,
    "ttft": 6297.506435020823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 42007,
    "finished_requests": 41934,
    "scheduler_time": 11.59466815132624
}
#Debug simulation 
Total elapsed time: 3.1846113740466535. Arrivals time: 0.10745961079373956 Scheduler time: 2.7394746742211282 Scheduler overhead time: 0.13003160152584314 Adapter cache time: 0.02183641167357564 Engine time: 0.12380143022164702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 17280, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125445 . Total input tokens: 27917658 . Total output tokens: 25112075
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.1767348111607134,
    "estimated_duration": 3600.01961820251,
    "input_throughput": 2902.657793075444,
    "output_throughput": 2558.847444447956,
    "total_throughput": 5461.5052375234,
    "itl": 25.05334135741883,
    "ttft": 6297.4931777966385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 42007,
    "finished_requests": 41934,
    "scheduler_time": 11.59467694980631
}
#Debug simulation 
Total elapsed time: 3.1768274032510817. Arrivals time: 0.10804883623495698 Scheduler time: 2.7344726026058197 Scheduler overhead time: 0.12630023574456573 Adapter cache time: 0.02192228054627776 Engine time: 0.1240662345662713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 17280, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125445 . Total input tokens: 27917658 . Total output tokens: 25112075
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.1965268589556217,
    "estimated_duration": 3600.019703496151,
    "input_throughput": 2902.657724304084,
    "output_throughput": 2558.8473838223395,
    "total_throughput": 5461.505108126423,
    "itl": 25.053328980839904,
    "ttft": 6297.497610532687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 42007,
    "finished_requests": 41934,
    "scheduler_time": 11.594685039422393
}
#Debug simulation 
Total elapsed time: 3.1966162831522524. Arrivals time: 0.11076078750193119 Scheduler time: 2.749862250406295 Scheduler overhead time: 0.12662054877728224 Adapter cache time: 0.021912668365985155 Engine time: 0.12555800937116146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 17280, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125445 . Total input tokens: 27917658 . Total output tokens: 25112075
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 3.1719055003486574,
    "estimated_duration": 3600.019658609985,
    "input_throughput": 2902.657760495324,
    "output_throughput": 2558.847415726845,
    "total_throughput": 5461.505176222169,
    "itl": 25.053341712637643,
    "ttft": 6297.51684971432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 42007,
    "finished_requests": 41934,
    "scheduler_time": 11.594685039422398
}
#Debug simulation 
Total elapsed time: 3.1720021120272577. Arrivals time: 0.10783231304958463 Scheduler time: 2.726856929715723 Scheduler overhead time: 0.1269754613749683 Adapter cache time: 0.02173961978405714 Engine time: 0.1266760821454227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 17280, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125445 . Total input tokens: 27917658 . Total output tokens: 25112075
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 3.150388367008418,
    "estimated_duration": 3600.020009937547,
    "input_throughput": 2902.657477223656,
    "output_throughput": 2558.847166007782,
    "total_throughput": 5461.5046432314375,
    "itl": 25.053322676317404,
    "ttft": 6297.540210403496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 42007,
    "finished_requests": 41934,
    "scheduler_time": 11.594678617778307
}
#Debug simulation 
Total elapsed time: 3.150483707897365. Arrivals time: 0.10518604004755616 Scheduler time: 2.7147122942842543 Scheduler overhead time: 0.1257318458519876 Adapter cache time: 0.021551024168729782 Engine time: 0.12232032557949424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 17280, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125445 . Total input tokens: 27917658 . Total output tokens: 25112075
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 3.143875847104937,
    "estimated_duration": 3600.017293301468,
    "input_throughput": 2902.6596676198083,
    "output_throughput": 2558.849096958654,
    "total_throughput": 5461.508764578462,
    "itl": 25.05324773114118,
    "ttft": 6297.496968937308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 42007,
    "finished_requests": 41934,
    "scheduler_time": 11.594642339627995
}
#Debug simulation 
Total elapsed time: 3.143944113049656. Arrivals time: 0.09880059584975243 Scheduler time: 2.7152303480543196 Scheduler overhead time: 0.12565747927874327 Adapter cache time: 0.021574222948402166 Engine time: 0.1209843517281115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.4-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      1.6     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 17280, 33, 17280, 33, 4320, 4320, 33, 4320, 17280, 17280, 17280, 17280]
Prompts retrieved: 125445 . Total input tokens: 27917658 . Total output tokens: 25112075
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 3.160662573762238,
    "estimated_duration": 3600.020695224332,
    "input_throughput": 2902.6569246843846,
    "output_throughput": 2558.8466789149857,
    "total_throughput": 5461.503603599371,
    "itl": 25.05330219257714,
    "ttft": 6297.55271769047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 42007,
    "finished_requests": 41934,
    "scheduler_time": 11.594672196134264
}
#Debug simulation 
Total elapsed time: 3.160735586192459. Arrivals time: 0.09922266518697143 Scheduler time: 2.72764919931069 Scheduler overhead time: 0.12593837501481175 Adapter cache time: 0.021747508086264133 Engine time: 0.12433983478695154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 17280, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 111780 . Total input tokens: 24878349 . Total output tokens: 22368476
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8736163903959095,
    "estimated_duration": 3600.0068404338344,
    "input_throughput": 2574.502330357542,
    "output_throughput": 2303.745622605694,
    "total_throughput": 4878.2479529632365,
    "itl": 24.0291717424956,
    "ttft": 5030.4951687490075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 37510,
    "finished_requests": 37457,
    "scheduler_time": 6.85008386719511
}
#Debug simulation 
Total elapsed time: 2.873684441205114. Arrivals time: 0.09003212349489331 Scheduler time: 2.4400862832553685 Scheduler overhead time: 0.1301779430359602 Adapter cache time: 0.02499937918037176 Engine time: 0.12507767137140036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 17280, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 111780 . Total input tokens: 24878349 . Total output tokens: 22368476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.901261738035828,
    "estimated_duration": 3600.011919904633,
    "input_throughput": 2574.498697839179,
    "output_throughput": 2303.7423721140626,
    "total_throughput": 4878.241069953241,
    "itl": 24.029206619032692,
    "ttft": 5030.551289402207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 37510,
    "finished_requests": 37457,
    "scheduler_time": 6.850123105923516
}
#Debug simulation 
Total elapsed time: 2.901331014931202. Arrivals time: 0.0907474597916007 Scheduler time: 2.4627557080239058 Scheduler overhead time: 0.12995869806036353 Adapter cache time: 0.025109907146543264 Engine time: 0.12932243896648288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 17280, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 111780 . Total input tokens: 24878349 . Total output tokens: 22368476
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8876512637361884,
    "estimated_duration": 3600.0123377195687,
    "input_throughput": 2574.4983990446453,
    "output_throughput": 2303.7421047433204,
    "total_throughput": 4878.240503787965,
    "itl": 24.029239421328242,
    "ttft": 5030.530381020813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 37510,
    "finished_requests": 37457,
    "scheduler_time": 6.850100379925264
}
#Debug simulation 
Total elapsed time: 2.887720685917884. Arrivals time: 0.09012616891413927 Scheduler time: 2.451944829430431 Scheduler overhead time: 0.12982467049732804 Adapter cache time: 0.025005523581057787 Engine time: 0.1270674648694694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 17280, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 111780 . Total input tokens: 24878349 . Total output tokens: 22368476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8802702273242176,
    "estimated_duration": 3600.0068583856346,
    "input_throughput": 2574.5023175195247,
    "output_throughput": 2303.745611117832,
    "total_throughput": 4878.247928637356,
    "itl": 24.029142726557318,
    "ttft": 5030.508211548719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 37510,
    "finished_requests": 37457,
    "scheduler_time": 6.850024737924504
}
#Debug simulation 
Total elapsed time: 2.8803383940830827. Arrivals time: 0.09001021226868033 Scheduler time: 2.443402263801545 Scheduler overhead time: 0.13099455833435059 Adapter cache time: 0.025107600260525942 Engine time: 0.12713901046663523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 17280, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 111780 . Total input tokens: 24878349 . Total output tokens: 22368476
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.9254991482011974,
    "estimated_duration": 3600.0132875536306,
    "input_throughput": 2574.497719784299,
    "output_throughput": 2303.741496919808,
    "total_throughput": 4878.239216704107,
    "itl": 24.029203203430246,
    "ttft": 5030.498147854989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 37510,
    "finished_requests": 37457,
    "scheduler_time": 6.850101797653279
}
#Debug simulation 
Total elapsed time: 2.9255993561819196. Arrivals time: 0.10052152397111058 Scheduler time: 2.4768617781810462 Scheduler overhead time: 0.1305215135216713 Adapter cache time: 0.025396905839443207 Engine time: 0.12871047155931592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 17280, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 111780 . Total input tokens: 24878349 . Total output tokens: 22368476
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.9116367399692535,
    "estimated_duration": 3600.0067037763424,
    "input_throughput": 2574.502428086536,
    "output_throughput": 2303.7457100566694,
    "total_throughput": 4878.248138143205,
    "itl": 24.02913656801743,
    "ttft": 5030.515366122585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 37510,
    "finished_requests": 37457,
    "scheduler_time": 6.850073275621003
}
#Debug simulation 
Total elapsed time: 2.911722628865391. Arrivals time: 0.09847317961975932 Scheduler time: 2.4677490456961095 Scheduler overhead time: 0.12956842966377735 Adapter cache time: 0.025061479303985834 Engine time: 0.12766124308109283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.05_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  1.6 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 17280, 540, 17280, 540, 1080, 1080, 540, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 111780 . Total input tokens: 24878349 . Total output tokens: 22368476
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.898438604082912,
    "estimated_duration": 3600.0162942687157,
    "input_throughput": 2574.4955695770504,
    "output_throughput": 2303.7395728467636,
    "total_throughput": 4878.235142423814,
    "itl": 24.02920466492741,
    "ttft": 5030.485616301924,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 37510,
    "finished_requests": 37457,
    "scheduler_time": 6.849981371545147
}
#Debug simulation 
Total elapsed time: 2.898558362852782. Arrivals time: 0.09626262914389372 Scheduler time: 2.458912099711597 Scheduler overhead time: 0.12999616982415318 Adapter cache time: 0.025129119399935007 Engine time: 0.12461393279954791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 17280, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 110430 . Total input tokens: 24573462 . Total output tokens: 22088480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8584483126178384,
    "estimated_duration": 3599.9989049943224,
    "input_throughput": 2532.065214618274,
    "output_throughput": 2278.0062484527157,
    "total_throughput": 4810.071463070989,
    "itl": 23.745944812673656,
    "ttft": 5387.353840505821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 37022,
    "finished_requests": 36967,
    "scheduler_time": 6.189341156204472
}
#Debug simulation 
Total elapsed time: 2.858548176009208. Arrivals time: 0.0965057616122067 Scheduler time: 2.4162968723103404 Scheduler overhead time: 0.13067190255969763 Adapter cache time: 0.024238317273557186 Engine time: 0.12669310392811894 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 17280, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 110430 . Total input tokens: 24573462 . Total output tokens: 22088480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.857745355926454,
    "estimated_duration": 3600.0036132079686,
    "input_throughput": 2532.0619030927096,
    "output_throughput": 2278.0032691945653,
    "total_throughput": 4810.065172287275,
    "itl": 23.74606808239659,
    "ttft": 5387.329443675191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 37022,
    "finished_requests": 36967,
    "scheduler_time": 6.189293327372001
}
#Debug simulation 
Total elapsed time: 2.8578351526521146. Arrivals time: 0.09624657966196537 Scheduler time: 2.4145525442436337 Scheduler overhead time: 0.13052902417257428 Adapter cache time: 0.02446354227140546 Engine time: 0.12814149539917707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 17280, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 110430 . Total input tokens: 24573462 . Total output tokens: 22088480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8615838047116995,
    "estimated_duration": 3600.0060811996805,
    "input_throughput": 2532.060167232367,
    "output_throughput": 2278.001707504651,
    "total_throughput": 4810.061874737018,
    "itl": 23.746082197940527,
    "ttft": 5387.359560167593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 37022,
    "finished_requests": 36967,
    "scheduler_time": 6.189186619512946
}
#Debug simulation 
Total elapsed time: 2.8616749099455774. Arrivals time: 0.09437492862343788 Scheduler time: 2.4192890315316617 Scheduler overhead time: 0.13148979749530554 Adapter cache time: 0.02457824582234025 Engine time: 0.12806464359164238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 17280, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 110430 . Total input tokens: 24573462 . Total output tokens: 22088480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8897352307103574,
    "estimated_duration": 3600.001443972576,
    "input_throughput": 2532.063428824958,
    "output_throughput": 2278.004641839936,
    "total_throughput": 4810.068070664894,
    "itl": 23.74603854078785,
    "ttft": 5387.319186999344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 37022,
    "finished_requests": 36967,
    "scheduler_time": 6.189345909876534
}
#Debug simulation 
Total elapsed time: 2.889826681930572. Arrivals time: 0.09626563917845488 Scheduler time: 2.4422084162943065 Scheduler overhead time: 0.1317138341255486 Adapter cache time: 0.024222515523433685 Engine time: 0.13110231747850776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 17280, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 110430 . Total input tokens: 24573462 . Total output tokens: 22088480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.8836235092021525,
    "estimated_duration": 3600.006288584645,
    "input_throughput": 2532.060021368397,
    "output_throughput": 2278.001576276185,
    "total_throughput": 4810.061597644582,
    "itl": 23.746040069223447,
    "ttft": 5387.356845732339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 37022,
    "finished_requests": 36967,
    "scheduler_time": 6.189197919951067
}
#Debug simulation 
Total elapsed time: 2.883721030782908. Arrivals time: 0.09810669487342238 Scheduler time: 2.436106671579182 Scheduler overhead time: 0.1315641338005662 Adapter cache time: 0.024427650030702353 Engine time: 0.12918341858312488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 17280, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 110430 . Total input tokens: 24573462 . Total output tokens: 22088480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.88848806777969,
    "estimated_duration": 3599.9974697694993,
    "input_throughput": 2532.0662240864417,
    "output_throughput": 2278.007156634219,
    "total_throughput": 4810.073380720661,
    "itl": 23.745956265969347,
    "ttft": 5387.3150377356005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 37022,
    "finished_requests": 36967,
    "scheduler_time": 6.189358294544668
}
#Debug simulation 
Total elapsed time: 2.888581065926701. Arrivals time: 0.09769037133082747 Scheduler time: 2.439999031368643 Scheduler overhead time: 0.13208635849878192 Adapter cache time: 0.024448787793517113 Engine time: 0.13011534977704287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.025_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   1.6  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 17280, 270, 17280, 270, 1080, 1080, 270, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 110430 . Total input tokens: 24573462 . Total output tokens: 22088480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.879698152653873,
    "estimated_duration": 3600.006324006175,
    "input_throughput": 2532.0599964547073,
    "output_throughput": 2278.001553862252,
    "total_throughput": 4810.061550316959,
    "itl": 23.746003349327708,
    "ttft": 5387.362816039309,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 37022,
    "finished_requests": 36967,
    "scheduler_time": 6.189176027938841
}
#Debug simulation 
Total elapsed time: 2.879787327721715. Arrivals time: 0.0967830284498632 Scheduler time: 2.4332816414535046 Scheduler overhead time: 0.13178583793342113 Adapter cache time: 0.024532162118703127 Engine time: 0.12908638315275311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 17280, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109755 . Total input tokens: 24406867 . Total output tokens: 21959091
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.848301295656711,
    "estimated_duration": 3599.952152457558,
    "input_throughput": 2518.5659742200955,
    "output_throughput": 2252.8052197759353,
    "total_throughput": 4771.371193996031,
    "itl": 23.577445341810087,
    "ttft": 6103.83429494334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 36802,
    "finished_requests": 36740,
    "scheduler_time": 5.746318153910993
}
#Debug simulation 
Total elapsed time: 2.848419550806284. Arrivals time: 0.09489147877320647 Scheduler time: 2.4025510558858514 Scheduler overhead time: 0.13245697738602757 Adapter cache time: 0.02392876986414194 Engine time: 0.1297131017781794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 17280, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109755 . Total input tokens: 24406867 . Total output tokens: 21959091
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8355466928333044,
    "estimated_duration": 3599.9530614212676,
    "input_throughput": 2518.5653382992846,
    "output_throughput": 2252.8046509579103,
    "total_throughput": 4771.369989257195,
    "itl": 23.577398881944788,
    "ttft": 6103.840054112491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 36802,
    "finished_requests": 36740,
    "scheduler_time": 5.746238925722192
}
#Debug simulation 
Total elapsed time: 2.835643989033997. Arrivals time: 0.09348945412784815 Scheduler time: 2.395435671787709 Scheduler overhead time: 0.13145582005381584 Adapter cache time: 0.023952834773808718 Engine time: 0.12667743489146233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 17280, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109755 . Total input tokens: 24406867 . Total output tokens: 21959091
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8355586980469525,
    "estimated_duration": 3599.952607396922,
    "input_throughput": 2518.5656559395716,
    "output_throughput": 2252.8049350805836,
    "total_throughput": 4771.370591020155,
    "itl": 23.577385509703298,
    "ttft": 6103.8530998461565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 36802,
    "finished_requests": 36740,
    "scheduler_time": 5.746232253834116
}
#Debug simulation 
Total elapsed time: 2.835648823995143. Arrivals time: 0.09559680754318833 Scheduler time: 2.392071329522878 Scheduler overhead time: 0.13130503799766302 Adapter cache time: 0.024004506412893534 Engine time: 0.12864359933882952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 17280, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109755 . Total input tokens: 24406867 . Total output tokens: 21959091
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.840047797188163,
    "estimated_duration": 3599.952152589167,
    "input_throughput": 2518.5659741280206,
    "output_throughput": 2252.805219693576,
    "total_throughput": 4771.3711938215965,
    "itl": 23.577418940794267,
    "ttft": 6103.827875252574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 36802,
    "finished_requests": 36740,
    "scheduler_time": 5.746280332910614
}
#Debug simulation 
Total elapsed time: 2.840173847042024. Arrivals time: 0.09658649004995823 Scheduler time: 2.3945050234906375 Scheduler overhead time: 0.1321863210760057 Adapter cache time: 0.023954995442181826 Engine time: 0.12860074592754245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 17280, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109755 . Total input tokens: 24406867 . Total output tokens: 21959091
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.8549278331920505,
    "estimated_duration": 3599.952913272838,
    "input_throughput": 2518.5654419455013,
    "output_throughput": 2252.8047436673096,
    "total_throughput": 4771.370185612811,
    "itl": 23.5773733355803,
    "ttft": 6103.84033852442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 36802,
    "finished_requests": 36740,
    "scheduler_time": 5.7462693659705
}
#Debug simulation 
Total elapsed time: 2.85503794811666. Arrivals time: 0.09398963348940015 Scheduler time: 2.4127467526122928 Scheduler overhead time: 0.13239142298698425 Adapter cache time: 0.02409152453765273 Engine time: 0.12725443625822663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 17280, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109755 . Total input tokens: 24406867 . Total output tokens: 21959091
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8551826179027557,
    "estimated_duration": 3599.9519305913536,
    "input_throughput": 2518.566129440133,
    "output_throughput": 2252.8053586170513,
    "total_throughput": 4771.371488057184,
    "itl": 23.577419145646722,
    "ttft": 6103.830755056666,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 36802,
    "finished_requests": 36740,
    "scheduler_time": 5.746347301553291
}
#Debug simulation 
Total elapsed time: 2.8552695037797093. Arrivals time: 0.09639295982196927 Scheduler time: 2.4068755945190787 Scheduler overhead time: 0.13214718690142035 Adapter cache time: 0.02391624776646495 Engine time: 0.1307991286739707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    1.6   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 17280, 135, 17280, 135, 1080, 1080, 135, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109755 . Total input tokens: 24406867 . Total output tokens: 21959091
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8352882070466876,
    "estimated_duration": 3599.9530853458496,
    "input_throughput": 2518.5653215613934,
    "output_throughput": 2252.804635986213,
    "total_throughput": 4771.369957547606,
    "itl": 23.57739287399817,
    "ttft": 6103.8532028820755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 36802,
    "finished_requests": 36740,
    "scheduler_time": 5.746264487176449
}
#Debug simulation 
Total elapsed time: 2.8353731497190893. Arrivals time: 0.09482260094955564 Scheduler time: 2.3924287855625153 Scheduler overhead time: 0.13152473838999867 Adapter cache time: 0.023971016984432936 Engine time: 0.12815280817449093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 17280, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109410 . Total input tokens: 24332555 . Total output tokens: 21885352
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.810180034954101,
    "estimated_duration": 3600.015022350484,
    "input_throughput": 2522.4741962523717,
    "output_throughput": 2226.4009872844586,
    "total_throughput": 4748.87518353683,
    "itl": 23.45473274658196,
    "ttft": 6318.418072829091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 36691,
    "finished_requests": 36626,
    "scheduler_time": 5.310423274173522
}
#Debug simulation 
Total elapsed time: 2.810272946022451. Arrivals time: 0.09656625846400857 Scheduler time: 2.363863570149988 Scheduler overhead time: 0.13241546880453825 Adapter cache time: 0.023570554796606302 Engine time: 0.1292156740091741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 17280, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109410 . Total input tokens: 24332555 . Total output tokens: 21885352
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8370771701447666,
    "estimated_duration": 3600.0217571285307,
    "input_throughput": 2522.469477307602,
    "output_throughput": 2226.3968222217163,
    "total_throughput": 4748.866299529318,
    "itl": 23.45481960181209,
    "ttft": 6416.350008751718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 36691,
    "finished_requests": 36626,
    "scheduler_time": 5.310189925634058
}
#Debug simulation 
Total elapsed time: 2.837195029016584. Arrivals time: 0.09680324792861938 Scheduler time: 2.388508218806237 Scheduler overhead time: 0.13254675455391407 Adapter cache time: 0.023904279340058565 Engine time: 0.13044039392843843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 17280, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109410 . Total input tokens: 24332555 . Total output tokens: 21885352
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8417032691650093,
    "estimated_duration": 3600.0218445445325,
    "input_throughput": 2522.469416056808,
    "output_throughput": 2226.3967681601807,
    "total_throughput": 4748.866184216989,
    "itl": 23.454820558609033,
    "ttft": 6416.358110394458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 36691,
    "finished_requests": 36626,
    "scheduler_time": 5.310210024552256
}
#Debug simulation 
Total elapsed time: 2.8417891170829535. Arrivals time: 0.09651723271235824 Scheduler time: 2.390701213851571 Scheduler overhead time: 0.13338583009317517 Adapter cache time: 0.02373766340315342 Engine time: 0.13204110553488135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 17280, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109410 . Total input tokens: 24332555 . Total output tokens: 21885352
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8329727188684046,
    "estimated_duration": 3600.0171853666952,
    "input_throughput": 2522.4726806616677,
    "output_throughput": 2226.3996495848924,
    "total_throughput": 4748.87233024656,
    "itl": 23.45479963485611,
    "ttft": 6318.356170915723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 36691,
    "finished_requests": 36626,
    "scheduler_time": 5.310351092345702
}
#Debug simulation 
Total elapsed time: 2.8330748630687594. Arrivals time: 0.09464841382578015 Scheduler time: 2.388663304504007 Scheduler overhead time: 0.13330377265810966 Adapter cache time: 0.023869400843977928 Engine time: 0.12769093457609415 
