INFO 06-01 00:47:20 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:20 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.477821715641767,
    "estimated_duration": 3600.0464174520434,
    "input_throughput": 4080.855715854309,
    "output_throughput": 3596.6702921469996,
    "total_throughput": 7677.526008001309,
    "itl": 238.0658013952575,
    "ttft": 2275648.0765923117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7460369985737847,
    "arrivals": 1680953,
    "finished_requests": 59275,
    "scheduler_time": 90.24352540326669
}
#Debug simulation 
Total elapsed time: 7.477977281901985. Arrivals time: 0.25583385257050395 Scheduler time: 7.124564455356449 Scheduler overhead time: 0.026857662945985794 Adapter cache time: 0.032518221996724606 Engine time: 0.02645924035459757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 7.506838040892035,
    "estimated_duration": 3600.0129243370548,
    "input_throughput": 4081.778401588932,
    "output_throughput": 3597.793194696694,
    "total_throughput": 7679.571596285626,
    "itl": 238.09224566918778,
    "ttft": 2275696.454290438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9743290192144953,
    "arrivals": 1680953,
    "finished_requests": 59290,
    "scheduler_time": 90.23748852689592
}
#Debug simulation 
Total elapsed time: 7.50697498768568. Arrivals time: 0.2624042583629489 Scheduler time: 7.149678828194737 Scheduler overhead time: 0.026098734699189663 Adapter cache time: 0.03067789413034916 Engine time: 0.02648513065651059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.609950096812099,
    "estimated_duration": 3600.0200787992003,
    "input_throughput": 3592.6307956354594,
    "output_throughput": 3184.628071247897,
    "total_throughput": 6777.258866883357,
    "itl": 159.3166564427193,
    "ttft": 2337130.055075344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.226463343295618,
    "arrivals": 1680953,
    "finished_requests": 52239,
    "scheduler_time": 102.53149345091312
}
#Debug simulation 
Total elapsed time: 4.610044807661325. Arrivals time: 0.21826689643785357 Scheduler time: 4.2241565878503025 Scheduler overhead time: 0.034982097800821066 Adapter cache time: 0.08135872567072511 Engine time: 0.03504841402173042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 7.475133453961462,
    "estimated_duration": 3600.121390549285,
    "input_throughput": 4080.770731388725,
    "output_throughput": 3596.5953909194277,
    "total_throughput": 7677.366122308153,
    "itl": 238.0701920334216,
    "ttft": 2275676.026749556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.820808116425714,
    "arrivals": 1680953,
    "finished_requests": 59275,
    "scheduler_time": 90.24372738253592
}
#Debug simulation 
Total elapsed time: 7.475257521960884. Arrivals time: 0.2543452885001898 Scheduler time: 7.125343490857631 Scheduler overhead time: 0.026313619688153267 Adapter cache time: 0.03119771694764495 Engine time: 0.026340727228671312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.619485515169799,
    "estimated_duration": 3600.1619395859825,
    "input_throughput": 3592.4892316058854,
    "output_throughput": 3184.5025841583224,
    "total_throughput": 6776.991815764208,
    "itl": 159.3227654342625,
    "ttft": 2337177.755302617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.36818786058511,
    "arrivals": 1680953,
    "finished_requests": 52239,
    "scheduler_time": 102.53162972051729
}
#Debug simulation 
Total elapsed time: 4.619578269310296. Arrivals time: 0.21839156141504645 Scheduler time: 4.233352152630687 Scheduler overhead time: 0.035123813431710005 Adapter cache time: 0.08110884670168161 Engine time: 0.035287472885102034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 7.93125269189477,
    "estimated_duration": 3600.2201047888975,
    "input_throughput": 4081.2338058040923,
    "output_throughput": 3596.8386996048125,
    "total_throughput": 7678.072505408904,
    "itl": 238.05649523606374,
    "ttft": 2275663.1668711994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1224,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.65982156096017,
    "arrivals": 1680953,
    "finished_requests": 59282,
    "scheduler_time": 90.24990038389858
}
#Debug simulation 
Total elapsed time: 7.931321206968278. Arrivals time: 0.7051915978081524 Scheduler time: 7.130190005525947 Scheduler overhead time: 0.026437058579176664 Adapter cache time: 0.03126835310831666 Engine time: 0.0266078501008451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 4320, 540, 34560, 34560, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 540, 34560, 4320, 4320, 540, 540, 540, 4320, 540, 4320, 540, 34560, 540, 4320, 34560, 540, 34560, 4320, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 4320, 4320, 540, 540, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 540, 540, 4320, 4320, 34560, 540, 540, 34560, 540, 34560, 4320, 540, 34560, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 34560, 540, 34560, 4320, 4320, 34560, 34560, 540, 4320, 34560, 540, 4320, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 34560, 540, 34560, 4320, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 34560, 540, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 540, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 540, 540, 540, 540, 540, 4320, 540, 540, 4320, 34560, 34560, 540, 540, 34560, 540, 540, 540, 4320, 540, 4320, 34560, 34560, 4320, 4320, 540, 34560, 4320, 34560, 540, 4320, 4320, 540, 540, 4320, 540, 34560, 34560, 540, 34560, 34560, 540, 4320, 34560, 540, 540, 4320, 4320, 540, 540, 34560, 34560, 34560, 34560, 4320, 540, 4320, 4320, 540, 540, 540, 540, 540, 540, 540, 540, 4320, 34560, 4320, 4320, 4320, 34560, 540, 4320, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 4320, 540, 34560, 34560, 34560, 4320, 540, 34560, 34560, 4320, 4320, 34560, 34560, 540, 34560, 34560, 4320, 540, 34560, 4320, 4320, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 4320, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 540, 34560, 540, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 34560, 34560, 540, 34560, 34560, 540, 34560, 4320, 34560, 4320, 4320, 4320, 540, 4320, 540, 540, 34560, 540, 4320, 540, 540, 4320, 34560, 4320, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5045760 . Total input tokens: 1124027934 . Total output tokens: 1008922740
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.601223683916032,
    "estimated_duration": 3600.129630290497,
    "input_throughput": 3592.444808426636,
    "output_throughput": 3184.4997756580537,
    "total_throughput": 6776.944584084689,
    "itl": 159.33011447325975,
    "ttft": 2337147.793954961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.51205019224367,
    "arrivals": 1680953,
    "finished_requests": 52237,
    "scheduler_time": 102.52671923796979
}
#Debug simulation 
Total elapsed time: 4.601296516135335. Arrivals time: 0.21864482294768095 Scheduler time: 4.2162668369710445 Scheduler overhead time: 0.034853662364184856 Adapter cache time: 0.08023383654654026 Engine time: 0.03508546343073249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.887967155780643,
    "estimated_duration": 3600.1333849909597,
    "input_throughput": 4080.237988192453,
    "output_throughput": 3599.7410690472357,
    "total_throughput": 7679.979057239689,
    "itl": 238.15720648578596,
    "ttft": 2275588.9221249362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.562407733937813,
    "arrivals": 1669342,
    "finished_requests": 59396,
    "scheduler_time": 90.24623043992956
}
#Debug simulation 
Total elapsed time: 6.888065053150058. Arrivals time: 0.2681413437239826 Scheduler time: 6.527336373925209 Scheduler overhead time: 0.02601723186671734 Adapter cache time: 0.02884369809180498 Engine time: 0.0260932263918221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.9594528381712735,
    "estimated_duration": 3600.108919260666,
    "input_throughput": 4080.037112603946,
    "output_throughput": 3599.6085925815028,
    "total_throughput": 7679.645705185449,
    "itl": 238.17209718269038,
    "ttft": 2275594.9502592366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.792176771236121,
    "arrivals": 1669342,
    "finished_requests": 59393,
    "scheduler_time": 90.240342730395
}
#Debug simulation 
Total elapsed time: 6.959549722261727. Arrivals time: 0.36949650989845395 Scheduler time: 6.497461723629385 Scheduler overhead time: 0.02605303330346942 Adapter cache time: 0.02903729071840644 Engine time: 0.025941847823560238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.49510500440374,
    "estimated_duration": 3600.0803288783814,
    "input_throughput": 3595.3986626828037,
    "output_throughput": 3188.123306008524,
    "total_throughput": 6783.521968691328,
    "itl": 159.6491744335399,
    "ttft": 2338116.772955515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.04757022621054,
    "arrivals": 1669342,
    "finished_requests": 52424,
    "scheduler_time": 102.47488451651711
}
#Debug simulation 
Total elapsed time: 4.4952002773061395. Arrivals time: 0.2193642514757812 Scheduler time: 4.109616931527853 Scheduler overhead time: 0.03478197194635868 Adapter cache time: 0.08006553165614605 Engine time: 0.03501098230481148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.829726538155228,
    "estimated_duration": 3600.212874453137,
    "input_throughput": 4080.147900207507,
    "output_throughput": 3599.6615900020975,
    "total_throughput": 7679.8094902096045,
    "itl": 238.1618233324742,
    "ttft": 2275620.1617827094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.640179312776267,
    "arrivals": 1669342,
    "finished_requests": 59396,
    "scheduler_time": 90.24646741046156
}
#Debug simulation 
Total elapsed time: 6.829823961015791. Arrivals time: 0.2534569129347801 Scheduler time: 6.483586503192782 Scheduler overhead time: 0.025928691495209932 Adapter cache time: 0.0291011487133801 Engine time: 0.026068710256367922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.498705605044961,
    "estimated_duration": 3600.038576985207,
    "input_throughput": 3595.291473470559,
    "output_throughput": 3187.9197276855066,
    "total_throughput": 6783.211201156066,
    "itl": 159.6560204059694,
    "ttft": 2338107.049184174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.187534190490217,
    "arrivals": 1669342,
    "finished_requests": 52421,
    "scheduler_time": 102.469870719597
}
#Debug simulation 
Total elapsed time: 4.498827572911978. Arrivals time: 0.2192705380730331 Scheduler time: 4.112316965125501 Scheduler overhead time: 0.03509118966758251 Adapter cache time: 0.08051563566550612 Engine time: 0.0353457722812891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.862493236083537,
    "estimated_duration": 3600.051197170166,
    "input_throughput": 4080.3311384978806,
    "output_throughput": 3599.8232497879203,
    "total_throughput": 7680.154388285801,
    "itl": 238.15229125215404,
    "ttft": 2275556.700399761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4804185432660457,
    "arrivals": 1669342,
    "finished_requests": 59396,
    "scheduler_time": 90.24603180965906
}
#Debug simulation 
Total elapsed time: 6.862596830818802. Arrivals time: 0.25754922023043036 Scheduler time: 6.51177780656144 Scheduler overhead time: 0.0260351886972785 Adapter cache time: 0.029349339194595814 Engine time: 0.02622154401615262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 4320, 270, 34560, 34560, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 270, 34560, 4320, 4320, 270, 270, 270, 4320, 270, 4320, 270, 34560, 270, 4320, 34560, 270, 34560, 4320, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 4320, 4320, 270, 270, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 270, 270, 4320, 4320, 34560, 270, 270, 34560, 270, 34560, 4320, 270, 34560, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 34560, 270, 34560, 4320, 4320, 34560, 34560, 270, 4320, 34560, 270, 4320, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 34560, 270, 34560, 4320, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 34560, 270, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 270, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 270, 270, 270, 270, 270, 4320, 270, 270, 4320, 34560, 34560, 270, 270, 34560, 270, 270, 270, 4320, 270, 4320, 34560, 34560, 4320, 4320, 270, 34560, 4320, 34560, 270, 4320, 4320, 270, 270, 4320, 270, 34560, 34560, 270, 34560, 34560, 270, 4320, 34560, 270, 270, 4320, 4320, 270, 270, 34560, 34560, 34560, 34560, 4320, 270, 4320, 4320, 270, 270, 270, 270, 270, 270, 270, 270, 4320, 34560, 4320, 4320, 4320, 34560, 270, 4320, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 4320, 270, 34560, 34560, 34560, 4320, 270, 34560, 34560, 4320, 4320, 34560, 34560, 270, 34560, 34560, 4320, 270, 34560, 4320, 4320, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 4320, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 270, 34560, 270, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 34560, 34560, 270, 34560, 34560, 270, 34560, 4320, 34560, 4320, 4320, 4320, 270, 4320, 270, 270, 34560, 270, 4320, 270, 270, 4320, 34560, 4320, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5011200 . Total input tokens: 1116308708 . Total output tokens: 1002055410
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.511570651084185,
    "estimated_duration": 3600.003403451391,
    "input_throughput": 3595.061601217387,
    "output_throughput": 3187.6347641777857,
    "total_throughput": 6782.6963653951725,
    "itl": 159.66284133781616,
    "ttft": 2338085.3724976396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3378,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.333408582731419,
    "arrivals": 1669342,
    "finished_requests": 52417,
    "scheduler_time": 102.46487194416889
}
#Debug simulation 
Total elapsed time: 4.511672241147608. Arrivals time: 0.22121080989018083 Scheduler time: 4.122438733000308 Scheduler overhead time: 0.03560193022713065 Adapter cache time: 0.08066159719601274 Engine time: 0.03539112862199545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.520295411814004,
    "estimated_duration": 3600.2069998499223,
    "input_throughput": 4081.3667104731817,
    "output_throughput": 3596.605139798842,
    "total_throughput": 7677.971850272023,
    "itl": 237.6346156360225,
    "ttft": 2273805.860709255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3512340796064457,
    "arrivals": 1663594,
    "finished_requests": 59715,
    "scheduler_time": 90.25464199439955
}
#Debug simulation 
Total elapsed time: 6.520391883794218. Arrivals time: 0.2657301826402545 Scheduler time: 6.163263649214059 Scheduler overhead time: 0.02590075135231018 Adapter cache time: 0.02782104816287756 Engine time: 0.026073660235852003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.532807560171932,
    "estimated_duration": 3600.161318943671,
    "input_throughput": 4081.3273901601788,
    "output_throughput": 3596.541891572551,
    "total_throughput": 7677.869281732729,
    "itl": 237.64709823816216,
    "ttft": 2273848.469213519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.567476511558056,
    "arrivals": 1663594,
    "finished_requests": 59714,
    "scheduler_time": 90.24864045282625
}
#Debug simulation 
Total elapsed time: 6.5329073262400925. Arrivals time: 0.2562167551368475 Scheduler time: 6.185764365363866 Scheduler overhead time: 0.025780450087040663 Adapter cache time: 0.027199908159673214 Engine time: 0.02629152312874794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.445595592260361,
    "estimated_duration": 3600.143375799934,
    "input_throughput": 3603.1239997817415,
    "output_throughput": 3189.856569934059,
    "total_throughput": 6792.980569715801,
    "itl": 159.75238900469944,
    "ttft": 2333979.471501345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.878523617647057,
    "arrivals": 1663594,
    "finished_requests": 52727,
    "scheduler_time": 102.38659790873164
}
#Debug simulation 
Total elapsed time: 4.445698791183531. Arrivals time: 0.22172294557094574 Scheduler time: 4.058067321777344 Scheduler overhead time: 0.034916880540549755 Adapter cache time: 0.07972203241661191 Engine time: 0.03499165456742048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.526991579215974,
    "estimated_duration": 3600.0126312616317,
    "input_throughput": 4081.495957099088,
    "output_throughput": 3596.6904359061377,
    "total_throughput": 7678.186393005226,
    "itl": 237.63818313882405,
    "ttft": 2273791.1760346415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4191564109641654,
    "arrivals": 1663594,
    "finished_requests": 59714,
    "scheduler_time": 90.24827287134312
}
#Debug simulation 
Total elapsed time: 6.527089886367321. Arrivals time: 0.2545326459221542 Scheduler time: 6.181212214753032 Scheduler overhead time: 0.025994422379881144 Adapter cache time: 0.027294046245515347 Engine time: 0.02645224053412676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.57300006179139,
    "estimated_duration": 3600.112031732906,
    "input_throughput": 3603.1550923030777,
    "output_throughput": 3189.8462877757433,
    "total_throughput": 6793.001380078821,
    "itl": 159.75827208841253,
    "ttft": 2334077.480697101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.018487581926736,
    "arrivals": 1663594,
    "finished_requests": 52726,
    "scheduler_time": 102.38176301596607
}
#Debug simulation 
Total elapsed time: 4.573095508851111. Arrivals time: 0.3457837435416877 Scheduler time: 4.063117613084614 Scheduler overhead time: 0.034911582712084055 Adapter cache time: 0.07793207094073296 Engine time: 0.0351074687205255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.509695363231003,
    "estimated_duration": 3600.1296674783075,
    "input_throughput": 4081.454380028532,
    "output_throughput": 3596.6823964620494,
    "total_throughput": 7678.136776490581,
    "itl": 237.62997629513723,
    "ttft": 2273775.181226012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.274105072917803,
    "arrivals": 1663594,
    "finished_requests": 59715,
    "scheduler_time": 90.25443862933773
}
#Debug simulation 
Total elapsed time: 6.509792782366276. Arrivals time: 0.2547591235488653 Scheduler time: 6.163752050604671 Scheduler overhead time: 0.026011232752352953 Adapter cache time: 0.027514141518622637 Engine time: 0.026161171961575747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 4320, 135, 34560, 34560, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 135, 34560, 4320, 4320, 135, 135, 135, 4320, 135, 4320, 135, 34560, 135, 4320, 34560, 135, 34560, 4320, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 4320, 4320, 135, 135, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 135, 135, 4320, 4320, 34560, 135, 135, 34560, 135, 34560, 4320, 135, 34560, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 34560, 135, 34560, 4320, 4320, 34560, 34560, 135, 4320, 34560, 135, 4320, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 34560, 135, 34560, 4320, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 34560, 135, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 135, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 135, 135, 135, 135, 135, 4320, 135, 135, 4320, 34560, 34560, 135, 135, 34560, 135, 135, 135, 4320, 135, 4320, 34560, 34560, 4320, 4320, 135, 34560, 4320, 34560, 135, 4320, 4320, 135, 135, 4320, 135, 34560, 34560, 135, 34560, 34560, 135, 4320, 34560, 135, 135, 4320, 4320, 135, 135, 34560, 34560, 34560, 34560, 4320, 135, 4320, 4320, 135, 135, 135, 135, 135, 135, 135, 135, 4320, 34560, 4320, 4320, 4320, 34560, 135, 4320, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 4320, 135, 34560, 34560, 34560, 4320, 135, 34560, 34560, 4320, 4320, 34560, 34560, 135, 34560, 34560, 4320, 135, 34560, 4320, 4320, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 4320, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 135, 34560, 135, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 34560, 34560, 135, 34560, 34560, 135, 34560, 4320, 34560, 4320, 4320, 4320, 135, 4320, 135, 135, 34560, 135, 4320, 135, 135, 4320, 34560, 4320, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4993920 . Total input tokens: 1112390199 . Total output tokens: 998610757
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.438491763081402,
    "estimated_duration": 3600.0819159234466,
    "input_throughput": 3602.968849855421,
    "output_throughput": 3189.6585322710694,
    "total_throughput": 6792.62738212649,
    "itl": 159.76370171399142,
    "ttft": 2334116.898226169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.159206068924915,
    "arrivals": 1663594,
    "finished_requests": 52723,
    "scheduler_time": 102.37696658477073
}
#Debug simulation 
Total elapsed time: 4.438586679287255. Arrivals time: 0.22014305787160993 Scheduler time: 4.054156489204615 Scheduler overhead time: 0.03474341006949544 Adapter cache time: 0.07827052334323525 Engine time: 0.035082451067864895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.373789058998227,
    "estimated_duration": 3600.1425335584922,
    "input_throughput": 4088.897276366914,
    "output_throughput": 3598.050599179018,
    "total_throughput": 7686.947875545931,
    "itl": 237.7199497345069,
    "ttft": 2272121.2850829354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2288145698491313,
    "arrivals": 1660646,
    "finished_requests": 59473,
    "scheduler_time": 90.2622349899213
}
#Debug simulation 
Total elapsed time: 6.373888687230647. Arrivals time: 0.26324034202843904 Scheduler time: 6.019810004159808 Scheduler overhead time: 0.025862264912575483 Adapter cache time: 0.027301480527967215 Engine time: 0.025985047686845064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.441801221109927,
    "estimated_duration": 3600.1403276310116,
    "input_throughput": 4092.530473581611,
    "output_throughput": 3598.5277853113216,
    "total_throughput": 7691.058258892933,
    "itl": 237.650783682136,
    "ttft": 2272362.23222116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.261766181665012,
    "arrivals": 1660646,
    "finished_requests": 59496,
    "scheduler_time": 90.26780487748036
}
#Debug simulation 
Total elapsed time: 6.4418964250944555. Arrivals time: 0.2517791907303035 Scheduler time: 6.100390020292252 Scheduler overhead time: 0.02592591429129243 Adapter cache time: 0.025820030365139246 Engine time: 0.026435256469994783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.583887682761997,
    "estimated_duration": 3600.133752428116,
    "input_throughput": 3613.901008879192,
    "output_throughput": 3186.89020713796,
    "total_throughput": 6800.791216017152,
    "itl": 159.38207957186,
    "ttft": 2333053.667269355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.341277559566802,
    "arrivals": 1660646,
    "finished_requests": 52508,
    "scheduler_time": 102.4896695760106
}
#Debug simulation 
Total elapsed time: 4.58398207789287. Arrivals time: 0.34249480767175555 Scheduler time: 4.077419545967132 Scheduler overhead time: 0.035073147621005774 Adapter cache time: 0.07743926299735904 Engine time: 0.03525754529982805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.456106717232615,
    "estimated_duration": 3600.2155669619915,
    "input_throughput": 4088.8143296435587,
    "output_throughput": 3597.9776096937126,
    "total_throughput": 7686.791939337271,
    "itl": 237.72424731132926,
    "ttft": 2272151.1365558766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.301597375760285,
    "arrivals": 1660646,
    "finished_requests": 59473,
    "scheduler_time": 90.26248558741372
}
#Debug simulation 
Total elapsed time: 6.456205475144088. Arrivals time: 0.3834849875420332 Scheduler time: 5.982097401283681 Scheduler overhead time: 0.02574962843209505 Adapter cache time: 0.02718421444296837 Engine time: 0.026037720497697592 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.921991388313472,
    "estimated_duration": 3600.088643878388,
    "input_throughput": 3613.790738770342,
    "output_throughput": 3186.810141330385,
    "total_throughput": 6800.600880100727,
    "itl": 159.38880597857363,
    "ttft": 2332974.516274376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.472564512583835,
    "arrivals": 1660646,
    "finished_requests": 52506,
    "scheduler_time": 102.48475285448346
}
#Debug simulation 
Total elapsed time: 4.9220830402337015. Arrivals time: 0.21958186477422714 Scheduler time: 4.538052094634622 Scheduler overhead time: 0.03520214976742864 Adapter cache time: 0.07756926957517862 Engine time: 0.035372404381632805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.34053710475564,
    "estimated_duration": 3600.068009908148,
    "input_throughput": 4088.9819190875737,
    "output_throughput": 3598.1250810677034,
    "total_throughput": 7687.107000155277,
    "itl": 237.7154651183945,
    "ttft": 2272091.1609810027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1055,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.15450306112172,
    "arrivals": 1660646,
    "finished_requests": 59473,
    "scheduler_time": 90.26202284817309
}
#Debug simulation 
Total elapsed time: 6.340611489024013. Arrivals time: 0.25364032108336687 Scheduler time: 5.995648806914687 Scheduler overhead time: 0.02578971115872264 Adapter cache time: 0.027890919242054224 Engine time: 0.026094491593539715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 4320, 66, 34560, 34560, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 66, 34560, 4320, 4320, 66, 66, 66, 4320, 66, 4320, 66, 34560, 66, 4320, 34560, 66, 34560, 4320, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 4320, 4320, 66, 66, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 66, 66, 4320, 4320, 34560, 66, 66, 34560, 66, 34560, 4320, 66, 34560, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 34560, 66, 34560, 4320, 4320, 34560, 34560, 66, 4320, 34560, 66, 4320, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 34560, 66, 34560, 4320, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 34560, 66, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 66, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 66, 66, 66, 66, 66, 4320, 66, 66, 4320, 34560, 34560, 66, 66, 34560, 66, 66, 66, 4320, 66, 4320, 34560, 34560, 4320, 4320, 66, 34560, 4320, 34560, 66, 4320, 4320, 66, 66, 4320, 66, 34560, 34560, 66, 34560, 34560, 66, 4320, 34560, 66, 66, 4320, 4320, 66, 66, 34560, 34560, 34560, 34560, 4320, 66, 4320, 4320, 66, 66, 66, 66, 66, 66, 66, 66, 4320, 34560, 4320, 4320, 4320, 34560, 66, 4320, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 4320, 66, 34560, 34560, 34560, 4320, 66, 34560, 34560, 4320, 4320, 34560, 34560, 66, 34560, 34560, 4320, 66, 34560, 4320, 4320, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 4320, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 66, 34560, 66, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 34560, 34560, 66, 34560, 34560, 66, 34560, 4320, 34560, 4320, 4320, 4320, 66, 4320, 66, 66, 34560, 66, 4320, 66, 66, 4320, 34560, 4320, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4985088 . Total input tokens: 1110432516 . Total output tokens: 996850533
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.5980523633770645,
    "estimated_duration": 3600.0476840171923,
    "input_throughput": 3613.3713055390403,
    "output_throughput": 3186.2019636363298,
    "total_throughput": 6799.57326917537,
    "itl": 159.39299495438465,
    "ttft": 2333035.5655837418,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.607749832979747,
    "arrivals": 1660646,
    "finished_requests": 52500,
    "scheduler_time": 102.4798688174778
}
#Debug simulation 
Total elapsed time: 4.598152108024806. Arrivals time: 0.3441258785314858 Scheduler time: 4.089311362244189 Scheduler overhead time: 0.03525386145338416 Adapter cache time: 0.0776320556178689 Engine time: 0.035473437048494816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.126608390361071,
    "estimated_duration": 3600.1669186775625,
    "input_throughput": 4113.133455889696,
    "output_throughput": 3593.0967347346345,
    "total_throughput": 7706.23019062433,
    "itl": 236.8395462212137,
    "ttft": 2272522.6587179336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.34511310411858,
    "arrivals": 1659330,
    "finished_requests": 59839,
    "scheduler_time": 90.3410631784393
}
#Debug simulation 
Total elapsed time: 6.126707287039608. Arrivals time: 0.2522848560474813 Scheduler time: 5.782254454679787 Scheduler overhead time: 0.02577647427096963 Adapter cache time: 0.028593010269105434 Engine time: 0.026180990505963564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.151905019767582,
    "estimated_duration": 3600.121107076231,
    "input_throughput": 4112.771920615969,
    "output_throughput": 3593.0171833872423,
    "total_throughput": 7705.789104003212,
    "itl": 236.8532370724955,
    "ttft": 2272555.665681399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.561496410968251,
    "arrivals": 1659330,
    "finished_requests": 59836,
    "scheduler_time": 90.3350077035249
}
#Debug simulation 
Total elapsed time: 6.152003325987607. Arrivals time: 0.25452981563284993 Scheduler time: 5.804291614331305 Scheduler overhead time: 0.0257443655282259 Adapter cache time: 0.02753724902868271 Engine time: 0.02828633226454258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.397158083040267,
    "estimated_duration": 3600.0574382182162,
    "input_throughput": 3626.333530517597,
    "output_throughput": 3187.14775997541,
    "total_throughput": 6813.481290493007,
    "itl": 159.36619750007688,
    "ttft": 2334756.128249826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.601621442194535,
    "arrivals": 1659330,
    "finished_requests": 52858,
    "scheduler_time": 102.47951856396931
}
#Debug simulation 
Total elapsed time: 4.397251452784985. Arrivals time: 0.21977467462420464 Scheduler time: 4.011943924240768 Scheduler overhead time: 0.03493329184129834 Adapter cache time: 0.07927366066724062 Engine time: 0.03508527250960469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 6.143831764813513,
    "estimated_duration": 3600.2331498942485,
    "input_throughput": 4113.057789169838,
    "output_throughput": 3593.0306348020736,
    "total_throughput": 7706.088423971912,
    "itl": 236.8433443090753,
    "ttft": 2272550.574294355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4111333337821597,
    "arrivals": 1659330,
    "finished_requests": 59839,
    "scheduler_time": 90.34127416536033
}
#Debug simulation 
Total elapsed time: 6.143929488956928. Arrivals time: 0.2534241178072989 Scheduler time: 5.799065211322159 Scheduler overhead time: 0.02576928725466132 Adapter cache time: 0.027890756726264954 Engine time: 0.026211291551589966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.879919607192278,
    "estimated_duration": 3600.02111550596,
    "input_throughput": 3626.2098418734645,
    "output_throughput": 3187.0354733704075,
    "total_throughput": 6813.245315243872,
    "itl": 159.3716258247945,
    "ttft": 2334744.6181604243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.73969909967798,
    "arrivals": 1659330,
    "finished_requests": 52856,
    "scheduler_time": 102.47463824571454
}
#Debug simulation 
Total elapsed time: 4.880013692192733. Arrivals time: 0.6735198847018182 Scheduler time: 4.039631627034396 Scheduler overhead time: 0.03508640406653285 Adapter cache time: 0.08009289251640439 Engine time: 0.035403802525252104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 6.14557071775198,
    "estimated_duration": 3600.0897274118106,
    "input_throughput": 4113.221647574266,
    "output_throughput": 3593.173776060247,
    "total_throughput": 7706.3954236345135,
    "itl": 236.83495720841503,
    "ttft": 2272491.75130968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.268124972327999,
    "arrivals": 1659330,
    "finished_requests": 59839,
    "scheduler_time": 90.3408600443429
}
#Debug simulation 
Total elapsed time: 6.145636500790715. Arrivals time: 0.25442095939069986 Scheduler time: 5.798166166525334 Scheduler overhead time: 0.025921784341335297 Adapter cache time: 0.029179422184824944 Engine time: 0.02635373268276453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 4320, 33, 34560, 34560, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 33, 34560, 4320, 4320, 33, 33, 33, 4320, 33, 4320, 33, 34560, 33, 4320, 34560, 33, 34560, 4320, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 4320, 4320, 33, 33, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 33, 33, 4320, 4320, 34560, 33, 33, 34560, 33, 34560, 4320, 33, 34560, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 34560, 33, 34560, 4320, 4320, 34560, 34560, 33, 4320, 34560, 33, 4320, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 34560, 33, 34560, 4320, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 34560, 33, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 34560, 33, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 34560, 33, 33, 33, 33, 33, 4320, 33, 33, 4320, 34560, 34560, 33, 33, 34560, 33, 33, 33, 4320, 33, 4320, 34560, 34560, 4320, 4320, 33, 34560, 4320, 34560, 33, 4320, 4320, 33, 33, 4320, 33, 34560, 34560, 33, 34560, 34560, 33, 4320, 34560, 33, 33, 4320, 4320, 33, 33, 34560, 34560, 34560, 34560, 4320, 33, 4320, 4320, 33, 33, 33, 33, 33, 33, 33, 33, 4320, 34560, 4320, 4320, 4320, 34560, 33, 4320, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 4320, 33, 34560, 34560, 34560, 4320, 33, 34560, 34560, 4320, 4320, 34560, 34560, 33, 34560, 34560, 4320, 33, 34560, 4320, 4320, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 4320, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 33, 34560, 33, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 34560, 34560, 33, 34560, 34560, 33, 34560, 4320, 34560, 4320, 4320, 4320, 33, 4320, 33, 33, 34560, 33, 4320, 33, 33, 4320, 34560, 4320, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4980864 . Total input tokens: 1109503977 . Total output tokens: 996018309
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.408835230860859,
    "estimated_duration": 3600.1559449360784,
    "input_throughput": 3626.0740366989253,
    "output_throughput": 3186.916115713902,
    "total_throughput": 6812.990152412827,
    "itl": 159.37750563056014,
    "ttft": 2334792.2584471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3243,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.874381404928243,
    "arrivals": 1659330,
    "finished_requests": 52856,
    "scheduler_time": 102.47478537069398
}
#Debug simulation 
Total elapsed time: 4.408931360114366. Arrivals time: 0.21830120170488954 Scheduler time: 4.025665580760688 Scheduler overhead time: 0.03482706192880869 Adapter cache time: 0.07867814088240266 Engine time: 0.035136046819388866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.87552949693054,
    "estimated_duration": 3600.0356952308425,
    "input_throughput": 4102.452378337593,
    "output_throughput": 3597.998769056491,
    "total_throughput": 7700.451147394084,
    "itl": 237.3113632229631,
    "ttft": 2267437.080386451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.545603792006307,
    "arrivals": 1542191,
    "finished_requests": 59812,
    "scheduler_time": 90.24433680686596
}
#Debug simulation 
Total elapsed time: 4.87562991399318. Arrivals time: 0.24406100995838642 Scheduler time: 4.528215329628438 Scheduler overhead time: 0.025295292027294636 Adapter cache time: 0.04115587705746293 Engine time: 0.025379568338394165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.875164846889675,
    "estimated_duration": 3600.132350437886,
    "input_throughput": 4102.0336372366355,
    "output_throughput": 3597.681345916248,
    "total_throughput": 7699.714983152884,
    "itl": 237.33443249950636,
    "ttft": 2267518.5558059462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.901339396077508,
    "arrivals": 1542191,
    "finished_requests": 59809,
    "scheduler_time": 90.2383489301221
}
#Debug simulation 
Total elapsed time: 4.875287221744657. Arrivals time: 0.24404873047024012 Scheduler time: 4.527560918126255 Scheduler overhead time: 0.025831655133515596 Adapter cache time: 0.04040181636810303 Engine time: 0.025889530777931213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.24946199869737,
    "estimated_duration": 3600.0799285676435,
    "input_throughput": 3761.5167631535983,
    "output_throughput": 3307.640451399011,
    "total_throughput": 7069.15721455261,
    "itl": 154.0322747790876,
    "ttft": 2311266.4781165873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.892046452090112,
    "arrivals": 1542191,
    "finished_requests": 54783,
    "scheduler_time": 106.18620222513901
}
#Debug simulation 
Total elapsed time: 4.249555916991085. Arrivals time: 0.22178546199575067 Scheduler time: 3.8695106231607497 Scheduler overhead time: 0.03487271023914218 Adapter cache time: 0.07106612296774983 Engine time: 0.03587248036637902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.85302508296445,
    "estimated_duration": 3600.1411584564707,
    "input_throughput": 4102.332200310742,
    "output_throughput": 3597.8933685904285,
    "total_throughput": 7700.225568901172,
    "itl": 237.3177316435116,
    "ttft": 2267478.2495931303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.650870465873587,
    "arrivals": 1542191,
    "finished_requests": 59812,
    "scheduler_time": 90.24453335844757
}
#Debug simulation 
Total elapsed time: 4.853123048786074. Arrivals time: 0.2430870975367725 Scheduler time: 4.505678324494511 Scheduler overhead time: 0.025191310327500105 Adapter cache time: 0.0424451595172286 Engine time: 0.025261410512030125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.258195266127586,
    "estimated_duration": 3600.0134202235918,
    "input_throughput": 3761.5670885912823,
    "output_throughput": 3307.5085034712088,
    "total_throughput": 7069.075592062491,
    "itl": 154.03565017561021,
    "ttft": 2311294.6373913903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.995919079668629,
    "arrivals": 1542191,
    "finished_requests": 54779,
    "scheduler_time": 106.18131243147559
}
#Debug simulation 
Total elapsed time: 4.258289520163089. Arrivals time: 0.22232474759221077 Scheduler time: 3.8761665672063828 Scheduler overhead time: 0.03486641217023134 Adapter cache time: 0.07238785037770867 Engine time: 0.03594457171857357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.874531257897615,
    "estimated_duration": 3600.1686495622107,
    "input_throughput": 4102.5958608344845,
    "output_throughput": 3598.290597185022,
    "total_throughput": 7700.886458019506,
    "itl": 237.3053405097492,
    "ttft": 2267438.447848314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4179711343625865,
    "arrivals": 1542191,
    "finished_requests": 59817,
    "scheduler_time": 90.25074309205273
}
#Debug simulation 
Total elapsed time: 4.874629305675626. Arrivals time: 0.24261699430644512 Scheduler time: 4.529015694744885 Scheduler overhead time: 0.02532533323392272 Adapter cache time: 0.04059050604701042 Engine time: 0.025588203687220812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 34560, 1080, 540, 34560, 34560, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 540, 34560, 1080, 1080, 540, 540, 540, 1080, 540, 1080, 540, 34560, 540, 1080, 34560, 540, 34560, 1080, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 1080, 1080, 540, 540, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 540, 540, 1080, 1080, 34560, 540, 540, 34560, 540, 34560, 1080, 540, 34560, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 34560, 540, 34560, 1080, 1080, 34560, 34560, 540, 1080, 34560, 540, 1080, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 34560, 540, 34560, 1080, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 34560, 540, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 540, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 540, 540, 540, 540, 540, 1080, 540, 540, 1080, 34560, 34560, 540, 540, 34560, 540, 540, 540, 1080, 540, 1080, 34560, 34560, 1080, 1080, 540, 34560, 1080, 34560, 540, 1080, 1080, 540, 540, 1080, 540, 34560, 34560, 540, 34560, 34560, 540, 1080, 34560, 540, 540, 1080, 1080, 540, 540, 34560, 34560, 34560, 34560, 1080, 540, 1080, 1080, 540, 540, 540, 540, 540, 540, 540, 540, 1080, 34560, 1080, 1080, 1080, 34560, 540, 1080, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 540, 540, 1080, 540, 34560, 34560, 34560, 1080, 540, 34560, 34560, 1080, 1080, 34560, 34560, 540, 34560, 34560, 1080, 540, 34560, 1080, 1080, 34560, 34560, 34560, 540, 34560, 540, 34560, 34560, 540, 540, 34560, 540, 1080, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 540, 34560, 540, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 34560, 34560, 540, 34560, 34560, 540, 34560, 1080, 34560, 1080, 1080, 1080, 540, 1080, 540, 540, 34560, 540, 1080, 540, 540, 1080, 34560, 1080, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4631040 . Total input tokens: 1031716165 . Total output tokens: 925998705
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.261924175079912,
    "estimated_duration": 3600.1129051024122,
    "input_throughput": 3761.463142116311,
    "output_throughput": 3307.4171043703086,
    "total_throughput": 7068.880246486619,
    "itl": 154.0398911217085,
    "ttft": 2311329.7574251886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.095264570936218,
    "arrivals": 1542191,
    "finished_requests": 54779,
    "scheduler_time": 106.18145181911308
}
#Debug simulation 
Total elapsed time: 4.262020295951515. Arrivals time: 0.22058910643681884 Scheduler time: 3.8827577610500157 Scheduler overhead time: 0.03500271728262305 Adapter cache time: 0.07121470244601369 Engine time: 0.03594351094216108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.58140030875802,
    "estimated_duration": 3600.1825185191587,
    "input_throughput": 4107.1848229745,
    "output_throughput": 3605.0588916637817,
    "total_throughput": 7712.243714638282,
    "itl": 236.71227391958382,
    "ttft": 2272040.16743927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.814926713472398,
    "arrivals": 1530695,
    "finished_requests": 59748,
    "scheduler_time": 90.43611233473489
}
#Debug simulation 
Total elapsed time: 4.581499363761395. Arrivals time: 0.24178010085597634 Scheduler time: 4.235744239296764 Scheduler overhead time: 0.025054016150534153 Adapter cache time: 0.042279158253222704 Engine time: 0.02513834275305271 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.738378130830824,
    "estimated_duration": 3600.0179407269447,
    "input_throughput": 4106.54259045575,
    "output_throughput": 3604.5300922527363,
    "total_throughput": 7711.072682708485,
    "itl": 236.73673555319758,
    "ttft": 2272083.7034399654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.187753755179971,
    "arrivals": 1530695,
    "finished_requests": 59736,
    "scheduler_time": 90.42317401908754
}
#Debug simulation 
Total elapsed time: 4.738472629804164. Arrivals time: 0.3620724775828421 Scheduler time: 4.272366119548678 Scheduler overhead time: 0.024935055524110794 Adapter cache time: 0.042331145610660315 Engine time: 0.02529505454003811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.281764514744282,
    "estimated_duration": 3600.0737363528046,
    "input_throughput": 3811.8208139543426,
    "output_throughput": 3352.872436504198,
    "total_throughput": 7164.693250458541,
    "itl": 151.97527131600162,
    "ttft": 2312485.900723028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.318196076806574,
    "arrivals": 1530695,
    "finished_requests": 55325,
    "scheduler_time": 107.62848476906946
}
#Debug simulation 
Total elapsed time: 4.281862331088632. Arrivals time: 0.22107046330347657 Scheduler time: 3.907864096108824 Scheduler overhead time: 0.03526880964636803 Adapter cache time: 0.0646876897662878 Engine time: 0.0363003620877862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.610603154171258,
    "estimated_duration": 3600.0300216751148,
    "input_throughput": 4106.807696320439,
    "output_throughput": 3604.861048897988,
    "total_throughput": 7711.668745218427,
    "itl": 236.7193166885911,
    "ttft": 2272050.2716686153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.930747299881011,
    "arrivals": 1530695,
    "finished_requests": 59743,
    "scheduler_time": 90.42959289001466
}
#Debug simulation 
Total elapsed time: 4.610706753097475. Arrivals time: 0.24628474609926343 Scheduler time: 4.260429115965962 Scheduler overhead time: 0.024915922433137894 Adapter cache time: 0.04239162104204297 Engine time: 0.025235602166503668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.305224344134331,
    "estimated_duration": 3600.1535865495325,
    "input_throughput": 3811.736269049641,
    "output_throughput": 3352.79807092028,
    "total_throughput": 7164.534339969921,
    "itl": 151.978691017928,
    "ttft": 2312516.4905820526,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.3979239773935355,
    "arrivals": 1530695,
    "finished_requests": 55325,
    "scheduler_time": 107.62860706526507
}
#Debug simulation 
Total elapsed time: 4.3053455632179976. Arrivals time: 0.22265202784910798 Scheduler time: 3.929032419808209 Scheduler overhead time: 0.03529054671525955 Adapter cache time: 0.06545057985931635 Engine time: 0.03618887532502413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.697871716227382,
    "estimated_duration": 3600.048499706842,
    "input_throughput": 4107.33772092351,
    "output_throughput": 3605.1930969976906,
    "total_throughput": 7712.530817921201,
    "itl": 236.7038860286738,
    "ttft": 2271990.6102242954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.681095560313969,
    "arrivals": 1530695,
    "finished_requests": 59748,
    "scheduler_time": 90.43592467532235
}
#Debug simulation 
Total elapsed time: 4.6979681509546936. Arrivals time: 0.36274272250011563 Scheduler time: 4.231589935719967 Scheduler overhead time: 0.02484105248004198 Adapter cache time: 0.042306839954108 Engine time: 0.02508385945111513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 1080, 270, 34560, 34560, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 270, 34560, 1080, 1080, 270, 270, 270, 1080, 270, 1080, 270, 34560, 270, 1080, 34560, 270, 34560, 1080, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 1080, 1080, 270, 270, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 270, 270, 1080, 1080, 34560, 270, 270, 34560, 270, 34560, 1080, 270, 34560, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 34560, 270, 34560, 1080, 1080, 34560, 34560, 270, 1080, 34560, 270, 1080, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 34560, 270, 34560, 1080, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 34560, 270, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 270, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 270, 270, 270, 270, 270, 1080, 270, 270, 1080, 34560, 34560, 270, 270, 34560, 270, 270, 270, 1080, 270, 1080, 34560, 34560, 1080, 1080, 270, 34560, 1080, 34560, 270, 1080, 1080, 270, 270, 1080, 270, 34560, 34560, 270, 34560, 34560, 270, 1080, 34560, 270, 270, 1080, 1080, 270, 270, 34560, 34560, 34560, 34560, 1080, 270, 1080, 1080, 270, 270, 270, 270, 270, 270, 270, 270, 1080, 34560, 1080, 1080, 1080, 34560, 270, 1080, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 1080, 270, 34560, 34560, 34560, 1080, 270, 34560, 34560, 1080, 1080, 34560, 34560, 270, 34560, 34560, 1080, 270, 34560, 1080, 1080, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 1080, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 270, 34560, 270, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 34560, 34560, 270, 34560, 34560, 270, 34560, 1080, 34560, 1080, 1080, 1080, 270, 1080, 270, 270, 34560, 270, 1080, 270, 270, 1080, 34560, 1080, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4596480 . Total input tokens: 1024130951 . Total output tokens: 919050936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.285038533620536,
    "estimated_duration": 3600.0684722967285,
    "input_throughput": 3811.4861163310184,
    "output_throughput": 3352.6731763242883,
    "total_throughput": 7164.159292655307,
    "itl": 151.98247117141307,
    "ttft": 2312507.1140456228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4770231090484165,
    "arrivals": 1530695,
    "finished_requests": 55321,
    "scheduler_time": 107.62373610111027
}
#Debug simulation 
Total elapsed time: 4.285137468017638. Arrivals time: 0.2263458496890962 Scheduler time: 3.9060911904089153 Scheduler overhead time: 0.035110043827444315 Adapter cache time: 0.06484984885901213 Engine time: 0.036177432630211115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.967930258251727,
    "estimated_duration": 3600.0195572102466,
    "input_throughput": 4159.650180235242,
    "output_throughput": 3637.8405149967234,
    "total_throughput": 7797.490695231966,
    "itl": 234.08365235461125,
    "ttft": 2265767.49095505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4170633067611265,
    "arrivals": 1525074,
    "finished_requests": 60020,
    "scheduler_time": 91.39647023529568
}
#Debug simulation 
Total elapsed time: 4.968001337256283. Arrivals time: 0.7074651322327554 Scheduler time: 4.1597427958622575 Scheduler overhead time: 0.024511887691915035 Adapter cache time: 0.03983401507139206 Engine time: 0.02512052794918418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.543647070880979,
    "estimated_duration": 3600.118781482812,
    "input_throughput": 4159.282209525477,
    "output_throughput": 3637.549424023781,
    "total_throughput": 7796.831633549258,
    "itl": 234.10479212134317,
    "ttft": 2265815.565278377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.779026046239149,
    "arrivals": 1525074,
    "finished_requests": 60017,
    "scheduler_time": 91.39027378699143
}
#Debug simulation 
Total elapsed time: 4.543714116793126. Arrivals time: 0.23595823347568512 Scheduler time: 4.205412033479661 Scheduler overhead time: 0.0246386188082397 Adapter cache time: 0.04102020710706711 Engine time: 0.0253120306879282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.386776968836784,
    "estimated_duration": 3600.0399025495044,
    "input_throughput": 3852.955071463756,
    "output_throughput": 3383.6619397949835,
    "total_throughput": 7236.61701125874,
    "itl": 149.52332995389926,
    "ttft": 2306723.593775126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4198244751989275,
    "arrivals": 1525074,
    "finished_requests": 55551,
    "scheduler_time": 109.0070027797175
}
#Debug simulation 
Total elapsed time: 4.386870414949954. Arrivals time: 0.23774309642612934 Scheduler time: 3.9987581982277334 Scheduler overhead time: 0.03593521285802126 Adapter cache time: 0.06038744514808059 Engine time: 0.037016625981777906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.538505947217345,
    "estimated_duration": 3600.1324867532353,
    "input_throughput": 4159.5196996499935,
    "output_throughput": 3637.726402622155,
    "total_throughput": 7797.246102272148,
    "itl": 234.0905399895947,
    "ttft": 2265810.1681064507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.529782901990545,
    "arrivals": 1525074,
    "finished_requests": 60020,
    "scheduler_time": 91.39668018287227
}
#Debug simulation 
Total elapsed time: 4.538605346810073. Arrivals time: 0.23898678738623857 Scheduler time: 4.19807070447132 Scheduler overhead time: 0.02464194316416979 Adapter cache time: 0.04014057153835893 Engine time: 0.025324595160782337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.3424833989702165,
    "estimated_duration": 3600.1105758378544,
    "input_throughput": 3852.87943461899,
    "output_throughput": 3383.595515580807,
    "total_throughput": 7236.474950199797,
    "itl": 149.52623314380287,
    "ttft": 2306749.1210696655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.49037234937765,
    "arrivals": 1525074,
    "finished_requests": 55551,
    "scheduler_time": 109.00712819394643
}
#Debug simulation 
Total elapsed time: 4.342579938005656. Arrivals time: 0.2317443462088704 Scheduler time: 3.9613045789301395 Scheduler overhead time: 0.03569368924945593 Adapter cache time: 0.06007579993456602 Engine time: 0.03689285879954696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.5210503078997135,
    "estimated_duration": 3600.1579929006266,
    "input_throughput": 4159.710776452405,
    "output_throughput": 3638.057281327077,
    "total_throughput": 7797.768057779483,
    "itl": 234.07743902116118,
    "ttft": 2265788.873353152,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.2923890219767,
    "arrivals": 1525074,
    "finished_requests": 60024,
    "scheduler_time": 91.40303819149538
}
#Debug simulation 
Total elapsed time: 4.521174630150199. Arrivals time: 0.23973997868597507 Scheduler time: 4.180202341172844 Scheduler overhead time: 0.02461941121146083 Adapter cache time: 0.039827095810323954 Engine time: 0.025363470893353224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 1080, 135, 34560, 34560, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 135, 34560, 1080, 1080, 135, 135, 135, 1080, 135, 1080, 135, 34560, 135, 1080, 34560, 135, 34560, 1080, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 1080, 1080, 135, 135, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 135, 135, 1080, 1080, 34560, 135, 135, 34560, 135, 34560, 1080, 135, 34560, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 34560, 135, 34560, 1080, 1080, 34560, 34560, 135, 1080, 34560, 135, 1080, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 34560, 135, 34560, 1080, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 34560, 135, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 135, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 135, 135, 135, 135, 135, 1080, 135, 135, 1080, 34560, 34560, 135, 135, 34560, 135, 135, 135, 1080, 135, 1080, 34560, 34560, 1080, 1080, 135, 34560, 1080, 34560, 135, 1080, 1080, 135, 135, 1080, 135, 34560, 34560, 135, 34560, 34560, 135, 1080, 34560, 135, 135, 1080, 1080, 135, 135, 34560, 34560, 34560, 34560, 1080, 135, 1080, 1080, 135, 135, 135, 135, 135, 135, 135, 135, 1080, 34560, 1080, 1080, 1080, 34560, 135, 1080, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 1080, 135, 34560, 34560, 34560, 1080, 135, 34560, 34560, 1080, 1080, 34560, 34560, 135, 34560, 34560, 1080, 135, 34560, 1080, 1080, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 1080, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 135, 34560, 135, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 34560, 34560, 135, 34560, 34560, 135, 34560, 1080, 34560, 1080, 1080, 1080, 135, 1080, 135, 135, 34560, 135, 1080, 135, 135, 1080, 34560, 1080, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4579200 . Total input tokens: 1020308388 . Total output tokens: 915535080
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.333153867162764,
    "estimated_duration": 3600.015972880688,
    "input_throughput": 3852.6359617515136,
    "output_throughput": 3383.336099548932,
    "total_throughput": 7235.972061300446,
    "itl": 149.53059921497155,
    "ttft": 2306737.4684411185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.559159670546557,
    "arrivals": 1525074,
    "finished_requests": 55546,
    "scheduler_time": 109.00227872996768
}
#Debug simulation 
Total elapsed time: 4.333248394075781. Arrivals time: 0.2222794145345688 Scheduler time: 3.960919502656907 Scheduler overhead time: 0.03581435885280371 Adapter cache time: 0.06045698840171099 Engine time: 0.036843696143478155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.539511738810688,
    "estimated_duration": 3600.031546539577,
    "input_throughput": 4140.356496133314,
    "output_throughput": 3639.1369993946173,
    "total_throughput": 7779.493495527931,
    "itl": 234.96995048627036,
    "ttft": 2265421.1220442858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.294643797003812,
    "arrivals": 1522091,
    "finished_requests": 60124,
    "scheduler_time": 91.28516190910679
}
#Debug simulation 
Total elapsed time: 4.539612226188183. Arrivals time: 0.23990823840722442 Scheduler time: 4.197792808059603 Scheduler overhead time: 0.024647900834679604 Adapter cache time: 0.040747706312686205 Engine time: 0.025134079158306122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.552324226126075,
    "estimated_duration": 3600.1162653716756,
    "input_throughput": 4139.912130993718,
    "output_throughput": 3638.8733125116223,
    "total_throughput": 7778.7854435053405,
    "itl": 234.9898464256086,
    "ttft": 2265508.2786929114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.639402863839496,
    "arrivals": 1522091,
    "finished_requests": 60121,
    "scheduler_time": 91.2790232778983
}
#Debug simulation 
Total elapsed time: 4.552423732820898. Arrivals time: 0.2372498419135809 Scheduler time: 4.214588806964457 Scheduler overhead time: 0.02451134053990245 Adapter cache time: 0.0393746392801404 Engine time: 0.025283008348196745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.407251051161438,
    "estimated_duration": 3600.0051229973737,
    "input_throughput": 3795.4520988635736,
    "output_throughput": 3347.9577356725868,
    "total_throughput": 7143.409834536161,
    "itl": 146.55329786825502,
    "ttft": 2310308.419052277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.3244885225966065,
    "arrivals": 1522091,
    "finished_requests": 55159,
    "scheduler_time": 109.75355159103012
}
#Debug simulation 
Total elapsed time: 4.407349278219044. Arrivals time: 0.331974592525512 Scheduler time: 3.9232706003822386 Scheduler overhead time: 0.036480726674199104 Adapter cache time: 0.06055233906954527 Engine time: 0.03773194970563054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.541758153121918,
    "estimated_duration": 3600.1472797225883,
    "input_throughput": 4140.223396957401,
    "output_throughput": 3639.0200128172273,
    "total_throughput": 7779.243409774628,
    "itl": 234.97711674184677,
    "ttft": 2265463.8181418143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.410180890194466,
    "arrivals": 1522091,
    "finished_requests": 60124,
    "scheduler_time": 91.28535799875755
}
#Debug simulation 
Total elapsed time: 4.54185211006552. Arrivals time: 0.23985103191807866 Scheduler time: 4.200942098163068 Scheduler overhead time: 0.02470136247575283 Adapter cache time: 0.0397170465439558 Engine time: 0.02522988338023424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.308117623906583,
    "estimated_duration": 3600.0700056064484,
    "input_throughput": 3795.3836949618694,
    "output_throughput": 3347.8973967812253,
    "total_throughput": 7143.281091743095,
    "itl": 146.55595117059227,
    "ttft": 2310332.1052907156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.38925172260025,
    "arrivals": 1522091,
    "finished_requests": 55159,
    "scheduler_time": 109.75367100015785
}
#Debug simulation 
Total elapsed time: 4.308217353187501. Arrivals time: 0.2240934413857758 Scheduler time: 3.9312556590884924 Scheduler overhead time: 0.036591524723917246 Adapter cache time: 0.06045815022662282 Engine time: 0.038443734869360924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.546998632140458,
    "estimated_duration": 3600.170712535168,
    "input_throughput": 4140.939747132719,
    "output_throughput": 3639.59490986832,
    "total_throughput": 7780.534657001039,
    "itl": 234.96216148410636,
    "ttft": 2265400.815527817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1730,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.172787010180617,
    "arrivals": 1522091,
    "finished_requests": 60133,
    "scheduler_time": 91.29163752761784
}
#Debug simulation 
Total elapsed time: 4.547094659879804. Arrivals time: 0.23857114184647799 Scheduler time: 4.207526437938213 Scheduler overhead time: 0.024507965426892042 Adapter cache time: 0.03969282936304808 Engine time: 0.02540442580357194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 1080, 66, 34560, 34560, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 66, 34560, 1080, 1080, 66, 66, 66, 1080, 66, 1080, 66, 34560, 66, 1080, 34560, 66, 34560, 1080, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 1080, 1080, 66, 66, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 66, 66, 1080, 1080, 34560, 66, 66, 34560, 66, 34560, 1080, 66, 34560, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 34560, 66, 34560, 1080, 1080, 34560, 34560, 66, 1080, 34560, 66, 1080, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 34560, 66, 34560, 1080, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 34560, 66, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 66, 66, 66, 66, 66, 1080, 66, 66, 1080, 34560, 34560, 66, 66, 34560, 66, 66, 66, 1080, 66, 1080, 34560, 34560, 1080, 1080, 66, 34560, 1080, 34560, 66, 1080, 1080, 66, 66, 1080, 66, 34560, 34560, 66, 34560, 34560, 66, 1080, 34560, 66, 66, 1080, 1080, 66, 66, 34560, 34560, 34560, 34560, 1080, 66, 1080, 1080, 66, 66, 66, 66, 66, 66, 66, 66, 1080, 34560, 1080, 1080, 1080, 34560, 66, 1080, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 1080, 66, 34560, 34560, 34560, 1080, 66, 34560, 34560, 1080, 1080, 34560, 34560, 66, 34560, 34560, 1080, 66, 34560, 1080, 1080, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 1080, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 66, 34560, 66, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 34560, 34560, 66, 34560, 34560, 66, 34560, 1080, 34560, 1080, 1080, 1080, 66, 1080, 66, 66, 34560, 66, 1080, 66, 66, 1080, 34560, 1080, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4570368 . Total input tokens: 1018326849 . Total output tokens: 913762655
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.472197983879596,
    "estimated_duration": 3600.140935599088,
    "input_throughput": 3795.308918295521,
    "output_throughput": 3347.8314364919033,
    "total_throughput": 7143.140354787424,
    "itl": 146.55882738028834,
    "ttft": 2310357.7044031825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4600511043517965,
    "arrivals": 1522091,
    "finished_requests": 55159,
    "scheduler_time": 109.75380161110897
}
#Debug simulation 
Total elapsed time: 4.472297294996679. Arrivals time: 0.34527004370465875 Scheduler time: 3.9721080609597266 Scheduler overhead time: 0.03671654872596264 Adapter cache time: 0.06036712462082505 Engine time: 0.04032260179519653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.688913700170815,
    "estimated_duration": 3600.0403125235266,
    "input_throughput": 4161.601732036741,
    "output_throughput": 3660.0948478723153,
    "total_throughput": 7821.696579909057,
    "itl": 233.5930886572965,
    "ttft": 2263325.357207246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.071228191696713,
    "arrivals": 1520700,
    "finished_requests": 60684,
    "scheduler_time": 91.85937982349634
}
#Debug simulation 
Total elapsed time: 4.689009960275143. Arrivals time: 0.359503744635731 Scheduler time: 4.227534054778516 Scheduler overhead time: 0.02573832916095853 Adapter cache time: 0.039333559572696686 Engine time: 0.02529082167893648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.585486825089902,
    "estimated_duration": 3600.0986128934896,
    "input_throughput": 4161.269345885892,
    "output_throughput": 3659.8286371412264,
    "total_throughput": 7821.097983027119,
    "itl": 233.61131285591026,
    "ttft": 2263336.350928127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.399882235752769,
    "arrivals": 1520700,
    "finished_requests": 60680,
    "scheduler_time": 91.85309407209705
}
#Debug simulation 
Total elapsed time: 4.585587258916348. Arrivals time: 0.2576326816342771 Scheduler time: 4.227989383041859 Scheduler overhead time: 0.02453318005427718 Adapter cache time: 0.03884200332686305 Engine time: 0.025176935829222202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.369159298017621,
    "estimated_duration": 3600.047366109433,
    "input_throughput": 3863.647776121285,
    "output_throughput": 3403.3316103951406,
    "total_throughput": 7266.979386516426,
    "itl": 149.73761837433096,
    "ttft": 2304767.161294109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.014782134797358,
    "arrivals": 1520700,
    "finished_requests": 56252,
    "scheduler_time": 109.29506297491345
}
#Debug simulation 
Total elapsed time: 4.369256689213216. Arrivals time: 0.2258350057527423 Scheduler time: 3.9936694470234215 Scheduler overhead time: 0.03594628535211086 Adapter cache time: 0.05976321641355753 Engine time: 0.03710230113938451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.545230568852276,
    "estimated_duration": 3600.137481951921,
    "input_throughput": 4161.489408420342,
    "output_throughput": 3659.996060166007,
    "total_throughput": 7821.485468586349,
    "itl": 233.59897816434048,
    "ttft": 2263363.7198910112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.168208690197086,
    "arrivals": 1520700,
    "finished_requests": 60684,
    "scheduler_time": 91.85956875321874
}
#Debug simulation 
Total elapsed time: 4.5453314911574125. Arrivals time: 0.24575648177415133 Scheduler time: 4.1994168274104595 Scheduler overhead time: 0.024494591169059277 Adapter cache time: 0.039234050549566746 Engine time: 0.025041880551725626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.35978001402691,
    "estimated_duration": 3600.113502676406,
    "input_throughput": 3863.5767982480274,
    "output_throughput": 3403.2690888471907,
    "total_throughput": 7266.845887095218,
    "itl": 149.74035586069394,
    "ttft": 2304791.617760427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.080802872665168,
    "arrivals": 1520700,
    "finished_requests": 56252,
    "scheduler_time": 109.295178804077
}
#Debug simulation 
Total elapsed time: 4.3599007949233055. Arrivals time: 0.22359834518283606 Scheduler time: 3.985562689602375 Scheduler overhead time: 0.03593127569183707 Adapter cache time: 0.05999779421836138 Engine time: 0.03778379876166582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.545029337983578,
    "estimated_duration": 3600.194283357718,
    "input_throughput": 4161.498469473392,
    "output_throughput": 3660.0538645682673,
    "total_throughput": 7821.552334041659,
    "itl": 233.5864018709703,
    "ttft": 2263325.353103917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.954513338652766,
    "arrivals": 1520700,
    "finished_requests": 60685,
    "scheduler_time": 91.86599758770241
}
#Debug simulation 
Total elapsed time: 4.545123225077987. Arrivals time: 0.23999632196500897 Scheduler time: 4.205056602135301 Scheduler overhead time: 0.024607911240309477 Adapter cache time: 0.038846975192427635 Engine time: 0.02515972126275301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 1080, 33, 34560, 34560, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 33, 34560, 1080, 1080, 33, 33, 33, 1080, 33, 1080, 33, 34560, 33, 1080, 34560, 33, 34560, 1080, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 1080, 1080, 33, 33, 34560, 1080, 34560, 1080, 34560, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 33, 33, 1080, 1080, 34560, 33, 33, 34560, 33, 34560, 1080, 33, 34560, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 34560, 33, 34560, 1080, 1080, 34560, 34560, 33, 1080, 34560, 33, 1080, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 34560, 33, 34560, 1080, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 34560, 33, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 34560, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 34560, 33, 33, 33, 33, 33, 1080, 33, 33, 1080, 34560, 34560, 33, 33, 34560, 33, 33, 33, 1080, 33, 1080, 34560, 34560, 1080, 1080, 33, 34560, 1080, 34560, 33, 1080, 1080, 33, 33, 1080, 33, 34560, 34560, 33, 34560, 34560, 33, 1080, 34560, 33, 33, 1080, 1080, 33, 33, 34560, 34560, 34560, 34560, 1080, 33, 1080, 1080, 33, 33, 33, 33, 33, 33, 33, 33, 1080, 34560, 1080, 1080, 1080, 34560, 33, 1080, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 1080, 33, 34560, 34560, 34560, 1080, 33, 34560, 34560, 1080, 1080, 34560, 34560, 33, 34560, 34560, 1080, 33, 34560, 1080, 1080, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 1080, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 33, 34560, 33, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 34560, 34560, 33, 34560, 34560, 33, 34560, 1080, 34560, 1080, 1080, 1080, 33, 1080, 33, 33, 34560, 33, 1080, 33, 33, 1080, 34560, 1080, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4566144 . Total input tokens: 1017376545 . Total output tokens: 912918458
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.3516085632145405,
    "estimated_duration": 3600.010796026009,
    "input_throughput": 3863.391747422837,
    "output_throughput": 3403.228960736563,
    "total_throughput": 7266.620708159399,
    "itl": 149.74239636556695,
    "ttft": 2304633.910269504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.142673735581287,
    "arrivals": 1520700,
    "finished_requests": 56248,
    "scheduler_time": 109.29025872772512
}
#Debug simulation 
Total elapsed time: 4.351706149987876. Arrivals time: 0.2223620368167758 Scheduler time: 3.9793245820328593 Scheduler overhead time: 0.03589997999370098 Adapter cache time: 0.06012354325503111 Engine time: 0.03703307220712304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.649704618845135,
    "estimated_duration": 3600.170397269025,
    "input_throughput": 4254.373907306884,
    "output_throughput": 3764.0415604437785,
    "total_throughput": 8018.415467750663,
    "itl": 228.51755460709123,
    "ttft": 2254108.5509646097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.0122994322959435,
    "arrivals": 1507762,
    "finished_requests": 62022,
    "scheduler_time": 94.17249245135325
}
#Debug simulation 
Total elapsed time: 4.64980393787846. Arrivals time: 0.24368651071563363 Scheduler time: 4.311682507395744 Scheduler overhead time: 0.024912566412240267 Adapter cache time: 0.03224058635532856 Engine time: 0.025679243728518486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.051732985768467,
    "estimated_duration": 3600.1779272136578,
    "input_throughput": 4254.015859669787,
    "output_throughput": 3763.591209639645,
    "total_throughput": 8017.607069309432,
    "itl": 228.53241682352174,
    "ttft": 2254148.187086051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.272982291749191,
    "arrivals": 1507762,
    "finished_requests": 62016,
    "scheduler_time": 94.16640822706871
}
#Debug simulation 
Total elapsed time: 5.051798034925014. Arrivals time: 0.6732469880953431 Scheduler time: 4.284647386521101 Scheduler overhead time: 0.024866885971277952 Adapter cache time: 0.031972923781722784 Engine time: 0.025530952028930187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.436519776005298,
    "estimated_duration": 3600.0048047412542,
    "input_throughput": 3908.768949826826,
    "output_throughput": 3466.265095970304,
    "total_throughput": 7375.034045797131,
    "itl": 147.09357515051872,
    "ttft": 2298705.2432632516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.924060681909266,
    "arrivals": 1507762,
    "finished_requests": 56881,
    "scheduler_time": 111.28164190266256
}
#Debug simulation 
Total elapsed time: 4.436587119940668. Arrivals time: 0.22678984282538295 Scheduler time: 4.066848705522716 Scheduler overhead time: 0.0363692669197917 Adapter cache time: 0.05163061572238803 Engine time: 0.03781181387603283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.613397360313684,
    "estimated_duration": 3600.2527350768546,
    "input_throughput": 4254.276609742798,
    "output_throughput": 3763.955476784249,
    "total_throughput": 8018.2320865270485,
    "itl": 228.5222069523683,
    "ttft": 2254142.228428893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.094426137590724,
    "arrivals": 1507762,
    "finished_requests": 62022,
    "scheduler_time": 94.172703553757
}
#Debug simulation 
Total elapsed time: 4.613519763108343. Arrivals time: 0.2451372561044991 Scheduler time: 4.274063714779913 Scheduler overhead time: 0.02481663879007101 Adapter cache time: 0.03240741975605488 Engine time: 0.025536374654620886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_384_slots_160_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.42263855971396,
    "estimated_duration": 3600.0549806243657,
    "input_throughput": 3908.7144712327513,
    "output_throughput": 3466.2167847880514,
    "total_throughput": 7374.931256020803,
    "itl": 147.09560835953712,
    "ttft": 2298724.203640788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.974110688902441,
    "arrivals": 1507762,
    "finished_requests": 56881,
    "scheduler_time": 111.28176777882234
}
#Debug simulation 
Total elapsed time: 4.422736589796841. Arrivals time: 0.2265352145768702 Scheduler time: 4.053603650070727 Scheduler overhead time: 0.03634305251762271 Adapter cache time: 0.05146389687433839 Engine time: 0.03765403386205435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_384_slots_160_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_384_slots_160_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.100976508110762,
    "estimated_duration": 3600.0778730430693,
    "input_throughput": 4254.483247345233,
    "output_throughput": 3764.13829863782,
    "total_throughput": 8018.621545983054,
    "itl": 228.51208388665998,
    "ttft": 2254072.9813052835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.91995593661665,
    "arrivals": 1507762,
    "finished_requests": 62022,
    "scheduler_time": 94.17231172090365
}
#Debug simulation 
Total elapsed time: 5.101044101174921. Arrivals time: 0.6834907550364733 Scheduler time: 4.323200817219913 Scheduler overhead time: 0.02498833928257227 Adapter cache time: 0.031877569388598204 Engine time: 0.025800426956266165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_384_slots_160_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_384_slots_160_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 34560, 540, 270, 34560, 34560, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 270, 34560, 270, 34560, 540, 540, 540, 270, 270, 540, 270, 34560, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 270, 34560, 540, 540, 270, 270, 270, 540, 270, 540, 270, 34560, 270, 540, 34560, 270, 34560, 540, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 34560, 34560, 540, 270, 270, 34560, 540, 540, 270, 270, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 270, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 270, 270, 540, 540, 34560, 270, 270, 34560, 270, 34560, 540, 270, 34560, 540, 540, 270, 34560, 34560, 34560, 270, 540, 34560, 270, 34560, 540, 540, 34560, 34560, 270, 540, 34560, 270, 540, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 34560, 270, 34560, 540, 540, 540, 540, 540, 270, 270, 34560, 270, 34560, 270, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 270, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 270, 270, 270, 270, 270, 540, 270, 270, 540, 34560, 34560, 270, 270, 34560, 270, 270, 270, 540, 270, 540, 34560, 34560, 540, 540, 270, 34560, 540, 34560, 270, 540, 540, 270, 270, 540, 270, 34560, 34560, 270, 34560, 34560, 270, 540, 34560, 270, 270, 540, 540, 270, 270, 34560, 34560, 34560, 34560, 540, 270, 540, 540, 270, 270, 270, 270, 270, 270, 270, 270, 540, 34560, 540, 540, 540, 34560, 270, 540, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 270, 270, 540, 270, 34560, 34560, 34560, 540, 270, 34560, 34560, 540, 540, 34560, 34560, 270, 34560, 34560, 540, 270, 34560, 540, 540, 34560, 34560, 34560, 270, 34560, 270, 34560, 34560, 270, 270, 34560, 270, 540, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 540, 540, 270, 34560, 270, 270, 270, 540, 270, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 540, 540, 540, 540, 270, 540, 34560, 34560, 270, 34560, 34560, 270, 34560, 540, 34560, 540, 540, 540, 270, 540, 270, 270, 34560, 270, 540, 270, 270, 540, 34560, 540, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4527360 . Total input tokens: 1008743448 . Total output tokens: 905196474
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.42061284231022,
    "estimated_duration": 3600.1041736892166,
    "input_throughput": 3908.661061210377,
    "output_throughput": 3466.169421206651,
    "total_throughput": 7374.830482417027,
    "itl": 147.09756407693723,
    "ttft": 2298743.8037835276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.023154665604291,
    "arrivals": 1507762,
    "finished_requests": 56881,
    "scheduler_time": 111.28191686700794
}
#Debug simulation 
Total elapsed time: 4.420681945048273. Arrivals time: 0.22802654327824712 Scheduler time: 4.049581057857722 Scheduler overhead time: 0.0364647856913507 Adapter cache time: 0.05169807281345129 Engine time: 0.03771356027573347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.095591014251113,
    "estimated_duration": 3600.0148480187363,
    "input_throughput": 4278.295687718186,
    "output_throughput": 3806.202079288948,
    "total_throughput": 8084.497767007134,
    "itl": 226.17193807165873,
    "ttft": 2242095.3241263344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3359316408867814,
    "arrivals": 1502157,
    "finished_requests": 62499,
    "scheduler_time": 95.14209308299681
}
#Debug simulation 
Total elapsed time: 5.095691400114447. Arrivals time: 0.6723659103736281 Scheduler time: 4.332968424074352 Scheduler overhead time: 0.025076583493500948 Adapter cache time: 0.0278987237252295 Engine time: 0.025772458873689175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.7089251996949315,
    "estimated_duration": 3600.232743816699,
    "input_throughput": 4278.036753721655,
    "output_throughput": 3805.9717176711615,
    "total_throughput": 8084.008471392817,
    "itl": 226.18444233900462,
    "ttft": 2242175.5745079843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5533434507204267,
    "arrivals": 1502157,
    "finished_requests": 62499,
    "scheduler_time": 95.14257707105708
}
#Debug simulation 
Total elapsed time: 4.708994198124856. Arrivals time: 0.24881541822105646 Scheduler time: 4.3690320225432515 Scheduler overhead time: 0.02510232524946332 Adapter cache time: 0.028640384785830975 Engine time: 0.025821687187999487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.44337671296671,
    "estimated_duration": 3600.0871623654493,
    "input_throughput": 3910.2814362834556,
    "output_throughput": 3487.551115776423,
    "total_throughput": 7397.832552059879,
    "itl": 145.98693443963512,
    "ttft": 2289792.151497547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2508846009149783,
    "arrivals": 1502157,
    "finished_requests": 57100,
    "scheduler_time": 111.96772394481732
}
#Debug simulation 
Total elapsed time: 4.443491038866341. Arrivals time: 0.2237244234420359 Scheduler time: 4.080908110830933 Scheduler overhead time: 0.03675906453281641 Adapter cache time: 0.046826825477182865 Engine time: 0.037909677252173424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.67874347884208,
    "estimated_duration": 3600.0833056930355,
    "input_throughput": 4278.214333441666,
    "output_throughput": 3806.1297021464943,
    "total_throughput": 8084.34403558816,
    "itl": 226.17579501614821,
    "ttft": 2242122.488979897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4042061594896555,
    "arrivals": 1502157,
    "finished_requests": 62499,
    "scheduler_time": 95.14227623858345
}
#Debug simulation 
Total elapsed time: 4.678840653970838. Arrivals time: 0.24313915660604835 Scheduler time: 4.345262098126113 Scheduler overhead time: 0.025262031238526106 Adapter cache time: 0.027654366567730904 Engine time: 0.02586298994719982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.433748837094754,
    "estimated_duration": 3600.1293999388795,
    "input_throughput": 3910.23555993265,
    "output_throughput": 3487.510198998169,
    "total_throughput": 7397.745758930819,
    "itl": 145.98857016568124,
    "ttft": 2289806.938732638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.293012119364001,
    "arrivals": 1502157,
    "finished_requests": 57100,
    "scheduler_time": 111.9678339998451
}
#Debug simulation 
Total elapsed time: 4.433846384752542. Arrivals time: 0.22657991107553244 Scheduler time: 4.067898141220212 Scheduler overhead time: 0.03672379208728671 Adapter cache time: 0.04729537898674607 Engine time: 0.037970010191202164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.707463209051639,
    "estimated_duration": 3600.185096884141,
    "input_throughput": 4278.894997185682,
    "output_throughput": 3806.727885147135,
    "total_throughput": 8085.622882332817,
    "itl": 226.16789069227536,
    "ttft": 2242107.413299052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2591548214432926,
    "arrivals": 1502157,
    "finished_requests": 62507,
    "scheduler_time": 95.14856198311935
}
#Debug simulation 
Total elapsed time: 4.707562705967575. Arrivals time: 0.24335783859714866 Scheduler time: 4.374016787391156 Scheduler overhead time: 0.025088278576731682 Adapter cache time: 0.02761056600138545 Engine time: 0.025799048133194447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 540, 135, 34560, 34560, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 135, 34560, 135, 34560, 540, 540, 540, 135, 135, 540, 135, 34560, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 135, 34560, 540, 540, 135, 135, 135, 540, 135, 540, 135, 34560, 135, 540, 34560, 135, 34560, 540, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 34560, 34560, 540, 135, 135, 34560, 540, 540, 135, 135, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 135, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 135, 135, 540, 540, 34560, 135, 135, 34560, 135, 34560, 540, 135, 34560, 540, 540, 135, 34560, 34560, 34560, 135, 540, 34560, 135, 34560, 540, 540, 34560, 34560, 135, 540, 34560, 135, 540, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 34560, 135, 34560, 540, 540, 540, 540, 540, 135, 135, 34560, 135, 34560, 135, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 135, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 135, 135, 135, 135, 135, 540, 135, 135, 540, 34560, 34560, 135, 135, 34560, 135, 135, 135, 540, 135, 540, 34560, 34560, 540, 540, 135, 34560, 540, 34560, 135, 540, 540, 135, 135, 540, 135, 34560, 34560, 135, 34560, 34560, 135, 540, 34560, 135, 135, 540, 540, 135, 135, 34560, 34560, 34560, 34560, 540, 135, 540, 540, 135, 135, 135, 135, 135, 135, 135, 135, 540, 34560, 540, 540, 540, 34560, 135, 540, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 540, 135, 34560, 34560, 34560, 540, 135, 34560, 34560, 540, 540, 34560, 34560, 135, 34560, 34560, 540, 135, 34560, 540, 540, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 540, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 540, 540, 135, 34560, 135, 135, 135, 540, 135, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 540, 540, 540, 540, 135, 540, 34560, 34560, 135, 34560, 34560, 135, 34560, 540, 34560, 540, 540, 540, 135, 540, 135, 135, 34560, 135, 540, 135, 135, 540, 34560, 540, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4510080 . Total input tokens: 1004889616 . Total output tokens: 901721610
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.4382948647253215,
    "estimated_duration": 3600.003788454941,
    "input_throughput": 3910.371996036636,
    "output_throughput": 3487.631885351042,
    "total_throughput": 7398.003881387678,
    "itl": 145.99011812620327,
    "ttft": 2289806.873304634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.333882099948864,
    "arrivals": 1502157,
    "finished_requests": 57100,
    "scheduler_time": 111.96287267868581
}
#Debug simulation 
Total elapsed time: 4.438391390722245. Arrivals time: 0.22316555911675096 Scheduler time: 4.076602170243859 Scheduler overhead time: 0.03641685238108039 Adapter cache time: 0.04705022042617202 Engine time: 0.03776796581223607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.719262259081006,
    "estimated_duration": 3600.0690757980374,
    "input_throughput": 4298.1058624743055,
    "output_throughput": 3816.4248270581725,
    "total_throughput": 8114.530689532478,
    "itl": 225.74903089797107,
    "ttft": 2244501.891044182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2655404227763256,
    "arrivals": 1499241,
    "finished_requests": 62689,
    "scheduler_time": 95.44024355252334
}
#Debug simulation 
Total elapsed time: 4.719362941104919. Arrivals time: 0.25483222026377916 Scheduler time: 4.3744468237273395 Scheduler overhead time: 0.025155507493764162 Adapter cache time: 0.027277022134512663 Engine time: 0.025919022969901562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.6438411409035325,
    "estimated_duration": 3600.09010507106,
    "input_throughput": 4297.805484980937,
    "output_throughput": 3816.244204734653,
    "total_throughput": 8114.04968971559,
    "itl": 225.76788093733546,
    "ttft": 2244525.3013804285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4821207220270356,
    "arrivals": 1499241,
    "finished_requests": 62685,
    "scheduler_time": 95.434106070316
}
#Debug simulation 
Total elapsed time: 4.643941895104945. Arrivals time: 0.24105127342045307 Scheduler time: 4.312867810018361 Scheduler overhead time: 0.02520894631743431 Adapter cache time: 0.027270138263702393 Engine time: 0.02582411700859666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.440698978025466,
    "estimated_duration": 3600.155824677628,
    "input_throughput": 3918.8817615313465,
    "output_throughput": 3500.534313991388,
    "total_throughput": 7419.416075522734,
    "itl": 146.72618646684143,
    "ttft": 2290875.3541062297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2502018145285185,
    "arrivals": 1499241,
    "finished_requests": 57270,
    "scheduler_time": 111.94669912329367
}
#Debug simulation 
Total elapsed time: 4.440802703145891. Arrivals time: 0.22621211363002658 Scheduler time: 4.076286302413791 Scheduler overhead time: 0.036662797909229994 Adapter cache time: 0.04658744251355529 Engine time: 0.037769218906760216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.683830317109823,
    "estimated_duration": 3600.1387689587464,
    "input_throughput": 4298.022657741977,
    "output_throughput": 3816.3509469313567,
    "total_throughput": 8114.373604673334,
    "itl": 225.75302304495227,
    "ttft": 2244531.5329881636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3350264073884657,
    "arrivals": 1499241,
    "finished_requests": 62689,
    "scheduler_time": 95.44045072851478
}
#Debug simulation 
Total elapsed time: 4.683954164851457. Arrivals time: 0.24074404779821634 Scheduler time: 4.352562302723527 Scheduler overhead time: 0.025292507838457823 Adapter cache time: 0.027537178248167038 Engine time: 0.02604484697803855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.558341715950519,
    "estimated_duration": 3600.0302747096753,
    "input_throughput": 3918.8473216764096,
    "output_throughput": 3500.4152849843067,
    "total_throughput": 7419.262606660716,
    "itl": 146.72851174850732,
    "ttft": 2290755.7833858854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2917005640454606,
    "arrivals": 1499241,
    "finished_requests": 57267,
    "scheduler_time": 111.94162745205512
}
#Debug simulation 
Total elapsed time: 4.5584396119229496. Arrivals time: 0.3357411604374647 Scheduler time: 4.085136995650828 Scheduler overhead time: 0.03653340367600322 Adapter cache time: 0.045758096501231194 Engine time: 0.03794387215748429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.696792081929743,
    "estimated_duration": 3600.252265941971,
    "input_throughput": 4298.11770313581,
    "output_throughput": 3816.885591600233,
    "total_throughput": 8115.003294736043,
    "itl": 225.74695874507873,
    "ttft": 2244486.6722931103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.190383664660545,
    "arrivals": 1499241,
    "finished_requests": 62695,
    "scheduler_time": 95.44672864353005
}
#Debug simulation 
Total elapsed time: 4.696894458960742. Arrivals time: 0.23921511229127645 Scheduler time: 4.367272810544819 Scheduler overhead time: 0.02535644918680191 Adapter cache time: 0.027219590730965137 Engine time: 0.026037360075861216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 540, 66, 34560, 34560, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 66, 34560, 66, 34560, 540, 540, 540, 66, 66, 540, 66, 34560, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 66, 34560, 540, 540, 66, 66, 66, 540, 66, 540, 66, 34560, 66, 540, 34560, 66, 34560, 540, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 34560, 34560, 540, 66, 66, 34560, 540, 540, 66, 66, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 66, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 66, 66, 540, 540, 34560, 66, 66, 34560, 66, 34560, 540, 66, 34560, 540, 540, 66, 34560, 34560, 34560, 66, 540, 34560, 66, 34560, 540, 540, 34560, 34560, 66, 540, 34560, 66, 540, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 34560, 66, 34560, 540, 540, 540, 540, 540, 66, 66, 34560, 66, 34560, 66, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 66, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 66, 66, 66, 66, 66, 540, 66, 66, 540, 34560, 34560, 66, 66, 34560, 66, 66, 66, 540, 66, 540, 34560, 34560, 540, 540, 66, 34560, 540, 34560, 66, 540, 540, 66, 66, 540, 66, 34560, 34560, 66, 34560, 34560, 66, 540, 34560, 66, 66, 540, 540, 66, 66, 34560, 34560, 34560, 34560, 540, 66, 540, 540, 66, 66, 66, 66, 66, 66, 66, 66, 540, 34560, 540, 540, 540, 34560, 66, 540, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 540, 66, 34560, 34560, 34560, 540, 66, 34560, 34560, 540, 540, 34560, 34560, 66, 34560, 34560, 540, 66, 34560, 540, 540, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 540, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 540, 540, 66, 34560, 66, 66, 66, 540, 66, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 540, 540, 540, 540, 66, 540, 34560, 34560, 66, 34560, 34560, 66, 34560, 540, 34560, 540, 540, 540, 66, 540, 66, 66, 34560, 66, 540, 66, 66, 540, 34560, 540, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4501248 . Total input tokens: 1002929360 . Total output tokens: 899961256
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.482318475842476,
    "estimated_duration": 3600.072784000164,
    "input_throughput": 3918.8010483288485,
    "output_throughput": 3500.373952439353,
    "total_throughput": 7419.175000768202,
    "itl": 146.7301915419317,
    "ttft": 2290772.335184633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 994,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3340795900673075,
    "arrivals": 1499241,
    "finished_requests": 57267,
    "scheduler_time": 111.94175771655809
}
#Debug simulation 
Total elapsed time: 4.482418218627572. Arrivals time: 0.23794767260551453 Scheduler time: 4.1058946112170815 Scheduler overhead time: 0.03661608789116144 Adapter cache time: 0.046766386833041906 Engine time: 0.03780912235379219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.856382665690035,
    "estimated_duration": 3600.1405979358788,
    "input_throughput": 4353.756908545928,
    "output_throughput": 3859.224000297629,
    "total_throughput": 8212.980908843558,
    "itl": 223.0073624335412,
    "ttft": 2239870.8307473874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8095277489303294,
    "arrivals": 1497804,
    "finished_requests": 63382,
    "scheduler_time": 96.53361254981044
}
#Debug simulation 
Total elapsed time: 4.856481391005218. Arrivals time: 0.3653984726406634 Scheduler time: 4.402522046118975 Scheduler overhead time: 0.025575058069080114 Adapter cache time: 0.02490514237433672 Engine time: 0.026154846418648958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.742279150057584,
    "estimated_duration": 3600.0740849656795,
    "input_throughput": 4353.480686814648,
    "output_throughput": 3858.994751807293,
    "total_throughput": 8212.475438621941,
    "itl": 223.0186543307309,
    "ttft": 2239913.856121279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.993292124331934,
    "arrivals": 1497804,
    "finished_requests": 63375,
    "scheduler_time": 96.52746224319569
}
#Debug simulation 
Total elapsed time: 4.7423809678293765. Arrivals time: 0.24809778714552522 Scheduler time: 4.4058568007312715 Scheduler overhead time: 0.025451562833040953 Adapter cache time: 0.024972351267933846 Engine time: 0.026176507584750652 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.419722916092724,
    "estimated_duration": 3600.1114137712534,
    "input_throughput": 3947.5639408372463,
    "output_throughput": 3504.3609905350586,
    "total_throughput": 7451.924931372305,
    "itl": 144.8384864792111,
    "ttft": 2288645.881401934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7356176697648915,
    "arrivals": 1497804,
    "finished_requests": 57358,
    "scheduler_time": 112.7780828705888
}
#Debug simulation 
Total elapsed time: 4.419846473727375. Arrivals time: 0.22270197048783302 Scheduler time: 4.061168748885393 Scheduler overhead time: 0.03680165717378259 Adapter cache time: 0.043641429860144854 Engine time: 0.03812256548553705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.764232047833502,
    "estimated_duration": 3600.19870041853,
    "input_throughput": 4353.686644622657,
    "output_throughput": 3859.1617174865446,
    "total_throughput": 8212.848362109202,
    "itl": 223.01050063925047,
    "ttft": 2239895.6897033933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.867444766252272,
    "arrivals": 1497804,
    "finished_requests": 63382,
    "scheduler_time": 96.53379801505137
}
#Debug simulation 
Total elapsed time: 4.764331350103021. Arrivals time: 0.24653063714504242 Scheduler time: 4.428853706456721 Scheduler overhead time: 0.025415507145226002 Adapter cache time: 0.025309131480753422 Engine time: 0.0262886518612504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.43260275805369,
    "estimated_duration": 3600.145736247051,
    "input_throughput": 3947.5263062030554,
    "output_throughput": 3504.3275812360757,
    "total_throughput": 7451.8538874391315,
    "itl": 144.8398503031539,
    "ttft": 2288659.2036739485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.769822699669754,
    "arrivals": 1497804,
    "finished_requests": 57358,
    "scheduler_time": 112.77820031651038
}
#Debug simulation 
Total elapsed time: 4.432701805140823. Arrivals time: 0.22217002511024475 Scheduler time: 4.074222531635314 Scheduler overhead time: 0.0367537853308022 Adapter cache time: 0.04393000341951847 Engine time: 0.03822112549096346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.218237027991563,
    "estimated_duration": 3600.0757698317107,
    "input_throughput": 4353.8353085087165,
    "output_throughput": 3859.293494994823,
    "total_throughput": 8213.12880350354,
    "itl": 223.00371382580957,
    "ttft": 2239845.0297314483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7448661707201367,
    "arrivals": 1497804,
    "finished_requests": 63382,
    "scheduler_time": 96.53344602373483
}
#Debug simulation 
Total elapsed time: 5.2183099538087845. Arrivals time: 0.2580046015791595 Scheduler time: 4.872128436341882 Scheduler overhead time: 0.02543547283858061 Adapter cache time: 0.02476296853274107 Engine time: 0.026189221534878016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 540, 33, 34560, 34560, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 540, 540, 34560, 34560, 540, 540, 33, 34560, 33, 34560, 540, 540, 540, 33, 33, 540, 33, 34560, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 33, 34560, 540, 540, 33, 33, 33, 540, 33, 540, 33, 34560, 33, 540, 34560, 33, 34560, 540, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 34560, 34560, 540, 33, 33, 34560, 540, 540, 33, 33, 34560, 540, 34560, 540, 34560, 34560, 540, 34560, 34560, 33, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 33, 33, 540, 540, 34560, 33, 33, 34560, 33, 34560, 540, 33, 34560, 540, 540, 33, 34560, 34560, 34560, 33, 540, 34560, 33, 34560, 540, 540, 34560, 34560, 33, 540, 34560, 33, 540, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 34560, 33, 34560, 540, 540, 540, 540, 540, 33, 33, 34560, 33, 34560, 33, 540, 34560, 540, 34560, 540, 34560, 540, 34560, 33, 540, 540, 540, 540, 540, 540, 540, 540, 34560, 33, 33, 33, 33, 33, 540, 33, 33, 540, 34560, 34560, 33, 33, 34560, 33, 33, 33, 540, 33, 540, 34560, 34560, 540, 540, 33, 34560, 540, 34560, 33, 540, 540, 33, 33, 540, 33, 34560, 34560, 33, 34560, 34560, 33, 540, 34560, 33, 33, 540, 540, 33, 33, 34560, 34560, 34560, 34560, 540, 33, 540, 540, 33, 33, 33, 33, 33, 33, 33, 33, 540, 34560, 540, 540, 540, 34560, 33, 540, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 540, 33, 34560, 34560, 34560, 540, 33, 34560, 34560, 540, 540, 34560, 34560, 33, 34560, 34560, 540, 33, 34560, 540, 540, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 540, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 540, 540, 33, 34560, 33, 33, 33, 540, 33, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 540, 540, 540, 540, 33, 540, 34560, 34560, 33, 34560, 34560, 33, 34560, 540, 34560, 540, 540, 540, 33, 540, 33, 33, 34560, 33, 540, 33, 33, 540, 34560, 540, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4497024 . Total input tokens: 1001990086 . Total output tokens: 899106028
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.450105866417289,
    "estimated_duration": 3600.0176523494397,
    "input_throughput": 3947.1973118593733,
    "output_throughput": 3504.226428380714,
    "total_throughput": 7451.423740240088,
    "itl": 144.84127364367268,
    "ttft": 2288651.8430991927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.804656498506687,
    "arrivals": 1497804,
    "finished_requests": 57353,
    "scheduler_time": 112.77328845399632
}
#Debug simulation 
Total elapsed time: 4.450203326996416. Arrivals time: 0.22552325995638967 Scheduler time: 4.088283820077777 Scheduler overhead time: 0.036911954171955585 Adapter cache time: 0.04386519780382514 Engine time: 0.038132885936647654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.940830335021019,
    "estimated_duration": 3600.175395967828,
    "input_throughput": 4440.217001067148,
    "output_throughput": 3900.961607517608,
    "total_throughput": 8341.178608584756,
    "itl": 218.92904674214418,
    "ttft": 2228992.1604941087,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3688175138039975,
    "arrivals": 1490652,
    "finished_requests": 64645,
    "scheduler_time": 97.80057073878744
}
#Debug simulation 
Total elapsed time: 4.940926337148994. Arrivals time: 0.2520775869488716 Scheduler time: 4.602724587544799 Scheduler overhead time: 0.02567520970478654 Adapter cache time: 0.022006459068506956 Engine time: 0.02640742901712656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.742976262234151,
    "estimated_duration": 3600.1035713307565,
    "input_throughput": 4440.071426637136,
    "output_throughput": 3900.7744421111247,
    "total_throughput": 8340.845868748262,
    "itl": 218.936789622843,
    "ttft": 2228973.2816939303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.530854447027675,
    "arrivals": 1490652,
    "finished_requests": 64641,
    "scheduler_time": 97.79465416044965
}
#Debug simulation 
Total elapsed time: 4.743075502105057. Arrivals time: 0.24609766900539398 Scheduler time: 4.410901143681258 Scheduler overhead time: 0.025816014036536217 Adapter cache time: 0.021749905310571194 Engine time: 0.026525913272053003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.491396259050816,
    "estimated_duration": 3600.0945865767844,
    "input_throughput": 4026.3392117658295,
    "output_throughput": 3548.606763731629,
    "total_throughput": 7574.945975497459,
    "itl": 143.42479062860048,
    "ttft": 2280616.2483273335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.305190561898055,
    "arrivals": 1490652,
    "finished_requests": 58590,
    "scheduler_time": 113.88835214156533
}
#Debug simulation 
Total elapsed time: 4.491495436988771. Arrivals time: 0.23276015557348728 Scheduler time: 4.12595331389457 Scheduler overhead time: 0.03721542051061988 Adapter cache time: 0.039788362104445696 Engine time: 0.038327913265675306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.821790998801589,
    "estimated_duration": 3600.000310483164,
    "input_throughput": 4440.198783720287,
    "output_throughput": 3900.886330233464,
    "total_throughput": 8341.085113953752,
    "itl": 218.93126516648306,
    "ttft": 2228932.586849177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4278884267806804,
    "arrivals": 1490652,
    "finished_requests": 64641,
    "scheduler_time": 97.79435933307722
}
#Debug simulation 
Total elapsed time: 4.821888799779117. Arrivals time: 0.2470932062715292 Scheduler time: 4.487996409647167 Scheduler overhead time: 0.025837662164121866 Adapter cache time: 0.022296797949820757 Engine time: 0.02664721617475152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.632907569874078,
    "estimated_duration": 3600.123876360507,
    "input_throughput": 4026.3064543917067,
    "output_throughput": 3548.5778930793417,
    "total_throughput": 7574.884347471048,
    "itl": 143.42589572504218,
    "ttft": 2280627.630426604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.334365440346304,
    "arrivals": 1490652,
    "finished_requests": 58590,
    "scheduler_time": 113.88846704686716
}
#Debug simulation 
Total elapsed time: 4.633006668649614. Arrivals time: 0.3444126476533711 Scheduler time: 4.154984307941049 Scheduler overhead time: 0.03715442167595029 Adapter cache time: 0.040505216922611 Engine time: 0.038353671319782734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.777773891109973,
    "estimated_duration": 3600.1207122420956,
    "input_throughput": 4440.284445363627,
    "output_throughput": 3901.0208608403964,
    "total_throughput": 8341.305306204024,
    "itl": 218.92612398597137,
    "ttft": 2228970.6078991597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 774,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3142989282542388,
    "arrivals": 1490652,
    "finished_requests": 64645,
    "scheduler_time": 97.80040559850441
}
#Debug simulation 
Total elapsed time: 4.77789936773479. Arrivals time: 0.24553563632071018 Scheduler time: 4.445585547015071 Scheduler overhead time: 0.02587125264108181 Adapter cache time: 0.02199032437056303 Engine time: 0.02688595000654459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 34560, 270, 135, 34560, 34560, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 135, 34560, 135, 34560, 270, 270, 270, 135, 135, 270, 135, 34560, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 135, 34560, 270, 270, 135, 135, 135, 270, 135, 270, 135, 34560, 135, 270, 34560, 135, 34560, 270, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 34560, 34560, 270, 135, 135, 34560, 270, 270, 135, 135, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 135, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 135, 135, 270, 270, 34560, 135, 135, 34560, 135, 34560, 270, 135, 34560, 270, 270, 135, 34560, 34560, 34560, 135, 270, 34560, 135, 34560, 270, 270, 34560, 34560, 135, 270, 34560, 135, 270, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 34560, 135, 34560, 270, 270, 270, 270, 270, 135, 135, 34560, 135, 34560, 135, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 135, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 135, 135, 135, 135, 135, 270, 135, 135, 270, 34560, 34560, 135, 135, 34560, 135, 135, 135, 270, 135, 270, 34560, 34560, 270, 270, 135, 34560, 270, 34560, 135, 270, 270, 135, 135, 270, 135, 34560, 34560, 135, 34560, 34560, 135, 270, 34560, 135, 135, 270, 270, 135, 135, 34560, 34560, 34560, 34560, 270, 135, 270, 270, 135, 135, 135, 135, 135, 135, 135, 135, 270, 34560, 270, 270, 270, 34560, 135, 270, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 135, 135, 270, 135, 34560, 34560, 34560, 270, 135, 34560, 34560, 270, 270, 34560, 34560, 135, 34560, 34560, 270, 135, 34560, 270, 270, 34560, 34560, 34560, 135, 34560, 135, 34560, 34560, 135, 135, 34560, 135, 270, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 270, 270, 135, 34560, 135, 135, 135, 270, 135, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 270, 270, 270, 270, 135, 270, 34560, 34560, 135, 34560, 34560, 135, 34560, 270, 34560, 270, 270, 270, 135, 270, 135, 135, 34560, 135, 270, 135, 135, 270, 34560, 270, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4475520 . Total input tokens: 997227558 . Total output tokens: 894761538
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.476388969924301,
    "estimated_duration": 3600.155454656654,
    "input_throughput": 4026.2711381673944,
    "output_throughput": 3548.546767189079,
    "total_throughput": 7574.817905356474,
    "itl": 143.4270740353328,
    "ttft": 2280640.710164115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 704,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3658038869500215,
    "arrivals": 1490652,
    "finished_requests": 58590,
    "scheduler_time": 113.88860689643552
}
#Debug simulation 
Total elapsed time: 4.476486723870039. Arrivals time: 0.22739385161548853 Scheduler time: 4.115595099050552 Scheduler overhead time: 0.03695614170283079 Adapter cache time: 0.040678960271179676 Engine time: 0.038290494587272406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.793682365678251,
    "estimated_duration": 3600.1578836239432,
    "input_throughput": 4456.18262270516,
    "output_throughput": 3921.5938457088905,
    "total_throughput": 8377.77646841405,
    "itl": 218.34403475705966,
    "ttft": 2228346.2878748584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1239784942893687,
    "arrivals": 1487737,
    "finished_requests": 64730,
    "scheduler_time": 98.20793212949833
}
#Debug simulation 
Total elapsed time: 4.793780942913145. Arrivals time: 0.24650270864367485 Scheduler time: 4.462510757613927 Scheduler overhead time: 0.026008525397628546 Adapter cache time: 0.01990439184010029 Engine time: 0.026863941457122564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.810086984653026,
    "estimated_duration": 3600.052667349538,
    "input_throughput": 4456.287583095616,
    "output_throughput": 3921.7079038997335,
    "total_throughput": 8377.99548699535,
    "itl": 218.35294248332323,
    "ttft": 2228331.441362585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.263457346463114,
    "arrivals": 1487737,
    "finished_requests": 64729,
    "scheduler_time": 98.20176426659783
}
#Debug simulation 
Total elapsed time: 4.810181534849107. Arrivals time: 0.252128595020622 Scheduler time: 4.473316461779177 Scheduler overhead time: 0.025920433923602104 Adapter cache time: 0.02020040387287736 Engine time: 0.026546217501163483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.489236459136009,
    "estimated_duration": 3600.02428832017,
    "input_throughput": 4028.4778208446915,
    "output_throughput": 3551.430761586834,
    "total_throughput": 7579.908582431525,
    "itl": 142.8599294428533,
    "ttft": 2278932.745853086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.060747059900323,
    "arrivals": 1487737,
    "finished_requests": 58484,
    "scheduler_time": 114.18981803092883
}
#Debug simulation 
Total elapsed time: 4.4893301273696125. Arrivals time: 0.2251408058218658 Scheduler time: 4.134643467143178 Scheduler overhead time: 0.03720654733479023 Adapter cache time: 0.036737474612891674 Engine time: 0.0380495167337358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.8193794740363955,
    "estimated_duration": 3600.203574251698,
    "input_throughput": 4456.126068741691,
    "output_throughput": 3921.544076277548,
    "total_throughput": 8377.670145019238,
    "itl": 218.34639363689618,
    "ttft": 2228365.3571554236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1694804232218132,
    "arrivals": 1487737,
    "finished_requests": 64730,
    "scheduler_time": 98.2081208282553
}
#Debug simulation 
Total elapsed time: 4.81951031088829. Arrivals time: 0.24821359617635608 Scheduler time: 4.4860661290585995 Scheduler overhead time: 0.02584750298410654 Adapter cache time: 0.020319164264947176 Engine time: 0.02696201065555215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.443924497347325,
    "estimated_duration": 3600.0513192705316,
    "input_throughput": 4028.4475730581044,
    "output_throughput": 3551.404095703457,
    "total_throughput": 7579.851668761561,
    "itl": 142.86096814732252,
    "ttft": 2278943.8935222174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.087658370193099,
    "arrivals": 1487737,
    "finished_requests": 58484,
    "scheduler_time": 114.189937671022
}
#Debug simulation 
Total elapsed time: 4.444017371162772. Arrivals time: 0.2241720473393798 Scheduler time: 4.090822114143521 Scheduler overhead time: 0.03698945976793766 Adapter cache time: 0.03652110043913126 Engine time: 0.03804117813706398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.8590776370838284,
    "estimated_duration": 3600.1088404372904,
    "input_throughput": 4456.2433279243105,
    "output_throughput": 3921.6472683878915,
    "total_throughput": 8377.890596312202,
    "itl": 218.34144076035864,
    "ttft": 2228326.118318251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 694,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0750949046620732,
    "arrivals": 1487737,
    "finished_requests": 64730,
    "scheduler_time": 98.20777253238565
}
#Debug simulation 
Total elapsed time: 4.859174551907927. Arrivals time: 0.35385264456272125 Scheduler time: 4.421396071091294 Scheduler overhead time: 0.025700373109430075 Adapter cache time: 0.01994661893695593 Engine time: 0.026388955302536488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 270, 66, 34560, 34560, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 66, 34560, 66, 34560, 270, 270, 270, 66, 66, 270, 66, 34560, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 66, 34560, 270, 270, 66, 66, 66, 270, 66, 270, 66, 34560, 66, 270, 34560, 66, 34560, 270, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 34560, 34560, 270, 66, 66, 34560, 270, 270, 66, 66, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 66, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 66, 66, 270, 270, 34560, 66, 66, 34560, 66, 34560, 270, 66, 34560, 270, 270, 66, 34560, 34560, 34560, 66, 270, 34560, 66, 34560, 270, 270, 34560, 34560, 66, 270, 34560, 66, 270, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 34560, 66, 34560, 270, 270, 270, 270, 270, 66, 66, 34560, 66, 34560, 66, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 66, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 66, 66, 66, 66, 66, 270, 66, 66, 270, 34560, 34560, 66, 66, 34560, 66, 66, 66, 270, 66, 270, 34560, 34560, 270, 270, 66, 34560, 270, 34560, 66, 270, 270, 66, 66, 270, 66, 34560, 34560, 66, 34560, 34560, 66, 270, 34560, 66, 66, 270, 270, 66, 66, 34560, 34560, 34560, 34560, 270, 66, 270, 270, 66, 66, 66, 66, 66, 66, 66, 66, 270, 34560, 270, 270, 270, 34560, 66, 270, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 270, 66, 34560, 34560, 34560, 270, 66, 34560, 34560, 270, 270, 34560, 34560, 66, 34560, 34560, 270, 66, 34560, 270, 270, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 270, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 270, 270, 66, 34560, 66, 66, 66, 270, 66, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 270, 270, 270, 270, 66, 270, 34560, 34560, 66, 34560, 34560, 66, 34560, 270, 34560, 270, 270, 270, 66, 270, 66, 66, 34560, 66, 270, 66, 66, 270, 34560, 270, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4466688 . Total input tokens: 995282892 . Total output tokens: 892945377
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.523527002893388,
    "estimated_duration": 3600.077984623287,
    "input_throughput": 4028.417734822363,
    "output_throughput": 3551.3777908724524,
    "total_throughput": 7579.795525694815,
    "itl": 142.86197674746003,
    "ttft": 2278954.8711889596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.11419241912663,
    "arrivals": 1487737,
    "finished_requests": 58484,
    "scheduler_time": 114.1900689748694
}
#Debug simulation 
Total elapsed time: 4.523635042831302. Arrivals time: 0.32137739891186357 Scheduler time: 4.074119010940194 Scheduler overhead time: 0.03710522875189781 Adapter cache time: 0.03602259745821357 Engine time: 0.037617303896695375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.7924018441699445,
    "estimated_duration": 3600.1168164027217,
    "input_throughput": 4495.147470289671,
    "output_throughput": 3962.977238681919,
    "total_throughput": 8458.12470897159,
    "itl": 216.1837867055292,
    "ttft": 2230377.2365440014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.77202240373709,
    "arrivals": 1486263,
    "finished_requests": 65430,
    "scheduler_time": 99.18890523854456
}
#Debug simulation 
Total elapsed time: 4.792501226998866. Arrivals time: 0.22762962616980076 Scheduler time: 4.481977812945843 Scheduler overhead time: 0.026246690191328526 Adapter cache time: 0.017876121681183577 Engine time: 0.026754756458103657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.774792027194053,
    "estimated_duration": 3600.2272970950885,
    "input_throughput": 4495.009527053363,
    "output_throughput": 3962.855626229973,
    "total_throughput": 8457.865153283336,
    "itl": 216.18928367384902,
    "ttft": 2230426.7886913507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.882010793252851,
    "arrivals": 1486263,
    "finished_requests": 65430,
    "scheduler_time": 99.18939754136034
}
#Debug simulation 
Total elapsed time: 4.774887557141483. Arrivals time: 0.22755773272365332 Scheduler time: 4.465370683930814 Scheduler overhead time: 0.026217687409371138 Adapter cache time: 0.017630877438932657 Engine time: 0.02608170872554183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.473044989164919,
    "estimated_duration": 3600.1035557613536,
    "input_throughput": 4033.270647663149,
    "output_throughput": 3574.488011436813,
    "total_throughput": 7607.758659099962,
    "itl": 142.0498582573534,
    "ttft": 2280842.7459164164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7564697976037966,
    "arrivals": 1486263,
    "finished_requests": 58764,
    "scheduler_time": 114.89484420166869
}
#Debug simulation 
Total elapsed time: 4.473144214134663. Arrivals time: 0.20983459241688251 Scheduler time: 4.135593560524285 Scheduler overhead time: 0.037291310261934996 Adapter cache time: 0.03421914903447032 Engine time: 0.03864860441535711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.9034725381061435,
    "estimated_duration": 3600.1526232534725,
    "input_throughput": 4495.102761886607,
    "output_throughput": 3962.937823204476,
    "total_throughput": 8458.040585091083,
    "itl": 216.18547988358762,
    "ttft": 2230393.3119114116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8076464452966936,
    "arrivals": 1486263,
    "finished_requests": 65430,
    "scheduler_time": 99.18908804768304
}
#Debug simulation 
Total elapsed time: 4.903568773996085. Arrivals time: 0.3362699127756059 Scheduler time: 4.485639346763492 Scheduler overhead time: 0.026125262025743723 Adapter cache time: 0.017421944998204708 Engine time: 0.026112039107829332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.452833365648985,
    "estimated_duration": 3600.1252989321124,
    "input_throughput": 4033.2462884853076,
    "output_throughput": 3574.466423103976,
    "total_throughput": 7607.712711589284,
    "itl": 142.05064399851594,
    "ttft": 2280852.370273382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7780994488671467,
    "arrivals": 1486263,
    "finished_requests": 58764,
    "scheduler_time": 114.89495772117793
}
#Debug simulation 
Total elapsed time: 4.45293159969151. Arrivals time: 0.21251244144514203 Scheduler time: 4.114379003178328 Scheduler overhead time: 0.03698114678263664 Adapter cache time: 0.03402132913470268 Engine time: 0.037557664792984724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.787556861992925,
    "estimated_duration": 3600.0758620899005,
    "input_throughput": 4495.198606899768,
    "output_throughput": 3963.022321345661,
    "total_throughput": 8458.220928245428,
    "itl": 216.18170703607356,
    "ttft": 2230359.2759019337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.731239120748335,
    "arrivals": 1486263,
    "finished_requests": 65430,
    "scheduler_time": 99.18873420864306
}
#Debug simulation 
Total elapsed time: 4.787682847119868. Arrivals time: 0.2280276925303042 Scheduler time: 4.477347449399531 Scheduler overhead time: 0.026185705792158842 Adapter cache time: 0.017646133434027433 Engine time: 0.026470927521586418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 270, 33, 34560, 34560, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 270, 270, 34560, 34560, 270, 270, 33, 34560, 33, 34560, 270, 270, 270, 33, 33, 270, 33, 34560, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 33, 34560, 270, 270, 33, 33, 33, 270, 33, 270, 33, 34560, 33, 270, 34560, 33, 34560, 270, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 34560, 34560, 270, 33, 33, 34560, 270, 270, 33, 33, 34560, 270, 34560, 270, 34560, 34560, 270, 34560, 34560, 33, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 33, 33, 270, 270, 34560, 33, 33, 34560, 33, 34560, 270, 33, 34560, 270, 270, 33, 34560, 34560, 34560, 33, 270, 34560, 33, 34560, 270, 270, 34560, 34560, 33, 270, 34560, 33, 270, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 34560, 33, 34560, 270, 270, 270, 270, 270, 33, 33, 34560, 33, 34560, 33, 270, 34560, 270, 34560, 270, 34560, 270, 34560, 33, 270, 270, 270, 270, 270, 270, 270, 270, 34560, 33, 33, 33, 33, 33, 270, 33, 33, 270, 34560, 34560, 33, 33, 34560, 33, 33, 33, 270, 33, 270, 34560, 34560, 270, 270, 33, 34560, 270, 34560, 33, 270, 270, 33, 33, 270, 33, 34560, 34560, 33, 34560, 34560, 33, 270, 34560, 33, 33, 270, 270, 33, 33, 34560, 34560, 34560, 34560, 270, 33, 270, 270, 33, 33, 33, 33, 33, 33, 33, 33, 270, 34560, 270, 270, 270, 34560, 33, 270, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 270, 33, 34560, 34560, 34560, 270, 33, 34560, 34560, 270, 270, 34560, 34560, 33, 34560, 34560, 270, 33, 34560, 270, 270, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 270, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 270, 270, 33, 34560, 33, 33, 33, 270, 33, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 270, 270, 270, 270, 33, 270, 34560, 34560, 33, 34560, 34560, 33, 34560, 270, 34560, 270, 270, 270, 33, 270, 33, 33, 34560, 33, 270, 33, 33, 270, 34560, 270, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4462464 . Total input tokens: 994358162 . Total output tokens: 892094577
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.446777552831918,
    "estimated_duration": 3600.147059656242,
    "input_throughput": 4033.221909936771,
    "output_throughput": 3574.444817603852,
    "total_throughput": 7607.6667275406235,
    "itl": 142.0514262157073,
    "ttft": 2280861.983876108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7997291001304967,
    "arrivals": 1486263,
    "finished_requests": 58764,
    "scheduler_time": 114.89508879405992
}
#Debug simulation 
Total elapsed time: 4.446871038991958. Arrivals time: 0.20852806605398655 Scheduler time: 4.112048771232367 Scheduler overhead time: 0.03792231995612383 Adapter cache time: 0.033481648191809654 Engine time: 0.037391921039670706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.92308196099475,
    "estimated_duration": 3600.1235136968567,
    "input_throughput": 4526.076379881685,
    "output_throughput": 3979.8042887943125,
    "total_throughput": 8505.880668675998,
    "itl": 214.69891737291312,
    "ttft": 2226611.4240128016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.465973629343804,
    "arrivals": 1482016,
    "finished_requests": 65852,
    "scheduler_time": 99.7413492106826
}
#Debug simulation 
Total elapsed time: 4.923172513954341. Arrivals time: 0.3358102021738887 Scheduler time: 4.50794200738892 Scheduler overhead time: 0.026437690947204828 Adapter cache time: 0.014606093056499958 Engine time: 0.02626503398641944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.803876920137554,
    "estimated_duration": 3600.221008071342,
    "input_throughput": 4525.953813243542,
    "output_throughput": 3979.69651526351,
    "total_throughput": 8505.650328507052,
    "itl": 214.7035435605547,
    "ttft": 2226656.6779969786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5629845931590587,
    "arrivals": 1482016,
    "finished_requests": 65852,
    "scheduler_time": 99.74183262132928
}
#Debug simulation 
Total elapsed time: 4.804004011210054. Arrivals time: 0.23004727344959974 Scheduler time: 4.494529378600419 Scheduler overhead time: 0.02648188453167677 Adapter cache time: 0.01453604968264699 Engine time: 0.026336508337408304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.43466978892684,
    "estimated_duration": 3600.045307994512,
    "input_throughput": 4054.5978595284537,
    "output_throughput": 3587.3006851667346,
    "total_throughput": 7641.898544695188,
    "itl": 141.87424752043557,
    "ttft": 2278480.2233041395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4217324726283633,
    "arrivals": 1482016,
    "finished_requests": 59083,
    "scheduler_time": 115.10705459043822
}
#Debug simulation 
Total elapsed time: 4.43475979520008. Arrivals time: 0.21239688340574503 Scheduler time: 4.09981035022065 Scheduler overhead time: 0.03693206701427698 Adapter cache time: 0.030604828614741564 Engine time: 0.037543556187301874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.932845187373459,
    "estimated_duration": 3600.157378775452,
    "input_throughput": 4526.033805095028,
    "output_throughput": 3979.7668525461563,
    "total_throughput": 8505.800657641184,
    "itl": 214.70050006174895,
    "ttft": 2226626.5464457627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4996523188007953,
    "arrivals": 1482016,
    "finished_requests": 65852,
    "scheduler_time": 99.74153559978527
}
#Debug simulation 
Total elapsed time: 4.932937582023442. Arrivals time: 0.3363246596418321 Scheduler time: 4.517520966473967 Scheduler overhead time: 0.0263914386741817 Adapter cache time: 0.014525329228490591 Engine time: 0.026148910634219646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.476471180096269,
    "estimated_duration": 3600.0628962090836,
    "input_throughput": 4054.578050669772,
    "output_throughput": 3587.283159302325,
    "total_throughput": 7641.861209972097,
    "itl": 141.87485569951315,
    "ttft": 2278488.7814130927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4392122489400259,
    "arrivals": 1482016,
    "finished_requests": 59083,
    "scheduler_time": 115.107163028708
}
#Debug simulation 
Total elapsed time: 4.476564980112016. Arrivals time: 0.21350455656647682 Scheduler time: 4.137612151913345 Scheduler overhead time: 0.0385849648155272 Adapter cache time: 0.030784945469349623 Engine time: 0.03830705722793937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.807327021844685,
    "estimated_duration": 3600.0896079791933,
    "input_throughput": 4526.119006561732,
    "output_throughput": 3979.841770672617,
    "total_throughput": 8505.960777234348,
    "itl": 214.6972740935108,
    "ttft": 2226595.925268129,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 479,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4322340912581282,
    "arrivals": 1482016,
    "finished_requests": 65852,
    "scheduler_time": 99.74118303105513
}
#Debug simulation 
Total elapsed time: 4.80741909891367. Arrivals time: 0.2295639500953257 Scheduler time: 4.498733594082296 Scheduler overhead time: 0.02627469040453434 Adapter cache time: 0.014520219527184963 Engine time: 0.026301987003535032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_384_slots_160_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 34560, 135, 66, 34560, 34560, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 66, 34560, 66, 34560, 135, 135, 135, 66, 66, 135, 66, 34560, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 66, 34560, 135, 135, 66, 66, 66, 135, 66, 135, 66, 34560, 66, 135, 34560, 66, 34560, 135, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 34560, 34560, 135, 66, 66, 34560, 135, 135, 66, 66, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 66, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 66, 66, 135, 135, 34560, 66, 66, 34560, 66, 34560, 135, 66, 34560, 135, 135, 66, 34560, 34560, 34560, 66, 135, 34560, 66, 34560, 135, 135, 34560, 34560, 66, 135, 34560, 66, 135, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 34560, 66, 34560, 135, 135, 135, 135, 135, 66, 66, 34560, 66, 34560, 66, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 66, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 66, 66, 66, 66, 66, 135, 66, 66, 135, 34560, 34560, 66, 66, 34560, 66, 66, 66, 135, 66, 135, 34560, 34560, 135, 135, 66, 34560, 135, 34560, 66, 135, 135, 66, 66, 135, 66, 34560, 34560, 66, 34560, 34560, 66, 135, 34560, 66, 66, 135, 135, 66, 66, 34560, 34560, 34560, 34560, 135, 66, 135, 135, 66, 66, 66, 66, 66, 66, 66, 66, 135, 34560, 135, 135, 135, 34560, 66, 135, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 66, 66, 135, 66, 34560, 34560, 34560, 135, 66, 34560, 34560, 135, 135, 34560, 34560, 66, 34560, 34560, 135, 66, 34560, 135, 135, 34560, 34560, 34560, 66, 34560, 66, 34560, 34560, 66, 66, 34560, 66, 135, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 135, 135, 66, 34560, 66, 66, 66, 135, 66, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 135, 135, 135, 135, 66, 135, 34560, 34560, 66, 34560, 34560, 66, 34560, 135, 34560, 135, 135, 135, 66, 135, 66, 66, 34560, 66, 135, 66, 66, 135, 34560, 135, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4449408 . Total input tokens: 991485117 . Total output tokens: 889450721
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.591753895860165,
    "estimated_duration": 3600.082017027562,
    "input_throughput": 4054.5565159240227,
    "output_throughput": 3587.2641064613636,
    "total_throughput": 7641.820622385386,
    "itl": 141.8755192865677,
    "ttft": 2278497.43708581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 435,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4582010706886657,
    "arrivals": 1482016,
    "finished_requests": 59083,
    "scheduler_time": 115.10729502545169
}
#Debug simulation 
Total elapsed time: 4.591845212038606. Arrivals time: 0.32009007036685944 Scheduler time: 4.147860924713314 Scheduler overhead time: 0.037045607808977365 Adapter cache time: 0.03154760552570224 Engine time: 0.03785206051543355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.845916681922972,
    "estimated_duration": 3600.082762051264,
    "input_throughput": 4557.215232088705,
    "output_throughput": 4002.576316270479,
    "total_throughput": 8559.791548359184,
    "itl": 213.54674576830757,
    "ttft": 2227605.9799877056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3160097298910938,
    "arrivals": 1480643,
    "finished_requests": 66302,
    "scheduler_time": 100.33643091125863
}
#Debug simulation 
Total elapsed time: 4.84602797171101. Arrivals time: 0.23189851641654968 Scheduler time: 4.535213918425143 Scheduler overhead time: 0.026624031364917755 Adapter cache time: 0.013526678550988436 Engine time: 0.026544048450887203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.84432964399457,
    "estimated_duration": 3600.174344813239,
    "input_throughput": 4557.099303714717,
    "output_throughput": 4002.474497036478,
    "total_throughput": 8559.573800751195,
    "itl": 213.55099717100947,
    "ttft": 2227649.3270896217,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4070744363847247,
    "arrivals": 1480643,
    "finished_requests": 66302,
    "scheduler_time": 100.33694896671993
}
#Debug simulation 
Total elapsed time: 4.844419276341796. Arrivals time: 0.22991834906861186 Scheduler time: 4.535801567602903 Scheduler overhead time: 0.02641860954463482 Adapter cache time: 0.013527918606996536 Engine time: 0.026630026288330555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.4992318991571665,
    "estimated_duration": 3600.0932001809106,
    "input_throughput": 4085.7406133987993,
    "output_throughput": 3601.8050864206502,
    "total_throughput": 7687.5456998194495,
    "itl": 141.8868506020027,
    "ttft": 2282915.295975259,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3189439095556812,
    "arrivals": 1480643,
    "finished_requests": 59455,
    "scheduler_time": 115.41013719792426
}
#Debug simulation 
Total elapsed time: 4.499301064293832. Arrivals time: 0.21259249094873667 Scheduler time: 4.163605555891991 Scheduler overhead time: 0.038228077813982964 Adapter cache time: 0.029402407351881266 Engine time: 0.03782074525952339 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 4.857609981205314,
    "estimated_duration": 3600.1102939879675,
    "input_throughput": 4557.180380667202,
    "output_throughput": 4002.545706464448,
    "total_throughput": 8559.72608713165,
    "itl": 213.5479662486038,
    "ttft": 2227620.529483364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.343333566708021,
    "arrivals": 1480643,
    "finished_requests": 66302,
    "scheduler_time": 100.33663901111179
}
#Debug simulation 
Total elapsed time: 4.857675655279309. Arrivals time: 0.2308292044326663 Scheduler time: 4.5477443230338395 Scheduler overhead time: 0.026629792992025614 Adapter cache time: 0.013862640596926212 Engine time: 0.026492377743124962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.480548089835793,
    "estimated_duration": 3600.111167158113,
    "input_throughput": 4085.720222803885,
    "output_throughput": 3601.787110989651,
    "total_throughput": 7687.507333793536,
    "itl": 141.88748127313468,
    "ttft": 2282923.4392235586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3368009472265883,
    "arrivals": 1480643,
    "finished_requests": 59455,
    "scheduler_time": 115.41024713746933
}
#Debug simulation 
Total elapsed time: 4.480612676590681. Arrivals time: 0.21333123045042157 Scheduler time: 4.1449844292365015 Scheduler overhead time: 0.03740217396989465 Adapter cache time: 0.02954250108450651 Engine time: 0.03787029441446066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.850189617834985,
    "estimated_duration": 3600.052304997012,
    "input_throughput": 4557.253786903971,
    "output_throughput": 4002.6101787462667,
    "total_throughput": 8559.863965650236,
    "itl": 213.54532828838998,
    "ttft": 2227591.639835876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2857216268079268,
    "arrivals": 1480643,
    "finished_requests": 66302,
    "scheduler_time": 100.33626196004599
}
#Debug simulation 
Total elapsed time: 4.850255264900625. Arrivals time: 0.23093584133312106 Scheduler time: 4.540262288413942 Scheduler overhead time: 0.026598454918712378 Adapter cache time: 0.013798699714243412 Engine time: 0.026558760087937117 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 135, 33, 34560, 34560, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 135, 135, 34560, 34560, 135, 135, 33, 34560, 33, 34560, 135, 135, 135, 33, 33, 135, 33, 34560, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 33, 34560, 135, 135, 33, 33, 33, 135, 33, 135, 33, 34560, 33, 135, 34560, 33, 34560, 135, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 34560, 34560, 135, 33, 33, 34560, 135, 135, 33, 33, 34560, 135, 34560, 135, 34560, 34560, 135, 34560, 34560, 33, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 33, 33, 135, 135, 34560, 33, 33, 34560, 33, 34560, 135, 33, 34560, 135, 135, 33, 34560, 34560, 34560, 33, 135, 34560, 33, 34560, 135, 135, 34560, 34560, 33, 135, 34560, 33, 135, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 34560, 33, 34560, 135, 135, 135, 135, 135, 33, 33, 34560, 33, 34560, 33, 135, 34560, 135, 34560, 135, 34560, 135, 34560, 33, 135, 135, 135, 135, 135, 135, 135, 135, 34560, 33, 33, 33, 33, 33, 135, 33, 33, 135, 34560, 34560, 33, 33, 34560, 33, 33, 33, 135, 33, 135, 34560, 34560, 135, 135, 33, 34560, 135, 34560, 33, 135, 135, 33, 33, 135, 33, 34560, 34560, 33, 34560, 34560, 33, 135, 34560, 33, 33, 135, 135, 33, 33, 34560, 34560, 34560, 34560, 135, 33, 135, 135, 33, 33, 33, 33, 33, 33, 33, 33, 135, 34560, 135, 135, 135, 34560, 33, 135, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 135, 33, 34560, 34560, 34560, 135, 33, 34560, 34560, 135, 135, 34560, 34560, 33, 34560, 34560, 135, 33, 34560, 135, 135, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 135, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 135, 135, 33, 34560, 33, 33, 33, 135, 33, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 135, 135, 135, 135, 33, 135, 34560, 34560, 33, 34560, 34560, 33, 34560, 135, 34560, 135, 135, 135, 33, 135, 33, 33, 34560, 33, 135, 33, 33, 135, 34560, 135, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4445184 . Total input tokens: 990564360 . Total output tokens: 888598380
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.4696741052903235,
    "estimated_duration": 3600.127896691449,
    "input_throughput": 4085.7012367582133,
    "output_throughput": 3601.770373746066,
    "total_throughput": 7687.47161050428,
    "itl": 141.88805464869247,
    "ttft": 2282931.720426199,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3534004470333478,
    "arrivals": 1480643,
    "finished_requests": 59455,
    "scheduler_time": 115.41037717100686
}
#Debug simulation 
Total elapsed time: 4.46974237030372. Arrivals time: 0.21287408052012324 Scheduler time: 4.134902223013341 Scheduler overhead time: 0.037131134420633316 Adapter cache time: 0.029658107552677393 Engine time: 0.037743426859378815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 4.902078970801085,
    "estimated_duration": 3600.0747815270065,
    "input_throughput": 4582.390644952841,
    "output_throughput": 4045.450409733592,
    "total_throughput": 8627.841054686434,
    "itl": 211.9856391653604,
    "ttft": 2223027.278856265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9456907128752197,
    "arrivals": 1477777,
    "finished_requests": 66768,
    "scheduler_time": 101.18149265018401
}
#Debug simulation 
Total elapsed time: 4.902151409070939. Arrivals time: 0.23585066804662347 Scheduler time: 4.589385922066867 Scheduler overhead time: 0.026670774444937706 Adapter cache time: 0.011072218883782625 Engine time: 0.02700460748746991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.272602882701904,
    "estimated_duration": 3600.1409477097827,
    "input_throughput": 4582.30642622325,
    "output_throughput": 4045.3760593081197,
    "total_throughput": 8627.68248553137,
    "itl": 211.9884202893057,
    "ttft": 2223060.418428854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0113649392710125,
    "arrivals": 1477777,
    "finished_requests": 66768,
    "scheduler_time": 101.18198460655164
}
#Debug simulation 
Total elapsed time: 5.27266850695014. Arrivals time: 0.6162785841152072 Scheduler time: 4.580344822257757 Scheduler overhead time: 0.026444036979228258 Adapter cache time: 0.010544005315750837 Engine time: 0.0269062127918005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.515675519127399,
    "estimated_duration": 3600.1552579633985,
    "input_throughput": 4083.526111125695,
    "output_throughput": 3621.0174467238307,
    "total_throughput": 7704.543557849526,
    "itl": 140.67770129005098,
    "ttft": 2278594.74416276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9341778758168269,
    "arrivals": 1477777,
    "finished_requests": 59501,
    "scheduler_time": 116.1582750786361
}
#Debug simulation 
Total elapsed time: 4.515741006005555. Arrivals time: 0.21328219724819064 Scheduler time: 4.180742297321558 Scheduler overhead time: 0.037871106527745724 Adapter cache time: 0.02801933791488409 Engine time: 0.03813984803855419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 5.246392807923257,
    "estimated_duration": 3600.099787691921,
    "input_throughput": 4582.358815830616,
    "output_throughput": 4045.422310179117,
    "total_throughput": 8627.781126009731,
    "itl": 211.9866771993715,
    "ttft": 2223040.0894717774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9705054074269756,
    "arrivals": 1477777,
    "finished_requests": 66768,
    "scheduler_time": 101.18168412052616
}
#Debug simulation 
Total elapsed time: 5.246484314091504. Arrivals time: 0.616871019359678 Scheduler time: 4.553876434452832 Scheduler overhead time: 0.026497026439756155 Adapter cache time: 0.010613360907882452 Engine time: 0.026445104274898767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 4.529019623994827,
    "estimated_duration": 3600.0055658759147,
    "input_throughput": 4083.6384086042603,
    "output_throughput": 3621.0352349353334,
    "total_throughput": 7704.673643539593,
    "itl": 140.67856112798543,
    "ttft": 2278606.4976082514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9458729779534093,
    "arrivals": 1477777,
    "finished_requests": 59498,
    "scheduler_time": 116.1532276733328
}
#Debug simulation 
Total elapsed time: 4.529084591660649. Arrivals time: 0.21351592475548387 Scheduler time: 4.19360511796549 Scheduler overhead time: 0.03745518019422889 Adapter cache time: 0.028544606175273657 Engine time: 0.03826366551220417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 5.255517520010471,
    "estimated_duration": 3600.0528565272066,
    "input_throughput": 4582.418552574751,
    "output_throughput": 4045.475047288361,
    "total_throughput": 8627.893599863111,
    "itl": 211.98471888859828,
    "ttft": 2223016.3324400485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9239255411247735,
    "arrivals": 1477777,
    "finished_requests": 66768,
    "scheduler_time": 101.18133282210589
}
#Debug simulation 
Total elapsed time: 5.255608716979623. Arrivals time: 0.6130393552593887 Scheduler time: 4.5667154006659985 Scheduler overhead time: 0.026525833178311586 Adapter cache time: 0.010554593056440353 Engine time: 0.02658305037766695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_384_slots_160_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [128 128 128]
Adapter prompts. [33, 33, 34560, 66, 33, 34560, 34560, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 66, 66, 34560, 34560, 66, 66, 33, 34560, 33, 34560, 66, 66, 66, 33, 33, 66, 33, 34560, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 33, 34560, 66, 66, 33, 33, 33, 66, 33, 66, 33, 34560, 33, 66, 34560, 33, 34560, 66, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 34560, 34560, 66, 33, 33, 34560, 66, 66, 33, 33, 34560, 66, 34560, 66, 34560, 34560, 66, 34560, 34560, 33, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 33, 33, 66, 66, 34560, 33, 33, 34560, 33, 34560, 66, 33, 34560, 66, 66, 33, 34560, 34560, 34560, 33, 66, 34560, 33, 34560, 66, 66, 34560, 34560, 33, 66, 34560, 33, 66, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 34560, 33, 34560, 66, 66, 66, 66, 66, 33, 33, 34560, 33, 34560, 33, 66, 34560, 66, 34560, 66, 34560, 66, 34560, 33, 66, 66, 66, 66, 66, 66, 66, 66, 34560, 33, 33, 33, 33, 33, 66, 33, 33, 66, 34560, 34560, 33, 33, 34560, 33, 33, 33, 66, 33, 66, 34560, 34560, 66, 66, 33, 34560, 66, 34560, 33, 66, 66, 33, 33, 66, 33, 34560, 34560, 33, 34560, 34560, 33, 66, 34560, 33, 33, 66, 66, 33, 33, 34560, 34560, 34560, 34560, 66, 33, 66, 66, 33, 33, 33, 33, 33, 33, 33, 33, 66, 34560, 66, 66, 66, 34560, 33, 66, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 33, 33, 66, 33, 34560, 34560, 34560, 66, 33, 34560, 34560, 66, 66, 34560, 34560, 33, 34560, 34560, 66, 33, 34560, 66, 66, 34560, 34560, 34560, 33, 34560, 33, 34560, 34560, 33, 33, 34560, 33, 66, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 66, 66, 33, 34560, 33, 33, 33, 66, 33, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 66, 66, 66, 66, 33, 66, 34560, 34560, 33, 34560, 34560, 33, 34560, 66, 34560, 66, 66, 66, 33, 66, 33, 33, 34560, 33, 66, 33, 33, 66, 34560, 66, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4436352 . Total input tokens: 988618624 . Total output tokens: 886810347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 4.510432962328196,
    "estimated_duration": 3600.0188938209517,
    "input_throughput": 4083.623290209089,
    "output_throughput": 3621.0218291838605,
    "total_throughput": 7704.64511939295,
    "itl": 140.678984769336,
    "ttft": 2278613.30715827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 285,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9590771255269699,
    "arrivals": 1477777,
    "finished_requests": 59498,
    "scheduler_time": 116.15335147080371
}
#Debug simulation 
Total elapsed time: 4.51049964921549. Arrivals time: 0.2146071926690638 Scheduler time: 4.1747625027783215 Scheduler overhead time: 0.03775190282613039 Adapter cache time: 0.0278078094124794 Engine time: 0.038008772768080235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 15.43945956369862,
    "estimated_duration": 3600.1285076989766,
    "input_throughput": 4081.6095782624934,
    "output_throughput": 3599.6634487591973,
    "total_throughput": 7681.273027021691,
    "itl": 237.84939293468327,
    "ttft": 2259823.525641542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.076569674918534,
    "arrivals": 1289312,
    "finished_requests": 59597,
    "scheduler_time": 90.10419783673488
}
#Debug simulation 
Total elapsed time: 15.439589276909828. Arrivals time: 0.26958305668085814 Scheduler time: 15.063968258909881 Scheduler overhead time: 0.030696125235408545 Adapter cache time: 0.032883703242987394 Engine time: 0.030149207916110754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 15.800442007835954,
    "estimated_duration": 3600.1639938727094,
    "input_throughput": 4082.2607039604854,
    "output_throughput": 3599.6737987647916,
    "total_throughput": 7681.9345027252775,
    "itl": 237.886680439802,
    "ttft": 2259541.1341295894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.280466890546939,
    "arrivals": 1289312,
    "finished_requests": 59612,
    "scheduler_time": 90.0999013039976
}
#Debug simulation 
Total elapsed time: 15.800532591994852. Arrivals time: 0.274232632946223 Scheduler time: 15.421695712488145 Scheduler overhead time: 0.030652400571852922 Adapter cache time: 0.03150911256670952 Engine time: 0.03018188290297985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.319195827003568,
    "estimated_duration": 3600.1404912470057,
    "input_throughput": 3595.1977517179525,
    "output_throughput": 3184.782657198069,
    "total_throughput": 6779.980408916022,
    "itl": 159.57488214643624,
    "ttft": 2322376.1420011274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.805397305189695,
    "arrivals": 1289312,
    "finished_requests": 52533,
    "scheduler_time": 102.24489021114334
}
#Debug simulation 
Total elapsed time: 6.3193111047148705. Arrivals time: 0.22226698184385896 Scheduler time: 5.920290912035853 Scheduler overhead time: 0.03534364188089967 Adapter cache time: 0.09062459832057357 Engine time: 0.0346837374381721 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 16.10971234086901,
    "estimated_duration": 3600.235322258364,
    "input_throughput": 4082.9050559893167,
    "output_throughput": 3599.959124857978,
    "total_throughput": 7682.864180847295,
    "itl": 237.87395276999516,
    "ttft": 2259528.0421326333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.099459164477829,
    "arrivals": 1289312,
    "finished_requests": 59621,
    "scheduler_time": 90.10589163105813
}
#Debug simulation 
Total elapsed time: 16.109781052917242. Arrivals time: 0.2745664706453681 Scheduler time: 15.730392653029412 Scheduler overhead time: 0.030770348850637674 Adapter cache time: 0.031524973921477795 Engine time: 0.030253074131906033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 6.317670744843781,
    "estimated_duration": 3600.130723406077,
    "input_throughput": 3595.2075061747887,
    "output_throughput": 3184.791298120518,
    "total_throughput": 6779.998804295307,
    "itl": 159.58204051387762,
    "ttft": 2322433.5451512258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.971769564616562,
    "arrivals": 1289312,
    "finished_requests": 52533,
    "scheduler_time": 102.24001125537715
}
#Debug simulation 
Total elapsed time: 6.317775029689074. Arrivals time: 0.22052653739228845 Scheduler time: 5.919955193530768 Scheduler overhead time: 0.03512844676151872 Adapter cache time: 0.09132805652916431 Engine time: 0.03475718013942242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 15.58777879877016,
    "estimated_duration": 3600.0344728752884,
    "input_throughput": 4081.7161920852077,
    "output_throughput": 3599.7574738915373,
    "total_throughput": 7681.473665976745,
    "itl": 237.84377008087918,
    "ttft": 2259787.889832543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1332,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9827469928095933,
    "arrivals": 1289312,
    "finished_requests": 59597,
    "scheduler_time": 90.10398569498669
}
#Debug simulation 
Total elapsed time: 15.587866606656462. Arrivals time: 0.28277196548879147 Scheduler time: 15.200145958457142 Scheduler overhead time: 0.030568871647119522 Adapter cache time: 0.031983617693185806 Engine time: 0.03006845898926258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [4320, 4320, 17280, 8640, 4320, 17280, 17280, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 8640, 8640, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 4320, 4320, 8640, 8640, 17280, 4320, 4320, 17280, 4320, 17280, 8640, 4320, 17280, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 17280, 4320, 17280, 8640, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 17280, 4320, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 4320, 4320, 4320, 4320, 4320, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 17280, 4320, 17280, 17280, 4320, 8640, 17280, 4320, 4320, 8640, 8640, 4320, 4320, 17280, 17280, 17280, 17280, 8640, 4320, 8640, 8640, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 4320, 8640, 17280, 8640, 8640, 8640, 17280, 4320, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 17280, 17280, 8640, 4320, 17280, 17280, 8640, 8640, 17280, 17280, 4320, 17280, 17280, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 17280, 4320, 8640, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 4320, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 17280, 17280, 4320, 17280, 17280, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 4320, 8640, 4320, 4320, 17280, 4320, 8640, 4320, 4320, 8640, 17280, 8640, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3870720 . Total input tokens: 862545660 . Total output tokens: 773736307
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 6.3080039313063025,
    "estimated_duration": 3600.1173520251914,
    "input_throughput": 3594.853371299059,
    "output_throughput": 3184.70813001425,
    "total_throughput": 6779.561501313308,
    "itl": 159.58823908946727,
    "ttft": 2322495.770167588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3918,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.133866195305341,
    "arrivals": 1289312,
    "finished_requests": 52530,
    "scheduler_time": 102.23515147848073
}
#Debug simulation 
Total elapsed time: 6.308115419000387. Arrivals time: 0.2225792007520795 Scheduler time: 5.909069630783051 Scheduler overhead time: 0.035192504059523344 Adapter cache time: 0.09048850974068046 Engine time: 0.03474196419119835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 13.816626670770347,
    "estimated_duration": 3600.231384537184,
    "input_throughput": 4109.35865498597,
    "output_throughput": 3604.195290261345,
    "total_throughput": 7713.553945247315,
    "itl": 236.45531617363545,
    "ttft": 2250951.8820299613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.76823990504736,
    "arrivals": 1150725,
    "finished_requests": 59937,
    "scheduler_time": 90.41917590530903
}
#Debug simulation 
Total elapsed time: 13.816712939646095. Arrivals time: 0.26959007792174816 Scheduler time: 13.437595244962722 Scheduler overhead time: 0.030453029088675976 Adapter cache time: 0.03749552695080638 Engine time: 0.02936876704916358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 13.847408827859908,
    "estimated_duration": 3600.1124862325482,
    "input_throughput": 4117.640228378811,
    "output_throughput": 3609.221670069973,
    "total_throughput": 7726.861898448784,
    "itl": 236.34523267791454,
    "ttft": 2251968.5977844936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1469,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.79525886719341,
    "arrivals": 1150725,
    "finished_requests": 60056,
    "scheduler_time": 90.43744914889193
}
#Debug simulation 
Total elapsed time: 13.847525138873607. Arrivals time: 0.26732240291312337 Scheduler time: 13.470135018229485 Scheduler overhead time: 0.030483883805572987 Adapter cache time: 0.037610337138175964 Engine time: 0.029674635734409094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.795961492694914,
    "estimated_duration": 3600.121371037003,
    "input_throughput": 3626.023584932583,
    "output_throughput": 3188.0350180232945,
    "total_throughput": 6814.058602955878,
    "itl": 159.5179843766043,
    "ttft": 2315541.7523288317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.397533436826736,
    "arrivals": 1150725,
    "finished_requests": 52878,
    "scheduler_time": 102.21673796505002
}
#Debug simulation 
Total elapsed time: 5.7960555627942085. Arrivals time: 0.22036585537716746 Scheduler time: 5.407835658639669 Scheduler overhead time: 0.03510483540594578 Adapter cache time: 0.08177988464012742 Engine time: 0.03483886132016778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 14.004277443978935,
    "estimated_duration": 3600.065433994765,
    "input_throughput": 4109.316141952522,
    "output_throughput": 3604.078658537757,
    "total_throughput": 7713.394800490279,
    "itl": 236.45966250664034,
    "ttft": 2250967.6976109627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8705593297280245,
    "arrivals": 1150725,
    "finished_requests": 59934,
    "scheduler_time": 90.41270392398484
}
#Debug simulation 
Total elapsed time: 14.004387848079205. Arrivals time: 0.26867280155420303 Scheduler time: 13.624682058114558 Scheduler overhead time: 0.030490314587950706 Adapter cache time: 0.0388125516474247 Engine time: 0.029300478752702475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.802060240879655,
    "estimated_duration": 3600.087813740339,
    "input_throughput": 3625.983496896314,
    "output_throughput": 3187.8783501328694,
    "total_throughput": 6813.861847029183,
    "itl": 159.52360607741218,
    "ttft": 2315580.607034767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.54215029120378,
    "arrivals": 1150725,
    "finished_requests": 52876,
    "scheduler_time": 102.21178368833635
}
#Debug simulation 
Total elapsed time: 5.802157253958285. Arrivals time: 0.22351538436487317 Scheduler time: 5.4101233021356165 Scheduler overhead time: 0.03518627304583788 Adapter cache time: 0.08252319041639566 Engine time: 0.03469778597354889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 14.073305409867316,
    "estimated_duration": 3600.121446324727,
    "input_throughput": 4109.4841439594975,
    "output_throughput": 3604.30535287825,
    "total_throughput": 7713.789496837748,
    "itl": 236.44868875592476,
    "ttft": 2250913.283623831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.658498359457461,
    "arrivals": 1150725,
    "finished_requests": 59937,
    "scheduler_time": 90.4189792382447
}
#Debug simulation 
Total elapsed time: 14.073390629142523. Arrivals time: 0.273761791177094 Scheduler time: 13.688017897773534 Scheduler overhead time: 0.03083820641040802 Adapter cache time: 0.03878835216164589 Engine time: 0.029843847267329693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [128 128 128]
Adapter prompts. [1080, 1080, 17280, 8640, 1080, 17280, 17280, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 8640, 8640, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 1080, 1080, 8640, 8640, 17280, 1080, 1080, 17280, 1080, 17280, 8640, 1080, 17280, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 17280, 1080, 17280, 8640, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 17280, 1080, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 1080, 1080, 1080, 1080, 1080, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 17280, 1080, 17280, 17280, 1080, 8640, 17280, 1080, 1080, 8640, 8640, 1080, 1080, 17280, 17280, 17280, 17280, 8640, 1080, 8640, 8640, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 8640, 17280, 8640, 8640, 8640, 17280, 1080, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 17280, 17280, 8640, 1080, 17280, 17280, 8640, 8640, 17280, 17280, 1080, 17280, 17280, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 17280, 1080, 8640, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 1080, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 17280, 17280, 1080, 17280, 17280, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 1080, 8640, 1080, 1080, 17280, 1080, 8640, 1080, 1080, 8640, 17280, 8640, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 3456000 . Total input tokens: 770123435 . Total output tokens: 690892714
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.797623530961573,
    "estimated_duration": 3600.0532755920917,
    "input_throughput": 3625.683288771126,
    "output_throughput": 3187.7150479426114,
    "total_throughput": 6813.398336713737,
    "itl": 159.53037097520385,
    "ttft": 2315559.8729152274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.68552419360657,
    "arrivals": 1150725,
    "finished_requests": 52872,
    "scheduler_time": 102.20687387538113
}
#Debug simulation 
Total elapsed time: 5.797727437224239. Arrivals time: 0.2206392497755587 Scheduler time: 5.408028486184776 Scheduler overhead time: 0.034968146588653326 Adapter cache time: 0.08289091475307941 Engine time: 0.035058551002293825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 12.028961120173335,
    "estimated_duration": 3600.240145085614,
    "input_throughput": 4106.0947059820255,
    "output_throughput": 3599.664877269407,
    "total_throughput": 7705.759583251433,
    "itl": 236.9356017127205,
    "ttft": 2253206.935319555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.973292583890862,
    "arrivals": 1127715,
    "finished_requests": 59714,
    "scheduler_time": 90.24879072089183
}
#Debug simulation 
Total elapsed time: 12.029047369025648. Arrivals time: 0.26410184567794204 Scheduler time: 11.65529667912051 Scheduler overhead time: 0.029700085520744324 Adapter cache time: 0.038880947045981884 Engine time: 0.028680008370429277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 12.276729761157185,
    "estimated_duration": 3600.1604488349412,
    "input_throughput": 4102.364105682983,
    "output_throughput": 3597.328559117719,
    "total_throughput": 7699.692664800702,
    "itl": 237.26172455850516,
    "ttft": 2253126.433177779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.259201042705575,
    "arrivals": 1127715,
    "finished_requests": 59666,
    "scheduler_time": 90.1389715805943
}
#Debug simulation 
Total elapsed time: 12.27684833202511. Arrivals time: 0.2713710586540401 Scheduler time: 11.894307768903673 Scheduler overhead time: 0.030042170081287622 Adapter cache time: 0.040266990195959806 Engine time: 0.028672507498413324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.588374929036945,
    "estimated_duration": 3600.070163325719,
    "input_throughput": 3625.6862804979296,
    "output_throughput": 3187.33926824354,
    "total_throughput": 6813.02554874147,
    "itl": 159.7133158385114,
    "ttft": 2316873.1277069137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.79669414762356,
    "arrivals": 1127715,
    "finished_requests": 52747,
    "scheduler_time": 102.1922466638629
}
#Debug simulation 
Total elapsed time: 5.588464338332415. Arrivals time: 0.27809336641803384 Scheduler time: 5.144910368602723 Scheduler overhead time: 0.034940711222589016 Adapter cache time: 0.079827222507447 Engine time: 0.034603580832481384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 12.223140875808895,
    "estimated_duration": 3600.2079390011727,
    "input_throughput": 4102.352489144708,
    "output_throughput": 3597.4774844792046,
    "total_throughput": 7699.829973623912,
    "itl": 237.24792814164755,
    "ttft": 2253111.224033989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.041419737976862,
    "arrivals": 1127715,
    "finished_requests": 59670,
    "scheduler_time": 90.1452743418714
}
#Debug simulation 
Total elapsed time: 12.22325647296384. Arrivals time: 0.3467186358757317 Scheduler time: 11.76585456263274 Scheduler overhead time: 0.029707100708037615 Adapter cache time: 0.039830662310123444 Engine time: 0.028781020548194647 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.498272166587412,
    "estimated_duration": 3600.0388559644293,
    "input_throughput": 3625.476146841055,
    "output_throughput": 3187.1597666204107,
    "total_throughput": 6812.635913461466,
    "itl": 159.71994076324626,
    "ttft": 2316931.5962091284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3301,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.935777835398328,
    "arrivals": 1127715,
    "finished_requests": 52743,
    "scheduler_time": 102.18745820680093
}
#Debug simulation 
Total elapsed time: 5.498360981699079. Arrivals time: 0.21488539036363363 Scheduler time: 5.1190333515405655 Scheduler overhead time: 0.0347786471247673 Adapter cache time: 0.07886979123577476 Engine time: 0.03477486735209823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 12.231760404072702,
    "estimated_duration": 3600.1254767087103,
    "input_throughput": 4106.225490094523,
    "output_throughput": 3599.7795309756584,
    "total_throughput": 7706.005021070181,
    "itl": 236.9287063939237,
    "ttft": 2253166.898978689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8588317292159,
    "arrivals": 1127715,
    "finished_requests": 59714,
    "scheduler_time": 90.24858319845225
}
#Debug simulation 
Total elapsed time: 12.231874720659107. Arrivals time: 0.6027765814214945 Scheduler time: 11.519488101825118 Scheduler overhead time: 0.029136850032955408 Adapter cache time: 0.03996424563229084 Engine time: 0.028388630598783493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [128 128 128]
Adapter prompts. [540, 540, 17280, 8640, 540, 17280, 17280, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 540, 17280, 8640, 8640, 540, 540, 540, 8640, 540, 8640, 540, 17280, 540, 8640, 17280, 540, 17280, 8640, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 8640, 8640, 540, 540, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 540, 540, 8640, 8640, 17280, 540, 540, 17280, 540, 17280, 8640, 540, 17280, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 17280, 540, 17280, 8640, 8640, 17280, 17280, 540, 8640, 17280, 540, 8640, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 17280, 540, 17280, 8640, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 17280, 540, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 540, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 540, 540, 540, 540, 540, 8640, 540, 540, 8640, 17280, 17280, 540, 540, 17280, 540, 540, 540, 8640, 540, 8640, 17280, 17280, 8640, 8640, 540, 17280, 8640, 17280, 540, 8640, 8640, 540, 540, 8640, 540, 17280, 17280, 540, 17280, 17280, 540, 8640, 17280, 540, 540, 8640, 8640, 540, 540, 17280, 17280, 17280, 17280, 8640, 540, 8640, 8640, 540, 540, 540, 540, 540, 540, 540, 540, 8640, 17280, 8640, 8640, 8640, 17280, 540, 8640, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 540, 540, 8640, 540, 17280, 17280, 17280, 8640, 540, 17280, 17280, 8640, 8640, 17280, 17280, 540, 17280, 17280, 8640, 540, 17280, 8640, 8640, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 540, 540, 17280, 540, 8640, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 540, 17280, 540, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 17280, 17280, 540, 17280, 17280, 540, 17280, 8640, 17280, 8640, 8640, 8640, 540, 8640, 540, 540, 17280, 540, 8640, 540, 540, 8640, 17280, 8640, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 3386880 . Total input tokens: 754730995 . Total output tokens: 677056423
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.484240656718612,
    "estimated_duration": 3600.154563318961,
    "input_throughput": 3625.689611494479,
    "output_throughput": 3187.7892457538965,
    "total_throughput": 6813.478857248376,
    "itl": 159.73609049340737,
    "ttft": 2316766.97076982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.225829951389976,
    "arrivals": 1127715,
    "finished_requests": 52742,
    "scheduler_time": 102.18720440117167
}
#Debug simulation 
Total elapsed time: 5.4843320907093585. Arrivals time: 0.22153355833142996 Scheduler time: 5.097330768126994 Scheduler overhead time: 0.03466156078502536 Adapter cache time: 0.08002911508083344 Engine time: 0.03471675468608737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.143769431859255,
    "estimated_duration": 3600.0142281360777,
    "input_throughput": 4091.5435513782177,
    "output_throughput": 3596.3402307727265,
    "total_throughput": 7687.883782150944,
    "itl": 237.47042847993131,
    "ttft": 2254477.0007538376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.5172799100448655,
    "arrivals": 1116080,
    "finished_requests": 59683,
    "scheduler_time": 90.09177080408942
}
#Debug simulation 
Total elapsed time: 11.143855961039662. Arrivals time: 0.2610480636358261 Scheduler time: 10.779050400014967 Scheduler overhead time: 0.02897097310051322 Adapter cache time: 0.034755812492221594 Engine time: 0.028200595173984766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 11.563701419625431,
    "estimated_duration": 3600.04996304556,
    "input_throughput": 4091.457660642915,
    "output_throughput": 3596.23925581506,
    "total_throughput": 7687.696916457975,
    "itl": 237.48780924187398,
    "ttft": 2254497.0944894063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.812381978325942,
    "arrivals": 1116080,
    "finished_requests": 59682,
    "scheduler_time": 90.08565940932375
}
#Debug simulation 
Total elapsed time: 11.563768316991627. Arrivals time: 0.5905469418503344 Scheduler time: 10.867317858152092 Scheduler overhead time: 0.029598567634820938 Adapter cache time: 0.036257702857255936 Engine time: 0.02825187100097537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.300763001199812,
    "estimated_duration": 3600.0018633735153,
    "input_throughput": 3596.2034163693884,
    "output_throughput": 3186.2097396947656,
    "total_throughput": 6782.4131560641545,
    "itl": 159.26058989647206,
    "ttft": 2318912.5351939565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2999,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.807741223927243,
    "arrivals": 1116080,
    "finished_requests": 52547,
    "scheduler_time": 102.26124653140863
}
#Debug simulation 
Total elapsed time: 5.300847669132054. Arrivals time: 0.21432782569900155 Scheduler time: 4.926597950980067 Scheduler overhead time: 0.03475066274404526 Adapter cache time: 0.0744441649876535 Engine time: 0.03471666760742664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 11.274095514789224,
    "estimated_duration": 3600.1110816240525,
    "input_throughput": 4091.4334769235224,
    "output_throughput": 3596.2434787316374,
    "total_throughput": 7687.67695565516,
    "itl": 237.4761172608713,
    "ttft": 2254508.7884798544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.613934536629735,
    "arrivals": 1116080,
    "finished_requests": 59683,
    "scheduler_time": 90.09196966532535
}
#Debug simulation 
Total elapsed time: 11.274186585098505. Arrivals time: 0.25961322896182537 Scheduler time: 10.908306984230876 Scheduler overhead time: 0.029476564843207598 Adapter cache time: 0.03641413664445281 Engine time: 0.028452910017222166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.298727850895375,
    "estimated_duration": 3600.126626380141,
    "input_throughput": 3596.0787893222796,
    "output_throughput": 3186.0993210489464,
    "total_throughput": 6782.178110371226,
    "itl": 159.26590406688382,
    "ttft": 2318954.9532739893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2999,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.932363226264266,
    "arrivals": 1116080,
    "finished_requests": 52547,
    "scheduler_time": 102.26138753580415
}
#Debug simulation 
Total elapsed time: 5.298812469933182. Arrivals time: 0.21002239547669888 Scheduler time: 4.929216611664742 Scheduler overhead time: 0.03487160010263324 Adapter cache time: 0.07402915600687265 Engine time: 0.034640475176274776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.210301043931395,
    "estimated_duration": 3600.1708622824103,
    "input_throughput": 4091.7832968241046,
    "output_throughput": 3596.345977810526,
    "total_throughput": 7688.129274634631,
    "itl": 237.46318497384433,
    "ttft": 2254477.951362039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1476,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.413314235275491,
    "arrivals": 1116080,
    "finished_requests": 59688,
    "scheduler_time": 90.09826064736548
}
#Debug simulation 
Total elapsed time: 11.210412418004125. Arrivals time: 0.25589285884052515 Scheduler time: 10.849429068621248 Scheduler overhead time: 0.029401531908661127 Adapter cache time: 0.035539016127586365 Engine time: 0.028109684120863676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [128 128 128]
Adapter prompts. [270, 270, 17280, 8640, 270, 17280, 17280, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 270, 17280, 8640, 8640, 270, 270, 270, 8640, 270, 8640, 270, 17280, 270, 8640, 17280, 270, 17280, 8640, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 8640, 8640, 270, 270, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 270, 270, 8640, 8640, 17280, 270, 270, 17280, 270, 17280, 8640, 270, 17280, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 17280, 270, 17280, 8640, 8640, 17280, 17280, 270, 8640, 17280, 270, 8640, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 17280, 270, 17280, 8640, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 17280, 270, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 270, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 270, 270, 270, 270, 270, 8640, 270, 270, 8640, 17280, 17280, 270, 270, 17280, 270, 270, 270, 8640, 270, 8640, 17280, 17280, 8640, 8640, 270, 17280, 8640, 17280, 270, 8640, 8640, 270, 270, 8640, 270, 17280, 17280, 270, 17280, 17280, 270, 8640, 17280, 270, 270, 8640, 8640, 270, 270, 17280, 17280, 17280, 17280, 8640, 270, 8640, 8640, 270, 270, 270, 270, 270, 270, 270, 270, 8640, 17280, 8640, 8640, 8640, 17280, 270, 8640, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 270, 270, 8640, 270, 17280, 17280, 17280, 8640, 270, 17280, 17280, 8640, 8640, 17280, 17280, 270, 17280, 17280, 8640, 270, 17280, 8640, 8640, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 270, 270, 17280, 270, 8640, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 270, 17280, 270, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 17280, 17280, 270, 17280, 17280, 270, 17280, 8640, 17280, 8640, 8640, 8640, 270, 8640, 270, 270, 17280, 270, 8640, 270, 270, 8640, 17280, 8640, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 3352320 . Total input tokens: 746987983 . Total output tokens: 670185332
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.357713561039418,
    "estimated_duration": 3600.0814879371974,
    "input_throughput": 3596.1238775786974,
    "output_throughput": 3186.1392689120426,
    "total_throughput": 6782.26314649074,
    "itl": 159.27136548767257,
    "ttft": 2319032.2740877895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2999,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.06138661112583,
    "arrivals": 1116080,
    "finished_requests": 52547,
    "scheduler_time": 102.25652812283388
}
#Debug simulation 
Total elapsed time: 5.357800524681807. Arrivals time: 0.28991447715088725 Scheduler time: 4.908121949527413 Scheduler overhead time: 0.034924281761050224 Adapter cache time: 0.07446706341579556 Engine time: 0.034395386930555105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.038319282699376,
    "estimated_duration": 3600.2536114963377,
    "input_throughput": 4108.896371289717,
    "output_throughput": 3603.156166159212,
    "total_throughput": 7712.052537448929,
    "itl": 236.69017543957216,
    "ttft": 2249646.6184612056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.315287718945297,
    "arrivals": 1110230,
    "finished_requests": 59684,
    "scheduler_time": 90.28558640214762
}
#Debug simulation 
Total elapsed time: 11.038429768756032. Arrivals time: 0.25615689996629953 Scheduler time: 10.67896923283115 Scheduler overhead time: 0.02897370746359229 Adapter cache time: 0.033986125607043505 Engine time: 0.028322116937488317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.39333603112027,
    "estimated_duration": 3600.0782240682756,
    "input_throughput": 4109.721811344565,
    "output_throughput": 3600.7242601943412,
    "total_throughput": 7710.446071538907,
    "itl": 236.51257156047757,
    "ttft": 2250176.498918909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.03151073273263,
    "arrivals": 1110230,
    "finished_requests": 59666,
    "scheduler_time": 90.32375737756622
}
#Debug simulation 
Total elapsed time: 10.393421549350023. Arrivals time: 0.25127465883269906 Scheduler time: 10.039503803476691 Scheduler overhead time: 0.02854730049148202 Adapter cache time: 0.03463611751794815 Engine time: 0.027565844357013702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.310636929702014,
    "estimated_duration": 3600.171849284904,
    "input_throughput": 3619.401669003167,
    "output_throughput": 3187.936987585657,
    "total_throughput": 6807.338656588824,
    "itl": 159.390059468283,
    "ttft": 2314158.6851710887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.100428523402442,
    "arrivals": 1110230,
    "finished_requests": 52638,
    "scheduler_time": 102.22997943080037
}
#Debug simulation 
Total elapsed time: 5.3107242048718035. Arrivals time: 0.21201211959123611 Scheduler time: 4.943966556340456 Scheduler overhead time: 0.034550577867776155 Adapter cache time: 0.0696290829218924 Engine time: 0.03456564527004957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 10.362419154960662,
    "estimated_duration": 3600.1449284011624,
    "input_throughput": 4109.844268566981,
    "output_throughput": 3600.759485468,
    "total_throughput": 7710.603754034981,
    "itl": 236.49782959338177,
    "ttft": 2250155.651184064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.822309929691158,
    "arrivals": 1110230,
    "finished_requests": 59670,
    "scheduler_time": 90.33024724518367
}
#Debug simulation 
Total elapsed time: 10.362499798182398. Arrivals time: 0.24195007840171456 Scheduler time: 10.016869139391929 Scheduler overhead time: 0.028391279745846987 Adapter cache time: 0.0360791115090251 Engine time: 0.027314146049320698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.605276539921761,
    "estimated_duration": 3600.105905580984,
    "input_throughput": 3619.218251274553,
    "output_throughput": 3187.700390205048,
    "total_throughput": 6806.9186414796,
    "itl": 159.3948999556992,
    "ttft": 2314113.088373843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.20997465725954,
    "arrivals": 1110230,
    "finished_requests": 52633,
    "scheduler_time": 102.22509782767072
}
#Debug simulation 
Total elapsed time: 5.6053609270602465. Arrivals time: 0.5369015750475228 Scheduler time: 4.9144368027336895 Scheduler overhead time: 0.03472604742273688 Adapter cache time: 0.06913484679535031 Engine time: 0.03423938527703285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.408950383774936,
    "estimated_duration": 3600.208546374269,
    "input_throughput": 4109.878305494639,
    "output_throughput": 3600.914456207251,
    "total_throughput": 7710.79276170189,
    "itl": 236.48525852659702,
    "ttft": 2250124.0779051865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1542,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.610657554739028,
    "arrivals": 1110230,
    "finished_requests": 59671,
    "scheduler_time": 90.33675523484843
}
#Debug simulation 
Total elapsed time: 10.409044541884214. Arrivals time: 0.2507531768642366 Scheduler time: 10.054566521663219 Scheduler overhead time: 0.028615692630410194 Adapter cache time: 0.03547656023874879 Engine time: 0.027551632840186357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [128 128 128]
Adapter prompts. [135, 135, 17280, 8640, 135, 17280, 17280, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 135, 17280, 8640, 8640, 135, 135, 135, 8640, 135, 8640, 135, 17280, 135, 8640, 17280, 135, 17280, 8640, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 8640, 8640, 135, 135, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 135, 135, 8640, 8640, 17280, 135, 135, 17280, 135, 17280, 8640, 135, 17280, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 17280, 135, 17280, 8640, 8640, 17280, 17280, 135, 8640, 17280, 135, 8640, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 17280, 135, 17280, 8640, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 17280, 135, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 135, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 135, 135, 135, 135, 135, 8640, 135, 135, 8640, 17280, 17280, 135, 135, 17280, 135, 135, 135, 8640, 135, 8640, 17280, 17280, 8640, 8640, 135, 17280, 8640, 17280, 135, 8640, 8640, 135, 135, 8640, 135, 17280, 17280, 135, 17280, 17280, 135, 8640, 17280, 135, 135, 8640, 8640, 135, 135, 17280, 17280, 17280, 17280, 8640, 135, 8640, 8640, 135, 135, 135, 135, 135, 135, 135, 135, 8640, 17280, 8640, 8640, 8640, 17280, 135, 8640, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 135, 135, 8640, 135, 17280, 17280, 17280, 8640, 135, 17280, 17280, 8640, 8640, 17280, 17280, 135, 17280, 17280, 8640, 135, 17280, 8640, 8640, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 135, 135, 17280, 135, 8640, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 135, 17280, 135, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 17280, 17280, 135, 17280, 17280, 135, 17280, 8640, 17280, 8640, 8640, 8640, 135, 8640, 135, 135, 17280, 135, 8640, 135, 135, 8640, 17280, 8640, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 3335040 . Total input tokens: 743135530 . Total output tokens: 666723998
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.27246524207294,
    "estimated_duration": 3600.0521549096143,
    "input_throughput": 3619.1034016636672,
    "output_throughput": 3187.562986927924,
    "total_throughput": 6806.666388591591,
    "itl": 159.40072643390425,
    "ttft": 2314016.1889424836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.331955830081835,
    "arrivals": 1110230,
    "finished_requests": 52630,
    "scheduler_time": 102.22019185477514
}
#Debug simulation 
Total elapsed time: 5.272544679231942. Arrivals time: 0.2053711786866188 Scheduler time: 4.913160743191838 Scheduler overhead time: 0.03461427101865411 Adapter cache time: 0.0688234711997211 Engine time: 0.03461902728304267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.913952386938035,
    "estimated_duration": 3600.0192724036724,
    "input_throughput": 4100.879435054477,
    "output_throughput": 3619.6839555526785,
    "total_throughput": 7720.563390607155,
    "itl": 236.73714857021196,
    "ttft": 2246675.542261021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8990613857704277,
    "arrivals": 1107373,
    "finished_requests": 59836,
    "scheduler_time": 90.60722786094496
}
#Debug simulation 
Total elapsed time: 10.914032385218889. Arrivals time: 0.25140927638858557 Scheduler time: 10.562848520465195 Scheduler overhead time: 0.030060438439249992 Adapter cache time: 0.02939260471612215 Engine time: 0.028036664240062237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.964645644184202,
    "estimated_duration": 3600.106614461999,
    "input_throughput": 4098.633340669848,
    "output_throughput": 3618.7381083842943,
    "total_throughput": 7717.371449054142,
    "itl": 236.79476406910817,
    "ttft": 2245810.3744586036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.164931885814286,
    "arrivals": 1107373,
    "finished_requests": 59836,
    "scheduler_time": 90.58396212448002
}
#Debug simulation 
Total elapsed time: 10.964724656194448. Arrivals time: 0.2489449307322502 Scheduler time: 10.616063326131552 Scheduler overhead time: 0.029432727955281734 Adapter cache time: 0.029789465945214033 Engine time: 0.028427451848983765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.309422857128084,
    "estimated_duration": 3600.162723685528,
    "input_throughput": 3611.4581472833734,
    "output_throughput": 3192.777349861822,
    "total_throughput": 6804.235497145196,
    "itl": 160.32009369480124,
    "ttft": 2311205.9449838223,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.90804550653305,
    "arrivals": 1107373,
    "finished_requests": 52685,
    "scheduler_time": 102.09841609786749
}
#Debug simulation 
Total elapsed time: 5.3095042472705245. Arrivals time: 0.2865504762157798 Scheduler time: 4.870550307445228 Scheduler overhead time: 0.034724920988082886 Adapter cache time: 0.0671267188154161 Engine time: 0.03459633933380246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128 256]
---Simulation End---
#Simulation results
{
    "duration": 11.028948682826012,
    "estimated_duration": 3600.1144443296075,
    "input_throughput": 4100.7710250025475,
    "output_throughput": 3619.588266290947,
    "total_throughput": 7720.359291293494,
    "itl": 236.74272161954954,
    "ttft": 2246710.4838634497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.994009159640365,
    "arrivals": 1107373,
    "finished_requests": 59836,
    "scheduler_time": 90.60745201289555
}
#Debug simulation 
Total elapsed time: 11.029056328814477. Arrivals time: 0.25202974351122975 Scheduler time: 10.676739224698395 Scheduler overhead time: 0.02938459115102887 Adapter cache time: 0.030337652191519737 Engine time: 0.0286530670709908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [128 128 128]
---Simulation End---
#Simulation results
{
    "duration": 5.216973841190338,
    "estimated_duration": 3600.0957923589235,
    "input_throughput": 3611.3683495852365,
    "output_throughput": 3192.801153901637,
    "total_throughput": 6804.1695034868735,
    "itl": 160.32446932957006,
    "ttft": 2311263.1369669703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.017954315859507,
    "arrivals": 1107373,
    "finished_requests": 52684,
    "scheduler_time": 102.09349001641442
}
#Debug simulation 
Total elapsed time: 5.217051988933235. Arrivals time: 0.20768248476088047 Scheduler time: 4.855702874716371 Scheduler overhead time: 0.03468372579663992 Adapter cache time: 0.06855314457789063 Engine time: 0.03448998462408781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 11.016103405039757,
    "estimated_duration": 3600.195869055145,
    "input_throughput": 4100.931876207831,
    "output_throughput": 3619.644728779726,
    "total_throughput": 7720.576604987557,
    "itl": 236.73291816741568,
    "ttft": 2246668.429422083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8093240757052733,
    "arrivals": 1107373,
    "finished_requests": 59838,
    "scheduler_time": 90.61372256614706
}
#Debug simulation 
Total elapsed time: 11.0161825241521. Arrivals time: 0.25591936241835356 Scheduler time: 10.661270471755415 Scheduler overhead time: 0.028889179229736328 Adapter cache time: 0.029849577695131302 Engine time: 0.028142535127699375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_384_slots_160_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [128 128 128]
Adapter prompts. [66, 66, 17280, 8640, 66, 17280, 17280, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 66, 17280, 8640, 8640, 66, 66, 66, 8640, 66, 8640, 66, 17280, 66, 8640, 17280, 66, 17280, 8640, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 8640, 8640, 66, 66, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 66, 66, 8640, 8640, 17280, 66, 66, 17280, 66, 17280, 8640, 66, 17280, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 17280, 66, 17280, 8640, 8640, 17280, 17280, 66, 8640, 17280, 66, 8640, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 17280, 66, 17280, 8640, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 17280, 66, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 66, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 66, 66, 66, 66, 66, 8640, 66, 66, 8640, 17280, 17280, 66, 66, 17280, 66, 66, 66, 8640, 66, 8640, 17280, 17280, 8640, 8640, 66, 17280, 8640, 17280, 66, 8640, 8640, 66, 66, 8640, 66, 17280, 17280, 66, 17280, 17280, 66, 8640, 17280, 66, 66, 8640, 8640, 66, 66, 17280, 17280, 17280, 17280, 8640, 66, 8640, 8640, 66, 66, 66, 66, 66, 66, 66, 66, 8640, 17280, 8640, 8640, 8640, 17280, 66, 8640, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 66, 66, 8640, 66, 17280, 17280, 17280, 8640, 66, 17280, 17280, 8640, 8640, 17280, 17280, 66, 17280, 17280, 8640, 66, 17280, 8640, 8640, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 66, 66, 17280, 66, 8640, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 66, 17280, 66, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 17280, 17280, 66, 17280, 17280, 66, 17280, 8640, 17280, 8640, 8640, 8640, 66, 8640, 66, 66, 17280, 66, 8640, 66, 66, 8640, 17280, 8640, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 3326208 . Total input tokens: 741177771 . Total output tokens: 664984004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 5.309879046864808,
    "estimated_duration": 3600.0404460369778,
    "input_throughput": 3611.0819294574308,
    "output_throughput": 3192.6271863563234,
    "total_throughput": 6803.709115813755,
    "itl": 160.32859545490584,
    "ttft": 2311330.5826367764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2724,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.138300689458402,
    "arrivals": 1107373,
    "finished_requests": 52681,
    "scheduler_time": 102.08862319215935
}
#Debug simulation 
Total elapsed time: 5.309964194893837. Arrivals time: 0.28752116672694683 Scheduler time: 4.868953372351825 Scheduler overhead time: 0.03503177873790264 Adapter cache time: 0.06798924691975117 Engine time: 0.034464542753994465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_384_slots_160_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [8]. Counts: [384]
---Simulation End---
#Simulation results
{
    "duration": 10.452511963900179,
    "estimated_duration": 3600.2543433146684,
    "input_throughput": 4119.046485573218,
    "output_throughput": 3629.295253615357,
    "total_throughput": 7748.341739188575,
    "itl": 236.2798036536656,
    "ttft": 2248926.6191101484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.935787238697622,
    "arrivals": 1105887,
    "finished_requests": 60019,
    "scheduler_time": 90.80615191441886
}
#Debug simulation 
Total elapsed time: 10.452594207134098. Arrivals time: 0.25158134615048766 Scheduler time: 10.10246472293511 Scheduler overhead time: 0.028135504107922316 Adapter cache time: 0.030767328571528196 Engine time: 0.027835397981107235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 384,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_384_slots_160_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [128 128 128]
Adapter prompts. [33, 33, 17280, 8640, 33, 17280, 17280, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 8640, 8640, 17280, 17280, 8640, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 33, 17280, 8640, 8640, 33, 33, 33, 8640, 33, 8640, 33, 17280, 33, 8640, 17280, 33, 17280, 8640, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 8640, 8640, 33, 33, 17280, 8640, 17280, 8640, 17280, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 33, 33, 8640, 8640, 17280, 33, 33, 17280, 33, 17280, 8640, 33, 17280, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 17280, 33, 17280, 8640, 8640, 17280, 17280, 33, 8640, 17280, 33, 8640, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 17280, 33, 17280, 8640, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 17280, 33, 8640, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 33, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 8640, 17280, 33, 33, 33, 33, 33, 8640, 33, 33, 8640, 17280, 17280, 33, 33, 17280, 33, 33, 33, 8640, 33, 8640, 17280, 17280, 8640, 8640, 33, 17280, 8640, 17280, 33, 8640, 8640, 33, 33, 8640, 33, 17280, 17280, 33, 17280, 17280, 33, 8640, 17280, 33, 33, 8640, 8640, 33, 33, 17280, 17280, 17280, 17280, 8640, 33, 8640, 8640, 33, 33, 33, 33, 33, 33, 33, 33, 8640, 17280, 8640, 8640, 8640, 17280, 33, 8640, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 33, 33, 8640, 33, 17280, 17280, 17280, 8640, 33, 17280, 17280, 8640, 8640, 17280, 17280, 33, 17280, 17280, 8640, 33, 17280, 8640, 8640, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 33, 33, 17280, 33, 8640, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 33, 17280, 33, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 17280, 17280, 33, 17280, 17280, 33, 17280, 8640, 17280, 8640, 8640, 8640, 33, 8640, 33, 33, 17280, 33, 8640, 33, 33, 8640, 17280, 8640, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 3321984 . Total input tokens: 740234537 . Total output tokens: 664121746
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [256 128]
---Simulation End---
#Simulation results
{
    "duration": 10.04830930614844,
    "estimated_duration": 3600.0925421749002,
    "input_throughput": 4116.760840555075,
    "output_throughput": 3627.3353662489208,
    "total_throughput": 7744.096206803996,
    "itl": 236.38312010649003,
    "ttft": 2247751.274849453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2655166390724295,
    "arrivals": 1105887,
    "finished_requests": 59987,
    "scheduler_time": 90.78604220904947
}
#Debug simulation 
Total elapsed time: 10.048388720024377. Arrivals time: 0.24727546190842986 Scheduler time: 9.701920155901462 Scheduler overhead time: 0.028175215236842632 Adapter cache time: 0.03128543309867382 Engine time: 0.02786082960665226 
