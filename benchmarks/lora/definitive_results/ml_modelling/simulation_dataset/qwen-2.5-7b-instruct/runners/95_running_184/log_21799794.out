INFO 06-01 00:47:09 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:09 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.633251382037997,
    "estimated_duration": 3600.06072201179,
    "input_throughput": 5597.473363932334,
    "output_throughput": 4878.956038881634,
    "total_throughput": 10476.429402813968,
    "itl": 148.16156361601332,
    "ttft": 53573.08078499335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 81595,
    "finished_requests": 80426,
    "scheduler_time": 67.25749381669257
}
#Debug simulation 
Total elapsed time: 5.633371559903026. Arrivals time: 0.1657241270877421 Scheduler time: 5.331013834103942 Scheduler overhead time: 0.037712777964770794 Adapter cache time: 0.04316999576985836 Engine time: 0.03807418933138251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.635679027996957,
    "estimated_duration": 3600.0176701922537,
    "input_throughput": 5383.472186947629,
    "output_throughput": 4708.140501736716,
    "total_throughput": 10091.612688684345,
    "itl": 106.18964965460609,
    "ttft": 250119.07032316353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 81595,
    "finished_requests": 77352,
    "scheduler_time": 61.112042647241076
}
#Debug simulation 
Total elapsed time: 5.6358073353767395. Arrivals time: 0.1880964352749288 Scheduler time: 5.266515105962753 Scheduler overhead time: 0.0505193080753088 Adapter cache time: 0.05496841948479414 Engine time: 0.05184729630127549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.660359574016184,
    "estimated_duration": 3600.056714237658,
    "input_throughput": 5597.479595336651,
    "output_throughput": 4878.961470394345,
    "total_throughput": 10476.441065730996,
    "itl": 148.16091633563613,
    "ttft": 53572.89296106965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 81595,
    "finished_requests": 80426,
    "scheduler_time": 67.25728395188622
}
#Debug simulation 
Total elapsed time: 5.660478585865349. Arrivals time: 0.16855977848172188 Scheduler time: 5.35389314731583 Scheduler overhead time: 0.03804951161146164 Adapter cache time: 0.0438523362390697 Engine time: 0.0383473914116621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.62913733581081,
    "estimated_duration": 3600.063192030087,
    "input_throughput": 5383.5838334467835,
    "output_throughput": 4708.169578112879,
    "total_throughput": 10091.753411559663,
    "itl": 106.19072460877648,
    "ttft": 249974.4886569733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 81595,
    "finished_requests": 77354,
    "scheduler_time": 61.113276998763055
}
#Debug simulation 
Total elapsed time: 5.629229451995343. Arrivals time: 0.18142935633659363 Scheduler time: 5.2669010940007865 Scheduler overhead time: 0.050446308217942715 Adapter cache time: 0.05473212152719498 Engine time: 0.05188216641545296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.6655301307328045,
    "estimated_duration": 3600.0579080592966,
    "input_throughput": 5597.477739146436,
    "output_throughput": 4878.95985247321,
    "total_throughput": 10476.437591619646,
    "itl": 148.15997841361343,
    "ttft": 53574.35231671191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 81595,
    "finished_requests": 80426,
    "scheduler_time": 67.25713864902677
}
#Debug simulation 
Total elapsed time: 5.66560493176803. Arrivals time: 0.164211540017277 Scheduler time: 5.36363958613947 Scheduler overhead time: 0.037743508350104094 Adapter cache time: 0.04397578630596399 Engine time: 0.038304466754198074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [53 53 54]
Adapter prompts. [66, 4320, 66, 66, 135, 66, 66, 66, 4320, 66, 135, 4320, 135, 66, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 66, 4320, 135, 4320, 4320, 4320, 135, 4320, 66, 135, 135, 135, 4320, 66, 66, 4320, 66, 4320, 66, 66, 135, 66, 135, 4320, 66, 66, 135, 66, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 66, 4320, 4320, 4320, 135, 135, 66, 66, 66, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 66, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 135, 66, 66, 135, 135, 4320, 4320, 4320, 66, 4320, 135, 135, 66, 66, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 4320, 135, 4320, 66, 66, 66, 135, 135, 135, 4320, 4320, 135, 4320, 66, 135, 135, 66, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 135, 135, 4320, 135, 66, 66]
Prompts retrieved: 243933 . Total input tokens: 54337243 . Total output tokens: 48869824
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.700101590249687,
    "estimated_duration": 3600.0475521391077,
    "input_throughput": 5383.511389588199,
    "output_throughput": 4708.174476731206,
    "total_throughput": 10091.685866319403,
    "itl": 106.1902473527201,
    "ttft": 250004.68729419587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 81595,
    "finished_requests": 77353,
    "scheduler_time": 61.113534011053396
}
#Debug simulation 
Total elapsed time: 5.700189899187535. Arrivals time: 0.18014169484376907 Scheduler time: 5.3374149752780795 Scheduler overhead time: 0.05068768002092838 Adapter cache time: 0.05561100924387574 Engine time: 0.052270343992859125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.690328823868185,
    "estimated_duration": 3600.0485324928713,
    "input_throughput": 5529.784618268732,
    "output_throughput": 4900.698654688188,
    "total_throughput": 10430.483272956919,
    "itl": 121.120299225014,
    "ttft": 40265.03220424042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 81010,
    "finished_requests": 80104,
    "scheduler_time": 66.59138805424519
}
#Debug simulation 
Total elapsed time: 5.690431013703346. Arrivals time: 0.16746462834998965 Scheduler time: 5.373165833763778 Scheduler overhead time: 0.04382929531857371 Adapter cache time: 0.04074119683355093 Engine time: 0.04467123560607433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.706153235863894,
    "estimated_duration": 3600.0498928837296,
    "input_throughput": 5529.782528667569,
    "output_throughput": 4900.696802806729,
    "total_throughput": 10430.479331474296,
    "itl": 121.12082536700169,
    "ttft": 40265.254405676984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 81010,
    "finished_requests": 80104,
    "scheduler_time": 66.5915883133633
}
#Debug simulation 
Total elapsed time: 5.706244609784335. Arrivals time: 0.16901591094210744 Scheduler time: 5.387932614888996 Scheduler overhead time: 0.04373253043740988 Adapter cache time: 0.0406296057626605 Engine time: 0.04438393656164408 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.703925766982138,
    "estimated_duration": 3600.0514697495105,
    "input_throughput": 5401.996377944325,
    "output_throughput": 4795.928098550583,
    "total_throughput": 10197.924476494907,
    "itl": 104.2942798745978,
    "ttft": 165842.58289583153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 81010,
    "finished_requests": 78205,
    "scheduler_time": 62.934943309885725
}
#Debug simulation 
Total elapsed time: 5.70399966975674. Arrivals time: 0.17747508455067873 Scheduler time: 5.351155721582472 Scheduler overhead time: 0.0514417109079659 Adapter cache time: 0.04670741502195597 Engine time: 0.05321628460660577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.761054596398026,
    "estimated_duration": 3600.0451865484933,
    "input_throughput": 5529.789757746376,
    "output_throughput": 4900.703209482437,
    "total_throughput": 10430.492967228813,
    "itl": 121.11890811236894,
    "ttft": 40264.92216726674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 81010,
    "finished_requests": 80104,
    "scheduler_time": 66.59138234117435
}
#Debug simulation 
Total elapsed time: 5.761140247341245. Arrivals time: 0.17377340188249946 Scheduler time: 5.435705284122378 Scheduler overhead time: 0.044296213425695896 Adapter cache time: 0.04147003684192896 Engine time: 0.04491729196161032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.809079763945192,
    "estimated_duration": 3600.120980301731,
    "input_throughput": 5401.826245953019,
    "output_throughput": 4795.935496187942,
    "total_throughput": 10197.76174214096,
    "itl": 104.2969862148017,
    "ttft": 166055.45179140073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 81010,
    "finished_requests": 78204,
    "scheduler_time": 62.93379155121376
}
#Debug simulation 
Total elapsed time: 5.80922303814441. Arrivals time: 0.18035821290686727 Scheduler time: 5.451582232024521 Scheduler overhead time: 0.051669102162122726 Adapter cache time: 0.04735612077638507 Engine time: 0.05359531566500664 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.690982518251985,
    "estimated_duration": 3600.0475103343206,
    "input_throughput": 5529.786188335964,
    "output_throughput": 4900.700046139556,
    "total_throughput": 10430.48623447552,
    "itl": 121.121543942563,
    "ttft": 40264.93157342603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 81010,
    "finished_requests": 80104,
    "scheduler_time": 66.59141767909891
}
#Debug simulation 
Total elapsed time: 5.691097307018936. Arrivals time: 0.16973075037822127 Scheduler time: 5.370092128869146 Scheduler overhead time: 0.04375076061114669 Adapter cache time: 0.04206897271797061 Engine time: 0.04489387525245547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 135, 33, 33, 33, 4320, 33, 135, 4320, 135, 33, 135, 135, 135, 135, 4320, 4320, 4320, 135, 135, 135, 4320, 4320, 33, 4320, 135, 4320, 4320, 4320, 135, 4320, 33, 135, 135, 135, 4320, 33, 33, 4320, 33, 4320, 33, 33, 135, 33, 135, 4320, 33, 33, 135, 33, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 33, 4320, 4320, 4320, 135, 135, 33, 33, 33, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 33, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 135, 33, 33, 135, 135, 4320, 4320, 4320, 33, 4320, 135, 135, 33, 33, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 4320, 135, 4320, 33, 33, 33, 135, 135, 135, 4320, 4320, 135, 4320, 33, 135, 135, 33, 4320, 4320, 4320, 4320, 4320, 4320, 135, 135, 135, 135, 135, 4320, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 135, 135, 4320, 135, 33, 33]
Prompts retrieved: 242184 . Total input tokens: 53958931 . Total output tokens: 48513936
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.71085487306118,
    "estimated_duration": 3600.0366319949567,
    "input_throughput": 5401.924199094439,
    "output_throughput": 4795.849810681645,
    "total_throughput": 10197.774009776085,
    "itl": 104.2961034417765,
    "ttft": 165953.6864193589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 81010,
    "finished_requests": 78203,
    "scheduler_time": 62.93414049729703
}
#Debug simulation 
Total elapsed time: 5.710928451735526. Arrivals time: 0.17787152528762817 Scheduler time: 5.358344790060073 Scheduler overhead time: 0.05127832107245922 Adapter cache time: 0.04719647066667676 Engine time: 0.05210940958932042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.6740742567926645,
    "estimated_duration": 3600.0674276912487,
    "input_throughput": 5444.697187955297,
    "output_throughput": 4882.543272605474,
    "total_throughput": 10327.24046056077,
    "itl": 93.76301124118419,
    "ttft": 21498.919880569512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 79794,
    "finished_requests": 79319,
    "scheduler_time": 64.53851154339655
}
#Debug simulation 
Total elapsed time: 5.6741683119907975. Arrivals time: 0.17351404018700123 Scheduler time: 5.335670440457761 Scheduler overhead time: 0.05366483749821782 Adapter cache time: 0.031580176670104265 Engine time: 0.05456099472939968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.8044986561872065,
    "estimated_duration": 3600.093880012145,
    "input_throughput": 5444.657182088228,
    "output_throughput": 4882.507397262847,
    "total_throughput": 10327.164579351074,
    "itl": 93.764727529315,
    "ttft": 21588.399289192286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 79794,
    "finished_requests": 79319,
    "scheduler_time": 64.53913520787083
}
#Debug simulation 
Total elapsed time: 5.8046014229767025. Arrivals time: 0.17215602891519666 Scheduler time: 5.466612176038325 Scheduler overhead time: 0.05387248191982508 Adapter cache time: 0.031565872486680746 Engine time: 0.05490648793056607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.66555158700794,
    "estimated_duration": 3600.039698821443,
    "input_throughput": 5444.739125076019,
    "output_throughput": 4882.580879803742,
    "total_throughput": 10327.320004879763,
    "itl": 93.7719849496199,
    "ttft": 21702.170412542535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 79794,
    "finished_requests": 79319,
    "scheduler_time": 64.56420590651025
}
#Debug simulation 
Total elapsed time: 5.665670481976122. Arrivals time: 0.17516195634379983 Scheduler time: 5.32568453066051 Scheduler overhead time: 0.053421888034790754 Adapter cache time: 0.032248100731521845 Engine time: 0.05406516045331955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 5.647016474977136,
    "estimated_duration": 3600.094032759257,
    "input_throughput": 5444.6569510788,
    "output_throughput": 4882.507190104673,
    "total_throughput": 10327.164141183473,
    "itl": 93.76324628473036,
    "ttft": 21588.479490947662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 79794,
    "finished_requests": 79319,
    "scheduler_time": 64.53905354767423
}
#Debug simulation 
Total elapsed time: 5.647093538194895. Arrivals time: 0.17391464672982693 Scheduler time: 5.30891132587567 Scheduler overhead time: 0.053645330015569925 Adapter cache time: 0.031717230565845966 Engine time: 0.05373886227607727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 5.681504112668335,
    "estimated_duration": 3600.0825253911066,
    "input_throughput": 5444.674354477625,
    "output_throughput": 4882.52279663795,
    "total_throughput": 10327.197151115575,
    "itl": 93.77234302723923,
    "ttft": 21926.609677435732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 79794,
    "finished_requests": 79319,
    "scheduler_time": 64.56513752940565
}
#Debug simulation 
Total elapsed time: 5.681595320813358. Arrivals time: 0.1759764882735908 Scheduler time: 5.339448121841997 Scheduler overhead time: 0.0538822109811008 Adapter cache time: 0.03238596813753247 Engine time: 0.05457673594355583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 5.659428956918418,
    "estimated_duration": 3600.0929357835926,
    "input_throughput": 5444.6586101071325,
    "output_throughput": 4882.508677841702,
    "total_throughput": 10327.167287948834,
    "itl": 93.76128640185252,
    "ttft": 21588.35267569819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 79794,
    "finished_requests": 79319,
    "scheduler_time": 64.53879481737212
}
#Debug simulation 
Total elapsed time: 5.659541366156191. Arrivals time: 0.17175927618518472 Scheduler time: 5.323721279390156 Scheduler overhead time: 0.05305921798571944 Adapter cache time: 0.03158178739249706 Engine time: 0.054216662887483835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [53 53 54]
Adapter prompts. [33, 4320, 33, 33, 66, 33, 33, 33, 4320, 33, 66, 4320, 66, 33, 66, 66, 66, 66, 4320, 4320, 4320, 66, 66, 66, 4320, 4320, 33, 4320, 66, 4320, 4320, 4320, 66, 4320, 33, 66, 66, 66, 4320, 33, 33, 4320, 33, 4320, 33, 33, 66, 33, 66, 4320, 33, 33, 66, 33, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 33, 4320, 4320, 4320, 66, 66, 33, 33, 33, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 33, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 66, 33, 33, 66, 66, 4320, 4320, 4320, 33, 4320, 66, 66, 33, 33, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 4320, 66, 4320, 33, 33, 33, 66, 66, 66, 4320, 4320, 66, 4320, 33, 66, 66, 33, 4320, 4320, 4320, 4320, 4320, 4320, 66, 66, 66, 66, 66, 4320, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 66, 66, 4320, 66, 33, 33]
Prompts retrieved: 238527 . Total input tokens: 53140527 . Total output tokens: 47775506
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 5.70182991726324,
    "estimated_duration": 3600.0944971992412,
    "input_throughput": 5444.6562486760195,
    "output_throughput": 4882.506560223551,
    "total_throughput": 10327.16280889957,
    "itl": 93.76962440508375,
    "ttft": 21925.704088089686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 79794,
    "finished_requests": 79319,
    "scheduler_time": 64.56465703402529
}
#Debug simulation 
Total elapsed time: 5.701952029950917. Arrivals time: 0.17513219406828284 Scheduler time: 5.361212273128331 Scheduler overhead time: 0.05334189999848604 Adapter cache time: 0.03240686561912298 Engine time: 0.05444777337834239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.875147514976561,
    "estimated_duration": 3599.823359285655,
    "input_throughput": 2322.330616149717,
    "output_throughput": 2058.3062724139722,
    "total_throughput": 4380.636888563689,
    "itl": 39.12081896697541,
    "ttft": 10459.922890549302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 33938,
    "finished_requests": 33840,
    "scheduler_time": 13.347906486347167
}
#Debug simulation 
Total elapsed time: 2.8752182479947805. Arrivals time: 0.09214197658002377 Scheduler time: 2.3334776535630226 Scheduler overhead time: 0.09221153892576694 Adapter cache time: 0.21971924556419253 Engine time: 0.09301803726702929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.8782073711045086,
    "estimated_duration": 3599.822461936775,
    "input_throughput": 2322.3311950507045,
    "output_throughput": 2058.3067855000613,
    "total_throughput": 4380.637980550766,
    "itl": 39.121724413282685,
    "ttft": 10459.954047837327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 33938,
    "finished_requests": 33840,
    "scheduler_time": 13.34821305777227
}
#Debug simulation 
Total elapsed time: 2.878288622945547. Arrivals time: 0.09170160023495555 Scheduler time: 2.3421875685453415 Scheduler overhead time: 0.0917016607709229 Adapter cache time: 0.2185400240123272 Engine time: 0.08972018305212259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.835600056219846,
    "estimated_duration": 3599.7820306859867,
    "input_throughput": 2322.24421610521,
    "output_throughput": 2058.1948953692913,
    "total_throughput": 4380.439111474501,
    "itl": 39.121526949156696,
    "ttft": 10566.014760047074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 33938,
    "finished_requests": 33839,
    "scheduler_time": 13.348058521080734
}
#Debug simulation 
Total elapsed time: 2.8356718593277037. Arrivals time: 0.09088835772126913 Scheduler time: 2.3000366939231753 Scheduler overhead time: 0.09178517665714025 Adapter cache time: 0.21836707321926951 Engine time: 0.09075045539066195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.87543668737635,
    "estimated_duration": 3599.823350581631,
    "input_throughput": 2322.3306217648874,
    "output_throughput": 2058.3062773907573,
    "total_throughput": 4380.636899155645,
    "itl": 39.12166492760282,
    "ttft": 10459.955932051287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 33938,
    "finished_requests": 33840,
    "scheduler_time": 13.348107892763206
}
#Debug simulation 
Total elapsed time: 2.8755169361829758. Arrivals time: 0.09219053946435452 Scheduler time: 2.334278166294098 Scheduler overhead time: 0.09209372755140066 Adapter cache time: 0.22081864159554243 Engine time: 0.09159717429429293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_160_slots_160_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.8679828606545925,
    "estimated_duration": 3599.822151841585,
    "input_throughput": 2322.3313951005134,
    "output_throughput": 2058.30696280633,
    "total_throughput": 4380.638357906843,
    "itl": 39.12144453882997,
    "ttft": 10459.979041525643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 33938,
    "finished_requests": 33840,
    "scheduler_time": 13.348213057772293
}
#Debug simulation 
Total elapsed time: 2.86806977679953. Arrivals time: 0.09332698490470648 Scheduler time: 2.327816625125706 Scheduler overhead time: 0.09199915546923876 Adapter cache time: 0.21837543230503798 Engine time: 0.09269226435571909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_160_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_160_slots_160_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.851780890021473,
    "estimated_duration": 3599.8224557926665,
    "input_throughput": 2322.3311990144152,
    "output_throughput": 2058.30678901314,
    "total_throughput": 4380.637988027555,
    "itl": 39.12077458065732,
    "ttft": 10459.974369035348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 33938,
    "finished_requests": 33840,
    "scheduler_time": 13.347729348779328
}
#Debug simulation 
Total elapsed time: 2.8518928149715066. Arrivals time: 0.09148896113038063 Scheduler time: 2.315773345064372 Scheduler overhead time: 0.09188988152891397 Adapter cache time: 0.21808634931221604 Engine time: 0.09059914806857705 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_160_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_160_slots_160_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [53 53 54]
Adapter prompts. [270, 1080, 270, 270, 540, 270, 270, 270, 1080, 270, 540, 1080, 540, 270, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 270, 1080, 540, 1080, 1080, 1080, 540, 1080, 270, 540, 540, 540, 1080, 270, 270, 1080, 270, 1080, 270, 270, 540, 270, 540, 1080, 270, 270, 540, 270, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 270, 1080, 1080, 1080, 540, 540, 270, 270, 270, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 270, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 540, 270, 270, 540, 540, 1080, 1080, 1080, 270, 1080, 540, 540, 270, 270, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 1080, 540, 1080, 270, 270, 270, 540, 540, 540, 1080, 1080, 540, 1080, 270, 540, 540, 270, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 540, 540, 1080, 540, 270, 270]
Prompts retrieved: 101250 . Total input tokens: 22534809 . Total output tokens: 20221767
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.858398230280727,
    "estimated_duration": 3599.8224526986724,
    "input_throughput": 2322.3312010104246,
    "output_throughput": 2058.306790782224,
    "total_throughput": 4380.637991792649,
    "itl": 39.122092227843844,
    "ttft": 10460.000427083316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 33938,
    "finished_requests": 33840,
    "scheduler_time": 13.348196878540097
}
#Debug simulation 
Total elapsed time: 2.8584976312704384. Arrivals time: 0.09178015356883407 Scheduler time: 2.3181412373669446 Scheduler overhead time: 0.09186744783073664 Adapter cache time: 0.22264112113043666 Engine time: 0.08992789965122938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.7259343415498734,
    "estimated_duration": 3599.7498551286517,
    "input_throughput": 2145.5210253002356,
    "output_throughput": 1940.1220309932896,
    "total_throughput": 4085.6430562935257,
    "itl": 35.66243622265699,
    "ttft": 9306.020746177835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.040135521770077
}
#Debug simulation 
Total elapsed time: 2.726015248801559. Arrivals time: 0.08687290549278259 Scheduler time: 2.1894699297845364 Scheduler overhead time: 0.09845013543963432 Adapter cache time: 0.20611378643661737 Engine time: 0.09770571021363139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.7340977136045694,
    "estimated_duration": 3599.7508034560933,
    "input_throughput": 2145.5204600787592,
    "output_throughput": 1940.1215198826428,
    "total_throughput": 4085.641979961402,
    "itl": 35.6629148409239,
    "ttft": 9305.998150112348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.040211664258884
}
#Debug simulation 
Total elapsed time: 2.734168561641127. Arrivals time: 0.08669471181929111 Scheduler time: 2.1970688910223544 Scheduler overhead time: 0.09858281025663018 Adapter cache time: 0.2065336429513991 Engine time: 0.09769999608397484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6897801337763667,
    "estimated_duration": 3599.751266720088,
    "input_throughput": 2145.5201839645765,
    "output_throughput": 1940.1212702019345,
    "total_throughput": 4085.641454166511,
    "itl": 35.66279347162522,
    "ttft": 9305.955504415082,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.04018822939665
}
#Debug simulation 
Total elapsed time: 2.689865515101701. Arrivals time: 0.08656206540763378 Scheduler time: 2.15462932176888 Scheduler overhead time: 0.09884464833885431 Adapter cache time: 0.2046013167127967 Engine time: 0.09738533617928624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6924746320582926,
    "estimated_duration": 3599.7512659849654,
    "input_throughput": 2145.5201844027233,
    "output_throughput": 1940.121270598136,
    "total_throughput": 4085.6414550008594,
    "itl": 35.66265709129478,
    "ttft": 9305.941593924003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.040065092061393
}
#Debug simulation 
Total elapsed time: 2.6925488393753767. Arrivals time: 0.08618429722264409 Scheduler time: 2.1599942576140165 Scheduler overhead time: 0.09790090378373861 Adapter cache time: 0.20393427042290568 Engine time: 0.09715574327856302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.6912263561971486,
    "estimated_duration": 3599.7324368131426,
    "input_throughput": 2145.5311292073425,
    "output_throughput": 1940.1161399047962,
    "total_throughput": 4085.6472691121385,
    "itl": 35.66230930956138,
    "ttft": 9420.150706015445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 31534,
    "finished_requests": 31452,
    "scheduler_time": 10.040205951478862
}
#Debug simulation 
Total elapsed time: 2.6913091680034995. Arrivals time: 0.08594803139567375 Scheduler time: 2.1566176996566355 Scheduler overhead time: 0.09880183218047023 Adapter cache time: 0.20502996910363436 Engine time: 0.09757103538140655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.676524532958865,
    "estimated_duration": 3599.7512017159515,
    "input_throughput": 2145.520222708278,
    "output_throughput": 1940.1213052365524,
    "total_throughput": 4085.6415279448306,
    "itl": 35.662353223866695,
    "ttft": 9305.869476763668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.039947792628181
}
#Debug simulation 
Total elapsed time: 2.676616221666336. Arrivals time: 0.08661308651790023 Scheduler time: 2.1420751423574984 Scheduler overhead time: 0.09847532445564866 Adapter cache time: 0.2060336652211845 Engine time: 0.09561928175389767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 540, 135, 135, 135, 1080, 135, 540, 1080, 540, 135, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 135, 1080, 540, 1080, 1080, 1080, 540, 1080, 135, 540, 540, 540, 1080, 135, 135, 1080, 135, 1080, 135, 135, 540, 135, 540, 1080, 135, 135, 540, 135, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 135, 1080, 1080, 1080, 540, 540, 135, 135, 135, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 135, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 540, 135, 135, 540, 540, 1080, 1080, 1080, 135, 1080, 540, 540, 135, 135, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 1080, 540, 1080, 135, 135, 135, 540, 540, 540, 1080, 1080, 540, 1080, 135, 540, 540, 135, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 540, 540, 1080, 540, 135, 135]
Prompts retrieved: 94095 . Total input tokens: 20974801 . Total output tokens: 18811600
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6875401069410145,
    "estimated_duration": 3599.7498206730793,
    "input_throughput": 2145.521045836428,
    "output_throughput": 1940.1220495634732,
    "total_throughput": 4085.6430953999015,
    "itl": 35.66289250139002,
    "ttft": 9305.98720147741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 31534,
    "finished_requests": 31453,
    "scheduler_time": 10.040330631664098
}
#Debug simulation 
Total elapsed time: 2.6876329937949777. Arrivals time: 0.09150577615946531 Scheduler time: 2.148689397610724 Scheduler overhead time: 0.09822557168081403 Adapter cache time: 0.2042918438091874 Engine time: 0.09735262906178832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5821181046776474,
    "estimated_duration": 3599.991232843471,
    "input_throughput": 2077.347559008671,
    "output_throughput": 1833.1230753547052,
    "total_throughput": 3910.4706343633757,
    "itl": 33.19905191216698,
    "ttft": 7644.544565027025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.239613773696663
}
#Debug simulation 
Total elapsed time: 2.5822004936635494. Arrivals time: 0.08375517930835485 Scheduler time: 2.0474464599974453 Scheduler overhead time: 0.10352006834000349 Adapter cache time: 0.19462834019213915 Engine time: 0.1026081251911819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6109254457987845,
    "estimated_duration": 3599.992242144953,
    "input_throughput": 2077.346976599091,
    "output_throughput": 1833.122561416421,
    "total_throughput": 3910.4695380155117,
    "itl": 33.199659809475726,
    "ttft": 7644.520228665764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.239940569161994
}
#Debug simulation 
Total elapsed time: 2.6109984908252954. Arrivals time: 0.08324587810784578 Scheduler time: 2.0761849670670927 Scheduler overhead time: 0.10439511248841882 Adapter cache time: 0.19549752585589886 Engine time: 0.10142311127856374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.606429701205343,
    "estimated_duration": 3599.9912454808536,
    "input_throughput": 2077.347551716365,
    "output_throughput": 1833.1230689197234,
    "total_throughput": 3910.470620636089,
    "itl": 33.19965771968557,
    "ttft": 7644.510562795193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.2399486587780695
}
#Debug simulation 
Total elapsed time: 2.606504005845636. Arrivals time: 0.08439117949455976 Scheduler time: 2.070063413120806 Scheduler overhead time: 0.10437931260094047 Adapter cache time: 0.19430702552199364 Engine time: 0.10327143780887127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.638970660045743,
    "estimated_duration": 3599.980939854367,
    "input_throughput": 2077.3534985167257,
    "output_throughput": 1833.1283165812995,
    "total_throughput": 3910.481815098025,
    "itl": 33.199440643294245,
    "ttft": 7644.485355696017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.239673153211293
}
#Debug simulation 
Total elapsed time: 2.639041061978787. Arrivals time: 0.08431279426440597 Scheduler time: 2.101803055498749 Scheduler overhead time: 0.10441409097984433 Adapter cache time: 0.19480202673003078 Engine time: 0.10354178445413709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.6025238037109375,
    "estimated_duration": 3599.991443777944,
    "input_throughput": 2077.347437290545,
    "output_throughput": 1833.1229679464361,
    "total_throughput": 3910.4704052369807,
    "itl": 33.19975251345781,
    "ttft": 7644.518238096022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978161,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.239902748161611
}
#Debug simulation 
Total elapsed time: 2.602609734982252. Arrivals time: 0.08415778493508697 Scheduler time: 2.060251482296735 Scheduler overhead time: 0.10800445079803467 Adapter cache time: 0.1951806782744825 Engine time: 0.10427136765792966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5911737121641636,
    "estimated_duration": 3599.991285161915,
    "input_throughput": 2077.347528818711,
    "output_throughput": 1833.1230487140442,
    "total_throughput": 3910.470577532755,
    "itl": 33.199270390765854,
    "ttft": 7644.473917458529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.239649718349021
}
#Debug simulation 
Total elapsed time: 2.5912444521673024. Arrivals time: 0.0839797374792397 Scheduler time: 2.0508428127504885 Scheduler overhead time: 0.10429602628573775 Adapter cache time: 0.19862401206046343 Engine time: 0.10318987164646387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 540, 66, 66, 66, 1080, 66, 540, 1080, 540, 66, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 66, 1080, 540, 1080, 1080, 1080, 540, 1080, 66, 540, 540, 540, 1080, 66, 66, 1080, 66, 1080, 66, 66, 540, 66, 540, 1080, 66, 66, 540, 66, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 66, 1080, 1080, 1080, 540, 540, 66, 66, 66, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 66, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 540, 66, 66, 540, 540, 1080, 1080, 1080, 66, 1080, 540, 540, 66, 66, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 1080, 540, 1080, 66, 66, 66, 540, 540, 540, 1080, 1080, 540, 1080, 66, 540, 540, 66, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 540, 540, 1080, 540, 66, 66]
Prompts retrieved: 90438 . Total input tokens: 20159241 . Total output tokens: 18070510
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.6132457521744072,
    "estimated_duration": 3599.9912926347197,
    "input_throughput": 2077.347524506586,
    "output_throughput": 1833.1230449088766,
    "total_throughput": 3910.4705694154627,
    "itl": 33.200169727042926,
    "ttft": 7644.541480878939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 30357,
    "finished_requests": 30293,
    "scheduler_time": 7.240113078179766
}
#Debug simulation 
Total elapsed time: 2.6133718071505427. Arrivals time: 0.08355036051943898 Scheduler time: 2.0734388544224203 Scheduler overhead time: 0.10475979978218675 Adapter cache time: 0.19907071813941002 Engine time: 0.10207594512030482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.586965173948556,
    "estimated_duration": 3600.0058458658627,
    "input_throughput": 2033.3078093209135,
    "output_throughput": 1803.982903932757,
    "total_throughput": 3837.2907132536707,
    "itl": 32.46742293222294,
    "ttft": 5997.022688870005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.376931735859385
}
#Debug simulation 
Total elapsed time: 2.5870356019586325. Arrivals time: 0.08196765230968595 Scheduler time: 2.044509235303849 Scheduler overhead time: 0.1064298995770514 Adapter cache time: 0.18809802317991853 Engine time: 0.11465869192034006 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.5980890169739723,
    "estimated_duration": 3600.0254489710223,
    "input_throughput": 2033.2967374139582,
    "output_throughput": 1803.973080761484,
    "total_throughput": 3837.269818175442,
    "itl": 32.46794355447023,
    "ttft": 5996.970341633233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.377116963043282
}
#Debug simulation 
Total elapsed time: 2.598177050240338. Arrivals time: 0.08305554371327162 Scheduler time: 2.061336040496826 Scheduler overhead time: 0.10621298989281058 Adapter cache time: 0.19047167943790555 Engine time: 0.10589295206591487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.5832703397609293,
    "estimated_duration": 3600.0063986245,
    "input_throughput": 2033.3074971191202,
    "output_throughput": 1803.9826269423793,
    "total_throughput": 3837.2901240614997,
    "itl": 32.46821915352337,
    "ttft": 5996.976922851638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.377198818312108
}
#Debug simulation 
Total elapsed time: 2.583342923782766. Arrivals time: 0.0824192981235683 Scheduler time: 2.0516298445872962 Scheduler overhead time: 0.10694233886897564 Adapter cache time: 0.18666392704471946 Engine time: 0.10442517697811127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.52440233156085,
    "estimated_duration": 3600.006634899683,
    "input_throughput": 2033.3073636693382,
    "output_throughput": 1803.9825085436185,
    "total_throughput": 3837.2898722129567,
    "itl": 32.46803202483432,
    "ttft": 5997.026612929991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.377116379301282
}
#Debug simulation 
Total elapsed time: 2.5244808518327773. Arrivals time: 0.08076641662046313 Scheduler time: 1.9974497272633016 Scheduler overhead time: 0.1058782059699297 Adapter cache time: 0.18606908805668354 Engine time: 0.10318577382713556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.551330972928554,
    "estimated_duration": 3600.0198257061884,
    "input_throughput": 2033.2999134425897,
    "output_throughput": 1803.9758985844067,
    "total_throughput": 3837.2758120269964,
    "itl": 32.468330676719845,
    "ttft": 5996.921959670263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.377344306279568
}
#Debug simulation 
Total elapsed time: 2.5514037180691957. Arrivals time: 0.08216905687004328 Scheduler time: 2.017708234023303 Scheduler overhead time: 0.10624475684016943 Adapter cache time: 0.18969002179801464 Engine time: 0.10461070202291012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.5673269899562,
    "estimated_duration": 3600.0073772269457,
    "input_throughput": 2033.306944398117,
    "output_throughput": 1803.982136559548,
    "total_throughput": 3837.2890809576647,
    "itl": 32.46768686503489,
    "ttft": 5997.049303111403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.376985152349943
}
#Debug simulation 
Total elapsed time: 2.567411999683827. Arrivals time: 0.08214548649266362 Scheduler time: 2.036135491449386 Scheduler overhead time: 0.1055746553465724 Adapter cache time: 0.18883405858650804 Engine time: 0.10386909963563085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 540, 33, 33, 33, 1080, 33, 540, 1080, 540, 33, 540, 540, 540, 540, 1080, 1080, 1080, 540, 540, 540, 1080, 1080, 33, 1080, 540, 1080, 1080, 1080, 540, 1080, 33, 540, 540, 540, 1080, 33, 33, 1080, 33, 1080, 33, 33, 540, 33, 540, 1080, 33, 33, 540, 33, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 33, 1080, 1080, 1080, 540, 540, 33, 33, 33, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 33, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 540, 33, 33, 540, 540, 1080, 1080, 1080, 33, 1080, 540, 540, 33, 33, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 1080, 540, 1080, 33, 33, 33, 540, 540, 540, 1080, 1080, 540, 1080, 33, 540, 540, 33, 1080, 1080, 1080, 1080, 1080, 1080, 540, 540, 540, 540, 540, 1080, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 540, 540, 1080, 540, 33, 33]
Prompts retrieved: 88689 . Total input tokens: 19774958 . Total output tokens: 17728710
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.548273461870849,
    "estimated_duration": 3600.021824514371,
    "input_throughput": 2033.2987845115158,
    "output_throughput": 1803.9748969788711,
    "total_throughput": 3837.273681490387,
    "itl": 32.46823215426079,
    "ttft": 5996.908309457401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 29680,
    "finished_requests": 29631,
    "scheduler_time": 6.377342638307556
}
#Debug simulation 
Total elapsed time: 2.5483434828929603. Arrivals time: 0.08186216419562697 Scheduler time: 2.0189747158437967 Scheduler overhead time: 0.10593287227675319 Adapter cache time: 0.1867366610094905 Engine time: 0.10370758082717657 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.3806375889107585,
    "estimated_duration": 3599.981266153424,
    "input_throughput": 1820.0141932962954,
    "output_throughput": 1617.051192663597,
    "total_throughput": 3437.0653859598924,
    "itl": 29.645141509085924,
    "ttft": 8132.130015724728,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.534602091386732
}
#Debug simulation 
Total elapsed time: 2.380717643070966. Arrivals time: 0.07672880031168461 Scheduler time: 1.8403562125749886 Scheduler overhead time: 0.11352838110178709 Adapter cache time: 0.1832603202201426 Engine time: 0.11199722858145833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.412164052017033,
    "estimated_duration": 3599.9497115299428,
    "input_throughput": 1820.0301462587538,
    "output_throughput": 1617.0653665953523,
    "total_throughput": 3437.0955128541063,
    "itl": 29.645243550660904,
    "ttft": 8132.210706576535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5347823146545534
}
#Debug simulation 
Total elapsed time: 2.41223620204255. Arrivals time: 0.07666930789127946 Scheduler time: 1.8717297087423503 Scheduler overhead time: 0.11370860738679767 Adapter cache time: 0.1844955449923873 Engine time: 0.11081556277349591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.379998054821044,
    "estimated_duration": 3599.9496955047816,
    "input_throughput": 1820.0301543606104,
    "output_throughput": 1617.065373793712,
    "total_throughput": 3437.0955281543224,
    "itl": 29.6452553088966,
    "ttft": 8132.17483680606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5347394897381177
}
#Debug simulation 
Total elapsed time: 2.380075430031866. Arrivals time: 0.0762680871412158 Scheduler time: 1.8400881388224661 Scheduler overhead time: 0.11369899241253734 Adapter cache time: 0.18458873638883233 Engine time: 0.11052209930494428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3775748731568456,
    "estimated_duration": 3599.9511426230956,
    "input_throughput": 1820.0294227398567,
    "output_throughput": 1617.064723761302,
    "total_throughput": 3437.094146501159,
    "itl": 29.645108155604376,
    "ttft": 8132.172497965632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5347613817503474
}
#Debug simulation 
Total elapsed time: 2.3776590549387038. Arrivals time: 0.07734767068177462 Scheduler time: 1.8347815740853548 Scheduler overhead time: 0.11318433796986938 Adapter cache time: 0.18517559161409736 Engine time: 0.11242061527445912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.3844794360920787,
    "estimated_duration": 3599.9658408870782,
    "input_throughput": 1820.0219917602046,
    "output_throughput": 1617.0581214641588,
    "total_throughput": 3437.0801132243637,
    "itl": 29.808771650566243,
    "ttft": 8132.446684527311,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.607826464636891
}
#Debug simulation 
Total elapsed time: 2.3845591000281274. Arrivals time: 0.07606290932744741 Scheduler time: 1.8430229290388525 Scheduler overhead time: 0.11347170313820243 Adapter cache time: 0.1822906220331788 Engine time: 0.11483293399214745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.431227983906865,
    "estimated_duration": 3599.9511160769694,
    "input_throughput": 1820.0294361607973,
    "output_throughput": 1617.0647356855764,
    "total_throughput": 3437.0941718463737,
    "itl": 29.644923234240366,
    "ttft": 8132.143951700501,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.5346472931391832
}
#Debug simulation 
Total elapsed time: 2.4313000608235598. Arrivals time: 0.07757385168224573 Scheduler time: 1.8880578032694757 Scheduler overhead time: 0.11452261032536626 Adapter cache time: 0.18330674292519689 Engine time: 0.11216373043134809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [53 53 54]
Adapter prompts. [135, 1080, 135, 135, 270, 135, 135, 135, 1080, 135, 270, 1080, 270, 135, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 135, 1080, 270, 1080, 1080, 1080, 270, 1080, 135, 270, 270, 270, 1080, 135, 135, 1080, 135, 1080, 135, 135, 270, 135, 270, 1080, 135, 135, 270, 135, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 135, 1080, 1080, 1080, 270, 270, 135, 135, 135, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 135, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 270, 135, 135, 270, 270, 1080, 1080, 1080, 135, 1080, 270, 270, 135, 135, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 1080, 270, 1080, 135, 135, 135, 270, 270, 270, 1080, 1080, 270, 1080, 135, 270, 270, 135, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 270, 270, 1080, 270, 135, 135]
Prompts retrieved: 79785 . Total input tokens: 17763858 . Total output tokens: 15946259
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.3769744667224586,
    "estimated_duration": 3599.9511593225016,
    "input_throughput": 1820.0294142971281,
    "output_throughput": 1617.0647162600835,
    "total_throughput": 3437.094130557212,
    "itl": 29.645722859053443,
    "ttft": 8132.171919786069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 26722,
    "finished_requests": 26662,
    "scheduler_time": 2.534946025192234
}
#Debug simulation 
Total elapsed time: 2.3770576301030815. Arrivals time: 0.07622600952163339 Scheduler time: 1.8362918924540281 Scheduler overhead time: 0.11431291326880455 Adapter cache time: 0.18373253615573049 Engine time: 0.11162589630112052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.338767191860825,
    "estimated_duration": 3600.015078922917,
    "input_throughput": 1741.8727040099348,
    "output_throughput": 1554.390989293914,
    "total_throughput": 3296.2636933038484,
    "itl": 28.58385917221835,
    "ttft": 4985.258012370711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5661948112925168
}
#Debug simulation 
Total elapsed time: 2.338863260578364. Arrivals time: 0.07391370600089431 Scheduler time: 1.7998046036809683 Scheduler overhead time: 0.11699940264225006 Adapter cache time: 0.17550159571692348 Engine time: 0.11571906926110387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.309418860822916,
    "estimated_duration": 3600.0049322233376,
    "input_throughput": 1741.8776135196065,
    "output_throughput": 1554.3953703819107,
    "total_throughput": 3296.272983901517,
    "itl": 28.584040893811274,
    "ttft": 4985.279020021974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5663517248201246
}
#Debug simulation 
Total elapsed time: 2.30953525705263. Arrivals time: 0.07440328178927302 Scheduler time: 1.774181964341551 Scheduler overhead time: 0.11689510801807046 Adapter cache time: 0.1741613494232297 Engine time: 0.11331218527629972 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.323995277751237,
    "estimated_duration": 3600.004821487533,
    "input_throughput": 1741.8776670995956,
    "output_throughput": 1554.395418194964,
    "total_throughput": 3296.2730852945597,
    "itl": 28.583933014980904,
    "ttft": 4985.232033773085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.566304021109639
}
#Debug simulation 
Total elapsed time: 2.3240899280644953. Arrivals time: 0.07418653229251504 Scheduler time: 1.7886631707660854 Scheduler overhead time: 0.11670581391081214 Adapter cache time: 0.1728652771562338 Engine time: 0.1148845013231039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2759363120421767,
    "estimated_duration": 3600.0048236246203,
    "input_throughput": 1741.8776660655567,
    "output_throughput": 1554.395417272221,
    "total_throughput": 3296.2730833377777,
    "itl": 28.5837426638354,
    "ttft": 4985.228667024583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5662351342509342
}
#Debug simulation 
Total elapsed time: 2.276043567340821. Arrivals time: 0.07271861424669623 Scheduler time: 1.747332246042788 Scheduler overhead time: 0.11632313812151551 Adapter cache time: 0.17226709984242916 Engine time: 0.11129367304965854 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.2982226009480655,
    "estimated_duration": 3600.013682439624,
    "input_throughput": 1741.873379700736,
    "output_throughput": 1554.3915922585797,
    "total_throughput": 3296.2649719593155,
    "itl": 28.584012776642822,
    "ttft": 4985.2631603966265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.5662597784651824
}
#Debug simulation 
Total elapsed time: 2.298386925831437. Arrivals time: 0.07314386265352368 Scheduler time: 1.7656099339947104 Scheduler overhead time: 0.11692280834540725 Adapter cache time: 0.17356426734477282 Engine time: 0.11216083215549588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.3220307771116495,
    "estimated_duration": 3600.0151458680903,
    "input_throughput": 1741.8726716184126,
    "output_throughput": 1554.3909603887648,
    "total_throughput": 3296.2636320071774,
    "itl": 28.58359786213982,
    "ttft": 4985.198954477326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.566152111498084
}
#Debug simulation 
Total elapsed time: 2.3221272761002183. Arrivals time: 0.07365366676822305 Scheduler time: 1.7855382622219622 Scheduler overhead time: 0.11694714846089482 Adapter cache time: 0.17371171806007624 Engine time: 0.1155611788854003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 270, 66, 66, 66, 1080, 66, 270, 1080, 270, 66, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 66, 1080, 270, 1080, 1080, 1080, 270, 1080, 66, 270, 270, 270, 1080, 66, 66, 1080, 66, 1080, 66, 66, 270, 66, 270, 1080, 66, 66, 270, 66, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 66, 1080, 1080, 1080, 270, 270, 66, 66, 66, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 66, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 270, 66, 66, 270, 270, 1080, 1080, 1080, 66, 1080, 270, 270, 66, 66, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 1080, 270, 1080, 66, 66, 66, 270, 270, 270, 1080, 1080, 270, 1080, 66, 270, 270, 66, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 270, 270, 1080, 270, 66, 66]
Prompts retrieved: 76128 . Total input tokens: 16944546 . Total output tokens: 15219954
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.290786098688841,
    "estimated_duration": 3600.019964225891,
    "input_throughput": 1741.8703402519595,
    "output_throughput": 1554.3888799525773,
    "total_throughput": 3296.259220204537,
    "itl": 28.743222329161302,
    "ttft": 4985.521506789282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 25517,
    "finished_requests": 25481,
    "scheduler_time": 1.621076898690744
}
#Debug simulation 
Total elapsed time: 2.2908941586501896. Arrivals time: 0.07361644227057695 Scheduler time: 1.7593689654022455 Scheduler overhead time: 0.11577671766281128 Adapter cache time: 0.17211724910885096 Engine time: 0.11383583024144173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.2657760260626674,
    "estimated_duration": 3599.9311378143175,
    "input_throughput": 1709.489644220362,
    "output_throughput": 1527.5353303948773,
    "total_throughput": 3237.024974615239,
    "itl": 28.252369778104857,
    "ttft": 7694.80604949729,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 24947,
    "finished_requests": 24894,
    "scheduler_time": 1.3061385669459638
}
#Debug simulation 
Total elapsed time: 2.2658481020480394. Arrivals time: 0.07248882111161947 Scheduler time: 1.7366445064544678 Scheduler overhead time: 0.11812769155949354 Adapter cache time: 0.1657378119416535 Engine time: 0.11527746263891459 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2641068547964096,
    "estimated_duration": 3599.9310468309063,
    "input_throughput": 1709.4896874254114,
    "output_throughput": 1527.5353690012764,
    "total_throughput": 3237.025056426688,
    "itl": 28.252597740433437,
    "ttft": 7694.898777607379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 24947,
    "finished_requests": 24894,
    "scheduler_time": 1.3063307995159168
}
#Debug simulation 
Total elapsed time: 2.2641884479671717. Arrivals time: 0.07176063256338239 Scheduler time: 1.73409269656986 Scheduler overhead time: 0.11918656481429935 Adapter cache time: 0.16604900732636452 Engine time: 0.11552248802036047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2577314651571214,
    "estimated_duration": 3599.9231272602156,
    "input_throughput": 1709.3787235071682,
    "output_throughput": 1527.4328938753858,
    "total_throughput": 3236.811617382554,
    "itl": 28.252360790958374,
    "ttft": 7839.170277325757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3063471038700902
}
#Debug simulation 
Total elapsed time: 2.257805381435901. Arrivals time: 0.07140533439815044 Scheduler time: 1.7293608337640762 Scheduler overhead time: 0.11829821486026049 Adapter cache time: 0.16647004103288054 Engine time: 0.11519228620454669 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2627087817527354,
    "estimated_duration": 3599.9231388494813,
    "input_throughput": 1709.3787180041495,
    "output_throughput": 1527.432888958107,
    "total_throughput": 3236.8116069622565,
    "itl": 28.25209769537921,
    "ttft": 7839.193655907541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3062443156970411
}
#Debug simulation 
Total elapsed time: 2.2628317098133266. Arrivals time: 0.07349381595849991 Scheduler time: 1.7306139688007534 Scheduler overhead time: 0.11783337406814098 Adapter cache time: 0.16785419452935457 Engine time: 0.11541811609640718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.246448769234121,
    "estimated_duration": 3599.9310846848425,
    "input_throughput": 1709.4896694498134,
    "output_throughput": 1527.5353529389618,
    "total_throughput": 3237.025022388775,
    "itl": 28.252820267729497,
    "ttft": 7694.838134886161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 24947,
    "finished_requests": 24894,
    "scheduler_time": 1.3063311748819288
}
#Debug simulation 
Total elapsed time: 2.2465183110907674. Arrivals time: 0.0716829146258533 Scheduler time: 1.7192903985269368 Scheduler overhead time: 0.11756172170862556 Adapter cache time: 0.16643059253692627 Engine time: 0.11429383279755712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.253978041931987,
    "estimated_duration": 3599.922441430802,
    "input_throughput": 1709.3790491647974,
    "output_throughput": 1527.4331848701013,
    "total_throughput": 3236.8122340348987,
    "itl": 28.2518966090743,
    "ttft": 7839.140051730876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 24947,
    "finished_requests": 24893,
    "scheduler_time": 1.3062609535492067
}
#Debug simulation 
Total elapsed time: 2.254069796297699. Arrivals time: 0.07242333330214024 Scheduler time: 1.725537583231926 Scheduler overhead time: 0.11838015727698803 Adapter cache time: 0.16589036025106907 Engine time: 0.11490168841555715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 270, 33, 33, 33, 1080, 33, 270, 1080, 270, 33, 270, 270, 270, 270, 1080, 1080, 1080, 270, 270, 270, 1080, 1080, 33, 1080, 270, 1080, 1080, 1080, 270, 1080, 33, 270, 270, 270, 1080, 33, 33, 1080, 33, 1080, 33, 33, 270, 33, 270, 1080, 33, 33, 270, 33, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 33, 1080, 1080, 1080, 270, 270, 33, 33, 33, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 33, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 270, 33, 33, 270, 270, 1080, 1080, 1080, 33, 1080, 270, 270, 33, 33, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 1080, 270, 1080, 33, 33, 33, 270, 270, 270, 1080, 1080, 270, 1080, 33, 270, 270, 33, 1080, 1080, 1080, 1080, 1080, 1080, 270, 270, 270, 270, 270, 1080, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 270, 270, 1080, 270, 33, 33]
Prompts retrieved: 74379 . Total input tokens: 16563634 . Total output tokens: 14864978
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.2764070690609515,
    "estimated_duration": 3599.954262464653,
    "input_throughput": 1709.478663150217,
    "output_throughput": 1527.5255181256607,
    "total_throughput": 3237.0041812758777,
    "itl": 28.252933023851966,
    "ttft": 7694.784785060048,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 24947,
    "finished_requests": 24894,
    "scheduler_time": 1.3065470925581357
}
#Debug simulation 
Total elapsed time: 2.2764870887622237. Arrivals time: 0.07199367741122842 Scheduler time: 1.746599887497723 Scheduler overhead time: 0.11830035503953695 Adapter cache time: 0.16710536694154143 Engine time: 0.11470279842615128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1025732927955687,
    "estimated_duration": 3599.249444436454,
    "input_throughput": 1574.1856982871957,
    "output_throughput": 1407.4012035565197,
    "total_throughput": 2981.586901843715,
    "itl": 26.729563266074607,
    "ttft": 7040.887550203151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39336915886509927
}
#Debug simulation 
Total elapsed time: 2.102647200692445. Arrivals time: 0.06735632894560695 Scheduler time: 1.578041402157396 Scheduler overhead time: 0.12188610807061195 Adapter cache time: 0.1568460469134152 Engine time: 0.1185452756471932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0976571612991393,
    "estimated_duration": 3599.238078235391,
    "input_throughput": 1574.1906694813117,
    "output_throughput": 1407.4056480541349,
    "total_throughput": 2981.596317535447,
    "itl": 26.72999752365127,
    "ttft": 7041.020252130778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39359483412940055
}
#Debug simulation 
Total elapsed time: 2.097784899175167. Arrivals time: 0.06699796114116907 Scheduler time: 1.5748937502503395 Scheduler overhead time: 0.12118391133844852 Adapter cache time: 0.15609100461006165 Engine time: 0.1189750274643302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.1337737548165023,
    "estimated_duration": 3599.238066921651,
    "input_throughput": 1574.1906744295768,
    "output_throughput": 1407.4056524781329,
    "total_throughput": 2981.5963269077097,
    "itl": 26.729984467432555,
    "ttft": 7041.031975928574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.3935665204731119
}
#Debug simulation 
Total elapsed time: 2.1338475509546697. Arrivals time: 0.06779884081333876 Scheduler time: 1.6089654914103448 Scheduler overhead time: 0.12195596750825644 Adapter cache time: 0.15553658874705434 Engine time: 0.11986833810806274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1269826819188893,
    "estimated_duration": 3599.2375701801284,
    "input_throughput": 1574.1908916883315,
    "output_throughput": 1407.4058467183888,
    "total_throughput": 2981.5967384067203,
    "itl": 26.729703392217285,
    "ttft": 7041.044880753002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39360851140353836
}
#Debug simulation 
Total elapsed time: 2.1270777876488864. Arrivals time: 0.06786848092451692 Scheduler time: 1.60029789339751 Scheduler overhead time: 0.12394943227991462 Adapter cache time: 0.15613577887415886 Engine time: 0.1190812410786748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.1441627857275307,
    "estimated_duration": 3599.2375728069624,
    "input_throughput": 1574.1908905394387,
    "output_throughput": 1407.405845691221,
    "total_throughput": 2981.5967362306596,
    "itl": 26.73023813287076,
    "ttft": 7041.001563699065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39359329127938697
}
#Debug simulation 
Total elapsed time: 2.144236212130636. Arrivals time: 0.06780906952917576 Scheduler time: 1.6153143011033535 Scheduler overhead time: 0.12234890041872859 Adapter cache time: 0.1572196795605123 Engine time: 0.12191498000174761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1404711580835283,
    "estimated_duration": 3599.2382192360733,
    "input_throughput": 1574.1906078121626,
    "output_throughput": 1407.4055929188135,
    "total_throughput": 2981.596200730976,
    "itl": 26.729390027321042,
    "ttft": 7041.097643537162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.39347444899617656
}
#Debug simulation 
Total elapsed time: 2.140546570997685. Arrivals time: 0.06822724547237158 Scheduler time: 1.6011500116437674 Scheduler overhead time: 0.12199676828458905 Adapter cache time: 0.1694292793981731 Engine time: 0.11974083306267858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [53 53 54]
Adapter prompts. [66, 1080, 66, 66, 135, 66, 66, 66, 1080, 66, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 66, 1080, 135, 1080, 1080, 1080, 135, 1080, 66, 135, 135, 135, 1080, 66, 66, 1080, 66, 1080, 66, 66, 135, 66, 135, 1080, 66, 66, 135, 66, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 66, 1080, 1080, 1080, 135, 135, 66, 66, 66, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 66, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 135, 66, 66, 135, 135, 1080, 1080, 1080, 66, 1080, 135, 135, 66, 66, 66, 66, 1080, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 1080, 135, 1080, 66, 66, 66, 135, 135, 135, 1080, 1080, 135, 1080, 66, 135, 135, 66, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 135, 135, 1080, 135, 66, 66]
Prompts retrieved: 68973 . Total input tokens: 15331429 . Total output tokens: 13800853
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.159947842825204,
    "estimated_duration": 3599.2376130516946,
    "input_throughput": 1574.190872937686,
    "output_throughput": 1407.4058299543683,
    "total_throughput": 2981.5967028920545,
    "itl": 26.73003326217428,
    "ttft": 7041.035604673775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 23153,
    "finished_requests": 23108,
    "scheduler_time": 0.3935698564171483
}
#Debug simulation 
Total elapsed time: 2.1600610236637294. Arrivals time: 0.06799231842160225 Scheduler time: 1.6317461696453393 Scheduler overhead time: 0.12259471556171775 Adapter cache time: 0.15677548060193658 Engine time: 0.12132972944527864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.076999543234706,
    "estimated_duration": 3600.021186613693,
    "input_throughput": 1544.0353575331533,
    "output_throughput": 1353.4656457350604,
    "total_throughput": 2897.5010032682135,
    "itl": 26.048446749171983,
    "ttft": 7224.769309204878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.19943628424817514
}
#Debug simulation 
Total elapsed time: 2.0770716462284327. Arrivals time: 0.0670543578453362 Scheduler time: 1.5527195381000638 Scheduler overhead time: 0.12510594446212053 Adapter cache time: 0.14951587514951825 Engine time: 0.12144132843241096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0735353380441666,
    "estimated_duration": 3600.0213762609355,
    "input_throughput": 1544.0352761941786,
    "output_throughput": 1353.4655744351983,
    "total_throughput": 2897.5008506293766,
    "itl": 26.04900538650582,
    "ttft": 7224.767300214768,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.1994105976719174
}
#Debug simulation 
Total elapsed time: 2.073645723052323. Arrivals time: 0.06607832247391343 Scheduler time: 1.5519783208146691 Scheduler overhead time: 0.12409032741561532 Adapter cache time: 0.1493737450800836 Engine time: 0.12065605027601123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0804034676402807,
    "estimated_duration": 3600.0213730933638,
    "input_throughput": 1544.0352775527379,
    "output_throughput": 1353.46557562608,
    "total_throughput": 2897.5008531788176,
    "itl": 26.048943927718295,
    "ttft": 7224.766465588083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.19948257023065077
}
#Debug simulation 
Total elapsed time: 2.0804771766997874. Arrivals time: 0.0664155283011496 Scheduler time: 1.5562516362406313 Scheduler overhead time: 0.12419833661988378 Adapter cache time: 0.14968014415353537 Engine time: 0.12344257114455104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.070828521158546,
    "estimated_duration": 3600.0212462555955,
    "input_throughput": 1544.035331952969,
    "output_throughput": 1353.4656233120631,
    "total_throughput": 2897.500955265032,
    "itl": 26.048788247763795,
    "ttft": 7224.737265969858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.19938991501171366
}
#Debug simulation 
Total elapsed time: 2.0709250969812274. Arrivals time: 0.06804822571575642 Scheduler time: 1.5480264965444803 Scheduler overhead time: 0.12346347561106086 Adapter cache time: 0.14890264021232724 Engine time: 0.12193073565140367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.0936707356013358,
    "estimated_duration": 3600.0211489870208,
    "input_throughput": 1544.0353736710897,
    "output_throughput": 1353.4656598812016,
    "total_throughput": 2897.501033552291,
    "itl": 26.048876415172256,
    "ttft": 7224.703930693609,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978161,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.19952789710511357
}
#Debug simulation 
Total elapsed time: 2.0937654487788677. Arrivals time: 0.06725111464038491 Scheduler time: 1.566210852470249 Scheduler overhead time: 0.12492162548005581 Adapter cache time: 0.15003480622544885 Engine time: 0.12384457746520638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.1059766919352114,
    "estimated_duration": 3600.0212301977363,
    "input_throughput": 1544.0353388401236,
    "output_throughput": 1353.4656293491832,
    "total_throughput": 2897.5009681893066,
    "itl": 26.0487292923563,
    "ttft": 7224.776702590996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.19940288342184645
}
#Debug simulation 
Total elapsed time: 2.106086765881628. Arrivals time: 0.0666794846765697 Scheduler time: 1.581254922784865 Scheduler overhead time: 0.12395653780549765 Adapter cache time: 0.1510057793930173 Engine time: 0.12262505711987615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 135, 33, 33, 33, 1080, 33, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 1080, 1080, 135, 135, 135, 1080, 1080, 33, 1080, 135, 1080, 1080, 1080, 135, 1080, 33, 135, 135, 135, 1080, 33, 33, 1080, 33, 1080, 33, 33, 135, 33, 135, 1080, 33, 33, 135, 33, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 33, 1080, 1080, 1080, 135, 135, 33, 33, 33, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 33, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 135, 33, 33, 135, 135, 1080, 1080, 1080, 33, 1080, 135, 135, 33, 33, 33, 33, 1080, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 1080, 135, 1080, 33, 33, 33, 135, 135, 135, 1080, 1080, 135, 1080, 33, 135, 135, 33, 1080, 1080, 1080, 1080, 1080, 1080, 135, 135, 135, 135, 135, 1080, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 135, 135, 1080, 135, 33, 33]
Prompts retrieved: 67224 . Total input tokens: 14934282 . Total output tokens: 13460039
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.0883294008672237,
    "estimated_duration": 3600.026250207772,
    "input_throughput": 1544.0331857800184,
    "output_throughput": 1353.4637420265444,
    "total_throughput": 2897.496927806563,
    "itl": 26.048961560723185,
    "ttft": 7224.941790542145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 22557,
    "finished_requests": 22512,
    "scheduler_time": 0.19947101954852808
}
#Debug simulation 
Total elapsed time: 2.088425751775503. Arrivals time: 0.06904407544061542 Scheduler time: 1.560607663821429 Scheduler overhead time: 0.12372399726882577 Adapter cache time: 0.15030254470184445 Engine time: 0.12402551108971238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.9978959700092673,
    "estimated_duration": 3599.8611357215905,
    "input_throughput": 1451.4337645284363,
    "output_throughput": 1307.8415590206575,
    "total_throughput": 2759.2753235490936,
    "itl": 25.473566667543746,
    "ttft": 3599.4332882363524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09570419927797473
}
#Debug simulation 
Total elapsed time: 1.9979663770645857. Arrivals time: 0.062441873364150524 Scheduler time: 1.4889957355335355 Scheduler overhead time: 0.12644657725468278 Adapter cache time: 0.13678380148485303 Engine time: 0.12163062812760472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9922126620076597,
    "estimated_duration": 3599.8765468631805,
    "input_throughput": 1451.4275509122297,
    "output_throughput": 1307.8359601254786,
    "total_throughput": 2759.263511037708,
    "itl": 25.474095114052066,
    "ttft": 3599.3787505057985,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09573584887829957
}
#Debug simulation 
Total elapsed time: 1.9922833782620728. Arrivals time: 0.0625851727090776 Scheduler time: 1.481700694654137 Scheduler overhead time: 0.1261972994543612 Adapter cache time: 0.13650301797315478 Engine time: 0.123506726231426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 2.048087795265019,
    "estimated_duration": 3599.875642681337,
    "input_throughput": 1451.4279154677222,
    "output_throughput": 1307.8362886150285,
    "total_throughput": 2759.264204082751,
    "itl": 25.47401184736173,
    "ttft": 3599.3969612228507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.0956846841017736
}
#Debug simulation 
Total elapsed time: 2.048169886227697. Arrivals time: 0.0631730817258358 Scheduler time: 1.534880752209574 Scheduler overhead time: 0.12663305131718516 Adapter cache time: 0.1376578537747264 Engine time: 0.1235114149749279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 2.018188325688243,
    "estimated_duration": 3599.872413210369,
    "input_throughput": 1451.4292175539567,
    "output_throughput": 1307.8374618842004,
    "total_throughput": 2759.266679438157,
    "itl": 25.473616751018014,
    "ttft": 3599.354357711031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09568005555173124
}
#Debug simulation 
Total elapsed time: 2.0182642340660095. Arrivals time: 0.0630969563499093 Scheduler time: 1.5025238320231438 Scheduler overhead time: 0.1279126233421266 Adapter cache time: 0.13821314461529255 Engine time: 0.12390092061832547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 2.0201524030417204,
    "estimated_duration": 3599.8722079959384,
    "input_throughput": 1451.4293002941772,
    "output_throughput": 1307.8375364388246,
    "total_throughput": 2759.266836733002,
    "itl": 25.474144538916565,
    "ttft": 3599.408921871647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09570766034401486
}
#Debug simulation 
Total elapsed time: 2.0202363920398057. Arrivals time: 0.06324855238199234 Scheduler time: 1.503376708831638 Scheduler overhead time: 0.12808619905263186 Adapter cache time: 0.13728720089420676 Engine time: 0.1263778768479824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 2.0231146798469126,
    "estimated_duration": 3599.8734021970567,
    "input_throughput": 1451.4288188054416,
    "output_throughput": 1307.8371025843874,
    "total_throughput": 2759.265921389829,
    "itl": 25.47362160583922,
    "ttft": 3599.3512822266625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09570040471394133
}
#Debug simulation 
Total elapsed time: 2.023187718819827. Arrivals time: 0.06319000804796815 Scheduler time: 1.5051580928266048 Scheduler overhead time: 0.12808429123833776 Adapter cache time: 0.13862560549750924 Engine time: 0.12535657873377204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [53 53 54]
Adapter prompts. [33, 1080, 33, 33, 66, 33, 33, 33, 1080, 33, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 1080, 1080, 66, 66, 66, 1080, 1080, 33, 1080, 66, 1080, 1080, 1080, 66, 1080, 33, 66, 66, 66, 1080, 33, 33, 1080, 33, 1080, 33, 33, 66, 33, 66, 1080, 33, 33, 66, 33, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 33, 1080, 1080, 1080, 66, 66, 33, 33, 33, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 33, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 66, 33, 33, 66, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 33, 1080, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 1080, 66, 1080, 33, 33, 33, 66, 66, 66, 1080, 1080, 66, 1080, 33, 66, 66, 33, 1080, 1080, 1080, 1080, 1080, 1080, 66, 66, 66, 66, 66, 1080, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 66, 66, 1080, 66, 33, 33]
Prompts retrieved: 63567 . Total input tokens: 14132716 . Total output tokens: 12724378
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.9989119437523186,
    "estimated_duration": 3599.8734468404405,
    "input_throughput": 1451.4288008057272,
    "output_throughput": 1307.837086365408,
    "total_throughput": 2759.265887171135,
    "itl": 25.47407117050209,
    "ttft": 3599.357824830954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 21252,
    "finished_requests": 21231,
    "scheduler_time": 0.09574952615243758
}
#Debug simulation 
Total elapsed time: 1.9989827708341181. Arrivals time: 0.06283139856532216 Scheduler time: 1.4877566467039287 Scheduler overhead time: 0.12577007384970784 Adapter cache time: 0.13665492134168744 Engine time: 0.12389266956597567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.8278040941804647,
    "estimated_duration": 3599.560905511842,
    "input_throughput": 1189.4386877699449,
    "output_throughput": 1036.954533616717,
    "total_throughput": 2226.393221386662,
    "itl": 23.941862304113965,
    "ttft": 6750.791898845886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.00303502520509902
}
#Debug simulation 
Total elapsed time: 1.8278868831694126. Arrivals time: 0.05500215571373701 Scheduler time: 1.284454143140465 Scheduler overhead time: 0.13164226990193129 Adapter cache time: 0.1604240955784917 Engine time: 0.13122364785522223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.764680789783597,
    "estimated_duration": 3599.557387937694,
    "input_throughput": 1189.4398501180694,
    "output_throughput": 1036.9555469536547,
    "total_throughput": 2226.395397071724,
    "itl": 23.942137765242627,
    "ttft": 6750.941289225052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0030196799589430495
}
#Debug simulation 
Total elapsed time: 1.7647550720721483. Arrivals time: 0.0544891026802361 Scheduler time: 1.2233953168615699 Scheduler overhead time: 0.1308095445856452 Adapter cache time: 0.15953609021380544 Engine time: 0.1314367284066975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.7960342057049274,
    "estimated_duration": 3599.557388587214,
    "input_throughput": 1189.4398499034417,
    "output_throughput": 1036.9555467665418,
    "total_throughput": 2226.3953966699833,
    "itl": 23.942180411453084,
    "ttft": 6750.959473622548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.003018845972934023
}
#Debug simulation 
Total elapsed time: 1.796107713598758. Arrivals time: 0.054508115630596876 Scheduler time: 1.2557230209931731 Scheduler overhead time: 0.1327726859599352 Adapter cache time: 0.1586411246098578 Engine time: 0.12888567987829447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.752963675186038,
    "estimated_duration": 3599.557531635734,
    "input_throughput": 1189.4398026344068,
    "output_throughput": 1036.9555055573223,
    "total_throughput": 2226.3953081917293,
    "itl": 23.9422967934306,
    "ttft": 6750.923034327076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801272,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0030196799589430495
}
#Debug simulation 
Total elapsed time: 1.753041414078325. Arrivals time: 0.05455668410286307 Scheduler time: 1.212569599505514 Scheduler overhead time: 0.13169028144329786 Adapter cache time: 0.15971775399520993 Engine time: 0.1296388846822083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.7528218538500369,
    "estimated_duration": 3599.5665889116435,
    "input_throughput": 1189.4368097506238,
    "output_throughput": 1036.9528963564956,
    "total_throughput": 2226.3897061071193,
    "itl": 23.94220705633421,
    "ttft": 6750.806351794779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0030431148211815186
}
#Debug simulation 
Total elapsed time: 1.7529071299359202. Arrivals time: 0.05455642193555832 Scheduler time: 1.2137969806790352 Scheduler overhead time: 0.13111471058800817 Adapter cache time: 0.15918341558426619 Engine time: 0.12892109341919422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.7746399259194732,
    "estimated_duration": 3599.5799466162616,
    "input_throughput": 1189.432395861836,
    "output_throughput": 1036.9490483212533,
    "total_throughput": 2226.381444183089,
    "itl": 23.942413250630192,
    "ttft": 6750.842545680513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0030092135068373544
}
#Debug simulation 
Total elapsed time: 1.7747472319751978. Arrivals time: 0.05475608818233013 Scheduler time: 1.2338530928827822 Scheduler overhead time: 0.13102891109883785 Adapter cache time: 0.16011090436950326 Engine time: 0.12978161917999387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_160_slots_160_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [53 53 54]
Adapter prompts. [135, 540, 135, 135, 270, 135, 135, 135, 540, 135, 270, 540, 270, 135, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 135, 540, 270, 540, 540, 540, 270, 540, 135, 270, 270, 270, 540, 135, 135, 540, 135, 540, 135, 135, 270, 135, 270, 540, 135, 135, 270, 135, 135, 135, 135, 135, 540, 270, 270, 540, 270, 135, 540, 540, 540, 270, 270, 135, 135, 135, 540, 135, 270, 270, 135, 540, 540, 540, 135, 135, 540, 270, 540, 540, 135, 540, 135, 270, 135, 135, 270, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 135, 540, 270, 540, 270, 540, 540, 540, 135, 270, 270, 540, 270, 540, 135, 135, 135, 270, 270, 270, 540, 540, 270, 540, 135, 270, 270, 135, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 270, 270, 540, 270, 135, 135]
Prompts retrieved: 50625 . Total input tokens: 11246464 . Total output tokens: 10123844
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.7965402421541512,
    "estimated_duration": 3599.557452814736,
    "input_throughput": 1189.439828680062,
    "output_throughput": 1036.955528263966,
    "total_throughput": 2226.395356944028,
    "itl": 23.942564402323935,
    "ttft": 6750.945272463932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 17165,
    "finished_requests": 17133,
    "scheduler_time": 0.0030196799589430495
}
#Debug simulation 
Total elapsed time: 1.7966221952810884. Arrivals time: 0.05522328708320856 Scheduler time: 1.25228282622993 Scheduler overhead time: 0.13130188174545765 Adapter cache time: 0.16066569834947586 Engine time: 0.13212696509435773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6848030160181224,
    "estimated_duration": 3599.6170217830195,
    "input_throughput": 1093.5874500477032,
    "output_throughput": 982.8612262333228,
    "total_throughput": 2076.448676281026,
    "itl": 23.495560805314145,
    "ttft": 5697.018929942937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 15906,
    "finished_requests": 15881,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.684890842065215. Arrivals time: 0.05109606822952628 Scheduler time: 1.1517888624221087 Scheduler overhead time: 0.1382836359553039 Adapter cache time: 0.14752027858048677 Engine time: 0.12994442135095596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.711895626038313,
    "estimated_duration": 3599.616942021518,
    "input_throughput": 1093.5874742797753,
    "output_throughput": 982.8612480118867,
    "total_throughput": 2076.448722291662,
    "itl": 23.49595802416736,
    "ttft": 5696.979364675591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 15906,
    "finished_requests": 15881,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.7119773980230093. Arrivals time: 0.05209110025316477 Scheduler time: 1.1796203861013055 Scheduler overhead time: 0.13337216572836041 Adapter cache time: 0.14782587438821793 Engine time: 0.13277249690145254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.7082421788945794,
    "estimated_duration": 3599.6170054997806,
    "input_throughput": 1093.5874549946589,
    "output_throughput": 982.861230679397,
    "total_throughput": 2076.448685674056,
    "itl": 23.495963540369495,
    "ttft": 5696.980775709096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 15906,
    "finished_requests": 15881,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.70832202071324. Arrivals time: 0.05165069783106446 Scheduler time: 1.1782643236219883 Scheduler overhead time: 0.1326892552897334 Adapter cache time: 0.14784401934593916 Engine time: 0.1319301212206483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6903872638940811,
    "estimated_duration": 3599.6161679431434,
    "input_throughput": 1093.5877094499642,
    "output_throughput": 982.8614593709876,
    "total_throughput": 2076.449168820952,
    "itl": 23.495557618729123,
    "ttft": 5696.812996438132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 15906,
    "finished_requests": 15881,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.6904741637408733. Arrivals time: 0.052215056493878365 Scheduler time: 1.158868424128741 Scheduler overhead time: 0.13349473662674427 Adapter cache time: 0.1469950177706778 Engine time: 0.13314345106482506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.702672537881881,
    "estimated_duration": 3599.6170302743485,
    "input_throughput": 1093.5874474679813,
    "output_throughput": 982.861223914799,
    "total_throughput": 2076.44867138278,
    "itl": 23.49582456347283,
    "ttft": 5697.036032337735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 15906,
    "finished_requests": 15881,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.7027578158304095. Arrivals time: 0.05158594669774175 Scheduler time: 1.1737538082525134 Scheduler overhead time: 0.13331446470692754 Adapter cache time: 0.14735437277704477 Engine time: 0.13103243615478277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.7441767673008144,
    "estimated_duration": 3599.6161611791476,
    "input_throughput": 1093.5877115049118,
    "output_throughput": 982.8614612178709,
    "total_throughput": 2076.449172722783,
    "itl": 23.495417012024298,
    "ttft": 5696.80161910012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 15906,
    "finished_requests": 15881,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.7442580773495138. Arrivals time: 0.05146168498322368 Scheduler time: 1.2154103219509125 Scheduler overhead time: 0.13208853034302592 Adapter cache time: 0.14798733312636614 Engine time: 0.13186111208051443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 270, 66, 66, 66, 540, 66, 270, 540, 270, 66, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 66, 540, 270, 540, 540, 540, 270, 540, 66, 270, 270, 270, 540, 66, 66, 540, 66, 540, 66, 66, 270, 66, 270, 540, 66, 66, 270, 66, 66, 66, 66, 66, 540, 270, 270, 540, 270, 66, 540, 540, 540, 270, 270, 66, 66, 66, 540, 66, 270, 270, 66, 540, 540, 540, 66, 66, 540, 270, 540, 540, 66, 540, 66, 270, 66, 66, 270, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 66, 540, 270, 540, 270, 540, 540, 540, 66, 270, 270, 540, 270, 540, 66, 66, 66, 270, 270, 270, 540, 540, 270, 540, 66, 270, 270, 66, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 270, 270, 540, 270, 66, 66]
Prompts retrieved: 46968 . Total input tokens: 10413330 . Total output tokens: 9394576
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.7127445256337523,
    "estimated_duration": 3599.6161691541556,
    "input_throughput": 1093.5877090820507,
    "output_throughput": 982.8614590403254,
    "total_throughput": 2076.449168122376,
    "itl": 23.49613589983732,
    "ttft": 5696.834552678175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 15906,
    "finished_requests": 15881,
    "scheduler_time": 8.339860090264041e-07
}
#Debug simulation 
Total elapsed time: 1.7128492780029774. Arrivals time: 0.051744939759373665 Scheduler time: 1.1788133066147566 Scheduler overhead time: 0.1325471573509276 Adapter cache time: 0.1472991220653057 Engine time: 0.13663910748437047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.6537913661450148,
    "estimated_duration": 3599.6902316091546,
    "input_throughput": 1045.5041289254555,
    "output_throughput": 940.5964908503904,
    "total_throughput": 1986.1006197758459,
    "itl": 23.097268573521962,
    "ttft": 6388.486990799398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6538696209900081. Arrivals time: 0.05010031023994088 Scheduler time: 1.1280553569085896 Scheduler overhead time: 0.13512793043628335 Adapter cache time: 0.13920661713927984 Engine time: 0.13386308075860143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6554798521101475,
    "estimated_duration": 3599.680429177386,
    "input_throughput": 1045.5069759789894,
    "output_throughput": 940.5990522257971,
    "total_throughput": 1986.1060282047868,
    "itl": 23.09745038728771,
    "ttft": 6388.392600162707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6555531932972372. Arrivals time: 0.04992438293993473 Scheduler time: 1.1301893084309995 Scheduler overhead time: 0.13566975900903344 Adapter cache time: 0.13865124015137553 Engine time: 0.13454081490635872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.6433284250088036,
    "estimated_duration": 3599.680738468254,
    "input_throughput": 1045.5068861472007,
    "output_throughput": 940.5989714078808,
    "total_throughput": 1986.1058575550815,
    "itl": 23.097617987714973,
    "ttft": 6388.409866829002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6433998150750995. Arrivals time: 0.04969326127320528 Scheduler time: 1.1240425407886505 Scheduler overhead time: 0.13374716509133577 Adapter cache time: 0.13731100782752037 Engine time: 0.13249852322041988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6548510463908315,
    "estimated_duration": 3599.6804341861484,
    "input_throughput": 1045.5069745242226,
    "output_throughput": 940.599050917004,
    "total_throughput": 1986.1060254412266,
    "itl": 23.09739079911008,
    "ttft": 6388.369560595142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.654930931981653. Arrivals time: 0.05118540721014142 Scheduler time: 1.1221361528150737 Scheduler overhead time: 0.13636629888787866 Adapter cache time: 0.138588878326118 Engine time: 0.1387061169371009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.6386761139146984,
    "estimated_duration": 3599.689788491282,
    "input_throughput": 1045.5042576258693,
    "output_throughput": 940.5966066367889,
    "total_throughput": 1986.1008642626582,
    "itl": 23.0975812946943,
    "ttft": 6388.516638249175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978161,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6387508432380855. Arrivals time: 0.04981470527127385 Scheduler time: 1.1184824504889548 Scheduler overhead time: 0.1338604548946023 Adapter cache time: 0.13817836251109838 Engine time: 0.1322327177040279 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.650106362067163,
    "estimated_duration": 3599.680535895266,
    "input_throughput": 1045.5069449833811,
    "output_throughput": 940.5990243403402,
    "total_throughput": 1986.1059693237214,
    "itl": 23.097170943950832,
    "ttft": 6388.46617973595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6501790606416762. Arrivals time: 0.04999486915767193 Scheduler time: 1.123804580885917 Scheduler overhead time: 0.134608069434762 Adapter cache time: 0.13848964218050241 Engine time: 0.1372123220935464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 270, 33, 33, 33, 540, 33, 270, 540, 270, 33, 270, 270, 270, 270, 540, 540, 540, 270, 270, 270, 540, 540, 33, 540, 270, 540, 540, 540, 270, 540, 33, 270, 270, 270, 540, 33, 33, 540, 33, 540, 33, 33, 270, 33, 270, 540, 33, 33, 270, 33, 33, 33, 33, 33, 540, 270, 270, 540, 270, 33, 540, 540, 540, 270, 270, 33, 33, 33, 540, 33, 270, 270, 33, 540, 540, 540, 33, 33, 540, 270, 540, 540, 33, 540, 33, 270, 33, 33, 270, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 33, 540, 270, 540, 270, 540, 540, 540, 33, 270, 270, 540, 270, 540, 33, 33, 33, 270, 270, 270, 540, 540, 270, 540, 33, 270, 270, 33, 540, 540, 540, 540, 540, 540, 270, 270, 270, 270, 270, 540, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 270, 270, 540, 270, 33, 33]
Prompts retrieved: 45219 . Total input tokens: 10025903 . Total output tokens: 9036130
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.657938462216407,
    "estimated_duration": 3599.6805273954446,
    "input_throughput": 1045.5069474521065,
    "output_throughput": 940.5990265613494,
    "total_throughput": 1986.1059740134558,
    "itl": 23.09725103126916,
    "ttft": 6388.482159826856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 15306,
    "finished_requests": 15279,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6580161862075329. Arrivals time: 0.05022623483091593 Scheduler time: 1.1339599695056677 Scheduler overhead time: 0.13462390005588531 Adapter cache time: 0.1392979435622692 Engine time: 0.13334627216681838 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.5064366669394076,
    "estimated_duration": 3599.8709367786005,
    "input_throughput": 920.4949450119126,
    "output_throughput": 810.9565735188315,
    "total_throughput": 1731.4515185307441,
    "itl": 22.022372953860017,
    "ttft": 6442.133412489911,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5065179038792849. Arrivals time: 0.046214408706873655 Scheduler time: 0.9869466396048665 Scheduler overhead time: 0.13880872586742043 Adapter cache time: 0.1282090083695948 Engine time: 0.13739188108593225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.511995417997241,
    "estimated_duration": 3599.8681145309015,
    "input_throughput": 920.4956666674449,
    "output_throughput": 810.9572092977686,
    "total_throughput": 1731.4528759652135,
    "itl": 22.022678552273447,
    "ttft": 6441.973247622371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5120689710602164. Arrivals time: 0.045962306670844555 Scheduler time: 0.9920577751472592 Scheduler overhead time: 0.1387033355422318 Adapter cache time: 0.12880072509869933 Engine time: 0.13764173444360495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4996723579242826,
    "estimated_duration": 3599.867994017865,
    "input_throughput": 920.4956974829437,
    "output_throughput": 810.9572364462407,
    "total_throughput": 1731.4529339291844,
    "itl": 22.022657068541406,
    "ttft": 6441.97701361984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.499744099099189. Arrivals time: 0.045318806543946266 Scheduler time: 0.9767279089428484 Scheduler overhead time: 0.13984589418396354 Adapter cache time: 0.1282868031412363 Engine time: 0.1406867471523583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.5256766248494387,
    "estimated_duration": 3599.8664166419426,
    "input_throughput": 920.4961008222851,
    "output_throughput": 810.9575917884315,
    "total_throughput": 1731.4536926107166,
    "itl": 22.02271477084418,
    "ttft": 6441.951808605158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5257535018026829. Arrivals time: 0.04601541114971042 Scheduler time: 0.9941900582052767 Scheduler overhead time: 0.13963610585778952 Adapter cache time: 0.12960755312815309 Engine time: 0.14744698349386454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.533222904894501,
    "estimated_duration": 3599.8776402559092,
    "input_throughput": 920.4932309211591,
    "output_throughput": 810.9550634038965,
    "total_throughput": 1731.4482943250555,
    "itl": 22.02290460375477,
    "ttft": 6441.984531442996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.533300403971225. Arrivals time: 0.04645311180502176 Scheduler time: 1.0111731118522584 Scheduler overhead time: 0.13892928324639797 Adapter cache time: 0.12921910686418414 Engine time: 0.13858858635649085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.506474647205323,
    "estimated_duration": 3599.865289164654,
    "input_throughput": 920.496389121531,
    "output_throughput": 810.9578457802321,
    "total_throughput": 1731.4542349017631,
    "itl": 22.022496116533134,
    "ttft": 6441.988418122777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5065467292442918. Arrivals time: 0.046213287860155106 Scheduler time: 0.9852163633331656 Scheduler overhead time: 0.13855830254033208 Adapter cache time: 0.12846056884154677 Engine time: 0.1385932331904769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [53 53 54]
Adapter prompts. [66, 540, 66, 66, 135, 66, 66, 66, 540, 66, 135, 540, 135, 66, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 66, 540, 135, 540, 540, 540, 135, 540, 66, 135, 135, 135, 540, 66, 66, 540, 66, 540, 66, 66, 135, 66, 135, 540, 66, 66, 135, 66, 66, 66, 66, 66, 540, 135, 135, 540, 135, 66, 540, 540, 540, 135, 135, 66, 66, 66, 540, 66, 135, 135, 66, 540, 540, 540, 66, 66, 540, 135, 540, 540, 66, 540, 66, 135, 66, 66, 135, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 66, 540, 135, 540, 135, 540, 540, 540, 66, 135, 135, 540, 135, 540, 66, 66, 66, 135, 135, 135, 540, 540, 135, 540, 66, 135, 135, 66, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 135, 135, 540, 135, 66, 66]
Prompts retrieved: 39813 . Total input tokens: 8823958 . Total output tokens: 7944526
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.515277000144124,
    "estimated_duration": 3599.86677521343,
    "input_throughput": 920.4960091345431,
    "output_throughput": 810.9575110114782,
    "total_throughput": 1731.4535201460214,
    "itl": 22.02291947562188,
    "ttft": 6441.960405327186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 13488,
    "finished_requests": 13464,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5153483389876783. Arrivals time: 0.04579850425943732 Scheduler time: 0.9951031915843487 Scheduler overhead time: 0.13990930328145623 Adapter cache time: 0.1287140934728086 Engine time: 0.13706766767427325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.4788782810792327,
    "estimated_duration": 3599.6138892202966,
    "input_throughput": 880.6969573858051,
    "output_throughput": 786.6679836079218,
    "total_throughput": 1667.364940993727,
    "itl": 21.812864928308,
    "ttft": 4229.2027334756685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4789559892378747. Arrivals time: 0.04470309102907777 Scheduler time: 0.9642442180775106 Scheduler overhead time: 0.1391187054105103 Adapter cache time: 0.12209870386868715 Engine time: 0.1390439635142684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4930140767246485,
    "estimated_duration": 3599.613318508475,
    "input_throughput": 880.6970970186269,
    "output_throughput": 786.6681083326292,
    "total_throughput": 1667.3652053512562,
    "itl": 21.813321088370213,
    "ttft": 4229.093305252165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4930940889753401. Arrivals time: 0.04442891711369157 Scheduler time: 0.974706806242466 Scheduler overhead time: 0.141658753156662 Adapter cache time: 0.12276244256645441 Engine time: 0.1393447546288371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4703536960296333,
    "estimated_duration": 3599.6132620804847,
    "input_throughput": 880.6971108245453,
    "output_throughput": 786.6681206645375,
    "total_throughput": 1667.3652314890828,
    "itl": 21.813203271051787,
    "ttft": 4229.102491398375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4704476268962026. Arrivals time: 0.044472682755440474 Scheduler time: 0.9561142292805016 Scheduler overhead time: 0.14016896346583962 Adapter cache time: 0.1214108495041728 Engine time: 0.1389386234804988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4764047162607312,
    "estimated_duration": 3599.610332560309,
    "input_throughput": 880.6978275743368,
    "output_throughput": 786.668760889428,
    "total_throughput": 1667.3665884637646,
    "itl": 21.813014678719178,
    "ttft": 4229.180959787404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4764769179746509. Arrivals time: 0.04442562721669674 Scheduler time: 0.9641628353856504 Scheduler overhead time: 0.1399026899598539 Adapter cache time: 0.12201621662825346 Engine time: 0.13676994619891047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.492776214145124,
    "estimated_duration": 3599.6179517170663,
    "input_throughput": 880.6959634390607,
    "output_throughput": 786.6670957814399,
    "total_throughput": 1667.3630592205006,
    "itl": 21.813232078517878,
    "ttft": 4229.217002853395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978161,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4928536070510745. Arrivals time: 0.044769525062292814 Scheduler time: 0.9753621760755777 Scheduler overhead time: 0.14103117492049932 Adapter cache time: 0.12188688013702631 Engine time: 0.13960417546331882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.482962909154594,
    "estimated_duration": 3599.624783920615,
    "input_throughput": 880.6942918498124,
    "output_throughput": 786.665602662005,
    "total_throughput": 1667.3598945118174,
    "itl": 21.812868232975777,
    "ttft": 4229.2019070381375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.483041471336037. Arrivals time: 0.044874506536871195 Scheduler time: 0.9676160640083253 Scheduler overhead time: 0.1404124447144568 Adapter cache time: 0.12180563434958458 Engine time: 0.1395860337652266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 135, 33, 33, 33, 540, 33, 135, 540, 135, 33, 135, 135, 135, 135, 540, 540, 540, 135, 135, 135, 540, 540, 33, 540, 135, 540, 540, 540, 135, 540, 33, 135, 135, 135, 540, 33, 33, 540, 33, 540, 33, 33, 135, 33, 135, 540, 33, 33, 135, 33, 33, 33, 33, 33, 540, 135, 135, 540, 135, 33, 540, 540, 540, 135, 135, 33, 33, 33, 540, 33, 135, 135, 33, 540, 540, 540, 33, 33, 540, 135, 540, 540, 33, 540, 33, 135, 33, 33, 135, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 33, 540, 135, 540, 135, 540, 540, 540, 33, 135, 135, 540, 135, 540, 33, 33, 33, 135, 135, 135, 540, 540, 135, 540, 33, 135, 135, 33, 540, 540, 540, 540, 540, 540, 135, 135, 135, 135, 135, 540, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 135, 135, 540, 135, 33, 33]
Prompts retrieved: 38064 . Total input tokens: 8436520 . Total output tokens: 7585704
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.4765116209164262,
    "estimated_duration": 3599.6248203367227,
    "input_throughput": 880.6942829401455,
    "output_throughput": 786.6655947035924,
    "total_throughput": 1667.359877643738,
    "itl": 21.813134759129657,
    "ttft": 4229.251172782195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 12878,
    "finished_requests": 12863,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4765910310670733. Arrivals time: 0.04489279258996248 Scheduler time: 0.9617229239083827 Scheduler overhead time: 0.1409157244488597 Adapter cache time: 0.12105133244767785 Engine time: 0.13824098045006394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.3567895842716098,
    "estimated_duration": 3599.8646484910437,
    "input_throughput": 797.1758052633738,
    "output_throughput": 700.3596652048604,
    "total_throughput": 1497.5354704682343,
    "itl": 21.244039071788375,
    "ttft": 5910.238588379026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3568609422072768. Arrivals time: 0.04155337996780872 Scheduler time: 0.8492394457571208 Scheduler overhead time: 0.14306793827563524 Adapter cache time: 0.110810452606529 Engine time: 0.1412344602867961 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3953350321389735,
    "estimated_duration": 3599.861327130982,
    "input_throughput": 797.1765407661172,
    "output_throughput": 700.3603113815905,
    "total_throughput": 1497.5368521477078,
    "itl": 21.244241028885533,
    "ttft": 5910.2115401489045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3954096962697804. Arrivals time: 0.04213022626936436 Scheduler time: 0.8845298239029944 Scheduler overhead time: 0.14340268867090344 Adapter cache time: 0.11288349376991391 Engine time: 0.14146890072152019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.380951311904937,
    "estimated_duration": 3599.8612331369486,
    "input_throughput": 797.1765615807635,
    "output_throughput": 700.3603296683204,
    "total_throughput": 1497.536891249084,
    "itl": 21.24420179103416,
    "ttft": 5910.182687363932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3810283481143415. Arrivals time: 0.04170108586549759 Scheduler time: 0.8738209339790046 Scheduler overhead time: 0.14211358921602368 Adapter cache time: 0.11141852848231792 Engine time: 0.14126273477450013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.3813458657823503,
    "estimated_duration": 3599.85895938929,
    "input_throughput": 797.1770650944736,
    "output_throughput": 700.3607720308346,
    "total_throughput": 1497.5378371253082,
    "itl": 21.244216956156546,
    "ttft": 5910.198954234498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3814247781410813. Arrivals time: 0.04184461897239089 Scheduler time: 0.8728483361192048 Scheduler overhead time: 0.1410731626674533 Adapter cache time: 0.11109114997088909 Engine time: 0.1434028665535152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.3791487501002848,
    "estimated_duration": 3599.873100091927,
    "input_throughput": 797.17393369414,
    "output_throughput": 700.3580209356875,
    "total_throughput": 1497.5319546298274,
    "itl": 21.244336684266447,
    "ttft": 5910.181487719929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3792497720569372. Arrivals time: 0.04265642026439309 Scheduler time: 0.864373676944524 Scheduler overhead time: 0.1474231192842126 Adapter cache time: 0.11159505415707827 Engine time: 0.14169087819755077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.3795546502806246,
    "estimated_duration": 3599.8569694766315,
    "input_throughput": 797.1775057544071,
    "output_throughput": 700.3611591730954,
    "total_throughput": 1497.5386649275026,
    "itl": 21.244201596706198,
    "ttft": 5910.140968149095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3796282862313092. Arrivals time: 0.04174718493595719 Scheduler time: 0.8714178809896111 Scheduler overhead time: 0.1434100903570652 Adapter cache time: 0.11155956331640482 Engine time: 0.14067668747156858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [53 53 54]
Adapter prompts. [33, 540, 33, 33, 66, 33, 33, 33, 540, 33, 66, 540, 66, 33, 66, 66, 66, 66, 540, 540, 540, 66, 66, 66, 540, 540, 33, 540, 66, 540, 540, 540, 66, 540, 33, 66, 66, 66, 540, 33, 33, 540, 33, 540, 33, 33, 66, 33, 66, 540, 33, 33, 66, 33, 33, 33, 33, 33, 540, 66, 66, 540, 66, 33, 540, 540, 540, 66, 66, 33, 33, 33, 540, 33, 66, 66, 33, 540, 540, 540, 33, 33, 540, 66, 540, 540, 33, 540, 33, 66, 33, 33, 66, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 33, 540, 66, 540, 66, 540, 540, 540, 33, 66, 66, 540, 66, 540, 33, 33, 33, 66, 66, 66, 540, 540, 66, 540, 33, 66, 66, 33, 540, 540, 540, 540, 540, 540, 66, 66, 66, 66, 66, 540, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 66, 66, 540, 66, 33, 33]
Prompts retrieved: 34407 . Total input tokens: 7613207 . Total output tokens: 6870626
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.3705995976924896,
    "estimated_duration": 3599.859699921034,
    "input_throughput": 797.1769011061598,
    "output_throughput": 700.3606279587242,
    "total_throughput": 1497.537529064884,
    "itl": 21.244421325028902,
    "ttft": 5910.188669158142,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 11642,
    "finished_requests": 11623,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.370670136064291. Arrivals time: 0.04145198129117489 Scheduler time: 0.860598964150995 Scheduler overhead time: 0.1426122528500855 Adapter cache time: 0.1107809953391552 Engine time: 0.14383992739021778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.1655024769715965,
    "estimated_duration": 3599.9858005778237,
    "input_throughput": 573.1986497471163,
    "output_throughput": 518.3653779135674,
    "total_throughput": 1091.5640276606837,
    "itl": 19.981336551453854,
    "ttft": 4663.086019540451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1655582920648158. Arrivals time: 0.03419097978621721 Scheduler time: 0.6680405302904546 Scheduler overhead time: 0.1464969189837575 Adapter cache time: 0.0982172186486423 Engine time: 0.14494232228025794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.168279386125505,
    "estimated_duration": 3599.9771592341467,
    "input_throughput": 573.200025646548,
    "output_throughput": 518.3666221918454,
    "total_throughput": 1091.5666478383935,
    "itl": 20.165383100041183,
    "ttft": 4663.319536622157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1683540898375213. Arrivals time: 0.03451947448775172 Scheduler time: 0.6753574251197278 Scheduler overhead time: 0.14539144514128566 Adapter cache time: 0.09706963924691081 Engine time: 0.14342654077336192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1819144012406468,
    "estimated_duration": 3599.979005377025,
    "input_throughput": 573.1997316978491,
    "output_throughput": 518.3663563628375,
    "total_throughput": 1091.5660880606865,
    "itl": 20.16544789928877,
    "ttft": 4663.344843661351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1820076704025269. Arrivals time: 0.034998863469809294 Scheduler time: 0.683320568408817 Scheduler overhead time: 0.14615183882415295 Adapter cache time: 0.09929275186732411 Engine time: 0.14494716003537178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1919227000325918,
    "estimated_duration": 3599.9738747139686,
    "input_throughput": 573.2005486189684,
    "output_throughput": 518.3670951357304,
    "total_throughput": 1091.5676437546988,
    "itl": 19.982104807741372,
    "ttft": 4662.983396775351,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1919811880216002. Arrivals time: 0.03477282961830497 Scheduler time: 0.6837650598026812 Scheduler overhead time: 0.15220886142924428 Adapter cache time: 0.0988941784016788 Engine time: 0.14823534339666367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.1712967418134212,
    "estimated_duration": 3599.985962387305,
    "input_throughput": 573.1986239834114,
    "output_throughput": 518.3653546144674,
    "total_throughput": 1091.5639785978788,
    "itl": 19.981818530706814,
    "ttft": 4663.06600773412,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978163,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.171359019819647. Arrivals time: 0.03461303701624274 Scheduler time: 0.6700403443537652 Scheduler overhead time: 0.1467824107967317 Adapter cache time: 0.09842005698010325 Engine time: 0.1472645099274814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.1871890220791101,
    "estimated_duration": 3599.987731427392,
    "input_throughput": 573.1983423126337,
    "output_throughput": 518.3650998888514,
    "total_throughput": 1091.5634422014853,
    "itl": 19.98135916567826,
    "ttft": 4662.885014036951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.187260551378131. Arrivals time: 0.0344750233925879 Scheduler time: 0.682693628128618 Scheduler overhead time: 0.1512683592736721 Adapter cache time: 0.0984682752750814 Engine time: 0.1453298470005393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_160_slots_160_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [53 53 54]
Adapter prompts. [66, 270, 66, 66, 135, 66, 66, 66, 270, 66, 135, 270, 135, 66, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 66, 270, 135, 270, 270, 270, 135, 270, 66, 135, 135, 135, 270, 66, 66, 270, 66, 270, 66, 66, 135, 66, 135, 270, 66, 66, 135, 66, 66, 66, 66, 66, 270, 135, 135, 270, 135, 66, 270, 270, 270, 135, 135, 66, 66, 66, 270, 66, 135, 135, 66, 270, 270, 270, 66, 66, 270, 135, 270, 270, 66, 270, 66, 135, 66, 66, 135, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 66, 270, 135, 270, 135, 270, 270, 270, 66, 135, 135, 270, 135, 270, 66, 66, 66, 135, 135, 135, 270, 270, 135, 270, 66, 135, 135, 66, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 135, 135, 270, 135, 66, 66]
Prompts retrieved: 25233 . Total input tokens: 5554084 . Total output tokens: 5037594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1625131787732244,
    "estimated_duration": 3599.970842502106,
    "input_throughput": 573.2010314188518,
    "output_throughput": 518.3675317500598,
    "total_throughput": 1091.5685631689116,
    "itl": 19.982034897167498,
    "ttft": 4663.040443572356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642179,
    "arrivals": 8553,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1626159348525107. Arrivals time: 0.034455508925020695 Scheduler time: 0.6648165229707956 Scheduler overhead time: 0.14649141067638993 Adapter cache time: 0.09790030959993601 Engine time: 0.1457066535949707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.1226320778951049,
    "estimated_duration": 3598.5117315516445,
    "input_throughput": 538.7521688484389,
    "output_throughput": 483.00634530668765,
    "total_throughput": 1021.7585141551266,
    "itl": 19.78283532763473,
    "ttft": 2750.094491644762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1226887400262058. Arrivals time: 0.03335349494591355 Scheduler time: 0.6301783854141831 Scheduler overhead time: 0.14745929557830095 Adapter cache time: 0.09164331201463938 Engine time: 0.1460020998492837 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1329005262814462,
    "estimated_duration": 3598.507237018236,
    "input_throughput": 538.7528417495788,
    "output_throughput": 483.0069485813269,
    "total_throughput": 1021.7597903309058,
    "itl": 19.78334588770882,
    "ttft": 2750.162549837105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574654,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1329770982265472. Arrivals time: 0.0329708200879395 Scheduler time: 0.6342546539381146 Scheduler overhead time: 0.14862748188897967 Adapter cache time: 0.09254874056205153 Engine time: 0.1495589865371585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1662031929008663,
    "estimated_duration": 3598.510098242622,
    "input_throughput": 538.7524133798573,
    "output_throughput": 483.0065645359242,
    "total_throughput": 1021.7589779157815,
    "itl": 19.783258548236866,
    "ttft": 2750.182700613525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1663162652403116. Arrivals time: 0.03362775221467018 Scheduler time: 0.6602915748953819 Scheduler overhead time: 0.15251990361139178 Adapter cache time: 0.092161497566849 Engine time: 0.14890607865527272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1424968028441072,
    "estimated_duration": 3598.505893412122,
    "input_throughput": 538.7530429085136,
    "output_throughput": 483.0071289259223,
    "total_throughput": 1021.7601718344358,
    "itl": 19.78249053120795,
    "ttft": 2750.2134904912864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1425495026633143. Arrivals time: 0.0337673663161695 Scheduler time: 0.6415345426648855 Scheduler overhead time: 0.14797443198040128 Adapter cache time: 0.09274551132693887 Engine time: 0.150005754083395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.1489551570266485,
    "estimated_duration": 3598.5140632455823,
    "input_throughput": 538.7518197584691,
    "output_throughput": 483.0060323377934,
    "total_throughput": 1021.7578520962625,
    "itl": 19.783363327420386,
    "ttft": 2750.108423720036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978161,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.149026035796851. Arrivals time: 0.033658383414149284 Scheduler time: 0.6502528842538595 Scheduler overhead time: 0.14800809184089303 Adapter cache time: 0.09272779431194067 Engine time: 0.14928078139200807 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.1329254019074142,
    "estimated_duration": 3598.5182180345682,
    "input_throughput": 538.7511977246231,
    "output_throughput": 483.0054746671018,
    "total_throughput": 1021.7566723917249,
    "itl": 19.782772947111358,
    "ttft": 2750.1039602313685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1329897376708686. Arrivals time: 0.033361311070621014 Scheduler time: 0.6390032428316772 Scheduler overhead time: 0.1473836130462587 Adapter cache time: 0.09197390731424093 Engine time: 0.14738741656765342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 135, 33, 33, 33, 270, 33, 135, 270, 135, 33, 135, 135, 135, 135, 270, 270, 270, 135, 135, 135, 270, 270, 33, 270, 135, 270, 270, 270, 135, 270, 33, 135, 135, 135, 270, 33, 33, 270, 33, 270, 33, 33, 135, 33, 135, 270, 33, 33, 135, 33, 33, 33, 33, 33, 270, 135, 135, 270, 135, 33, 270, 270, 270, 135, 135, 33, 33, 33, 270, 33, 135, 135, 33, 270, 270, 270, 33, 33, 270, 135, 270, 270, 33, 270, 33, 135, 33, 33, 135, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 33, 270, 135, 270, 135, 270, 270, 270, 33, 135, 135, 270, 135, 270, 33, 33, 33, 135, 135, 135, 270, 270, 135, 270, 33, 135, 135, 33, 270, 270, 270, 270, 270, 270, 135, 135, 135, 135, 135, 270, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 135, 135, 270, 135, 33, 33]
Prompts retrieved: 23484 . Total input tokens: 5172175 . Total output tokens: 4691996
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.1301191202364862,
    "estimated_duration": 3598.5208107354574,
    "input_throughput": 538.7508095593788,
    "output_throughput": 483.00512666613434,
    "total_throughput": 1021.7559362255132,
    "itl": 19.783397554296695,
    "ttft": 2750.180287377907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 7949,
    "finished_requests": 7943,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1301793353632092. Arrivals time: 0.03357335925102234 Scheduler time: 0.6332827713340521 Scheduler overhead time: 0.14777692407369614 Adapter cache time: 0.09193694638088346 Engine time: 0.14948577573522925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0341760823503137,
    "estimated_duration": 3597.501234640505,
    "input_throughput": 445.2698958309245,
    "output_throughput": 404.24197384474917,
    "total_throughput": 849.5118696756737,
    "itl": 19.28141829949007,
    "ttft": 7528.657845298745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0342534710653126. Arrivals time: 0.030737226363271475 Scheduler time: 0.5489740031771362 Scheduler overhead time: 0.14903526054695249 Adapter cache time: 0.08081865170970559 Engine time: 0.14904797030612826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0459064696915448,
    "estimated_duration": 3597.501234640505,
    "input_throughput": 445.2698958309245,
    "output_throughput": 404.24197384474917,
    "total_throughput": 849.5118696756737,
    "itl": 19.281603890882412,
    "ttft": 7528.68186601532,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574656,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0459607508964837. Arrivals time: 0.03013763204216957 Scheduler time: 0.556802423670888 Scheduler overhead time: 0.1499765245243907 Adapter cache time: 0.08218514174222946 Engine time: 0.15090122213587165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0294481636956334,
    "estimated_duration": 3597.501234640505,
    "input_throughput": 445.2698958309245,
    "output_throughput": 404.24197384474917,
    "total_throughput": 849.5118696756737,
    "itl": 19.281641836474257,
    "ttft": 7528.676002381863,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.02952029556036. Arrivals time: 0.030271544121205807 Scheduler time: 0.5451188622973859 Scheduler overhead time: 0.14969452330842614 Adapter cache time: 0.08066770108416677 Engine time: 0.1486276793293655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 1.02849555388093,
    "estimated_duration": 3597.501234640505,
    "input_throughput": 445.2698958309245,
    "output_throughput": 404.24197384474917,
    "total_throughput": 849.5118696756737,
    "itl": 19.28154439084891,
    "ttft": 7528.616506434265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0285554630681872. Arrivals time: 0.030203441623598337 Scheduler time: 0.5451473244465888 Scheduler overhead time: 0.14880121545866132 Adapter cache time: 0.08079897332936525 Engine time: 0.14812266500666738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 1.0314232190139592,
    "estimated_duration": 3597.501234640505,
    "input_throughput": 445.2698958309245,
    "output_throughput": 404.24197384474917,
    "total_throughput": 849.5118696756737,
    "itl": 19.28171400421889,
    "ttft": 7528.636085090974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0314834718592465. Arrivals time: 0.030279483646154404 Scheduler time: 0.5482608960010111 Scheduler overhead time: 0.14888283796608448 Adapter cache time: 0.08087806962430477 Engine time: 0.14818713488057256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 1.0318679879419506,
    "estimated_duration": 3597.501234640505,
    "input_throughput": 445.2698958309245,
    "output_throughput": 404.24197384474917,
    "total_throughput": 849.5118696756737,
    "itl": 19.281468012171405,
    "ttft": 7528.588903524645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0319640352390707. Arrivals time: 0.0303522115573287 Scheduler time: 0.5477247261442244 Scheduler overhead time: 0.14927854435518384 Adapter cache time: 0.0806972710415721 Engine time: 0.14874541945755482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [53 53 54]
Adapter prompts. [33, 270, 33, 33, 66, 33, 33, 33, 270, 33, 66, 270, 66, 33, 66, 66, 66, 66, 270, 270, 270, 66, 66, 66, 270, 270, 33, 270, 66, 270, 270, 270, 66, 270, 33, 66, 66, 66, 270, 33, 33, 270, 33, 270, 33, 33, 66, 33, 66, 270, 33, 33, 66, 33, 33, 33, 33, 33, 270, 66, 66, 270, 66, 33, 270, 270, 270, 66, 66, 33, 33, 33, 270, 33, 66, 66, 33, 270, 270, 270, 33, 33, 270, 66, 270, 270, 33, 270, 33, 66, 33, 33, 66, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 33, 270, 66, 270, 66, 270, 270, 270, 33, 66, 66, 270, 66, 270, 33, 33, 33, 66, 66, 66, 270, 270, 66, 270, 33, 66, 66, 33, 270, 270, 270, 270, 270, 270, 66, 66, 66, 66, 66, 270, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 66, 66, 270, 66, 33, 33]
Prompts retrieved: 19827 . Total input tokens: 4360331 . Total output tokens: 3963665
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 1.0396998459473252,
    "estimated_duration": 3597.501234640505,
    "input_throughput": 445.2698958309245,
    "output_throughput": 404.24197384474917,
    "total_throughput": 849.5118696756737,
    "itl": 19.28173649518128,
    "ttft": 7528.760249530396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.536504152864218,
    "arrivals": 6723,
    "finished_requests": 6709,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0397529560141265. Arrivals time: 0.03057524748146534 Scheduler time: 0.5501721622422338 Scheduler overhead time: 0.14902356546372175 Adapter cache time: 0.08142142137512565 Engine time: 0.15214251959696412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 0.8653611838817596,
    "estimated_duration": 3599.636942906097,
    "input_throughput": 293.24040639159983,
    "output_throughput": 249.432932887705,
    "total_throughput": 542.6733392793049,
    "itl": 18.50080638459436,
    "ttft": 4277.897216126934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48967803902924,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8654223731718957. Arrivals time: 0.024890916887670755 Scheduler time: 0.3881076602265239 Scheduler overhead time: 0.15227293502539396 Adapter cache time: 0.06225965032353997 Engine time: 0.1597275952808559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.8651575916446745,
    "estimated_duration": 3599.636942906097,
    "input_throughput": 293.24040639159983,
    "output_throughput": 249.432932887705,
    "total_throughput": 542.6733392793049,
    "itl": 18.50100737368465,
    "ttft": 4277.869128035206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5221277462574655,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8652106327936053. Arrivals time: 0.024361444171518087 Scheduler time: 0.38823850452899933 Scheduler overhead time: 0.15898308670148253 Adapter cache time: 0.062313868664205074 Engine time: 0.15369235025718808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.8607923649251461,
    "estimated_duration": 3599.636942906097,
    "input_throughput": 293.24040639159983,
    "output_throughput": 249.432932887705,
    "total_throughput": 542.6733392793049,
    "itl": 18.50101249190112,
    "ttft": 4277.877184660263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5230484977178294,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8608515812084079. Arrivals time: 0.024774760007858276 Scheduler time: 0.38787572644650936 Scheduler overhead time: 0.15244408464059234 Adapter cache time: 0.06334105413407087 Engine time: 0.1544294194318354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 0.8606631620787084,
    "estimated_duration": 3599.636942906097,
    "input_throughput": 293.24040639159983,
    "output_throughput": 249.432932887705,
    "total_throughput": 542.6733392793049,
    "itl": 18.500937261249653,
    "ttft": 4277.8801974073385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5004721943801271,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8607308911159635. Arrivals time: 0.025087368674576283 Scheduler time: 0.3900593384169042 Scheduler overhead time: 0.15184336807578802 Adapter cache time: 0.06261552451178432 Engine time: 0.15369944320991635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 0.8570493827573955,
    "estimated_duration": 3599.636942906097,
    "input_throughput": 293.24040639159983,
    "output_throughput": 249.432932887705,
    "total_throughput": 542.6733392793049,
    "itl": 18.501046675424416,
    "ttft": 4277.869788756869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5297134483978162,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8570958049967885. Arrivals time: 0.02488417038694024 Scheduler time: 0.38877198891714215 Scheduler overhead time: 0.15169330267235637 Adapter cache time: 0.061956074088811874 Engine time: 0.15282933041453362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 0.8625074429437518,
    "estimated_duration": 3599.636942906097,
    "input_throughput": 293.24040639159983,
    "output_throughput": 249.432932887705,
    "total_throughput": 542.6733392793049,
    "itl": 18.500719402595525,
    "ttft": 4277.965326082316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4784080471843487,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8625795962288976. Arrivals time: 0.02504020044580102 Scheduler time: 0.3887964552268386 Scheduler overhead time: 0.1515217088162899 Adapter cache time: 0.06224282132461667 Engine time: 0.15753555484116077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 160,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_160_slots_160_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [53 53 54]
Adapter prompts. [33, 135, 33, 33, 66, 33, 33, 33, 135, 33, 66, 135, 66, 33, 66, 66, 66, 66, 135, 135, 135, 66, 66, 66, 135, 135, 33, 135, 66, 135, 135, 135, 66, 135, 33, 66, 66, 66, 135, 33, 33, 135, 33, 135, 33, 33, 66, 33, 66, 135, 33, 33, 66, 33, 33, 33, 33, 33, 135, 66, 66, 135, 66, 33, 135, 135, 135, 66, 66, 33, 33, 33, 135, 33, 66, 66, 33, 135, 135, 135, 33, 33, 135, 66, 135, 135, 33, 135, 33, 66, 33, 33, 66, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 33, 135, 66, 135, 66, 135, 135, 135, 33, 66, 66, 135, 66, 135, 33, 33, 33, 66, 66, 66, 135, 135, 66, 135, 33, 66, 66, 33, 135, 135, 135, 135, 135, 135, 66, 66, 66, 66, 66, 135, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 66, 66, 135, 66, 33, 33]
Prompts retrieved: 12537 . Total input tokens: 2760590 . Total output tokens: 2526223
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 0.8650912721641362,
    "estimated_duration": 3599.636942906097,
    "input_throughput": 293.24040639159983,
    "output_throughput": 249.432932887705,
    "total_throughput": 542.6733392793049,
    "itl": 18.501118681674974,
    "ttft": 4277.865380659499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 160,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5365041528642178,
    "arrivals": 4238,
    "finished_requests": 4233,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8651384199038148. Arrivals time: 0.024834337644279003 Scheduler time: 0.3885350590571761 Scheduler overhead time: 0.15804892452433705 Adapter cache time: 0.06249726377427578 Engine time: 0.1530961594544351 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 103.94920619716868,
    "estimated_duration": 3600.0111345241858,
    "input_throughput": 7562.216610643403,
    "output_throughput": 6700.092332683299,
    "total_throughput": 14262.308943326701,
    "itl": 94.79265409812581,
    "ttft": 2013104.2055889277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2333765608049065,
    "arrivals": 1289329,
    "finished_requests": 110227,
    "scheduler_time": 296.51503279375055
}
#Debug simulation 
Total elapsed time: 103.94936655089259. Arrivals time: 0.5494469623081386 Scheduler time: 103.17756420746446 Scheduler overhead time: 0.0876187402755022 Adapter cache time: 0.01809901837259531 Engine time: 0.08311681961640716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.73024853272364,
    "estimated_duration": 3600.0726975876278,
    "input_throughput": 7815.751614920027,
    "output_throughput": 6921.246345024261,
    "total_throughput": 14736.997959944289,
    "itl": 100.91415743862811,
    "ttft": 2005014.5559125084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.383005204838706,
    "arrivals": 1289329,
    "finished_requests": 113888,
    "scheduler_time": 283.8073714983846
}
#Debug simulation 
Total elapsed time: 105.73040804965422. Arrivals time: 0.5871827322989702 Scheduler time: 104.92358326492831 Scheduler overhead time: 0.08677282789722085 Adapter cache time: 0.018117503728717566 Engine time: 0.08233768586069345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.82278384221718,
    "estimated_duration": 3600.0752633297866,
    "input_throughput": 7815.746044702197,
    "output_throughput": 6921.2414123125145,
    "total_throughput": 14736.987457014711,
    "itl": 100.91422585714815,
    "ttft": 2005015.6288637826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3855557853356084,
    "arrivals": 1289329,
    "finished_requests": 113888,
    "scheduler_time": 283.80738666002827
}
#Debug simulation 
Total elapsed time: 105.82295026397333. Arrivals time: 0.5946179949678481 Scheduler time: 105.00630163913593 Scheduler overhead time: 0.08762761205434799 Adapter cache time: 0.018097049556672573 Engine time: 0.08366402192041278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 105.82606272958219,
    "estimated_duration": 3600.01320668254,
    "input_throughput": 7815.880771706633,
    "output_throughput": 6921.360719940619,
    "total_throughput": 14737.241491647252,
    "itl": 100.91262288044048,
    "ttft": 2004988.9800024547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3241674789832885,
    "arrivals": 1289329,
    "finished_requests": 113888,
    "scheduler_time": 283.80661828055486
}
#Debug simulation 
Total elapsed time: 105.82622259994969. Arrivals time: 0.5909448014572263 Scheduler time: 105.01492040744051 Scheduler overhead time: 0.08766769943758845 Adapter cache time: 0.0182594396173954 Engine time: 0.08200926333665848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_192_slots_16_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 106.1595131168142,
    "estimated_duration": 3600.0932067867047,
    "input_throughput": 7815.707089737873,
    "output_throughput": 6921.206915706463,
    "total_throughput": 14736.914005444336,
    "itl": 100.91462132382414,
    "ttft": 2005023.2241338235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4036643305793453,
    "arrivals": 1289329,
    "finished_requests": 113888,
    "scheduler_time": 283.8075216874592
}
#Debug simulation 
Total elapsed time: 106.15968512697145. Arrivals time: 0.5799472904764116 Scheduler time: 105.3587656239979 Scheduler overhead time: 0.08749505784362555 Adapter cache time: 0.01792643591761589 Engine time: 0.08282958855852485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_192_slots_16_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_192_slots_16_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 103.35306444298476,
    "estimated_duration": 3600.072398606733,
    "input_throughput": 7562.464580028039,
    "output_throughput": 6700.375528374211,
    "total_throughput": 14262.84010840225,
    "itl": 94.79304075531978,
    "ttft": 2013080.514118478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.204990268845571,
    "arrivals": 1289329,
    "finished_requests": 110231,
    "scheduler_time": 296.52226006081673
}
#Debug simulation 
Total elapsed time: 103.35322869382799. Arrivals time: 0.5577189791947603 Scheduler time: 102.57293216558173 Scheduler overhead time: 0.08789855474606156 Adapter cache time: 0.01787693379446864 Engine time: 0.08329758327454329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_192_slots_16_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_192_slots_16_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 8640, 34560, 8640, 34560, 8640, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 17280, 34560, 17280, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 34560, 8640, 17280, 8640, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 8640, 34560, 8640, 17280, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 8640, 34560, 17280, 17280, 17280, 34560, 17280, 8640, 17280, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 17280, 8640, 17280, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 8640, 34560, 8640, 17280, 8640, 34560, 34560, 17280, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3870720 . Total input tokens: 862992993 . Total output tokens: 774449452
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 105.69907548232004,
    "estimated_duration": 3600.1110386610703,
    "input_throughput": 7815.668377402223,
    "output_throughput": 6921.172633960469,
    "total_throughput": 14736.841011362692,
    "itl": 100.91503259382583,
    "ttft": 2005030.8399473291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 424,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4210183531045923,
    "arrivals": 1289329,
    "finished_requests": 113888,
    "scheduler_time": 283.8076994235753
}
#Debug simulation 
Total elapsed time: 105.69924031710252. Arrivals time: 0.5970096150413156 Scheduler time: 104.87961469963193 Scheduler overhead time: 0.08858309732750058 Adapter cache time: 0.01806637831032276 Engine time: 0.08317853743210435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.66424279101193,
    "estimated_duration": 3600.032931360578,
    "input_throughput": 7770.0005898080235,
    "output_throughput": 6854.618407802664,
    "total_throughput": 14624.618997610687,
    "itl": 98.69569241440121,
    "ttft": 1988040.1814791528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2425580240367051,
    "arrivals": 1197398,
    "finished_requests": 112362,
    "scheduler_time": 288.31207543140886
}
#Debug simulation 
Total elapsed time: 107.66439709113911. Arrivals time: 0.5765703120268881 Scheduler time: 106.86518816137686 Scheduler overhead time: 0.0887817689217627 Adapter cache time: 0.017915320117026567 Engine time: 0.08280652249231935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.3136619720608,
    "estimated_duration": 3600.000234519585,
    "input_throughput": 7769.854771615801,
    "output_throughput": 6854.313720146998,
    "total_throughput": 14624.168491762799,
    "itl": 98.69771525169996,
    "ttft": 1988087.7314567328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.324281155709183,
    "arrivals": 1197398,
    "finished_requests": 112358,
    "scheduler_time": 288.30037771508097
}
#Debug simulation 
Total elapsed time: 107.31382000399753. Arrivals time: 0.5886415587738156 Scheduler time: 106.5001755701378 Scheduler overhead time: 0.0889861211180687 Adapter cache time: 0.018229521345347166 Engine time: 0.08383689122274518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.18903110036626,
    "estimated_duration": 3600.002709216238,
    "input_throughput": 7769.8494304993765,
    "output_throughput": 6854.309008387426,
    "total_throughput": 14624.158438886801,
    "itl": 98.69775274644735,
    "ttft": 1988088.815768037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3267254761234002,
    "arrivals": 1197398,
    "finished_requests": 112358,
    "scheduler_time": 288.3004080913019
}
#Debug simulation 
Total elapsed time: 107.18919122638181. Arrivals time: 0.5622247587889433 Scheduler time: 106.40430403128266 Scheduler overhead time: 0.08818341512233019 Adapter cache time: 0.01817407924681902 Engine time: 0.08294663717970252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 107.4198042419739,
    "estimated_duration": 3600.0012305329733,
    "input_throughput": 7769.8853996943935,
    "output_throughput": 6854.411823727844,
    "total_throughput": 14624.297223422238,
    "itl": 98.69638259406261,
    "ttft": 1988061.0024057613,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.268303597082848,
    "arrivals": 1197398,
    "finished_requests": 112359,
    "scheduler_time": 288.3061402167653
}
#Debug simulation 
Total elapsed time: 107.41995839122683. Arrivals time: 0.5752115678042173 Scheduler time: 106.62112544709817 Scheduler overhead time: 0.08873105840757489 Adapter cache time: 0.01839664438739419 Engine time: 0.0833167489618063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_192_slots_16_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 107.3914895709604,
    "estimated_duration": 3600.019461117987,
    "input_throughput": 7769.813275207533,
    "output_throughput": 6854.277113362328,
    "total_throughput": 14624.09038856986,
    "itl": 98.6981078001973,
    "ttft": 1988095.373009109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3439537448622332,
    "arrivals": 1197398,
    "finished_requests": 112358,
    "scheduler_time": 288.3005319558106
}
#Debug simulation 
Total elapsed time: 107.39165078895167. Arrivals time: 0.5823905295692384 Scheduler time: 106.58574615279213 Scheduler overhead time: 0.08864972088485956 Adapter cache time: 0.018357625231146812 Engine time: 0.0831228238530457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_192_slots_16_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_192_slots_16_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.5343378172256,
    "estimated_duration": 3600.0037094639038,
    "input_throughput": 7770.063660341479,
    "output_throughput": 6854.674048009458,
    "total_throughput": 14624.737708350936,
    "itl": 98.69506335882018,
    "ttft": 1988027.9400164871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2139604197302771,
    "arrivals": 1197398,
    "finished_requests": 112362,
    "scheduler_time": 288.3116512161387
}
#Debug simulation 
Total elapsed time: 107.53449816908687. Arrivals time: 0.5932658929377794 Scheduler time: 106.7177095413208 Scheduler overhead time: 0.08887489465996623 Adapter cache time: 0.018280346412211657 Engine time: 0.0832354980520904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_192_slots_16_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_192_slots_16_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 4320, 34560, 4320, 34560, 4320, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 17280, 34560, 17280, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 34560, 4320, 17280, 4320, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 4320, 34560, 4320, 17280, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 4320, 34560, 17280, 17280, 17280, 34560, 17280, 4320, 17280, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 17280, 4320, 17280, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 4320, 34560, 4320, 17280, 4320, 34560, 34560, 17280, 34560, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3594240 . Total input tokens: 801509885 . Total output tokens: 718996203
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.44877997785807,
    "estimated_duration": 3600.036815377905,
    "input_throughput": 7769.775820213039,
    "output_throughput": 6854.244071781734,
    "total_throughput": 14624.019891994774,
    "itl": 98.69850911263212,
    "ttft": 1988102.8054954805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3606789984554064,
    "arrivals": 1197398,
    "finished_requests": 112358,
    "scheduler_time": 288.30076080782896
}
#Debug simulation 
Total elapsed time: 107.44893852388486. Arrivals time: 0.5695442333817482 Scheduler time: 106.65554948709905 Scheduler overhead time: 0.08881130861118436 Adapter cache time: 0.017941767815500498 Engine time: 0.08367119496688247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.53495454182848,
    "estimated_duration": 3600.0596108148466,
    "input_throughput": 7766.111959927189,
    "output_throughput": 6883.600461935385,
    "total_throughput": 14649.712421862574,
    "itl": 102.9343311194262,
    "ttft": 1961302.6502081947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2517394872685037,
    "arrivals": 1127741,
    "finished_requests": 113429,
    "scheduler_time": 286.0188102480509
}
#Debug simulation 
Total elapsed time: 107.53511856123805. Arrivals time: 0.7070883577689528 Scheduler time: 106.60769582679495 Scheduler overhead time: 0.08756664022803307 Adapter cache time: 0.017973100766539574 Engine time: 0.0824006232433021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.45576520310715,
    "estimated_duration": 3600.0127398710097,
    "input_throughput": 7765.811962377032,
    "output_throughput": 6883.338418654564,
    "total_throughput": 14649.150381031595,
    "itl": 102.9350342937868,
    "ttft": 1961298.5947783215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.33325130659389,
    "arrivals": 1127741,
    "finished_requests": 113422,
    "scheduler_time": 286.01066517561014
}
#Debug simulation 
Total elapsed time: 107.45592849003151. Arrivals time: 0.9524949160404503 Scheduler time: 106.2815440618433 Scheduler overhead time: 0.08757840003818274 Adapter cache time: 0.01858661137521267 Engine time: 0.08268221467733383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.41920430213213,
    "estimated_duration": 3600.015354431683,
    "input_throughput": 7765.806322349266,
    "output_throughput": 6883.333419535349,
    "total_throughput": 14649.139741884615,
    "itl": 102.93510490537875,
    "ttft": 1961299.809119677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3358560326695519,
    "arrivals": 1127741,
    "finished_requests": 113422,
    "scheduler_time": 286.01067501018986
}
#Debug simulation 
Total elapsed time: 107.41936808498576. Arrivals time: 0.5948021640069783 Scheduler time: 106.59867047099397 Scheduler overhead time: 0.08942224970087409 Adapter cache time: 0.018392962403595448 Engine time: 0.08494008565321565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 64 128]
---Simulation End---
#Simulation results
{
    "duration": 106.87369586294517,
    "estimated_duration": 3600.086128025335,
    "input_throughput": 7766.054756955317,
    "output_throughput": 6883.549759292205,
    "total_throughput": 14649.604516247522,
    "itl": 102.93478352453148,
    "ttft": 1961313.231512649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2776823432859952,
    "arrivals": 1127741,
    "finished_requests": 113429,
    "scheduler_time": 286.0189844481532
}
#Debug simulation 
Total elapsed time: 106.87385976500809. Arrivals time: 0.7178510660305619 Scheduler time: 105.93238848727196 Scheduler overhead time: 0.08777563786134124 Adapter cache time: 0.01807348197326064 Engine time: 0.08440903481096029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_192_slots_16_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [64 64 64]
---Simulation End---
#Simulation results
{
    "duration": 107.36480023991317,
    "estimated_duration": 3600.03164927423,
    "input_throughput": 7765.771171938492,
    "output_throughput": 6883.302263466405,
    "total_throughput": 14649.073435404896,
    "itl": 102.93533106462336,
    "ttft": 1961305.7356369384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3529585476219699,
    "arrivals": 1127741,
    "finished_requests": 113422,
    "scheduler_time": 286.0108677236034
}
#Debug simulation 
Total elapsed time: 107.36496492289007. Arrivals time: 0.5920091876760125 Scheduler time: 106.5496481708251 Scheduler overhead time: 0.08806801028549671 Adapter cache time: 0.01814606972038746 Engine time: 0.08403564803302288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_192_slots_16_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_192_slots_16_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [16]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 106.98090105503798,
    "estimated_duration": 3600.0299494591363,
    "input_throughput": 7766.175946453013,
    "output_throughput": 6883.657177275183,
    "total_throughput": 14649.833123728196,
    "itl": 102.93388690355098,
    "ttft": 1961290.5171991112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2229305706149833,
    "arrivals": 1127741,
    "finished_requests": 113429,
    "scheduler_time": 286.0183579632512
}
#Debug simulation 
Total elapsed time: 106.98106434009969. Arrivals time: 0.5936825801618397 Scheduler time: 106.16651935176924 Scheduler overhead time: 0.08778420649468899 Adapter cache time: 0.01782438438385725 Engine time: 0.08265197044238448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_192_slots_16_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_192_slots_16_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [64 64 64]
Adapter prompts. [34560, 1080, 34560, 1080, 34560, 1080, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 17280, 34560, 17280, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 34560, 1080, 17280, 1080, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 1080, 34560, 1080, 17280, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 1080, 34560, 17280, 17280, 17280, 34560, 17280, 1080, 17280, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 17280, 1080, 17280, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 1080, 34560, 1080, 17280, 1080, 34560, 34560, 17280, 34560, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 3386880 . Total input tokens: 755191082 . Total output tokens: 677556911
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 107.01729897083715,
    "estimated_duration": 3600.0486084440154,
    "input_throughput": 7765.7345888125,
    "output_throughput": 6883.26983748985,
    "total_throughput": 14649.00442630235,
    "itl": 102.93566812783273,
    "ttft": 1961312.4525493677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.369809555001558,
    "arrivals": 1127741,
    "finished_requests": 113422,
    "scheduler_time": 286.0109758860252
}
#Debug simulation 
Total elapsed time: 107.01746342889965. Arrivals time: 0.5785003369674087 Scheduler time: 106.21494543598965 Scheduler overhead time: 0.08902312582358718 Adapter cache time: 0.018200681544840336 Engine time: 0.0837610112503171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_192_slots_16_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_192_slots_16_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [8]. Counts: [192]
---Simulation End---
#Simulation results
{
    "duration": 107.0550802280195,
    "estimated_duration": 3600.0314529384077,
    "input_throughput": 7961.30488710215,
    "output_throughput": 6986.467293076262,
    "total_throughput": 14947.772180178412,
    "itl": 105.78294632286662,
    "ttft": 1963772.5505409641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3037677789153623,
    "arrivals": 1116016,
    "finished_requests": 115401,
    "scheduler_time": 280.14748191000535
}
#Debug simulation 
Total elapsed time: 107.05524803698063. Arrivals time: 0.5930448961444199 Scheduler time: 106.24406749662012 Scheduler overhead time: 0.08587780687958002 Adapter cache time: 0.018005049787461758 Engine time: 0.08167229080572724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_192_slots_16_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_192_slots_16_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 109.61261420836672,
    "estimated_duration": 3600.042887386917,
    "input_throughput": 7923.94310077398,
    "output_throughput": 6979.88434749982,
    "total_throughput": 14903.827448273802,
    "itl": 105.17627432359743,
    "ttft": 1962907.720862823,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3520087990001828,
    "arrivals": 1116016,
    "finished_requests": 114902,
    "scheduler_time": 282.03006668862497
}
#Debug simulation 
Total elapsed time: 109.61277672415599. Arrivals time: 0.5849438603036106 Scheduler time: 108.80445601046085 Scheduler overhead time: 0.08835145644843578 Adapter cache time: 0.018434835132211447 Engine time: 0.08365603722631931 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_192_slots_16_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 192,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_192_slots_16_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [64 64 64]
Adapter prompts. [34560, 540, 34560, 540, 34560, 540, 34560, 540, 540, 540, 17280, 17280, 17280, 17280, 34560, 17280, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 540, 540, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 34560, 34560, 540, 17280, 34560, 540, 17280, 540, 17280, 540, 540, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 34560, 17280, 540, 540, 540, 540, 540, 34560, 540, 17280, 540, 34560, 34560, 540, 34560, 540, 17280, 17280, 34560, 540, 540, 540, 34560, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 17280, 540, 34560, 17280, 17280, 17280, 34560, 17280, 540, 17280, 34560, 34560, 17280, 34560, 17280, 540, 34560, 17280, 540, 17280, 17280, 540, 17280, 34560, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 34560, 34560, 540, 34560, 540, 34560, 540, 17280, 540, 34560, 34560, 17280, 34560, 540, 34560, 34560, 34560, 540, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 3352320 . Total input tokens: 747547103 . Total output tokens: 670674281
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [128  64]
---Simulation End---
#Simulation results
{
    "duration": 109.22097473824397,
    "estimated_duration": 3600.045920602201,
    "input_throughput": 7923.936424463218,
    "output_throughput": 6979.878466604868,
    "total_throughput": 14903.814891068087,
    "itl": 105.17633635391371,
    "ttft": 1962909.1826939727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3547916407510716,
    "arrivals": 1116016,
    "finished_requests": 114902,
    "scheduler_time": 282.030116984979
}
#Debug simulation 
Total elapsed time: 109.22114070504904. Arrivals time: 0.604238542728126 Scheduler time: 108.39430835004896 Scheduler overhead time: 0.08774760318920016 Adapter cache time: 0.018526131752878428 Engine time: 0.08364036772400141 
