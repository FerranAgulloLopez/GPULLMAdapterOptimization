INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.616826742887497,
    "estimated_duration": 3600.1314169155858,
    "input_throughput": 4100.73669273117,
    "output_throughput": 3615.18441767071,
    "total_throughput": 7715.92111040188,
    "itl": 236.2739227173892,
    "ttft": 1837630.2889286736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.379557961567887,
    "arrivals": 156118,
    "finished_requests": 59580,
    "scheduler_time": 68.5728713639496
}
#Debug simulation 
Total elapsed time: 4.616937627084553. Arrivals time: 0.20234483247622848 Scheduler time: 4.318271970842034 Scheduler overhead time: 0.02514939522370696 Adapter cache time: 0.033723640255630016 Engine time: 0.02565707638859749 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.647305776365101,
    "estimated_duration": 3600.084593455906,
    "input_throughput": 4100.658364204856,
    "output_throughput": 3614.8445021697216,
    "total_throughput": 7715.502866374578,
    "itl": 236.29208665589798,
    "ttft": 1837668.57180196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.677680885868557,
    "arrivals": 156118,
    "finished_requests": 59576,
    "scheduler_time": 68.56700677802378
}
#Debug simulation 
Total elapsed time: 4.647413446102291. Arrivals time: 0.1978813107125461 Scheduler time: 4.353232830762863 Scheduler overhead time: 0.02522259298712015 Adapter cache time: 0.03403667639940977 Engine time: 0.025343430694192648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.132841016631573,
    "estimated_duration": 3600.0798305466315,
    "input_throughput": 3701.2168138440416,
    "output_throughput": 3279.989487957286,
    "total_throughput": 6981.206301801328,
    "itl": 154.57735494292203,
    "ttft": 1937996.776913819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.120129008888814,
    "arrivals": 156118,
    "finished_requests": 53897,
    "scheduler_time": 71.91873906893454
}
#Debug simulation 
Total elapsed time: 4.132931937929243. Arrivals time: 0.18662821734324098 Scheduler time: 3.771753929555416 Scheduler overhead time: 0.035099273547530174 Adapter cache time: 0.08751014899462461 Engine time: 0.03549111681059003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.588400014676154,
    "estimated_duration": 3600.020329518806,
    "input_throughput": 4100.838508868448,
    "output_throughput": 3614.993474700603,
    "total_throughput": 7715.831983569051,
    "itl": 236.28041373346545,
    "ttft": 1837653.1700552898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1431,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.495726086096765,
    "arrivals": 156118,
    "finished_requests": 59577,
    "scheduler_time": 68.56866077647722
}
#Debug simulation 
Total elapsed time: 4.588489290792495. Arrivals time: 0.19856426306068897 Scheduler time: 4.293660975527018 Scheduler overhead time: 0.025160177145153284 Adapter cache time: 0.03417352167889476 Engine time: 0.025312697514891624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.137287789024413,
    "estimated_duration": 3600.0759150236313,
    "input_throughput": 3701.1969509850005,
    "output_throughput": 3279.960000488626,
    "total_throughput": 6981.156951473627,
    "itl": 154.58617521639442,
    "ttft": 1938056.9048387895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3086,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.21294279087288,
    "arrivals": 156118,
    "finished_requests": 53896,
    "scheduler_time": 71.91658689712712
}
#Debug simulation 
Total elapsed time: 4.13738154200837. Arrivals time: 0.18343242164701223 Scheduler time: 3.776928434614092 Scheduler overhead time: 0.03494766680523753 Adapter cache time: 0.09001655736938119 Engine time: 0.03561947541311383 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.603528149891645,
    "estimated_duration": 3600.216995677528,
    "input_throughput": 4100.959197105697,
    "output_throughput": 3615.264306464549,
    "total_throughput": 7716.223503570246,
    "itl": 236.26590109416594,
    "ttft": 1837568.6564957188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2817520222998,
    "arrivals": 156118,
    "finished_requests": 59584,
    "scheduler_time": 68.57626661275344
}
#Debug simulation 
Total elapsed time: 4.603621921967715. Arrivals time: 0.2013979940675199 Scheduler time: 4.3061076258309186 Scheduler overhead time: 0.025207951199263334 Adapter cache time: 0.03381867054849863 Engine time: 0.025390442926436663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.1199609958566725,
    "estimated_duration": 3600.118938726217,
    "input_throughput": 3700.824119081479,
    "output_throughput": 3279.284157255398,
    "total_throughput": 6980.108276336877,
    "itl": 154.59337518706897,
    "ttft": 1938142.5621527387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.389610499478312,
    "arrivals": 156118,
    "finished_requests": 53890,
    "scheduler_time": 71.91394963872217
}
#Debug simulation 
Total elapsed time: 4.120074537117034. Arrivals time: 0.1853539850562811 Scheduler time: 3.7573990947566926 Scheduler overhead time: 0.03507725754752755 Adapter cache time: 0.09021973796188831 Engine time: 0.03550163051113486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.472291074227542,
    "estimated_duration": 3600.167746859901,
    "input_throughput": 4078.7271684236403,
    "output_throughput": 3619.373017094881,
    "total_throughput": 7698.100185518521,
    "itl": 236.87092467129852,
    "ttft": 1839606.5238375138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9021218735143606,
    "arrivals": 155196,
    "finished_requests": 59481,
    "scheduler_time": 68.558921609581
}
#Debug simulation 
Total elapsed time: 4.4723798502236605. Arrivals time: 0.19736745348200202 Scheduler time: 4.1823383760638535 Scheduler overhead time: 0.02502934541553259 Adapter cache time: 0.030729896388947964 Engine time: 0.02530953288078308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.476847895886749,
    "estimated_duration": 3600.1009693502247,
    "input_throughput": 4078.671994205268,
    "output_throughput": 3619.300433774148,
    "total_throughput": 7697.972427979416,
    "itl": 236.88742932504255,
    "ttft": 1839689.1162626096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2141283595538575,
    "arrivals": 155196,
    "finished_requests": 59479,
    "scheduler_time": 68.55211514935267
}
#Debug simulation 
Total elapsed time: 4.4769423878751695. Arrivals time: 0.20060579013079405 Scheduler time: 4.182677575387061 Scheduler overhead time: 0.025039617903530598 Adapter cache time: 0.03153030760586262 Engine time: 0.025418612640351057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.1693255342543125,
    "estimated_duration": 3600.021341275906,
    "input_throughput": 3725.378471019499,
    "output_throughput": 3318.031441382096,
    "total_throughput": 7043.409912401595,
    "itl": 152.7162957353377,
    "ttft": 1933072.7041443116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.9410634183697235,
    "arrivals": 155196,
    "finished_requests": 54301,
    "scheduler_time": 72.72665185810015
}
#Debug simulation 
Total elapsed time: 4.169428148306906. Arrivals time: 0.19188053905963898 Scheduler time: 3.8056095093488693 Scheduler overhead time: 0.035626128781586885 Adapter cache time: 0.08360023377463222 Engine time: 0.036083363462239504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.504412788897753,
    "estimated_duration": 3600.080245587569,
    "input_throughput": 4078.6954729681265,
    "output_throughput": 3619.321268177287,
    "total_throughput": 7698.016741145414,
    "itl": 236.8781539756764,
    "ttft": 1839656.7412888068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1292,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.056819161954291,
    "arrivals": 155196,
    "finished_requests": 59479,
    "scheduler_time": 68.5543297327906
}
#Debug simulation 
Total elapsed time: 4.50450548902154. Arrivals time: 0.2006152058020234 Scheduler time: 4.209958089515567 Scheduler overhead time: 0.025264369789510965 Adapter cache time: 0.03140579164028168 Engine time: 0.025615517515689135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.132773125078529,
    "estimated_duration": 3600.1117832671357,
    "input_throughput": 3724.9490591734034,
    "output_throughput": 3317.5072661664003,
    "total_throughput": 7042.456325339804,
    "itl": 152.63564687051704,
    "ttft": 1933030.851844113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2426,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.027788387238825,
    "arrivals": 155196,
    "finished_requests": 54296,
    "scheduler_time": 72.73644520698981
}
#Debug simulation 
Total elapsed time: 4.132865412160754. Arrivals time: 0.18696822365745902 Scheduler time: 3.773600091226399 Scheduler overhead time: 0.035397759173065424 Adapter cache time: 0.08410197822377086 Engine time: 0.03615156374871731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.495017297100276,
    "estimated_duration": 3600.0322830214295,
    "input_throughput": 4078.7498126756645,
    "output_throughput": 3619.3694877270186,
    "total_throughput": 7698.119300402683,
    "itl": 236.86544373185285,
    "ttft": 1839609.3034433164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1291,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8601549307186085,
    "arrivals": 155196,
    "finished_requests": 59479,
    "scheduler_time": 68.55659407359155
}
#Debug simulation 
Total elapsed time: 4.495108956936747. Arrivals time: 0.20131880976259708 Scheduler time: 4.199975823517889 Scheduler overhead time: 0.025176782626658678 Adapter cache time: 0.03151621203869581 Engine time: 0.025548978708684444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.160080062691122,
    "estimated_duration": 3600.104651588512,
    "input_throughput": 3724.856163301537,
    "output_throughput": 3317.4077300031427,
    "total_throughput": 7042.263893304679,
    "itl": 152.67643980897026,
    "ttft": 1933087.6114341018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2427,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.145942346714094,
    "arrivals": 155196,
    "finished_requests": 54295,
    "scheduler_time": 72.72954320422154
}
#Debug simulation 
Total elapsed time: 4.160167685709894. Arrivals time: 0.18993346393108368 Scheduler time: 3.797815221361816 Scheduler overhead time: 0.03527145832777023 Adapter cache time: 0.08444959437474608 Engine time: 0.03617221489548683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.856916069984436,
    "estimated_duration": 3600.228996414449,
    "input_throughput": 4065.787208140951,
    "output_throughput": 3617.061029442615,
    "total_throughput": 7682.8482375835665,
    "itl": 237.51677203658386,
    "ttft": 1819936.4375984436,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.454568651954366,
    "arrivals": 146502,
    "finished_requests": 59210,
    "scheduler_time": 68.2701508614572
}
#Debug simulation 
Total elapsed time: 4.857010717969388. Arrivals time: 0.2030841070227325 Scheduler time: 4.542780950665474 Scheduler overhead time: 0.025425820611417294 Adapter cache time: 0.048509453888982534 Engine time: 0.02546754013746977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.833965879864991,
    "estimated_duration": 3600.043475220124,
    "input_throughput": 4065.476736806655,
    "output_throughput": 3616.5943799342313,
    "total_throughput": 7682.071116740886,
    "itl": 237.53863878266108,
    "ttft": 1820023.6192578524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.871382109604056,
    "arrivals": 146502,
    "finished_requests": 59200,
    "scheduler_time": 68.25940390577166
}
#Debug simulation 
Total elapsed time: 4.834060465916991. Arrivals time: 0.20091001875698566 Scheduler time: 4.522567272186279 Scheduler overhead time: 0.025443028192967176 Adapter cache time: 0.04817067040130496 Engine time: 0.025275531224906445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.147537681274116,
    "estimated_duration": 3600.124356333058,
    "input_throughput": 3688.121210769543,
    "output_throughput": 3294.591193533402,
    "total_throughput": 6982.712404302944,
    "itl": 154.41845902432635,
    "ttft": 1924173.7914679896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.043984282704672,
    "arrivals": 146502,
    "finished_requests": 53734,
    "scheduler_time": 71.8632142958997
}
#Debug simulation 
Total elapsed time: 4.147623921278864. Arrivals time: 0.18721126671880484 Scheduler time: 3.7605786565691233 Scheduler overhead time: 0.035276728216558695 Adapter cache time: 0.1123351831920445 Engine time: 0.03576966840773821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.885290357284248,
    "estimated_duration": 3600.193839935902,
    "input_throughput": 4065.8096899195325,
    "output_throughput": 3617.0485754266624,
    "total_throughput": 7682.858265346195,
    "itl": 237.52402914958222,
    "ttft": 1819979.5380042403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.595060737393581,
    "arrivals": 146502,
    "finished_requests": 59208,
    "scheduler_time": 68.26719134503399
}
#Debug simulation 
Total elapsed time: 4.8853804911486804. Arrivals time: 0.20267067663371563 Scheduler time: 4.572028057649732 Scheduler overhead time: 0.025361969135701656 Adapter cache time: 0.04795121913775802 Engine time: 0.025628359988331795 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_256_slots_160_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.165391413029283,
    "estimated_duration": 3600.0991778974276,
    "input_throughput": 3687.8550684134157,
    "output_throughput": 3294.1892470102093,
    "total_throughput": 6982.044315423625,
    "itl": 154.4368361083579,
    "ttft": 1924258.8470427557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.216427607851793,
    "arrivals": 146502,
    "finished_requests": 53727,
    "scheduler_time": 71.85699295751218
}
#Debug simulation 
Total elapsed time: 4.165479981806129. Arrivals time: 0.19026431161910295 Scheduler time: 3.770711116027087 Scheduler overhead time: 0.036561154294759035 Adapter cache time: 0.11482094181701541 Engine time: 0.03630523243919015 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_256_slots_160_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_256_slots_160_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.852747194934636,
    "estimated_duration": 3600.048800000242,
    "input_throughput": 4065.9907165700133,
    "output_throughput": 3617.2420773849303,
    "total_throughput": 7683.232793954943,
    "itl": 237.507358912716,
    "ttft": 1819862.1615026796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.303026021653599,
    "arrivals": 146502,
    "finished_requests": 59210,
    "scheduler_time": 68.26927028099294
}
#Debug simulation 
Total elapsed time: 4.852871262002736. Arrivals time: 0.2038730992935598 Scheduler time: 4.538119121920317 Scheduler overhead time: 0.025490802712738514 Adapter cache time: 0.04806065233424306 Engine time: 0.02558935945853591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_256_slots_160_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_256_slots_160_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.1687633018009365,
    "estimated_duration": 3600.0693192644403,
    "input_throughput": 3687.828989557517,
    "output_throughput": 3294.0471275211357,
    "total_throughput": 6981.876117078653,
    "itl": 154.4476769786561,
    "ttft": 1924415.6678254155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.435163716076733,
    "arrivals": 146502,
    "finished_requests": 53727,
    "scheduler_time": 71.85123448861968
}
#Debug simulation 
Total elapsed time: 4.168854086659849. Arrivals time: 0.18693021032959223 Scheduler time: 3.779069929383695 Scheduler overhead time: 0.036141093354672194 Adapter cache time: 0.11379342153668404 Engine time: 0.03622094262391329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.5669415751472116,
    "estimated_duration": 3600.216645466318,
    "input_throughput": 4101.212358593362,
    "output_throughput": 3612.645649082976,
    "total_throughput": 7713.858007676338,
    "itl": 235.75888815229305,
    "ttft": 1801299.351373312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.706308139222906,
    "arrivals": 142715,
    "finished_requests": 59476,
    "scheduler_time": 68.06409814135642
}
#Debug simulation 
Total elapsed time: 4.567030947189778. Arrivals time: 0.20890658302232623 Scheduler time: 4.239538158290088 Scheduler overhead time: 0.0253724604845047 Adapter cache time: 0.05555589031428099 Engine time: 0.025911880657076836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.554161758162081,
    "estimated_duration": 3600.1646120721507,
    "input_throughput": 4100.192238572054,
    "output_throughput": 3611.7123523737955,
    "total_throughput": 7711.904590945849,
    "itl": 235.79427182644204,
    "ttft": 1801547.1637838723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.206397680537453,
    "arrivals": 142715,
    "finished_requests": 59461,
    "scheduler_time": 68.05432548942963
}
#Debug simulation 
Total elapsed time: 4.554255999159068. Arrivals time: 0.1990063195116818 Scheduler time: 4.2369760614819825 Scheduler overhead time: 0.02530708722770214 Adapter cache time: 0.05587330274283886 Engine time: 0.0253156628459692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.271449331194162,
    "estimated_duration": 3600.0145938796422,
    "input_throughput": 3866.0090499803414,
    "output_throughput": 3418.959195589166,
    "total_throughput": 7284.968245569507,
    "itl": 147.38089551447027,
    "ttft": 1872592.2370384543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3484,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.378614411539706,
    "arrivals": 142715,
    "finished_requests": 56034,
    "scheduler_time": 74.24240977274277
}
#Debug simulation 
Total elapsed time: 4.27156594581902. Arrivals time: 0.19121182058006525 Scheduler time: 3.8900694139301777 Scheduler overhead time: 0.03669819002971053 Adapter cache time: 0.099215233232826 Engine time: 0.03724311292171478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.497429660987109,
    "estimated_duration": 3600.150300813728,
    "input_throughput": 4100.641019532766,
    "output_throughput": 3612.459456778913,
    "total_throughput": 7713.100476311679,
    "itl": 235.77896390344546,
    "ttft": 1801422.8281718602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2517,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.904315857144232,
    "arrivals": 142715,
    "finished_requests": 59469,
    "scheduler_time": 68.05913682364859
}
#Debug simulation 
Total elapsed time: 4.497522339224815. Arrivals time: 0.20134320110082626 Scheduler time: 4.178152846172452 Scheduler overhead time: 0.025275065563619137 Adapter cache time: 0.055647706147283316 Engine time: 0.02535348990932107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.2965434533543885,
    "estimated_duration": 3600.0457261666506,
    "input_throughput": 3865.7578426979594,
    "output_throughput": 3418.67741027417,
    "total_throughput": 7284.43525297213,
    "itl": 147.38694267046444,
    "ttft": 1872652.692957881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.530628665815373,
    "arrivals": 142715,
    "finished_requests": 56031,
    "scheduler_time": 74.24014569217
}
#Debug simulation 
Total elapsed time: 4.296631366945803. Arrivals time: 0.19163667224347591 Scheduler time: 3.9112221794202924 Scheduler overhead time: 0.03657052759081125 Adapter cache time: 0.10277035692706704 Engine time: 0.037286022678017616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.5467554070055485,
    "estimated_duration": 3600.032626140887,
    "input_throughput": 4101.321997136305,
    "output_throughput": 3612.8055911377187,
    "total_throughput": 7714.127588274024,
    "itl": 235.75072215234132,
    "ttft": 1801259.4929161505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2518,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.528946642563447,
    "arrivals": 142715,
    "finished_requests": 59475,
    "scheduler_time": 68.06348609294587
}
#Debug simulation 
Total elapsed time: 4.546848865225911. Arrivals time: 0.20229056244716048 Scheduler time: 4.226315810345113 Scheduler overhead time: 0.025389515329152346 Adapter cache time: 0.05574322585016489 Engine time: 0.025345082860440016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.299207322765142,
    "estimated_duration": 3600.019774407903,
    "input_throughput": 3865.773210173245,
    "output_throughput": 3418.5359445766117,
    "total_throughput": 7284.309154749857,
    "itl": 147.38982245798368,
    "ttft": 1872642.9305148108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.68863573349942,
    "arrivals": 142715,
    "finished_requests": 56028,
    "scheduler_time": 74.23746719158498
}
#Debug simulation 
Total elapsed time: 4.29929864872247. Arrivals time: 0.20080929528921843 Scheduler time: 3.9070030814036727 Scheduler overhead time: 0.03664612537249923 Adapter cache time: 0.10014658188447356 Engine time: 0.03751169145107269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.412846934981644,
    "estimated_duration": 3600.260082877802,
    "input_throughput": 4161.831827444831,
    "output_throughput": 3654.1993348113724,
    "total_throughput": 7816.031162256203,
    "itl": 233.03510572160195,
    "ttft": 1782594.7778344196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.874634965139213,
    "arrivals": 140795,
    "finished_requests": 60088,
    "scheduler_time": 68.76195444370533
}
#Debug simulation 
Total elapsed time: 4.412939418107271. Arrivals time: 0.2151244943961501 Scheduler time: 4.078022907022387 Scheduler overhead time: 0.02495858259499073 Adapter cache time: 0.05789436399936676 Engine time: 0.02532947715371847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.3890919191762805,
    "estimated_duration": 3600.0867074833004,
    "input_throughput": 4161.484491153605,
    "output_throughput": 3653.7114432989015,
    "total_throughput": 7815.195934452507,
    "itl": 233.06473354948534,
    "ttft": 1782662.7507920119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.385151282902527,
    "arrivals": 140795,
    "finished_requests": 60078,
    "scheduler_time": 68.74988535753242
}
#Debug simulation 
Total elapsed time: 4.389175176154822. Arrivals time: 0.19223888777196407 Scheduler time: 4.076866528019309 Scheduler overhead time: 0.024982711300253868 Adapter cache time: 0.0581307839602232 Engine time: 0.02541327429935336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.395648878999054,
    "estimated_duration": 3600.0598181503624,
    "input_throughput": 3989.8412041885904,
    "output_throughput": 3514.734931960377,
    "total_throughput": 7504.576136148967,
    "itl": 142.7809941566393,
    "ttft": 1833459.6026995862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.244370395168577,
    "arrivals": 140795,
    "finished_requests": 57580,
    "scheduler_time": 76.35478593553962
}
#Debug simulation 
Total elapsed time: 4.395742438733578. Arrivals time: 0.1972234626300633 Scheduler time: 4.0161167941987514 Scheduler overhead time: 0.03770639840513468 Adapter cache time: 0.08860445953905582 Engine time: 0.038351789116859436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.446771975141019,
    "estimated_duration": 3600.2024326923024,
    "input_throughput": 4161.892638018948,
    "output_throughput": 3654.135356539372,
    "total_throughput": 7816.02799455832,
    "itl": 233.04756839066647,
    "ttft": 1782594.1161607509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.071628790592952,
    "arrivals": 140795,
    "finished_requests": 60086,
    "scheduler_time": 68.75767413438444
}
#Debug simulation 
Total elapsed time: 4.446893624961376. Arrivals time: 0.20227142982184887 Scheduler time: 4.124313612468541 Scheduler overhead time: 0.02511416282504797 Adapter cache time: 0.0580743127502501 Engine time: 0.025436934549361467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.37635158514604,
    "estimated_duration": 3600.0838216528805,
    "input_throughput": 3990.7340250216157,
    "output_throughput": 3515.267317911971,
    "total_throughput": 7506.001342933587,
    "itl": 142.98718875201703,
    "ttft": 1833150.454076735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2521,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.32870920360066,
    "arrivals": 140795,
    "finished_requests": 57592,
    "scheduler_time": 76.31985028661111
}
#Debug simulation 
Total elapsed time: 4.37644670298323. Arrivals time: 0.19337230874225497 Scheduler time: 4.000964450184256 Scheduler overhead time: 0.03822123073041439 Adapter cache time: 0.08770754653960466 Engine time: 0.03844713047146797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.454085513949394,
    "estimated_duration": 3600.2505097114563,
    "input_throughput": 4162.1184302536085,
    "output_throughput": 3654.2857127612547,
    "total_throughput": 7816.404143014864,
    "itl": 233.02368285629942,
    "ttft": 1782549.7532768438,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.693399408783061,
    "arrivals": 140795,
    "finished_requests": 60090,
    "scheduler_time": 68.76409731063453
}
#Debug simulation 
Total elapsed time: 4.454174996353686. Arrivals time: 0.19972663931548595 Scheduler time: 4.1342000984586775 Scheduler overhead time: 0.02513071335852146 Adapter cache time: 0.05822827946394682 Engine time: 0.025308565236628056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.39822042407468,
    "estimated_duration": 3600.061225384381,
    "input_throughput": 3991.398784743107,
    "output_throughput": 3515.6979861220643,
    "total_throughput": 7507.0967708651715,
    "itl": 143.07085115047457,
    "ttft": 1833217.4293153468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.465838785022115,
    "arrivals": 140795,
    "finished_requests": 57601,
    "scheduler_time": 76.30582324084295
}
#Debug simulation 
Total elapsed time: 4.398309228010476. Arrivals time: 0.19442452583462 Scheduler time: 4.022340531460941 Scheduler overhead time: 0.03758476208895445 Adapter cache time: 0.08804790209978819 Engine time: 0.038270467426627874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.526742497924715,
    "estimated_duration": 3600.1616507019758,
    "input_throughput": 4222.548450577455,
    "output_throughput": 3720.0549029204317,
    "total_throughput": 7942.603353497887,
    "itl": 229.1574608795272,
    "ttft": 1761387.294989631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.353572556404582,
    "arrivals": 139799,
    "finished_requests": 61287,
    "scheduler_time": 69.88452653634272
}
#Debug simulation 
Total elapsed time: 4.5268622022122145. Arrivals time: 0.2038213280029595 Scheduler time: 4.206920207943767 Scheduler overhead time: 0.025102132465690374 Adapter cache time: 0.0534959533251822 Engine time: 0.025756108574569225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.461244851350784,
    "estimated_duration": 3600.0181988071313,
    "input_throughput": 4222.191711429826,
    "output_throughput": 3719.309809166145,
    "total_throughput": 7941.501520595971,
    "itl": 229.18563482318186,
    "ttft": 1761554.388557851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.780195048670033,
    "arrivals": 139799,
    "finished_requests": 61276,
    "scheduler_time": 69.87434802339826
}
#Debug simulation 
Total elapsed time: 4.461337447166443. Arrivals time: 0.19980484014376998 Scheduler time: 4.1452371552586555 Scheduler overhead time: 0.025028495118021965 Adapter cache time: 0.054032628424465656 Engine time: 0.025502063799649477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.4783221539109945,
    "estimated_duration": 3600.0834626266414,
    "input_throughput": 4032.6870614848403,
    "output_throughput": 3567.56006724058,
    "total_throughput": 7600.24712872542,
    "itl": 141.63166654190744,
    "ttft": 1814552.9642191052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1960,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.408102903906206,
    "arrivals": 139799,
    "finished_requests": 58503,
    "scheduler_time": 77.15119462157482
}
#Debug simulation 
Total elapsed time: 4.478414430748671. Arrivals time: 0.20154670672491193 Scheduler time: 4.098146610427648 Scheduler overhead time: 0.03815442696213722 Adapter cache time: 0.08336690999567509 Engine time: 0.03915449231863022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.471799442078918,
    "estimated_duration": 3600.0985763557164,
    "input_throughput": 4222.344660180784,
    "output_throughput": 3719.831475713679,
    "total_throughput": 7942.176135894462,
    "itl": 229.16489987660685,
    "ttft": 1761462.3166242414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.513809847167944,
    "arrivals": 139799,
    "finished_requests": 61283,
    "scheduler_time": 69.88042483499552
}
#Debug simulation 
Total elapsed time: 4.47189003508538. Arrivals time: 0.20517683867365122 Scheduler time: 4.151475140359253 Scheduler overhead time: 0.02501028496772051 Adapter cache time: 0.05311264330521226 Engine time: 0.0254332241602242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.423253559973091,
    "estimated_duration": 3600.0023194967225,
    "input_throughput": 4032.871012713584,
    "output_throughput": 3568.1590899074126,
    "total_throughput": 7601.030102620997,
    "itl": 141.75847184882804,
    "ttft": 1814464.2896939858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1959,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.478499596323713,
    "arrivals": 139799,
    "finished_requests": 58508,
    "scheduler_time": 77.12856259741574
}
#Debug simulation 
Total elapsed time: 4.4233718840405345. Arrivals time: 0.19791368721053004 Scheduler time: 4.048432148061693 Scheduler overhead time: 0.03778240876272321 Adapter cache time: 0.08281400706619024 Engine time: 0.03863050742074847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.480532112997025,
    "estimated_duration": 3600.214502248893,
    "input_throughput": 4222.619788488652,
    "output_throughput": 3720.037512107691,
    "total_throughput": 7942.657300596343,
    "itl": 229.1476036314116,
    "ttft": 1761341.6863408443,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.207344412216733,
    "arrivals": 139799,
    "finished_requests": 61289,
    "scheduler_time": 69.88832095020214
}
#Debug simulation 
Total elapsed time: 4.480621112044901. Arrivals time: 0.19862063974142075 Scheduler time: 4.165937220212072 Scheduler overhead time: 0.025085998699069023 Adapter cache time: 0.0536895957775414 Engine time: 0.025561396963894367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.438005397096276,
    "estimated_duration": 3600.0249832091995,
    "input_throughput": 4032.8445129449624,
    "output_throughput": 3567.7055186851844,
    "total_throughput": 7600.550031630147,
    "itl": 141.74042941524584,
    "ttft": 1814552.5245759592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1961,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.577187146879542,
    "arrivals": 139799,
    "finished_requests": 58504,
    "scheduler_time": 77.13033391418658
}
#Debug simulation 
Total elapsed time: 4.4380932450294495. Arrivals time: 0.19380670553073287 Scheduler time: 4.067421035841107 Scheduler overhead time: 0.03796649258583784 Adapter cache time: 0.0823672953993082 Engine time: 0.03879845840856433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.551640913821757,
    "estimated_duration": 3600.2454787396605,
    "input_throughput": 4273.832462498218,
    "output_throughput": 3773.7240641591397,
    "total_throughput": 8047.5565266573585,
    "itl": 226.3228752323228,
    "ttft": 1725895.2432957157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2933,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.976410552954759,
    "arrivals": 135085,
    "finished_requests": 62032,
    "scheduler_time": 70.55836224826515
}
#Debug simulation 
Total elapsed time: 4.5517333671450615. Arrivals time: 0.201345419511199 Scheduler time: 4.220349348150194 Scheduler overhead time: 0.02545803878456354 Adapter cache time: 0.06690856628119946 Engine time: 0.025811477564275265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.541024243924767,
    "estimated_duration": 3600.0375054279857,
    "input_throughput": 4272.932428289034,
    "output_throughput": 3773.2390230709852,
    "total_throughput": 8046.17145136002,
    "itl": 226.36596557576186,
    "ttft": 1726033.1329679468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2934,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.576514556615075,
    "arrivals": 135085,
    "finished_requests": 62016,
    "scheduler_time": 70.54356436187992
}
#Debug simulation 
Total elapsed time: 4.541138498578221. Arrivals time: 0.1996291233226657 Scheduler time: 4.210194168612361 Scheduler overhead time: 0.025598585605621338 Adapter cache time: 0.06776932207867503 Engine time: 0.026051125023514032 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.524023205041885,
    "estimated_duration": 3600.064651308748,
    "input_throughput": 4138.281237417232,
    "output_throughput": 3666.588319518473,
    "total_throughput": 7804.869556935704,
    "itl": 137.99909950333154,
    "ttft": 1767043.935940656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.32019491851304,
    "arrivals": 135085,
    "finished_requests": 60015,
    "scheduler_time": 78.76711073630824
}
#Debug simulation 
Total elapsed time: 4.524112441111356. Arrivals time: 0.19811864802613854 Scheduler time: 4.142282583285123 Scheduler overhead time: 0.03885774128139019 Adapter cache time: 0.08699504379183054 Engine time: 0.03948826156556606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.525641791988164,
    "estimated_duration": 3600.0206300386876,
    "input_throughput": 4273.440232989629,
    "output_throughput": 3773.618930582075,
    "total_throughput": 8047.059163571704,
    "itl": 226.3424656438646,
    "ttft": 1725946.977414979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.198174237860318,
    "arrivals": 135085,
    "finished_requests": 62023,
    "scheduler_time": 70.55032659587926
}
#Debug simulation 
Total elapsed time: 4.525730449240655. Arrivals time: 0.1999823935329914 Scheduler time: 4.195341509766877 Scheduler overhead time: 0.02560037514194846 Adapter cache time: 0.06704898970201612 Engine time: 0.025754884351044893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.52330511296168,
    "estimated_duration": 3600.0226109585224,
    "input_throughput": 4138.11039815484,
    "output_throughput": 3666.3778054676427,
    "total_throughput": 7804.4882036224835,
    "itl": 138.004906327274,
    "ttft": 1766874.7729655597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.447630616295708,
    "arrivals": 135085,
    "finished_requests": 60012,
    "scheduler_time": 78.76281996095146
}
#Debug simulation 
Total elapsed time: 4.523394650314003. Arrivals time: 0.19831927679479122 Scheduler time: 4.1410754094831645 Scheduler overhead time: 0.03884551813825965 Adapter cache time: 0.08738597109913826 Engine time: 0.03959571523591876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.577590859960765,
    "estimated_duration": 3600.1201385539307,
    "input_throughput": 4273.981258353359,
    "output_throughput": 3773.8554484621327,
    "total_throughput": 8047.836706815492,
    "itl": 226.30685312499625,
    "ttft": 1725836.97213705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.766827464653131,
    "arrivals": 135085,
    "finished_requests": 62032,
    "scheduler_time": 70.56073521740682
}
#Debug simulation 
Total elapsed time: 4.577707900200039. Arrivals time: 0.20174728240817785 Scheduler time: 4.244419534690678 Scheduler overhead time: 0.025916466489434242 Adapter cache time: 0.06764675304293633 Engine time: 0.026036606170237064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.549083416815847,
    "estimated_duration": 3600.0152007167003,
    "input_throughput": 4138.119193784018,
    "output_throughput": 3666.4411854072896,
    "total_throughput": 7804.560379191307,
    "itl": 138.01016138909245,
    "ttft": 1767048.6778435665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2855,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.57774577137034,
    "arrivals": 135085,
    "finished_requests": 60013,
    "scheduler_time": 78.76131572361668
}
#Debug simulation 
Total elapsed time: 4.54917426686734. Arrivals time: 0.19752914318814874 Scheduler time: 4.167729036416858 Scheduler overhead time: 0.03897799691185355 Adapter cache time: 0.08698013424873352 Engine time: 0.039641054812818766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.661262691020966,
    "estimated_duration": 3600.055174562484,
    "input_throughput": 4447.048510012254,
    "output_throughput": 3899.91300666837,
    "total_throughput": 8346.961516680623,
    "itl": 218.53636123646123,
    "ttft": 1667050.6506925083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.564746210735949,
    "arrivals": 133166,
    "finished_requests": 64656,
    "scheduler_time": 72.57923736016649
}
#Debug simulation 
Total elapsed time: 4.661352828145027. Arrivals time: 0.20561765506863594 Scheduler time: 4.334261333569884 Scheduler overhead time: 0.026260253973305225 Adapter cache time: 0.056421840097755194 Engine time: 0.026547004468739033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.659448673017323,
    "estimated_duration": 3600.1806417213734,
    "input_throughput": 4446.666596247689,
    "output_throughput": 3899.469609193709,
    "total_throughput": 8346.136205441398,
    "itl": 218.5620882084544,
    "ttft": 1667218.779051662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.009909389114208,
    "arrivals": 133166,
    "finished_requests": 64651,
    "scheduler_time": 72.57372172922437
}
#Debug simulation 
Total elapsed time: 4.659539257641882. Arrivals time: 0.2074064570479095 Scheduler time: 4.330582430586219 Scheduler overhead time: 0.026143471710383892 Adapter cache time: 0.05655373400077224 Engine time: 0.02660289965569973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.6290707108564675,
    "estimated_duration": 3600.141471625647,
    "input_throughput": 4260.4289639412555,
    "output_throughput": 3749.2190533015623,
    "total_throughput": 8009.648017242817,
    "itl": 134.71132338759787,
    "ttft": 1721061.2277667376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.673867620639453,
    "arrivals": 133166,
    "finished_requests": 61895,
    "scheduler_time": 80.21120902098335
}
#Debug simulation 
Total elapsed time: 4.629188919905573. Arrivals time: 0.2051384369842708 Scheduler time: 4.250849459785968 Scheduler overhead time: 0.03989310283213854 Adapter cache time: 0.07400951301679015 Engine time: 0.04051222838461399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.672728312667459,
    "estimated_duration": 3600.223826398234,
    "input_throughput": 4446.840188826948,
    "output_throughput": 3899.730315947027,
    "total_throughput": 8346.570504773976,
    "itl": 218.54557881039784,
    "ttft": 1667108.5962945397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.734405207540615,
    "arrivals": 133166,
    "finished_requests": 64656,
    "scheduler_time": 72.57986055085065
}
#Debug simulation 
Total elapsed time: 4.672821220941842. Arrivals time: 0.21116819884628057 Scheduler time: 4.338998112827539 Scheduler overhead time: 0.0263240491040051 Adapter cache time: 0.057121398858726025 Engine time: 0.026915247552096844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.643533993978053,
    "estimated_duration": 3600.087744222787,
    "input_throughput": 4260.379771191167,
    "output_throughput": 3749.2744507853613,
    "total_throughput": 8009.654221976528,
    "itl": 134.71563644610268,
    "ttft": 1721076.9975445885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2040,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.741698381379121,
    "arrivals": 133166,
    "finished_requests": 61894,
    "scheduler_time": 80.20966581932187
}
#Debug simulation 
Total elapsed time: 4.643622888252139. Arrivals time: 0.20355790946632624 Scheduler time: 4.266219248063862 Scheduler overhead time: 0.03985290927812457 Adapter cache time: 0.0746158785186708 Engine time: 0.040710363537073135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.6632563401944935,
    "estimated_duration": 3600.067868128906,
    "input_throughput": 4447.056718494827,
    "output_throughput": 3900.1367513933906,
    "total_throughput": 8347.193469888218,
    "itl": 218.5250637613096,
    "ttft": 1667004.077916219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.425618083744584,
    "arrivals": 133166,
    "finished_requests": 64658,
    "scheduler_time": 72.58252738245753
}
#Debug simulation 
Total elapsed time: 4.66334885917604. Arrivals time: 0.2080135317519307 Scheduler time: 4.333639300893992 Scheduler overhead time: 0.026253023650497198 Adapter cache time: 0.05646484065800905 Engine time: 0.026740744709968567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.6045349459163845,
    "estimated_duration": 3600.125088252869,
    "input_throughput": 4261.346376563024,
    "output_throughput": 3750.263857235084,
    "total_throughput": 8011.610233798107,
    "itl": 134.98129415404895,
    "ttft": 1720643.3597047632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2042,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.840843221023456,
    "arrivals": 133166,
    "finished_requests": 61911,
    "scheduler_time": 80.17531366191189
}
#Debug simulation 
Total elapsed time: 4.60465185996145. Arrivals time: 0.20016235951334238 Scheduler time: 4.230449141468853 Scheduler overhead time: 0.039680544286966324 Adapter cache time: 0.07520380197092891 Engine time: 0.04053880088031292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.777054964099079,
    "estimated_duration": 3600.0454064480914,
    "input_throughput": 4534.288642793919,
    "output_throughput": 4004.4775474716967,
    "total_throughput": 8538.766190265616,
    "itl": 213.33649226833552,
    "ttft": 1636805.9681159586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.8906594148046745,
    "arrivals": 132222,
    "finished_requests": 66112,
    "scheduler_time": 74.34796802874268
}
#Debug simulation 
Total elapsed time: 4.777145012281835. Arrivals time: 0.20652116369456053 Scheduler time: 4.451484060846269 Scheduler overhead time: 0.026761445682495832 Adapter cache time: 0.05227665137499571 Engine time: 0.02759096771478653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.7717236848548055,
    "estimated_duration": 3600.012471671794,
    "input_throughput": 4534.120958869868,
    "output_throughput": 4004.256127842165,
    "total_throughput": 8538.377086712033,
    "itl": 213.35106485680183,
    "ttft": 1636880.1572271213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.205101425144719,
    "arrivals": 132222,
    "finished_requests": 66109,
    "scheduler_time": 74.34146250976282
}
#Debug simulation 
Total elapsed time: 4.771812913008034. Arrivals time: 0.20925426622852683 Scheduler time: 4.4440824538469315 Scheduler overhead time: 0.026822279673069715 Adapter cache time: 0.05186929181218147 Engine time: 0.027299655601382256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.688883597031236,
    "estimated_duration": 3600.00623553288,
    "input_throughput": 4306.59031836513,
    "output_throughput": 3822.50532351177,
    "total_throughput": 8129.0956418769,
    "itl": 132.8272083763851,
    "ttft": 1700165.4789138003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.010373043175731,
    "arrivals": 132222,
    "finished_requests": 62837,
    "scheduler_time": 81.33203245414032
}
#Debug simulation 
Total elapsed time: 4.688977392856032. Arrivals time: 0.20389735652133822 Scheduler time: 4.315292976796627 Scheduler overhead time: 0.04013658128678799 Adapter cache time: 0.06970247020944953 Engine time: 0.040949433110654354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.798607198987156,
    "estimated_duration": 3600.176340339899,
    "input_throughput": 4534.123736410883,
    "output_throughput": 4004.331909652773,
    "total_throughput": 8538.455646063656,
    "itl": 213.3421658627235,
    "ttft": 1636845.9555363308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.018763013814932,
    "arrivals": 132222,
    "finished_requests": 66112,
    "scheduler_time": 74.3485587231908
}
#Debug simulation 
Total elapsed time: 4.798724866006523. Arrivals time: 0.20919268345460296 Scheduler time: 4.47091854037717 Scheduler overhead time: 0.026766230817884207 Adapter cache time: 0.051813280675560236 Engine time: 0.027495207265019417 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.674497013911605,
    "estimated_duration": 3600.098812417521,
    "input_throughput": 4306.51457302332,
    "output_throughput": 3822.5698007324577,
    "total_throughput": 8129.084373755777,
    "itl": 132.83685615107163,
    "ttft": 1700163.082735121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.071812044978098,
    "arrivals": 132222,
    "finished_requests": 62838,
    "scheduler_time": 81.33188522711536
}
#Debug simulation 
Total elapsed time: 4.674588365945965. Arrivals time: 0.2034700158983469 Scheduler time: 4.300933519843966 Scheduler overhead time: 0.04009318631142378 Adapter cache time: 0.07015298958867788 Engine time: 0.041111255530267954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.802315479144454,
    "estimated_duration": 3600.0662019883507,
    "input_throughput": 4534.289394729531,
    "output_throughput": 4004.5199702265504,
    "total_throughput": 8538.809364956081,
    "itl": 213.3271060484247,
    "ttft": 1636774.482113824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.7691302203688375,
    "arrivals": 132222,
    "finished_requests": 66113,
    "scheduler_time": 74.35058275205124
}
#Debug simulation 
Total elapsed time: 4.802406346891075. Arrivals time: 0.22029241221025586 Scheduler time: 4.463633839506656 Scheduler overhead time: 0.026620961725711823 Adapter cache time: 0.05190987093374133 Engine time: 0.027363209519535303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.689334741793573,
    "estimated_duration": 3600.111794160048,
    "input_throughput": 4306.649872693018,
    "output_throughput": 3822.6971235516544,
    "total_throughput": 8129.346996244672,
    "itl": 132.8296066811936,
    "ttft": 1700210.8363641556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.146112234666892,
    "arrivals": 132222,
    "finished_requests": 62840,
    "scheduler_time": 81.33330282428044
}
#Debug simulation 
Total elapsed time: 4.6894240328110754. Arrivals time: 0.20197400962933898 Scheduler time: 4.31906322715804 Scheduler overhead time: 0.03999332245439291 Adapter cache time: 0.06842339085415006 Engine time: 0.04109997907653451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.00094350008294,
    "estimated_duration": 3600.1163087995383,
    "input_throughput": 4781.971615172782,
    "output_throughput": 4180.576045060783,
    "total_throughput": 8962.547660233566,
    "itl": 203.161822531058,
    "ttft": 1567583.8694419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.260978431820551,
    "arrivals": 129353,
    "finished_requests": 69186,
    "scheduler_time": 77.07353660931028
}
#Debug simulation 
Total elapsed time: 5.0010611563920975. Arrivals time: 0.2160903261974454 Scheduler time: 4.665229732170701 Scheduler overhead time: 0.028234280180186033 Adapter cache time: 0.049422747921198606 Engine time: 0.02884416887536645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.94268686324358,
    "estimated_duration": 3600.212274381785,
    "input_throughput": 4781.400286447258,
    "output_throughput": 4180.106575128047,
    "total_throughput": 8961.506861575304,
    "itl": 203.1814576508529,
    "ttft": 1567682.1958542692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.605695119958698,
    "arrivals": 129353,
    "finished_requests": 69182,
    "scheduler_time": 77.0692461220494
}
#Debug simulation 
Total elapsed time: 4.942778803873807. Arrivals time: 0.21477587847039104 Scheduler time: 4.609177737496793 Scheduler overhead time: 0.027931228280067444 Adapter cache time: 0.049145618453621864 Engine time: 0.02871833136305213 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.867212411947548,
    "estimated_duration": 3600.0153211788365,
    "input_throughput": 4511.401355559175,
    "output_throughput": 3958.7403742863216,
    "total_throughput": 8470.141729845496,
    "itl": 127.81419808049657,
    "ttft": 1641418.294310738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.270387969706152,
    "arrivals": 129353,
    "finished_requests": 65288,
    "scheduler_time": 83.6033520640333
}
#Debug simulation 
Total elapsed time: 4.867303098086268. Arrivals time: 0.22892045369371772 Scheduler time: 4.474142337683588 Scheduler overhead time: 0.0417312141507864 Adapter cache time: 0.060241265688091516 Engine time: 0.04261233005672693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.982516559772193,
    "estimated_duration": 3600.0951697422056,
    "input_throughput": 4781.99941620787,
    "output_throughput": 4180.570593381765,
    "total_throughput": 8962.570009589635,
    "itl": 203.17039968549255,
    "ttft": 1567605.8823802634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1718,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.395955838532986,
    "arrivals": 129353,
    "finished_requests": 69185,
    "scheduler_time": 77.07077696893698
}
#Debug simulation 
Total elapsed time: 4.982609255705029. Arrivals time: 0.21917938068509102 Scheduler time: 4.644102816004306 Scheduler overhead time: 0.02807229571044445 Adapter cache time: 0.04950933763757348 Engine time: 0.028612373396754265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.868389580864459,
    "estimated_duration": 3600.0511299046784,
    "input_throughput": 4510.976487278389,
    "output_throughput": 3958.4343348971615,
    "total_throughput": 8469.41082217555,
    "itl": 127.81492237427949,
    "ttft": 1641441.882439222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.330121018253205,
    "arrivals": 129353,
    "finished_requests": 65284,
    "scheduler_time": 83.60329184051221
}
#Debug simulation 
Total elapsed time: 4.868510127067566. Arrivals time: 0.21375632379204035 Scheduler time: 4.489587494637817 Scheduler overhead time: 0.041665028780698776 Adapter cache time: 0.06113923666998744 Engine time: 0.042607801500707865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.970551787875593,
    "estimated_duration": 3600.132801262733,
    "input_throughput": 4782.138035008441,
    "output_throughput": 4180.696610614168,
    "total_throughput": 8962.834645622608,
    "itl": 203.15291879108176,
    "ttft": 1567535.5216551474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1719,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.139896456936694,
    "arrivals": 129353,
    "finished_requests": 69189,
    "scheduler_time": 77.0761855092432
}
#Debug simulation 
Total elapsed time: 4.970644206739962. Arrivals time: 0.2169949826784432 Scheduler time: 4.635211147367954 Scheduler overhead time: 0.027889409102499485 Adapter cache time: 0.048800764605402946 Engine time: 0.02860277332365513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.874723093118519,
    "estimated_duration": 3600.07341909373,
    "input_throughput": 4511.384660618542,
    "output_throughput": 3958.5451020017003,
    "total_throughput": 8469.929762620242,
    "itl": 127.81447573967911,
    "ttft": 1641395.5646585552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.40765079252414,
    "arrivals": 129353,
    "finished_requests": 65287,
    "scheduler_time": 83.60305661227125
}
#Debug simulation 
Total elapsed time: 4.874815862160176. Arrivals time: 0.21108048455789685 Scheduler time: 4.499384716153145 Scheduler overhead time: 0.041916425339877605 Adapter cache time: 0.06027708109468222 Engine time: 0.042620797641575336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.097125650849193,
    "estimated_duration": 3600.1067036582986,
    "input_throughput": 4880.580062292426,
    "output_throughput": 4293.913562142917,
    "total_throughput": 9174.493624435343,
    "itl": 198.56981745951018,
    "ttft": 1534972.1329301521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.064327723942802,
    "arrivals": 128453,
    "finished_requests": 70839,
    "scheduler_time": 78.92299534087743
}
#Debug simulation 
Total elapsed time: 5.097222580108792. Arrivals time: 0.22162795951589942 Scheduler time: 4.761485281866044 Scheduler overhead time: 0.02878219122067094 Adapter cache time: 0.04231464443728328 Engine time: 0.029572200495749712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.068450888618827,
    "estimated_duration": 3600.1083896573145,
    "input_throughput": 4880.126401325475,
    "output_throughput": 4293.656003360325,
    "total_throughput": 9173.782404685799,
    "itl": 198.58565020235937,
    "ttft": 1535052.8479672174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.328177812199551,
    "arrivals": 128453,
    "finished_requests": 70834,
    "scheduler_time": 78.91820860936895
}
#Debug simulation 
Total elapsed time: 5.068571233656257. Arrivals time: 0.21950515313073993 Scheduler time: 4.735229555051774 Scheduler overhead time: 0.028403368312865496 Adapter cache time: 0.042483283672481775 Engine time: 0.029654049314558506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.877987849060446,
    "estimated_duration": 3600.0124978808126,
    "input_throughput": 4563.619156786584,
    "output_throughput": 4027.4462959600596,
    "total_throughput": 8591.065452746643,
    "itl": 125.41469043291256,
    "ttft": 1619774.3556413513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.048474541623082,
    "arrivals": 128453,
    "finished_requests": 66185,
    "scheduler_time": 84.98990244663753
}
#Debug simulation 
Total elapsed time: 4.87807450722903. Arrivals time: 0.21097588865086436 Scheduler time: 4.509500813204795 Scheduler overhead time: 0.0421069310978055 Adapter cache time: 0.05252766516059637 Engine time: 0.0431831288151443 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.119171283673495,
    "estimated_duration": 3600.1203189240555,
    "input_throughput": 4880.132729911303,
    "output_throughput": 4293.787326702424,
    "total_throughput": 9173.920056613728,
    "itl": 198.58185507658806,
    "ttft": 1535031.804307347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1330,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.174527026344972,
    "arrivals": 128453,
    "finished_requests": 70835,
    "scheduler_time": 78.92084808865685
}
#Debug simulation 
Total elapsed time: 5.119261947926134. Arrivals time: 0.22502294462174177 Scheduler time: 4.77996298763901 Scheduler overhead time: 0.02865744149312377 Adapter cache time: 0.042730297427624464 Engine time: 0.02943385811522603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.922173995990306,
    "estimated_duration": 3600.110161781839,
    "input_throughput": 4562.515662540263,
    "output_throughput": 4026.327903484412,
    "total_throughput": 8588.843566024676,
    "itl": 125.3147110165077,
    "ttft": 1620015.850111316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1239,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.094288933742778,
    "arrivals": 128453,
    "finished_requests": 66165,
    "scheduler_time": 85.00891876128715
}
#Debug simulation 
Total elapsed time: 4.922286037821323. Arrivals time: 0.2147557269781828 Scheduler time: 4.548532721586525 Scheduler overhead time: 0.042536428198218346 Adapter cache time: 0.053114866372197866 Engine time: 0.04342412343248725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.078561349771917,
    "estimated_duration": 3600.016668486483,
    "input_throughput": 4880.533791357908,
    "output_throughput": 4294.010673705869,
    "total_throughput": 9174.544465063776,
    "itl": 198.56655479176823,
    "ttft": 1534965.0370090147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.970786791629985,
    "arrivals": 128453,
    "finished_requests": 70838,
    "scheduler_time": 78.92241513948078
}
#Debug simulation 
Total elapsed time: 5.078653301578015. Arrivals time: 0.22120682382956147 Scheduler time: 4.743000873830169 Scheduler overhead time: 0.028616812080144882 Adapter cache time: 0.042721756268292665 Engine time: 0.0297403153963387 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.866130453068763,
    "estimated_duration": 3600.0458532630155,
    "input_throughput": 4563.481874851479,
    "output_throughput": 4027.3323149089206,
    "total_throughput": 8590.8141897604,
    "itl": 125.42282039802282,
    "ttft": 1619844.9185150252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1240,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.155476427972362,
    "arrivals": 128453,
    "finished_requests": 66184,
    "scheduler_time": 84.98809685352252
}
#Debug simulation 
Total elapsed time: 4.866222987882793. Arrivals time: 0.21070944797247648 Scheduler time: 4.497477976139635 Scheduler overhead time: 0.04224463412538171 Adapter cache time: 0.052992208395153284 Engine time: 0.043007691856473684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.337914301082492,
    "estimated_duration": 3600.110935238062,
    "input_throughput": 5139.607732331297,
    "output_throughput": 4527.936581188176,
    "total_throughput": 9667.544313519473,
    "itl": 188.8720813166136,
    "ttft": 1453444.8642559794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1009,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0880321336282197,
    "arrivals": 126425,
    "finished_requests": 74863,
    "scheduler_time": 82.50099026452513
}
#Debug simulation 
Total elapsed time: 5.338002749253064. Arrivals time: 0.2276628352701664 Scheduler time: 5.0024673119187355 Scheduler overhead time: 0.02984744170680642 Adapter cache time: 0.03320106165483594 Engine time: 0.030775399412959814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.330294725950807,
    "estimated_duration": 3600.0114992004246,
    "input_throughput": 5139.4652500719485,
    "output_throughput": 4527.534149160386,
    "total_throughput": 9666.999399232334,
    "itl": 188.88184410041418,
    "ttft": 1453610.1311912213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1010,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.291258089295593,
    "arrivals": 126425,
    "finished_requests": 74854,
    "scheduler_time": 82.49480324819814
}
#Debug simulation 
Total elapsed time: 5.3304009498097. Arrivals time: 0.23220597486943007 Scheduler time: 4.990579502657056 Scheduler overhead time: 0.029803221113979816 Adapter cache time: 0.033141948748379946 Engine time: 0.030626107938587666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.028420899063349,
    "estimated_duration": 3600.0885571321464,
    "input_throughput": 4738.113723954673,
    "output_throughput": 4184.385123014919,
    "total_throughput": 8922.498846969593,
    "itl": 121.17966121147371,
    "ttft": 1562228.9381148764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.964177373927064,
    "arrivals": 126425,
    "finished_requests": 68962,
    "scheduler_time": 87.55823951135332
}
#Debug simulation 
Total elapsed time: 5.0285095809958875. Arrivals time: 0.21594387665390968 Scheduler time: 4.665538571309298 Scheduler overhead time: 0.04348198603838682 Adapter cache time: 0.03848402155563235 Engine time: 0.04461652226746082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.36804383713752,
    "estimated_duration": 3600.0497374084925,
    "input_throughput": 5139.572325275494,
    "output_throughput": 4527.807166279276,
    "total_throughput": 9667.379491554771,
    "itl": 188.8778584106308,
    "ttft": 1453499.6717122982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1009,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1591519183735053,
    "arrivals": 126425,
    "finished_requests": 74859,
    "scheduler_time": 82.49781830434158
}
#Debug simulation 
Total elapsed time: 5.3681351421400905. Arrivals time: 0.22754017496481538 Scheduler time: 5.032929874025285 Scheduler overhead time: 0.029783313162624836 Adapter cache time: 0.0329719977453351 Engine time: 0.030831376556307077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.070601094979793,
    "estimated_duration": 3600.0300454854582,
    "input_throughput": 4737.867124578391,
    "output_throughput": 4184.352021975603,
    "total_throughput": 8922.219146553995,
    "itl": 121.18248063995767,
    "ttft": 1562239.7181336354,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 906,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9937586855143303,
    "arrivals": 126425,
    "finished_requests": 68959,
    "scheduler_time": 87.55789144614512
}
#Debug simulation 
Total elapsed time: 5.070689880289137. Arrivals time: 0.21580052794888616 Scheduler time: 4.707041931338608 Scheduler overhead time: 0.043685588520020247 Adapter cache time: 0.03906829981133342 Engine time: 0.044603472109884024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.2919433680363,
    "estimated_duration": 3600.1443478279307,
    "input_throughput": 5118.876972563213,
    "output_throughput": 4510.818020337937,
    "total_throughput": 9629.69499290115,
    "itl": 189.599660855223,
    "ttft": 1458461.1413093214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9930403451970085,
    "arrivals": 126425,
    "finished_requests": 74569,
    "scheduler_time": 82.22289000599058
}
#Debug simulation 
Total elapsed time: 5.292036824859679. Arrivals time: 0.22557036951184273 Scheduler time: 4.960048332810402 Scheduler overhead time: 0.029606669209897518 Adapter cache time: 0.03238850133493543 Engine time: 0.0304029518738389 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.060133656021208,
    "estimated_duration": 3600.0995754360683,
    "input_throughput": 4738.625041484758,
    "output_throughput": 4184.821470715885,
    "total_throughput": 8923.446512200642,
    "itl": 121.2141514491081,
    "ttft": 1562238.2728213943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.0390008768439585,
    "arrivals": 126425,
    "finished_requests": 68968,
    "scheduler_time": 87.5537409302872
}
#Debug simulation 
Total elapsed time: 5.06022503785789. Arrivals time: 0.21607355307787657 Scheduler time: 4.696063309442252 Scheduler overhead time: 0.04364383593201637 Adapter cache time: 0.03914919449016452 Engine time: 0.04481208184733987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.696335773915052,
    "estimated_duration": 3600.0977534318463,
    "input_throughput": 3687.3845959725572,
    "output_throughput": 3242.406678783252,
    "total_throughput": 6929.791274755809,
    "itl": 158.87067327062405,
    "ttft": 79218.57056314882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.603031048195058,
    "arrivals": 54189,
    "finished_requests": 53269,
    "scheduler_time": 43.82054238184583
}
#Debug simulation 
Total elapsed time: 5.696419721934944. Arrivals time: 0.12993105361238122 Scheduler time: 5.410766582470387 Scheduler overhead time: 0.03659736551344395 Adapter cache time: 0.06667432095855474 Engine time: 0.03598433220759034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.690532585605979,
    "estimated_duration": 3600.1319674813935,
    "input_throughput": 3688.0889700520743,
    "output_throughput": 3243.024729498431,
    "total_throughput": 6931.113699550505,
    "itl": 159.0095443723915,
    "ttft": 78733.22233666187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2815,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.181064825632934,
    "arrivals": 54189,
    "finished_requests": 53277,
    "scheduler_time": 43.82684593432844
}
#Debug simulation 
Total elapsed time: 5.690619710832834. Arrivals time: 0.13090072106570005 Scheduler time: 5.404252973385155 Scheduler overhead time: 0.036261329893022776 Adapter cache time: 0.06666865386068821 Engine time: 0.03603116050362587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.025748143903911,
    "estimated_duration": 3600.1434644446103,
    "input_throughput": 3622.6078568266053,
    "output_throughput": 3186.4921810191654,
    "total_throughput": 6809.10003784577,
    "itl": 151.72111795080937,
    "ttft": 160834.41196224437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.345678359791197,
    "arrivals": 54189,
    "finished_requests": 52370,
    "scheduler_time": 43.35132308829503
}
#Debug simulation 
Total elapsed time: 5.0258376388810575. Arrivals time: 0.13066790159791708 Scheduler time: 4.7229093122296035 Scheduler overhead time: 0.03800786007195711 Adapter cache time: 0.07903507398441434 Engine time: 0.037899964954704046 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.6705159530974925,
    "estimated_duration": 3600.0812618244695,
    "input_throughput": 3687.363432811102,
    "output_throughput": 3242.429031750324,
    "total_throughput": 6929.792464561427,
    "itl": 158.89152450529497,
    "ttft": 79243.71242793144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.790634422632737,
    "arrivals": 54189,
    "finished_requests": 53269,
    "scheduler_time": 43.82016121583075
}
#Debug simulation 
Total elapsed time: 5.670599783305079. Arrivals time: 0.1305852858349681 Scheduler time: 5.385132302995771 Scheduler overhead time: 0.0362830413505435 Adapter cache time: 0.06615651957690716 Engine time: 0.03595282882452011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_160_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.871041481848806,
    "estimated_duration": 3600.1622194894903,
    "input_throughput": 3621.8204083728688,
    "output_throughput": 3184.918428932886,
    "total_throughput": 6806.738837305755,
    "itl": 151.53156877377612,
    "ttft": 163148.4749906215,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.400296295619988,
    "arrivals": 54189,
    "finished_requests": 52349,
    "scheduler_time": 43.34262821827029
}
#Debug simulation 
Total elapsed time: 4.871131367050111. Arrivals time: 0.13003485975787044 Scheduler time: 4.574306088965386 Scheduler overhead time: 0.036957573145627975 Adapter cache time: 0.0760083319619298 Engine time: 0.036754794884473085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_160_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_160_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.685384267941117,
    "estimated_duration": 3600.096528760226,
    "input_throughput": 3687.7494516992783,
    "output_throughput": 3243.165817006799,
    "total_throughput": 6930.915268706078,
    "itl": 158.87221683019396,
    "ttft": 78936.18604314094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2813,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.41101147955968,
    "arrivals": 54189,
    "finished_requests": 53273,
    "scheduler_time": 43.82294614845644
}
#Debug simulation 
Total elapsed time: 5.68549844995141. Arrivals time: 0.13130633812397718 Scheduler time: 5.398619004525244 Scheduler overhead time: 0.0365088083781302 Adapter cache time: 0.06637065950781107 Engine time: 0.036158929113298655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_160_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_160_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.022530362010002,
    "estimated_duration": 3600.003537374483,
    "input_throughput": 3621.8472744916303,
    "output_throughput": 3184.9057593876764,
    "total_throughput": 6806.753033879307,
    "itl": 151.55642825529316,
    "ttft": 163156.1984714411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.562430582455702,
    "arrivals": 54189,
    "finished_requests": 52345,
    "scheduler_time": 43.33700807949732
}
#Debug simulation 
Total elapsed time: 5.0226441021077335. Arrivals time: 0.13053587870672345 Scheduler time: 4.721041675657034 Scheduler overhead time: 0.03786525456234813 Adapter cache time: 0.07814880786463618 Engine time: 0.037664138711988926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.26530510885641,
    "estimated_duration": 3599.976570895122,
    "input_throughput": 3454.224980388705,
    "output_throughput": 3018.805202195469,
    "total_throughput": 6473.030182584173,
    "itl": 132.64037320208126,
    "ttft": 35712.244251870055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.739308974778663,
    "arrivals": 50289,
    "finished_requests": 49860,
    "scheduler_time": 39.40055305240337
}
#Debug simulation 
Total elapsed time: 4.265387922059745. Arrivals time: 0.11902769468724728 Scheduler time: 3.9403232615441084 Scheduler overhead time: 0.04140941146761179 Adapter cache time: 0.10536133963614702 Engine time: 0.04055279167369008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.392692678142339,
    "estimated_duration": 3599.9813663398904,
    "input_throughput": 3454.2295458164713,
    "output_throughput": 3018.489790420222,
    "total_throughput": 6472.719336236693,
    "itl": 132.74585735789654,
    "ttft": 35868.53332050382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4806,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.68422426140505,
    "arrivals": 50289,
    "finished_requests": 49858,
    "scheduler_time": 39.40448171261059
}
#Debug simulation 
Total elapsed time: 4.392777842935175. Arrivals time: 0.12035624729469419 Scheduler time: 4.062066071201116 Scheduler overhead time: 0.04192602075636387 Adapter cache time: 0.10781590966507792 Engine time: 0.04163033049553633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.255776806268841,
    "estimated_duration": 3600.0786343046016,
    "input_throughput": 3454.309547991893,
    "output_throughput": 3018.72239579545,
    "total_throughput": 6473.031943787343,
    "itl": 132.75133123901583,
    "ttft": 35657.93409868229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.715457543431322,
    "arrivals": 50289,
    "finished_requests": 49861,
    "scheduler_time": 39.405777393245664
}
#Debug simulation 
Total elapsed time: 4.2558806873857975. Arrivals time: 0.122267238330096 Scheduler time: 3.9275764850899577 Scheduler overhead time: 0.04095839289948344 Adapter cache time: 0.10596506157889962 Engine time: 0.040568938944488764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.278102674987167,
    "estimated_duration": 3599.973799516503,
    "input_throughput": 3454.0454160166446,
    "output_throughput": 3018.0766875190125,
    "total_throughput": 6472.122103535657,
    "itl": 132.6694093633105,
    "ttft": 36451.04435846326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.921790876757617,
    "arrivals": 50289,
    "finished_requests": 49851,
    "scheduler_time": 39.40147644808803
}
#Debug simulation 
Total elapsed time: 4.278191342018545. Arrivals time: 0.12004115851595998 Scheduler time: 3.9522164058871567 Scheduler overhead time: 0.04132805299013853 Adapter cache time: 0.10523365065455437 Engine time: 0.04062748700380325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.396273800171912,
    "estimated_duration": 3600.0158056921678,
    "input_throughput": 3454.2484453367783,
    "output_throughput": 3018.534247215803,
    "total_throughput": 6472.7826925525815,
    "itl": 132.76990384427666,
    "ttft": 35805.371440983334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.912247633280817,
    "arrivals": 50289,
    "finished_requests": 49859,
    "scheduler_time": 39.405985490961925
}
#Debug simulation 
Total elapsed time: 4.396365045104176. Arrivals time: 0.12082529347389936 Scheduler time: 4.064543155487627 Scheduler overhead time: 0.04196131229400635 Adapter cache time: 0.1086950390599668 Engine time: 0.04126259218901396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.271784572396427,
    "estimated_duration": 3600.033615701371,
    "input_throughput": 3453.988025491665,
    "output_throughput": 3018.026540811409,
    "total_throughput": 6472.014566303074,
    "itl": 132.59484178186946,
    "ttft": 36431.86990465325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.253569755800058,
    "arrivals": 50289,
    "finished_requests": 49851,
    "scheduler_time": 39.399432541890235
}
#Debug simulation 
Total elapsed time: 4.271871658042073. Arrivals time: 0.11954200360924006 Scheduler time: 3.9472944787703454 Scheduler overhead time: 0.041208615992218256 Adapter cache time: 0.10458885505795479 Engine time: 0.04058944759890437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.32139169704169,
    "estimated_duration": 3600.102319485446,
    "input_throughput": 3454.2732112617873,
    "output_throughput": 3018.617815716205,
    "total_throughput": 6472.891026977992,
    "itl": 132.79442057446997,
    "ttft": 35735.238624507794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.120596229395627,
    "arrivals": 50289,
    "finished_requests": 49860,
    "scheduler_time": 39.40781303920305
}
#Debug simulation 
Total elapsed time: 4.321476306766272. Arrivals time: 0.1207156553864479 Scheduler time: 3.991000459063798 Scheduler overhead time: 0.04199148993939161 Adapter cache time: 0.10750076407566667 Engine time: 0.04129010671749711 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.768273724708706,
    "estimated_duration": 3600.064276070521,
    "input_throughput": 3301.4077218012376,
    "output_throughput": 2921.586725523777,
    "total_throughput": 6222.994447325014,
    "itl": 123.09357937763316,
    "ttft": 32084.38519757869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5848,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.89773232651756,
    "arrivals": 48457,
    "finished_requests": 48035,
    "scheduler_time": 37.54493161879194
}
#Debug simulation 
Total elapsed time: 3.7683586697094142. Arrivals time: 0.11249130126088858 Scheduler time: 3.424749907106161 Scheduler overhead time: 0.04288203129544854 Adapter cache time: 0.12642470095306635 Engine time: 0.04219157714396715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.7304228181019425,
    "estimated_duration": 3600.0505522186095,
    "input_throughput": 3301.420307188586,
    "output_throughput": 2921.5978629850392,
    "total_throughput": 6223.018170173626,
    "itl": 123.23101266050458,
    "ttft": 32092.387503815076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5838,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.037994694639927,
    "arrivals": 48457,
    "finished_requests": 48035,
    "scheduler_time": 37.550801428793285
}
#Debug simulation 
Total elapsed time: 3.7305077370256186. Arrivals time: 0.11376631679013371 Scheduler time: 3.388226878363639 Scheduler overhead time: 0.04268483864143491 Adapter cache time: 0.12462978530675173 Engine time: 0.041857982985675335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.7434956319630146,
    "estimated_duration": 3600.076650381196,
    "input_throughput": 3301.3963740859576,
    "output_throughput": 2921.576683342647,
    "total_throughput": 6222.973057428604,
    "itl": 123.23169440031427,
    "ttft": 32091.80657483201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5833,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.056981506216406,
    "arrivals": 48457,
    "finished_requests": 48035,
    "scheduler_time": 37.55103071448453
}
#Debug simulation 
Total elapsed time: 3.7435866012237966. Arrivals time: 0.11458524083718657 Scheduler time: 3.4006118359975517 Scheduler overhead time: 0.042476329021155834 Adapter cache time: 0.12433399772271514 Engine time: 0.0421717232093215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.8219385161064565,
    "estimated_duration": 3600.121555914687,
    "input_throughput": 3301.3551946526686,
    "output_throughput": 2921.5402415287904,
    "total_throughput": 6222.8954361814585,
    "itl": 123.14262638254652,
    "ttft": 32232.779192113867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.305605162566692,
    "arrivals": 48457,
    "finished_requests": 48035,
    "scheduler_time": 37.54777338729136
}
#Debug simulation 
Total elapsed time: 3.8220181432552636. Arrivals time: 0.11390677141025662 Scheduler time: 3.477031094022095 Scheduler overhead time: 0.043102579191327095 Adapter cache time: 0.1258793189190328 Engine time: 0.04247385775670409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.7009143349714577,
    "estimated_duration": 3600.071906895851,
    "input_throughput": 3301.400724033882,
    "output_throughput": 2921.580532836918,
    "total_throughput": 6222.981256870799,
    "itl": 123.26285174859143,
    "ttft": 32093.600761333953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.30436660045646,
    "arrivals": 48457,
    "finished_requests": 48035,
    "scheduler_time": 37.552419158632766
}
#Debug simulation 
Total elapsed time: 3.7010066476650536. Arrivals time: 0.1131498315371573 Scheduler time: 3.3605807698331773 Scheduler overhead time: 0.042445503175258636 Adapter cache time: 0.12388540664687753 Engine time: 0.04166541062295437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.703143844846636,
    "estimated_duration": 3600.0209145186727,
    "input_throughput": 3301.447486615248,
    "output_throughput": 2921.6219154677483,
    "total_throughput": 6223.069402082997,
    "itl": 123.05966615778603,
    "ttft": 32088.636282068932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5836,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.449933521050458,
    "arrivals": 48457,
    "finished_requests": 48035,
    "scheduler_time": 37.543357721524174
}
#Debug simulation 
Total elapsed time: 3.7032363009639084. Arrivals time: 0.111080935690552 Scheduler time: 3.3632501224055886 Scheduler overhead time: 0.04286928987130523 Adapter cache time: 0.12464099703356624 Engine time: 0.041973302606493235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.6611464926972985,
    "estimated_duration": 3600.021798849456,
    "input_throughput": 3301.323343041511,
    "output_throughput": 2921.517031747234,
    "total_throughput": 6222.840374788745,
    "itl": 123.29469478218121,
    "ttft": 32171.293924600293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.54816692225487,
    "arrivals": 48457,
    "finished_requests": 48034,
    "scheduler_time": 37.553561141719555
}
#Debug simulation 
Total elapsed time: 3.661233303602785. Arrivals time: 0.10857691615819931 Scheduler time: 3.325885881204158 Scheduler overhead time: 0.04243903560563922 Adapter cache time: 0.12358167301863432 Engine time: 0.041683117393404245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.6302881906740367,
    "estimated_duration": 3600.0030087356567,
    "input_throughput": 3239.6636813078794,
    "output_throughput": 2893.658970484744,
    "total_throughput": 6133.322651792623,
    "itl": 110.26126393109786,
    "ttft": 26927.021015867627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4915,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.042297261427928,
    "arrivals": 47448,
    "finished_requests": 47096,
    "scheduler_time": 36.42548770071102
}
#Debug simulation 
Total elapsed time: 3.630380218848586. Arrivals time: 0.10760525846853852 Scheduler time: 3.277852668892592 Scheduler overhead time: 0.04495326895266771 Adapter cache time: 0.13496628450229764 Engine time: 0.04452234739437699 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.558362243231386,
    "estimated_duration": 3600.04460493507,
    "input_throughput": 3239.400974091635,
    "output_throughput": 2893.3224843162366,
    "total_throughput": 6132.7234584078715,
    "itl": 110.98115558456512,
    "ttft": 27088.420434166554,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4898,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.016920828436177,
    "arrivals": 47448,
    "finished_requests": 47094,
    "scheduler_time": 36.46370368126523
}
#Debug simulation 
Total elapsed time: 3.5584532422944903. Arrivals time: 0.10803076019510627 Scheduler time: 3.2098899059928954 Scheduler overhead time: 0.04427724797278643 Adapter cache time: 0.13205036567524076 Engine time: 0.044046645518392324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.5756311998702586,
    "estimated_duration": 3600.046308976195,
    "input_throughput": 3239.399440757892,
    "output_throughput": 2893.321114794825,
    "total_throughput": 6132.720555552717,
    "itl": 110.98397599333904,
    "ttft": 27088.236328875402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.06161153483996,
    "arrivals": 47448,
    "finished_requests": 47094,
    "scheduler_time": 36.464044271763115
}
#Debug simulation 
Total elapsed time: 3.5757229179143906. Arrivals time: 0.1068726172670722 Scheduler time: 3.227819087449461 Scheduler overhead time: 0.044462407007813454 Adapter cache time: 0.1321498528122902 Engine time: 0.04414470726624131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.5668293558992445,
    "estimated_duration": 3600.0969818706867,
    "input_throughput": 3239.4852301839765,
    "output_throughput": 2893.4209418401047,
    "total_throughput": 6132.906172024081,
    "itl": 110.88392246953487,
    "ttft": 27011.299475817683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4905,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.377152550582675,
    "arrivals": 47448,
    "finished_requests": 47095,
    "scheduler_time": 36.45904900488347
}
#Debug simulation 
Total elapsed time: 3.5669127251021564. Arrivals time: 0.10637964168563485 Scheduler time: 3.2196599347516894 Scheduler overhead time: 0.044245307333767414 Adapter cache time: 0.13254134263843298 Engine time: 0.04389058751985431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.570010185241699,
    "estimated_duration": 3600.0242666349272,
    "input_throughput": 3239.247887320578,
    "output_throughput": 2893.211330971351,
    "total_throughput": 6132.459218291929,
    "itl": 111.01519616701422,
    "ttft": 27164.275111207902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.25869688993195,
    "arrivals": 47448,
    "finished_requests": 47093,
    "scheduler_time": 36.46539654498211
}
#Debug simulation 
Total elapsed time: 3.570096175186336. Arrivals time: 0.10752390138804913 Scheduler time: 3.2220251760445535 Scheduler overhead time: 0.04410827113315463 Adapter cache time: 0.13225995190441608 Engine time: 0.04386749258264899 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.5779251861386,
    "estimated_duration": 3600.0813422557117,
    "input_throughput": 3239.6418000634126,
    "output_throughput": 2893.657673154891,
    "total_throughput": 6133.299473218303,
    "itl": 110.20292394761216,
    "ttft": 26850.27207631194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.68114694797118,
    "arrivals": 47448,
    "finished_requests": 47097,
    "scheduler_time": 36.42331297333689
}
#Debug simulation 
Total elapsed time: 3.57800704985857. Arrivals time: 0.10611538402736187 Scheduler time: 3.2288981825113297 Scheduler overhead time: 0.0445487997494638 Adapter cache time: 0.1337844911031425 Engine time: 0.044315507635474205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.5592922219075263,
    "estimated_duration": 3600.0293206871856,
    "input_throughput": 3239.2433397664768,
    "output_throughput": 2893.2072692151933,
    "total_throughput": 6132.4506089816705,
    "itl": 111.04521024756521,
    "ttft": 27164.4509767494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.44391802076135,
    "arrivals": 47448,
    "finished_requests": 47093,
    "scheduler_time": 36.46685499601109
}
#Debug simulation 
Total elapsed time: 3.5593721880577505. Arrivals time: 0.10670439852401614 Scheduler time: 3.2142333914525807 Scheduler overhead time: 0.04417994478717446 Adapter cache time: 0.13089505955576897 Engine time: 0.043203940615057945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.3368139257654548,
    "estimated_duration": 3599.848001867017,
    "input_throughput": 2948.3969863436714,
    "output_throughput": 2598.5583266705835,
    "total_throughput": 5546.955313014255,
    "itl": 71.86339531007954,
    "ttft": 13279.182119890076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.72028151869081,
    "arrivals": 42675,
    "finished_requests": 42519,
    "scheduler_time": 28.7719334140639
}
#Debug simulation 
Total elapsed time: 3.3368927370756865. Arrivals time: 0.10166552988812327 Scheduler time: 2.87989395391196 Scheduler overhead time: 0.05797098111361265 Adapter cache time: 0.21413809759542346 Engine time: 0.05604103533551097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.358738868031651,
    "estimated_duration": 3599.832100452339,
    "input_throughput": 2948.3547298404123,
    "output_throughput": 2598.5270254200423,
    "total_throughput": 5546.881755260455,
    "itl": 71.99496751231702,
    "ttft": 13364.042603131697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.18246166206977,
    "arrivals": 42675,
    "finished_requests": 42518,
    "scheduler_time": 28.788063709035384
}
#Debug simulation 
Total elapsed time: 3.3588183522224426. Arrivals time: 0.10182615229859948 Scheduler time: 2.901136456988752 Scheduler overhead time: 0.057936484925448895 Adapter cache time: 0.21413444681093097 Engine time: 0.05676199775189161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.3928447593934834,
    "estimated_duration": 3599.843431654628,
    "input_throughput": 2948.345449324607,
    "output_throughput": 2598.5188460544846,
    "total_throughput": 5546.864295379091,
    "itl": 71.996000688477,
    "ttft": 13363.90173581444,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.206129920575734,
    "arrivals": 42675,
    "finished_requests": 42518,
    "scheduler_time": 28.788418877761906
}
#Debug simulation 
Total elapsed time: 3.392930699046701. Arrivals time: 0.10349763929843903 Scheduler time: 2.931574835907668 Scheduler overhead time: 0.058184728026390076 Adapter cache time: 0.21593538345769048 Engine time: 0.05661041382700205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.345151702873409,
    "estimated_duration": 3599.8573426742046,
    "input_throughput": 2948.389335927241,
    "output_throughput": 2598.5515840055323,
    "total_throughput": 5546.940919932773,
    "itl": 71.90908513128858,
    "ttft": 13279.268822877106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.255897362913643,
    "arrivals": 42675,
    "finished_requests": 42519,
    "scheduler_time": 28.778010639387265
}
#Debug simulation 
Total elapsed time: 3.345231472980231. Arrivals time: 0.1021669628098607 Scheduler time: 2.8879160713404417 Scheduler overhead time: 0.057595085352659225 Adapter cache time: 0.21430653100833297 Engine time: 0.056090155616402626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.3348426618613303,
    "estimated_duration": 3599.840288694581,
    "input_throughput": 2948.3024658987774,
    "output_throughput": 2598.4219437112943,
    "total_throughput": 5546.724409610072,
    "itl": 72.28875185492755,
    "ttft": 13448.574286802379,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.512364625352493,
    "arrivals": 42675,
    "finished_requests": 42517,
    "scheduler_time": 28.825463790402534
}
#Debug simulation 
Total elapsed time: 3.334920725785196. Arrivals time: 0.10167809948325157 Scheduler time: 2.8794391700066626 Scheduler overhead time: 0.05767175694927573 Adapter cache time: 0.21292860666289926 Engine time: 0.05614778306335211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.327760176267475,
    "estimated_duration": 3599.8813124894577,
    "input_throughput": 2948.369704072315,
    "output_throughput": 2598.5342815458152,
    "total_throughput": 5546.903985618131,
    "itl": 71.81644778910542,
    "ttft": 13279.16720479459,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7091,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.20244664115144,
    "arrivals": 42675,
    "finished_requests": 42519,
    "scheduler_time": 28.76643221305896
}
#Debug simulation 
Total elapsed time: 3.3278513201512396. Arrivals time: 0.10696274740621448 Scheduler time: 2.866107801441103 Scheduler overhead time: 0.05802265787497163 Adapter cache time: 0.21334693394601345 Engine time: 0.05629683658480644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.3926751310937107,
    "estimated_duration": 3599.8943603866464,
    "input_throughput": 2948.313460748344,
    "output_throughput": 2598.4256935237754,
    "total_throughput": 5546.73915427212,
    "itl": 72.31643642657339,
    "ttft": 13364.164055474697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7090,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.804195795280837,
    "arrivals": 42675,
    "finished_requests": 42518,
    "scheduler_time": 28.82909029702345
}
#Debug simulation 
Total elapsed time: 3.392752375919372. Arrivals time: 0.10403898498043418 Scheduler time: 2.93058257130906 Scheduler overhead time: 0.05818599183112383 Adapter cache time: 0.21601762995123863 Engine time: 0.056705453898757696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.2311902330257,
    "estimated_duration": 3599.8933448835746,
    "input_throughput": 2792.313004019039,
    "output_throughput": 2485.1711267266273,
    "total_throughput": 5277.484130745666,
    "itl": 57.50604404977047,
    "ttft": 12486.722643985266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.570982148862404,
    "arrivals": 40673,
    "finished_requests": 40533,
    "scheduler_time": 24.9396794401111
}
#Debug simulation 
Total elapsed time: 3.2312671509571373. Arrivals time: 0.09880253113806248 Scheduler time: 2.7522002700716257 Scheduler overhead time: 0.06758501520380378 Adapter cache time: 0.2155180312693119 Engine time: 0.06541477143764496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.256380578968674,
    "estimated_duration": 3599.918956354172,
    "input_throughput": 2792.293138226706,
    "output_throughput": 2485.153446082142,
    "total_throughput": 5277.446584308848,
    "itl": 57.557474683439516,
    "ttft": 12487.018344821176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4757,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.511561696574635,
    "arrivals": 40673,
    "finished_requests": 40533,
    "scheduler_time": 24.949854032331775
}
#Debug simulation 
Total elapsed time: 3.2564555439166725. Arrivals time: 0.09930408792570233 Scheduler time: 2.7748571103438735 Scheduler overhead time: 0.06764946645125747 Adapter cache time: 0.2164105107076466 Engine time: 0.06634608469903469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.294157824013382,
    "estimated_duration": 3599.902726602111,
    "input_throughput": 2792.3057269627793,
    "output_throughput": 2485.1646501138416,
    "total_throughput": 5277.470377076621,
    "itl": 57.55795607353415,
    "ttft": 12486.854864625473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4758,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.544741280189296,
    "arrivals": 40673,
    "finished_requests": 40533,
    "scheduler_time": 24.950066739185853
}
#Debug simulation 
Total elapsed time: 3.2942344681359828. Arrivals time: 0.10019372776150703 Scheduler time: 2.8093099636025727 Scheduler overhead time: 0.06785345822572708 Adapter cache time: 0.21737884357571602 Engine time: 0.06761437142267823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.281166839879006,
    "estimated_duration": 3599.9067249429504,
    "input_throughput": 2792.3026256074177,
    "output_throughput": 2485.161889893627,
    "total_throughput": 5277.464515501045,
    "itl": 57.52494896020895,
    "ttft": 12486.892370958973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.929981729247396,
    "arrivals": 40673,
    "finished_requests": 40533,
    "scheduler_time": 24.943530490469204
}
#Debug simulation 
Total elapsed time: 3.2812465569004416. Arrivals time: 0.10019778972491622 Scheduler time: 2.7954247538000345 Scheduler overhead time: 0.0678419335745275 Adapter cache time: 0.21920143300667405 Engine time: 0.06660184916108847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.244347309693694,
    "estimated_duration": 3599.910794573227,
    "input_throughput": 2792.299468962724,
    "output_throughput": 2485.159080465659,
    "total_throughput": 5277.458549428383,
    "itl": 57.57017438391095,
    "ttft": 12487.032065877915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4764,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.745688343270372,
    "arrivals": 40673,
    "finished_requests": 40533,
    "scheduler_time": 24.952270909324195
}
#Debug simulation 
Total elapsed time: 3.2444229256361723. Arrivals time: 0.09915399178862572 Scheduler time: 2.7631683936342597 Scheduler overhead time: 0.06778663629665971 Adapter cache time: 0.2162244776263833 Engine time: 0.06623101932927966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.258312911260873,
    "estimated_duration": 3599.9108131628955,
    "input_throughput": 2792.2994545435,
    "output_throughput": 2485.1590676324845,
    "total_throughput": 5277.458522175984,
    "itl": 57.486558112556,
    "ttft": 12486.958872158644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4761,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.23562945403064,
    "arrivals": 40673,
    "finished_requests": 40533,
    "scheduler_time": 24.936207767722596
}
#Debug simulation 
Total elapsed time: 3.258391040377319. Arrivals time: 0.09951695706695318 Scheduler time: 2.7765275523997843 Scheduler overhead time: 0.06774109089747071 Adapter cache time: 0.21703617181628942 Engine time: 0.06559108942747116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.2587368856184185,
    "estimated_duration": 3599.9082872869503,
    "input_throughput": 2792.301413760641,
    "output_throughput": 2485.160811344548,
    "total_throughput": 5277.46222510519,
    "itl": 57.580865553000336,
    "ttft": 12486.790396788016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.944412241390717,
    "arrivals": 40673,
    "finished_requests": 40533,
    "scheduler_time": 24.954409528548073
}
#Debug simulation 
Total elapsed time: 3.2588204597122967. Arrivals time: 0.09919283026829362 Scheduler time: 2.777040135115385 Scheduler overhead time: 0.0678979535587132 Adapter cache time: 0.21699302271008492 Engine time: 0.06585440179333091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.20253571216017,
    "estimated_duration": 3599.9241095206517,
    "input_throughput": 2726.816094272358,
    "output_throughput": 2389.3342577005947,
    "total_throughput": 5116.150351972952,
    "itl": 50.94143998656861,
    "ttft": 11483.955405741825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3195,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.778258341864936,
    "arrivals": 39791,
    "finished_requests": 39665,
    "scheduler_time": 22.07506724104341
}
#Debug simulation 
Total elapsed time: 3.202636835165322. Arrivals time: 0.09977199463173747 Scheduler time: 2.6970435814000666 Scheduler overhead time: 0.07442294340580702 Adapter cache time: 0.22301469696685672 Engine time: 0.07326842797920108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.2452414026483893,
    "estimated_duration": 3599.920099104104,
    "input_throughput": 2726.8166319699553,
    "output_throughput": 2389.2469174914513,
    "total_throughput": 5116.063549461406,
    "itl": 51.51737878317326,
    "ttft": 11665.762396641172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3203,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.43763283520713,
    "arrivals": 39791,
    "finished_requests": 39663,
    "scheduler_time": 22.219449323254956
}
#Debug simulation 
Total elapsed time: 3.2453252519480884. Arrivals time: 0.10035303141921759 Scheduler time: 2.7434207685291767 Scheduler overhead time: 0.07378182839602232 Adapter cache time: 0.21991167310625315 Engine time: 0.0727374185808003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.234594432171434,
    "estimated_duration": 3599.939551293033,
    "input_throughput": 2726.8018976802414,
    "output_throughput": 2389.2340072517723,
    "total_throughput": 5116.035904932013,
    "itl": 51.519120670532914,
    "ttft": 11665.749005894726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.462014862428866,
    "arrivals": 39791,
    "finished_requests": 39663,
    "scheduler_time": 22.219840835649027
}
#Debug simulation 
Total elapsed time: 3.2346693729050457. Arrivals time: 0.09853276377543807 Scheduler time: 2.7364181238226593 Scheduler overhead time: 0.0738098667934537 Adapter cache time: 0.21862912271171808 Engine time: 0.07244246266782284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.1902014850638807,
    "estimated_duration": 3599.9206445885507,
    "input_throughput": 2726.8187188392726,
    "output_throughput": 2389.336557440446,
    "total_throughput": 5116.155276279719,
    "itl": 50.952675686459145,
    "ttft": 11483.867733633757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3196,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.034257265082688,
    "arrivals": 39791,
    "finished_requests": 39665,
    "scheduler_time": 22.07756251223899
}
#Debug simulation 
Total elapsed time: 3.190276767127216. Arrivals time: 0.09932939568534493 Scheduler time: 2.687887777108699 Scheduler overhead time: 0.07418340956792235 Adapter cache time: 0.2201148015446961 Engine time: 0.0737155987881124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.2005532109178603,
    "estimated_duration": 3599.9142880078366,
    "input_throughput": 2726.7379761511233,
    "output_throughput": 2389.1735502290594,
    "total_throughput": 5115.911526380182,
    "itl": 51.52384896087524,
    "ttft": 11756.093893343734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.57930313128923,
    "arrivals": 39791,
    "finished_requests": 39662,
    "scheduler_time": 22.220987708433718
}
#Debug simulation 
Total elapsed time: 3.200632033869624. Arrivals time: 0.10052863415330648 Scheduler time: 2.7008813400752842 Scheduler overhead time: 0.07338398415595293 Adapter cache time: 0.21808231715112925 Engine time: 0.07283868454396725 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.2045423220843077,
    "estimated_duration": 3599.933069430699,
    "input_throughput": 2726.8093074720346,
    "output_throughput": 2389.328310862248,
    "total_throughput": 5116.137618334283,
    "itl": 50.931562500064686,
    "ttft": 11483.773372318106,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.5442405413279,
    "arrivals": 39791,
    "finished_requests": 39665,
    "scheduler_time": 22.072626214412516
}
#Debug simulation 
Total elapsed time: 3.2046180800534785. Arrivals time: 0.09851016430184245 Scheduler time: 2.7024129880592227 Scheduler overhead time: 0.07424305472522974 Adapter cache time: 0.2221513967961073 Engine time: 0.07229771325364709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.164228124078363,
    "estimated_duration": 3599.911933455401,
    "input_throughput": 2726.739759596847,
    "output_throughput": 2389.1751128879537,
    "total_throughput": 5115.9148724848,
    "itl": 51.528131310554116,
    "ttft": 11756.318881376437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.7204280514264,
    "arrivals": 39791,
    "finished_requests": 39662,
    "scheduler_time": 22.222294949900018
}
#Debug simulation 
Total elapsed time: 3.164307019673288. Arrivals time: 0.09881562041118741 Scheduler time: 2.668329337146133 Scheduler overhead time: 0.07352703018113971 Adapter cache time: 0.21714209439232945 Engine time: 0.07175586838275194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.039689197205007,
    "estimated_duration": 3600.0260103522446,
    "input_throughput": 2540.508033469769,
    "output_throughput": 2242.6865741478423,
    "total_throughput": 4783.194607617612,
    "itl": 43.56155568399059,
    "ttft": 10877.773725094654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.818044682536051,
    "arrivals": 36981,
    "finished_requests": 36870,
    "scheduler_time": 17.770689739065993
}
#Debug simulation 
Total elapsed time: 3.0397670189850032. Arrivals time: 0.09452656609937549 Scheduler time: 2.526606746017933 Scheduler overhead time: 0.08333858707919717 Adapter cache time: 0.21356211975216866 Engine time: 0.08201573137193918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.0376867558807135,
    "estimated_duration": 3600.0161499395267,
    "input_throughput": 2540.514991899032,
    "output_throughput": 2242.692716846735,
    "total_throughput": 4783.2077087457665,
    "itl": 43.581349596538544,
    "ttft": 10877.78259245126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.474777116943237,
    "arrivals": 36981,
    "finished_requests": 36870,
    "scheduler_time": 17.777370052109926
}
#Debug simulation 
Total elapsed time: 3.0377645730040967. Arrivals time: 0.0948730343952775 Scheduler time: 2.5226701707579195 Scheduler overhead time: 0.08332653436809778 Adapter cache time: 0.21366871101781726 Engine time: 0.0836055688560009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.0677088210359216,
    "estimated_duration": 3600.0302680833884,
    "input_throughput": 2540.5050288283164,
    "output_throughput": 2242.6839217377897,
    "total_throughput": 4783.1889505661065,
    "itl": 43.581030108639425,
    "ttft": 10877.83168140976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.48970232257573,
    "arrivals": 36981,
    "finished_requests": 36870,
    "scheduler_time": 17.77751554598944
}
#Debug simulation 
Total elapsed time: 3.0677874367684126. Arrivals time: 0.0975798130966723 Scheduler time: 2.551458600908518 Scheduler overhead time: 0.08357208548113704 Adapter cache time: 0.2141886204481125 Engine time: 0.08131778938695788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 3.005340614821762,
    "estimated_duration": 3600.012345002252,
    "input_throughput": 2540.5176770287653,
    "output_throughput": 2242.6950872011384,
    "total_throughput": 4783.212764229904,
    "itl": 43.5699592880019,
    "ttft": 10877.648934637598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.066590393821377,
    "arrivals": 36981,
    "finished_requests": 36870,
    "scheduler_time": 17.773269891625226
}
#Debug simulation 
Total elapsed time: 3.0054145911708474. Arrivals time: 0.09362156363204122 Scheduler time: 2.495442010462284 Scheduler overhead time: 0.08313254080712795 Adapter cache time: 0.21295334352180362 Engine time: 0.08086254028603435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 3.03471748996526,
    "estimated_duration": 3600.0027970416595,
    "input_throughput": 2540.5244150131593,
    "output_throughput": 2242.701035297715,
    "total_throughput": 4783.225450310874,
    "itl": 43.58585838630933,
    "ttft": 10877.643281962886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3210,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.62188039418255,
    "arrivals": 36981,
    "finished_requests": 36870,
    "scheduler_time": 17.77881951111669
}
#Debug simulation 
Total elapsed time: 3.0347936120815575. Arrivals time: 0.09432625398039818 Scheduler time: 2.521109940018505 Scheduler overhead time: 0.08373310416936874 Adapter cache time: 0.21588013973087072 Engine time: 0.08003067830577493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 3.0143034826032817,
    "estimated_duration": 3600.0387538776367,
    "input_throughput": 2540.499040503069,
    "output_throughput": 2242.6786354184956,
    "total_throughput": 4783.1776759215645,
    "itl": 43.55443898525858,
    "ttft": 10877.786911261452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.59507139634125,
    "arrivals": 36981,
    "finished_requests": 36870,
    "scheduler_time": 17.76846938969527
}
#Debug simulation 
Total elapsed time: 3.0143768968991935. Arrivals time: 0.09386639716103673 Scheduler time: 2.504538706038147 Scheduler overhead time: 0.08340555755421519 Adapter cache time: 0.21125320484861732 Engine time: 0.08171828649938107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 3.0469498257152736,
    "estimated_duration": 3599.998896717071,
    "input_throughput": 2540.5271674778483,
    "output_throughput": 2242.7034650934575,
    "total_throughput": 4783.230632571306,
    "itl": 43.59014551106684,
    "ttft": 10877.780348293056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.760450224726789,
    "arrivals": 36981,
    "finished_requests": 36870,
    "scheduler_time": 17.780156489879275
}
#Debug simulation 
Total elapsed time: 3.0470229447819293. Arrivals time: 0.09445039974525571 Scheduler time: 2.5305622443556786 Scheduler overhead time: 0.08363649342209101 Adapter cache time: 0.21549161011353135 Engine time: 0.08315704250708222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.917979038786143,
    "estimated_duration": 3600.0042912037975,
    "input_throughput": 2471.4123318516713,
    "output_throughput": 2185.3376728529665,
    "total_throughput": 4656.750004704638,
    "itl": 40.95450205352211,
    "ttft": 9582.341172565706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.760617426347652,
    "arrivals": 35945,
    "finished_requests": 35850,
    "scheduler_time": 15.993970890369134
}
#Debug simulation 
Total elapsed time: 2.918057991657406. Arrivals time: 0.09120707493275404 Scheduler time: 2.4125279248692095 Scheduler overhead time: 0.08664213819429278 Adapter cache time: 0.20237085968255997 Engine time: 0.08333091251552105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.949581903871149,
    "estimated_duration": 3600.0167639462998,
    "input_throughput": 2471.4037693110904,
    "output_throughput": 2185.330101456537,
    "total_throughput": 4656.733870767627,
    "itl": 40.96683088353,
    "ttft": 9582.355636659508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.201161671043093,
    "arrivals": 35945,
    "finished_requests": 35850,
    "scheduler_time": 15.998571773065095
}
#Debug simulation 
Total elapsed time: 2.9496577088721097. Arrivals time: 0.09122367016971111 Scheduler time: 2.443189602345228 Scheduler overhead time: 0.08650875464081764 Adapter cache time: 0.20409942790865898 Engine time: 0.0831516170874238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.953028453979641,
    "estimated_duration": 3600.0083283071867,
    "input_throughput": 2471.409560372777,
    "output_throughput": 2185.33522218249,
    "total_throughput": 4656.744782555267,
    "itl": 40.96654880136119,
    "ttft": 9582.269134004515,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.215177231449582,
    "arrivals": 35945,
    "finished_requests": 35850,
    "scheduler_time": 15.99868817890734
}
#Debug simulation 
Total elapsed time: 2.9530937978997827. Arrivals time: 0.09119723783805966 Scheduler time: 2.4428623067215085 Scheduler overhead time: 0.08866656199097633 Adapter cache time: 0.20314763020724058 Engine time: 0.08552982332184911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.9384031696245074,
    "estimated_duration": 3599.9829871642064,
    "input_throughput": 2471.426957216944,
    "output_throughput": 2185.350605280833,
    "total_throughput": 4656.777562497778,
    "itl": 40.95915514007274,
    "ttft": 9582.24673188388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2208,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.923186971437883,
    "arrivals": 35945,
    "finished_requests": 35850,
    "scheduler_time": 15.995544904439283
}
#Debug simulation 
Total elapsed time: 2.938479672651738. Arrivals time: 0.09181755920872092 Scheduler time: 2.4279971849173307 Scheduler overhead time: 0.08660297561436892 Adapter cache time: 0.20433177379891276 Engine time: 0.08570522489026189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.9028444229625165,
    "estimated_duration": 3600.0230470341667,
    "input_throughput": 2471.399455992305,
    "output_throughput": 2185.3262874195525,
    "total_throughput": 4656.725743411857,
    "itl": 40.96942100727268,
    "ttft": 9582.272408435512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.299809529706683,
    "arrivals": 35945,
    "finished_requests": 35850,
    "scheduler_time": 15.999603014388722
}
#Debug simulation 
Total elapsed time: 2.902917875908315. Arrivals time: 0.09054403798654675 Scheduler time: 2.3972406177781522 Scheduler overhead time: 0.08788285218179226 Adapter cache time: 0.20217786077409983 Engine time: 0.08384004002436996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.938644614070654,
    "estimated_duration": 3600.0230400645046,
    "input_throughput": 2471.3994607769464,
    "output_throughput": 2185.3262916503545,
    "total_throughput": 4656.725752427301,
    "itl": 40.95098465658858,
    "ttft": 9582.400830794735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.605021101438708,
    "arrivals": 35945,
    "finished_requests": 35850,
    "scheduler_time": 15.992603161509253
}
#Debug simulation 
Total elapsed time: 2.9387167780660093. Arrivals time: 0.09152997378259897 Scheduler time: 2.4303334346041083 Scheduler overhead time: 0.08797916816547513 Adapter cache time: 0.20267873210832477 Engine time: 0.08474982064217329 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.932621684856713,
    "estimated_duration": 3599.9849190266636,
    "input_throughput": 2471.4256309733455,
    "output_throughput": 2185.34943255459,
    "total_throughput": 4656.775063527935,
    "itl": 40.971862292053736,
    "ttft": 9582.554619824621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.398652005828639,
    "arrivals": 35945,
    "finished_requests": 35850,
    "scheduler_time": 16.000443434958168
}
#Debug simulation 
Total elapsed time: 2.9326929631642997. Arrivals time: 0.09236667724326253 Scheduler time: 2.4236948085017502 Scheduler overhead time: 0.08709591953083873 Adapter cache time: 0.20271743508055806 Engine time: 0.08531666547060013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.814945748075843,
    "estimated_duration": 3600.0267333737697,
    "input_throughput": 2329.9007538589726,
    "output_throughput": 2081.9914837065226,
    "total_throughput": 4411.892237565495,
    "itl": 37.48561798361727,
    "ttft": 7468.534799852001,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.979413559378727,
    "arrivals": 34024,
    "finished_requests": 33954,
    "scheduler_time": 13.017469579730854
}
#Debug simulation 
Total elapsed time: 2.815025466028601. Arrivals time: 0.08836606098338962 Scheduler time: 2.308801128063351 Scheduler overhead time: 0.09308133507147431 Adapter cache time: 0.18622554326429963 Engine time: 0.09346216591075063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.834446335211396,
    "estimated_duration": 3600.0316618397533,
    "input_throughput": 2329.897564210189,
    "output_throughput": 2081.988633447089,
    "total_throughput": 4411.886197657278,
    "itl": 37.492256141531946,
    "ttft": 7468.582420290219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.309363536268825,
    "arrivals": 34024,
    "finished_requests": 33954,
    "scheduler_time": 13.020620109828984
}
#Debug simulation 
Total elapsed time: 2.8345180922187865. Arrivals time: 0.08800498070195317 Scheduler time: 2.325943390838802 Scheduler overhead time: 0.09301543887704611 Adapter cache time: 0.1902686688117683 Engine time: 0.09273958019912243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.803684996906668,
    "estimated_duration": 3600.005786610577,
    "input_throughput": 2329.9143104703353,
    "output_throughput": 2082.0035978488777,
    "total_throughput": 4411.917908319213,
    "itl": 37.49228434889586,
    "ttft": 7257.379268798547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.318730440996532,
    "arrivals": 34024,
    "finished_requests": 33954,
    "scheduler_time": 13.020623320650955
}
#Debug simulation 
Total elapsed time: 2.8037606738507748. Arrivals time: 0.08673619059845805 Scheduler time: 2.3035287517122924 Scheduler overhead time: 0.09229625621810555 Adapter cache time: 0.1888410598039627 Engine time: 0.08805302996188402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.8332169307395816,
    "estimated_duration": 3600.0164283515105,
    "input_throughput": 2329.5824246669595,
    "output_throughput": 2081.7935554343608,
    "total_throughput": 4411.37598010132,
    "itl": 37.66407466207796,
    "ttft": 7574.708808818536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.102075826753746,
    "arrivals": 34024,
    "finished_requests": 33952,
    "scheduler_time": 13.102449868651398
}
#Debug simulation 
Total elapsed time: 2.8333058548159897. Arrivals time: 0.08800134947523475 Scheduler time: 2.3284000218845904 Scheduler overhead time: 0.09389919601380825 Adapter cache time: 0.1900904648937285 Engine time: 0.0882864031009376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.8153753238730133,
    "estimated_duration": 3600.0168426247687,
    "input_throughput": 2329.9071550689005,
    "output_throughput": 2081.997203806202,
    "total_throughput": 4411.904358875102,
    "itl": 37.49438113819586,
    "ttft": 7362.934635560028,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.381607334203954,
    "arrivals": 34024,
    "finished_requests": 33954,
    "scheduler_time": 13.021296301635862
}
#Debug simulation 
Total elapsed time: 2.815448851790279. Arrivals time: 0.08805800136178732 Scheduler time: 2.309355256613344 Scheduler overhead time: 0.09231502283364534 Adapter cache time: 0.18980697449296713 Engine time: 0.09159026807174087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.808489117305726,
    "estimated_duration": 3600.0068741934097,
    "input_throughput": 2329.913606589789,
    "output_throughput": 2082.002968863587,
    "total_throughput": 4411.916575453376,
    "itl": 37.48254017863103,
    "ttft": 7257.371394532971,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.864811829805704,
    "arrivals": 34024,
    "finished_requests": 33954,
    "scheduler_time": 13.01615193141742
}
#Debug simulation 
Total elapsed time: 2.8085839091800153. Arrivals time: 0.08729042625054717 Scheduler time: 2.3047545989975333 Scheduler overhead time: 0.09291209932416677 Adapter cache time: 0.1894057341851294 Engine time: 0.0897567761130631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.843687950167805,
    "estimated_duration": 3600.0181350998205,
    "input_throughput": 2329.906318587872,
    "output_throughput": 2081.996456329566,
    "total_throughput": 4411.902774917438,
    "itl": 37.49551096998734,
    "ttft": 7468.652844479774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.455550560615875,
    "arrivals": 34024,
    "finished_requests": 33954,
    "scheduler_time": 13.022089792875942
}
#Debug simulation 
Total elapsed time: 2.843761323019862. Arrivals time: 0.08745798328891397 Scheduler time: 2.339180820155889 Scheduler overhead time: 0.09311786340549588 Adapter cache time: 0.19113176502287388 Engine time: 0.08834176789969206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.4476666529662907,
    "estimated_duration": 3599.774318385101,
    "input_throughput": 1857.2853208751508,
    "output_throughput": 1666.0286088963676,
    "total_throughput": 3523.3139297715184,
    "itl": 33.475326036793724,
    "ttft": 7622.460838005214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.972021005959714,
    "arrivals": 27120,
    "finished_requests": 27063,
    "scheduler_time": 5.059221422920384
}
#Debug simulation 
Total elapsed time: 2.4477413706481457. Arrivals time: 0.07417947193607688 Scheduler time: 1.8797220126725733 Scheduler overhead time: 0.10115365078672767 Adapter cache time: 0.24642060045152903 Engine time: 0.0975753883831203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.4561657877638936,
    "estimated_duration": 3599.74872508493,
    "input_throughput": 1857.298525702585,
    "output_throughput": 1666.0404539371018,
    "total_throughput": 3523.338979639687,
    "itl": 33.503524303597466,
    "ttft": 7622.666934372366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.484919490593366,
    "arrivals": 27120,
    "finished_requests": 27063,
    "scheduler_time": 5.073492715041902
}
#Debug simulation 
Total elapsed time: 2.456258098129183. Arrivals time: 0.07500172173604369 Scheduler time: 1.8851712788455188 Scheduler overhead time: 0.10164631670340896 Adapter cache time: 0.2456664852797985 Engine time: 0.09985462622717023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.4664545417763293,
    "estimated_duration": 3599.753330269421,
    "input_throughput": 1857.2961496502332,
    "output_throughput": 1666.0383225622668,
    "total_throughput": 3523.3344722125003,
    "itl": 33.50467788911734,
    "ttft": 7622.669390648298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7507,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.528200262952776,
    "arrivals": 27120,
    "finished_requests": 27063,
    "scheduler_time": 5.0737714732987795
}
#Debug simulation 
Total elapsed time: 2.466531615704298. Arrivals time: 0.07445713598281145 Scheduler time: 1.8968360093422234 Scheduler overhead time: 0.10132370283827186 Adapter cache time: 0.2462942572310567 Engine time: 0.09892515232786536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.4859992931596935,
    "estimated_duration": 3599.776379892964,
    "input_throughput": 1857.284257251223,
    "output_throughput": 1666.027654800692,
    "total_throughput": 3523.311912051915,
    "itl": 33.48353080837203,
    "ttft": 7622.563597938661,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.486721127644408,
    "arrivals": 27120,
    "finished_requests": 27063,
    "scheduler_time": 5.064058637971696
}
#Debug simulation 
Total elapsed time: 2.486085996031761. Arrivals time: 0.07790137827396393 Scheduler time: 1.9111971203237772 Scheduler overhead time: 0.10152165312319994 Adapter cache time: 0.2475812085904181 Engine time: 0.09902977617457509 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.4646743200719357,
    "estimated_duration": 3599.7732752616903,
    "input_throughput": 1857.2858590695455,
    "output_throughput": 1666.029091669396,
    "total_throughput": 3523.314950738941,
    "itl": 33.51039114240712,
    "ttft": 7622.715461254367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.842092555928094,
    "arrivals": 27120,
    "finished_requests": 27063,
    "scheduler_time": 5.0767415298850675
}
#Debug simulation 
Total elapsed time: 2.4647709811106324. Arrivals time: 0.07426155172288418 Scheduler time: 1.8973236470483243 Scheduler overhead time: 0.10111399414017797 Adapter cache time: 0.24575119838118553 Engine time: 0.09761936636641622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.446140726096928,
    "estimated_duration": 3599.7537336049913,
    "input_throughput": 1857.295941548886,
    "output_throughput": 1666.0381358904647,
    "total_throughput": 3523.3340774393505,
    "itl": 33.46408446803825,
    "ttft": 7622.423173573276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7506,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.44331751353543,
    "arrivals": 27120,
    "finished_requests": 27063,
    "scheduler_time": 5.054377160614993
}
#Debug simulation 
Total elapsed time: 2.4462158661335707. Arrivals time: 0.0733649986796081 Scheduler time: 1.8787291226908565 Scheduler overhead time: 0.10152542032301426 Adapter cache time: 0.2466830462217331 Engine time: 0.09691780945286155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_256_slots_160_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 135, 540, 540, 135, 540, 270, 540, 135, 270, 135, 540, 270, 270, 270, 270, 540, 135, 135, 135, 270, 540, 135, 540, 540, 270, 270, 270, 135, 540, 135, 270, 270, 135, 270, 135, 135, 270, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 540, 135, 540, 540, 270, 135, 135, 540, 270, 135, 270, 270, 540, 270, 135, 135, 540, 540, 540, 540, 540, 540, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 540, 540, 135, 540, 135, 270, 540, 540, 540, 270, 135, 540, 270, 135, 135, 135, 135, 135, 540, 270, 135, 540, 135, 540, 135, 135, 270, 270, 540, 270, 540, 135, 270, 135, 540, 540, 135, 540, 270, 135, 540, 135, 135, 540, 540, 270, 540, 540, 135, 540, 270, 270, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 135, 135, 135, 135, 135, 540, 135, 135, 135, 540, 135, 270, 540, 540, 270, 135, 540, 135, 270, 270, 135, 270, 135, 540, 135, 135, 540, 135, 540, 540, 270, 540, 270, 135, 270, 540, 270, 540, 135, 540, 135, 270, 540, 270, 540, 270, 540, 270, 540, 270, 135, 540, 135, 540, 270, 270, 135, 270, 540, 270, 270, 540, 135, 540, 540, 270, 135, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 135, 540, 270, 540, 540, 135, 540, 270, 270, 540, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 540, 270, 135, 135, 135, 135]
Prompts retrieved: 80865 . Total input tokens: 18012338 . Total output tokens: 16162627
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.4469228931702673,
    "estimated_duration": 3599.777818944285,
    "input_throughput": 1857.2835147811322,
    "output_throughput": 1666.0269887875606,
    "total_throughput": 3523.3105035686926,
    "itl": 33.51664867006336,
    "ttft": 7622.6216215487075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.157874899504534,
    "arrivals": 27120,
    "finished_requests": 27063,
    "scheduler_time": 5.079817502212417
}
#Debug simulation 
Total elapsed time: 2.4470184692181647. Arrivals time: 0.07462134025990963 Scheduler time: 1.8771006893366575 Scheduler overhead time: 0.10089433891698718 Adapter cache time: 0.24737618397921324 Engine time: 0.09835849609225988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.302399142179638,
    "estimated_duration": 3600.0172221820176,
    "input_throughput": 1727.092848803499,
    "output_throughput": 1530.5476779525843,
    "total_throughput": 3257.6405267560835,
    "itl": 30.57602833585466,
    "ttft": 5911.64621061198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.761511881251941,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.242639253491379
}
#Debug simulation 
Total elapsed time: 2.3024704293347895. Arrivals time: 0.06966350320726633 Scheduler time: 1.742806843481958 Scheduler overhead time: 0.10767700709402561 Adapter cache time: 0.22589654289186 Engine time: 0.10398099152371287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.280591290909797,
    "estimated_duration": 3600.001899111519,
    "input_throughput": 1727.1002000122544,
    "output_throughput": 1530.5541925852508,
    "total_throughput": 3257.654392597505,
    "itl": 30.593590536045735,
    "ttft": 5911.606476800058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5153,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.812479874429627,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.2491621948699643
}
#Debug simulation 
Total elapsed time: 2.2806639769114554. Arrivals time: 0.0697368448600173 Scheduler time: 1.7213186621665955 Scheduler overhead time: 0.10943523840978742 Adapter cache time: 0.22532515041530132 Engine time: 0.10230368562042713 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.2879013721831143,
    "estimated_duration": 3600.0166561003607,
    "input_throughput": 1727.093120378793,
    "output_throughput": 1530.5479186222947,
    "total_throughput": 3257.6410390010874,
    "itl": 30.59340060983335,
    "ttft": 5911.779126612658,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5152,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.83932874755808,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.2492625643389736
}
#Debug simulation 
Total elapsed time: 2.2879928559996188. Arrivals time: 0.07017990993335843 Scheduler time: 1.7253013476729393 Scheduler overhead time: 0.10946661559864879 Adapter cache time: 0.22531663393601775 Engine time: 0.10528278769925237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.297872230876237,
    "estimated_duration": 3600.0039329036385,
    "input_throughput": 1727.099224301438,
    "output_throughput": 1530.5533279114577,
    "total_throughput": 3257.6525522128954,
    "itl": 30.58328975209346,
    "ttft": 5911.678867695411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5152,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.12795283297682,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.244734964544783
}
#Debug simulation 
Total elapsed time: 2.2979448409751058. Arrivals time: 0.07040994241833687 Scheduler time: 1.7379222274757922 Scheduler overhead time: 0.10836255736649036 Adapter cache time: 0.22394282184541225 Engine time: 0.10479290969669819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.3140837461687624,
    "estimated_duration": 3600.0165380355447,
    "input_throughput": 1727.0931770199027,
    "output_throughput": 1530.54796881758,
    "total_throughput": 3257.641145837483,
    "itl": 30.596780115398897,
    "ttft": 5911.813102491741,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.042324530611438,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.2503168833777583
}
#Debug simulation 
Total elapsed time: 2.314155458007008. Arrivals time: 0.07135627279058099 Scheduler time: 1.7477717753499746 Scheduler overhead time: 0.10834304476156831 Adapter cache time: 0.2275325651280582 Engine time: 0.10656621912494302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.3028382901102304,
    "estimated_duration": 3600.0185592797693,
    "input_throughput": 1727.0922073368158,
    "output_throughput": 1530.547109485554,
    "total_throughput": 3257.63931682237,
    "itl": 30.57023496819905,
    "ttft": 5911.694934238898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.39875901874789,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.2404424222369825
}
#Debug simulation 
Total elapsed time: 2.3029085653834045. Arrivals time: 0.07037214422598481 Scheduler time: 1.743035285267979 Scheduler overhead time: 0.10812324983999133 Adapter cache time: 0.2240679720416665 Engine time: 0.10495847137644887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 66, 540, 540, 66, 540, 270, 540, 66, 270, 66, 540, 270, 270, 270, 270, 540, 66, 66, 66, 270, 540, 66, 540, 540, 270, 270, 270, 66, 540, 66, 270, 270, 66, 270, 66, 66, 270, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 540, 66, 540, 540, 270, 66, 66, 540, 270, 66, 270, 270, 540, 270, 66, 66, 540, 540, 540, 540, 540, 540, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 540, 540, 66, 540, 66, 270, 540, 540, 540, 270, 66, 540, 270, 66, 66, 66, 66, 66, 540, 270, 66, 540, 66, 540, 66, 66, 270, 270, 540, 270, 540, 66, 270, 66, 540, 540, 66, 540, 270, 66, 540, 66, 66, 540, 540, 270, 540, 540, 66, 540, 270, 270, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 270, 540, 540, 270, 66, 540, 66, 270, 270, 66, 270, 66, 540, 66, 66, 540, 66, 540, 540, 270, 540, 270, 66, 270, 540, 270, 540, 66, 540, 66, 270, 540, 270, 540, 270, 540, 270, 540, 270, 66, 540, 66, 540, 270, 270, 66, 270, 540, 270, 270, 540, 66, 540, 540, 270, 66, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 66, 540, 270, 540, 540, 66, 540, 270, 270, 540, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 540, 270, 66, 66, 66, 66]
Prompts retrieved: 75000 . Total input tokens: 16686693 . Total output tokens: 14993236
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.2622130098752677,
    "estimated_duration": 3600.022926304364,
    "input_throughput": 1727.0901122795617,
    "output_throughput": 1530.5452528482474,
    "total_throughput": 3257.635365127809,
    "itl": 30.60051518114678,
    "ttft": 5911.810964938752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.26102495107675,
    "arrivals": 25185,
    "finished_requests": 25144,
    "scheduler_time": 2.251801327928892
}
#Debug simulation 
Total elapsed time: 2.2622803379781544. Arrivals time: 0.06952100014314055 Scheduler time: 1.702068286947906 Scheduler overhead time: 0.10759742790833116 Adapter cache time: 0.2249703574925661 Engine time: 0.10582070564851165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.1973139750771224,
    "estimated_duration": 3599.8617859107953,
    "input_throughput": 1634.7141501464923,
    "output_throughput": 1468.5355478620033,
    "total_throughput": 3103.2496980084957,
    "itl": 29.355554559524926,
    "ttft": 5853.365856500312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.785158809618554,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.3847378027698731
}
#Debug simulation 
Total elapsed time: 2.197382425889373. Arrivals time: 0.06673390604555607 Scheduler time: 1.6461951290257275 Scheduler overhead time: 0.11095706559717655 Adapter cache time: 0.2148196347989142 Engine time: 0.1047626961953938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.243366612121463,
    "estimated_duration": 3599.87145900317,
    "input_throughput": 1634.7097575616012,
    "output_throughput": 1468.5316018099925,
    "total_throughput": 3103.2413593715937,
    "itl": 29.36468050711881,
    "ttft": 5853.421586365149,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.484878378017157,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.3878242834173622
}
#Debug simulation 
Total elapsed time: 2.2434616098180413. Arrivals time: 0.06926658330485225 Scheduler time: 1.6818215204402804 Scheduler overhead time: 0.11138021247461438 Adapter cache time: 0.2157419347204268 Engine time: 0.11086597526445985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.20771481981501,
    "estimated_duration": 3599.8627540175935,
    "input_throughput": 1634.713710524765,
    "output_throughput": 1468.5351529304896,
    "total_throughput": 3103.2488634552547,
    "itl": 29.366967372125107,
    "ttft": 5853.4552184468785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.50777461036975,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.3880641364438249
}
#Debug simulation 
Total elapsed time: 2.2077939775772393. Arrivals time: 0.06759256310760975 Scheduler time: 1.657505739480257 Scheduler overhead time: 0.11100846854969859 Adapter cache time: 0.21118019986897707 Engine time: 0.10643337108194828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.2394787850789726,
    "estimated_duration": 3599.8709560968714,
    "input_throughput": 1634.709985932519,
    "output_throughput": 1468.531806965622,
    "total_throughput": 3103.241792898141,
    "itl": 29.35759963705187,
    "ttft": 5853.410305090352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.03690907981981,
    "arrivals": 24188,
    "finished_requests": 24149,
    "scheduler_time": 1.3857735238724427
}
#Debug simulation 
Total elapsed time: 2.2395540620200336. Arrivals time: 0.06750381737947464 Scheduler time: 1.6855307053774595 Scheduler overhead time: 0.11125561548396945 Adapter cache time: 0.21489715296775103 Engine time: 0.10635359166190028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.240366911981255,
    "estimated_duration": 3599.885845078582,
    "input_throughput": 1634.7693380459225,
    "output_throughput": 1468.6296253609653,
    "total_throughput": 3103.398963406888,
    "itl": 29.367822218034892,
    "ttft": 5704.7086370375755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.653574104774052,
    "arrivals": 24188,
    "finished_requests": 24150,
    "scheduler_time": 1.388528580504558
}
#Debug simulation 
Total elapsed time: 2.2404383602552116. Arrivals time: 0.06766160996630788 Scheduler time: 1.6816318011842668 Scheduler overhead time: 0.11079499498009682 Adapter cache time: 0.21644459897652268 Engine time: 0.10974617069587111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.205113633070141,
    "estimated_duration": 3599.8766302848244,
    "input_throughput": 1634.773522651074,
    "output_throughput": 1468.6333846895463,
    "total_throughput": 3103.4069073406204,
    "itl": 29.352312942232647,
    "ttft": 5704.4385118205755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3528,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.548897440415294,
    "arrivals": 24188,
    "finished_requests": 24150,
    "scheduler_time": 1.3838987344113143
}
#Debug simulation 
Total elapsed time: 2.205214024055749. Arrivals time: 0.06781713292002678 Scheduler time: 1.6444223867729306 Scheduler overhead time: 0.11267292872071266 Adapter cache time: 0.21424631867557764 Engine time: 0.11148548033088446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_256_slots_160_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 540, 33, 540, 540, 33, 540, 270, 540, 33, 270, 33, 540, 270, 270, 270, 270, 540, 33, 33, 33, 270, 540, 33, 540, 540, 270, 270, 270, 33, 540, 33, 270, 270, 33, 270, 33, 33, 270, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 540, 33, 540, 540, 270, 33, 33, 540, 270, 33, 270, 270, 540, 270, 33, 33, 540, 540, 540, 540, 540, 540, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 540, 540, 33, 540, 33, 270, 540, 540, 540, 270, 33, 540, 270, 33, 33, 33, 33, 33, 540, 270, 33, 540, 33, 540, 33, 33, 270, 270, 540, 270, 540, 33, 270, 33, 540, 540, 33, 540, 270, 33, 540, 33, 33, 540, 540, 270, 540, 540, 33, 540, 270, 270, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 270, 540, 540, 270, 33, 540, 33, 270, 270, 33, 270, 33, 540, 33, 33, 540, 33, 540, 540, 270, 540, 270, 33, 270, 540, 270, 540, 33, 540, 33, 270, 540, 270, 540, 270, 540, 270, 540, 270, 33, 540, 33, 540, 270, 270, 33, 270, 540, 270, 270, 540, 33, 540, 540, 270, 33, 540, 540, 270, 270, 540, 540, 270, 270, 270, 270, 540, 540, 270, 270, 540, 33, 540, 270, 540, 540, 33, 540, 270, 270, 540, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 540, 270, 33, 33, 33, 33]
Prompts retrieved: 72195 . Total input tokens: 16059542 . Total output tokens: 14433736
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.2263391450978816,
    "estimated_duration": 3599.88727251894,
    "input_throughput": 1634.7686898212555,
    "output_throughput": 1468.6290430146196,
    "total_throughput": 3103.397732835875,
    "itl": 29.36880358553151,
    "ttft": 5704.547031675435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.803029914981902,
    "arrivals": 24188,
    "finished_requests": 24150,
    "scheduler_time": 1.3893494681609444
}
#Debug simulation 
Total elapsed time: 2.226411961019039. Arrivals time: 0.06854002550244331 Scheduler time: 1.6700458857230842 Scheduler overhead time: 0.11149977194145322 Adapter cache time: 0.21488912403583527 Engine time: 0.10738065233454108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.0518585480749607,
    "estimated_duration": 3599.946418186027,
    "input_throughput": 1450.9952074875787,
    "output_throughput": 1297.4448665137438,
    "total_throughput": 2748.4400740013225,
    "itl": 26.94144545631752,
    "ttft": 6653.570447382421,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.222808557000826,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.170896326603052
}
#Debug simulation 
Total elapsed time: 2.0519314338453114. Arrivals time: 0.06195640889927745 Scheduler time: 1.5047975052148104 Scheduler overhead time: 0.11774000199511647 Adapter cache time: 0.1948083844035864 Engine time: 0.11485110456123948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.021762922871858,
    "estimated_duration": 3599.94202226681,
    "input_throughput": 1450.996979309924,
    "output_throughput": 1297.4464508344875,
    "total_throughput": 2748.443430144411,
    "itl": 26.950473592696575,
    "ttft": 6653.644454512735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.962712794356415,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.17175411801982304
}
#Debug simulation 
Total elapsed time: 2.0218366677872837. Arrivals time: 0.06090255593881011 Scheduler time: 1.479546989314258 Scheduler overhead time: 0.11650331597775221 Adapter cache time: 0.19396436028182507 Engine time: 0.11354626202955842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.0567205883562565,
    "estimated_duration": 3599.9615588610714,
    "input_throughput": 1450.9891049093794,
    "output_throughput": 1297.4394097357226,
    "total_throughput": 2748.428514645102,
    "itl": 26.952590856886825,
    "ttft": 6653.58834992786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.9810984812297,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.17168297944709845
}
#Debug simulation 
Total elapsed time: 2.0568036013282835. Arrivals time: 0.06264956900849938 Scheduler time: 1.5075727491639555 Scheduler overhead time: 0.11773501802235842 Adapter cache time: 0.19611823791638017 Engine time: 0.11468524998053908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 2.055135129019618,
    "estimated_duration": 3599.966156035272,
    "input_throughput": 1450.9872519892715,
    "output_throughput": 1297.4377528993184,
    "total_throughput": 2748.4250048885897,
    "itl": 26.945076170469505,
    "ttft": 6653.5903821010825,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.482074816804838,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.171179129667946
}
#Debug simulation 
Total elapsed time: 2.0552108441479504. Arrivals time: 0.06180637562647462 Scheduler time: 1.504622294101864 Scheduler overhead time: 0.11801162548363209 Adapter cache time: 0.19449133425951004 Engine time: 0.1182116218842566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 2.038025082089007,
    "estimated_duration": 3599.9613787230724,
    "input_throughput": 1450.9891775152344,
    "output_throughput": 1297.4394746581243,
    "total_throughput": 2748.428652173359,
    "itl": 26.953418175143998,
    "ttft": 6653.644076846496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.13148542389198,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.17166254703090275
}
#Debug simulation 
Total elapsed time: 2.0381011092104018. Arrivals time: 0.061221092008054256 Scheduler time: 1.4945673481561244 Scheduler overhead time: 0.11712767602875829 Adapter cache time: 0.1920213266275823 Engine time: 0.11501317890360951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 2.042391813825816,
    "estimated_duration": 3599.941225718652,
    "input_throughput": 1450.9973003676575,
    "output_throughput": 1297.446737916558,
    "total_throughput": 2748.4440382842154,
    "itl": 26.938328532785654,
    "ttft": 6653.448707903882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.964514431406805,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.1706566405666199
}
#Debug simulation 
Total elapsed time: 2.042466589715332. Arrivals time: 0.06140710087493062 Scheduler time: 1.4976853062398732 Scheduler overhead time: 0.1172794341109693 Adapter cache time: 0.19483855040743947 Engine time: 0.11355691822245717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 250432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_256_slots_160_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 66, 540, 540, 66, 540, 135, 540, 66, 135, 66, 540, 135, 135, 135, 135, 540, 66, 66, 66, 135, 540, 66, 540, 540, 135, 135, 135, 66, 540, 66, 135, 135, 66, 135, 66, 66, 135, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 540, 66, 540, 540, 135, 66, 66, 540, 135, 66, 135, 135, 540, 135, 66, 66, 540, 540, 540, 540, 540, 540, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 540, 540, 66, 540, 66, 135, 540, 540, 540, 135, 66, 540, 135, 66, 66, 66, 66, 66, 540, 135, 66, 540, 66, 540, 66, 66, 135, 135, 540, 135, 540, 66, 135, 66, 540, 540, 66, 540, 135, 66, 540, 66, 66, 540, 540, 135, 540, 540, 66, 540, 135, 135, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 66, 66, 66, 66, 66, 540, 66, 66, 66, 540, 66, 135, 540, 540, 135, 66, 540, 66, 135, 135, 66, 135, 66, 540, 66, 66, 540, 66, 540, 540, 135, 540, 135, 66, 135, 540, 135, 540, 66, 540, 66, 135, 540, 135, 540, 135, 540, 135, 540, 135, 66, 540, 66, 540, 135, 135, 66, 135, 540, 135, 135, 540, 66, 540, 540, 135, 66, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 66, 540, 135, 540, 540, 66, 540, 135, 135, 540, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 540, 135, 66, 66, 66, 66]
Prompts retrieved: 63525 . Total input tokens: 14099936 . Total output tokens: 12725172
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 2.042365681845695,
    "estimated_duration": 3599.9616863041983,
    "input_throughput": 1450.989053542558,
    "output_throughput": 1297.4393638047516,
    "total_throughput": 2748.4284173473097,
    "itl": 26.95631128353906,
    "ttft": 6653.644681298484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.29169574778451,
    "arrivals": 21245,
    "finished_requests": 21206,
    "scheduler_time": 0.17192662703758638
}
#Debug simulation 
Total elapsed time: 2.0424407538957894. Arrivals time: 0.06207032781094313 Scheduler time: 1.4974361159838736 Scheduler overhead time: 0.11746207810938358 Adapter cache time: 0.1931290877982974 Engine time: 0.11428482923656702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 587328,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_256_slots_160_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 1.9778878376819193,
    "estimated_duration": 3600.0169542130243,
    "input_throughput": 1394.9664859558432,
    "output_throughput": 1245.5255230819319,
    "total_throughput": 2640.492009037775,
    "itl": 26.450379432150125,
    "ttft": 6031.808067823721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2342,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.167662296290723,
    "arrivals": 20441,
    "finished_requests": 20407,
    "scheduler_time": 0.11790298503672973
}
#Debug simulation 
Total elapsed time: 1.9779660808853805. Arrivals time: 0.05987146031111479 Scheduler time: 1.440286573022604 Scheduler overhead time: 0.11971013015136123 Adapter cache time: 0.1828947626054287 Engine time: 0.11592996120452881 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 160,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 477168,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_256_slots_160_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 540, 33, 540, 540, 33, 540, 135, 540, 33, 135, 33, 540, 135, 135, 135, 135, 540, 33, 33, 33, 135, 540, 33, 540, 540, 135, 135, 135, 33, 540, 33, 135, 135, 33, 135, 33, 33, 135, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 540, 33, 540, 540, 135, 33, 33, 540, 135, 33, 135, 135, 540, 135, 33, 33, 540, 540, 540, 540, 540, 540, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 540, 540, 33, 540, 33, 135, 540, 540, 540, 135, 33, 540, 135, 33, 33, 33, 33, 33, 540, 135, 33, 540, 33, 540, 33, 33, 135, 135, 540, 135, 540, 33, 135, 33, 540, 540, 33, 540, 135, 33, 540, 33, 33, 540, 540, 135, 540, 540, 33, 540, 135, 135, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 33, 33, 33, 33, 33, 540, 33, 33, 33, 540, 33, 135, 540, 540, 135, 33, 540, 33, 135, 135, 33, 135, 33, 540, 33, 33, 540, 33, 540, 540, 135, 540, 135, 33, 135, 540, 135, 540, 33, 540, 33, 135, 540, 135, 540, 135, 540, 135, 540, 135, 33, 540, 33, 540, 135, 135, 33, 135, 540, 135, 135, 540, 33, 540, 540, 135, 33, 540, 540, 135, 135, 540, 540, 135, 135, 135, 135, 540, 540, 135, 135, 540, 33, 540, 135, 540, 540, 33, 540, 135, 135, 540, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 540, 135, 33, 33, 33, 33]
Prompts retrieved: 60720 . Total input tokens: 13472222 . Total output tokens: 12171855
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 1.9999432382173836,
    "estimated_duration": 3600.0075265225623,
    "input_throughput": 1394.970139090493,
    "output_throughput": 1245.5287848609719,
    "total_throughput": 2640.498923951465,
    "itl": 26.24522855326879,
    "ttft": 6031.633609767543,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.63875081840637,
    "arrivals": 20441,
    "finished_requests": 20407,
    "scheduler_time": 0.1084142378456677
}
#Debug simulation 
Total elapsed time: 2.0000168941915035. Arrivals time: 0.060123436618596315 Scheduler time: 1.4576704273931682 Scheduler overhead time: 0.11953263031318784 Adapter cache time: 0.1832716166973114 Engine time: 0.12013366632163525 
