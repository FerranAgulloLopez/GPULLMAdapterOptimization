INFO 06-01 00:46:59 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:59 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.14088932197774,
    "estimated_duration": 3600.06513714127,
    "input_throughput": 6387.057768143293,
    "output_throughput": 5631.335053036975,
    "total_throughput": 12018.392821180269,
    "itl": 152.0185488197923,
    "ttft": 1253067.0842662042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.376543409388978,
    "arrivals": 143761,
    "finished_requests": 92510,
    "scheduler_time": 97.90250914447567
}
#Debug simulation 
Total elapsed time: 20.141046415956225. Arrivals time: 0.34282322390936315 Scheduler time: 19.680484704556875 Scheduler overhead time: 0.044673872587736696 Adapter cache time: 0.008470347616821527 Engine time: 0.045439130160957575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.21807558601722,
    "estimated_duration": 3600.0676064691643,
    "input_throughput": 6387.053387186703,
    "output_throughput": 5631.331190439311,
    "total_throughput": 12018.384577626013,
    "itl": 152.01855384451437,
    "ttft": 1253068.7770524435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3769844671711334,
    "arrivals": 143761,
    "finished_requests": 92510,
    "scheduler_time": 97.9026101331589
}
#Debug simulation 
Total elapsed time: 20.21825631498359. Arrivals time: 0.347813205444254 Scheduler time: 19.75314508372685 Scheduler overhead time: 0.04394547070842236 Adapter cache time: 0.008477911062072963 Engine time: 0.04540191689739004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 20.18738768697949,
    "estimated_duration": 3600.155964739871,
    "input_throughput": 6387.023569314018,
    "output_throughput": 5631.233535035155,
    "total_throughput": 12018.257104349172,
    "itl": 152.0166329976142,
    "ttft": 1253062.7890527316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3597910013329239,
    "arrivals": 143761,
    "finished_requests": 92513,
    "scheduler_time": 97.90522879978573
}
#Debug simulation 
Total elapsed time: 20.187490305979736. Arrivals time: 0.3537499418016523 Scheduler time: 19.714708957762923 Scheduler overhead time: 0.04566457000328228 Adapter cache time: 0.008383240434341133 Engine time: 0.045555389020591974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 20.244092229986563,
    "estimated_duration": 3600.0940955618535,
    "input_throughput": 6387.006669727459,
    "output_throughput": 5631.325310355817,
    "total_throughput": 12018.331980083276,
    "itl": 152.0188550253945,
    "ttft": 1253047.9516555523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.382140372414142,
    "arrivals": 143761,
    "finished_requests": 92511,
    "scheduler_time": 97.90334665904547
}
#Debug simulation 
Total elapsed time: 20.244266414956655. Arrivals time: 0.35177545878104866 Scheduler time: 19.77407284057699 Scheduler overhead time: 0.04514552594628185 Adapter cache time: 0.00833014614181593 Engine time: 0.04580805968726054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 20.300451571005397,
    "estimated_duration": 3600.0860271141933,
    "input_throughput": 6387.020984171233,
    "output_throughput": 5631.337931180204,
    "total_throughput": 12018.358915351437,
    "itl": 152.017419055209,
    "ttft": 1253041.2282924864,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3438557839137506,
    "arrivals": 143761,
    "finished_requests": 92511,
    "scheduler_time": 97.90331109806323
}
#Debug simulation 
Total elapsed time: 20.30058541300241. Arrivals time: 0.35388329188572243 Scheduler time: 19.827336898772046 Scheduler overhead time: 0.04524386493721977 Adapter cache time: 0.008618385414592922 Engine time: 0.04600973229389638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 540, 8640, 540, 540, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 540, 8640, 4320, 540, 540, 4320, 8640, 540, 4320, 540, 540, 4320, 4320, 4320, 540, 540, 8640, 4320, 4320, 540, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 540, 8640, 4320, 4320, 4320, 8640, 8640, 540, 540, 4320, 540, 8640, 540, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 540, 540, 8640, 4320, 8640, 540, 4320, 8640, 540, 8640, 4320, 540, 8640, 540, 540, 8640, 540, 540, 4320]
Prompts retrieved: 432000 . Total input tokens: 96291061 . Total output tokens: 86418789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.280007630004548,
    "estimated_duration": 3600.1055299357504,
    "input_throughput": 6386.986383815911,
    "output_throughput": 5631.307424580359,
    "total_throughput": 12018.293808396269,
    "itl": 152.0188345496846,
    "ttft": 1253053.1199252487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3870447700843211,
    "arrivals": 143761,
    "finished_requests": 92511,
    "scheduler_time": 97.90363720009427
}
#Debug simulation 
Total elapsed time: 20.28013580699917. Arrivals time: 0.3515251018689014 Scheduler time: 19.810645291872788 Scheduler overhead time: 0.044831122271716595 Adapter cache time: 0.00858422223245725 Engine time: 0.04523671860806644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.473294182971586,
    "estimated_duration": 3600.0359397859065,
    "input_throughput": 6391.8650771493285,
    "output_throughput": 5631.167671399858,
    "total_throughput": 12023.032748549185,
    "itl": 151.83024459198757,
    "ttft": 1244804.4651519505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3213512131129388,
    "arrivals": 140843,
    "finished_requests": 92640,
    "scheduler_time": 97.49599072443424
}
#Debug simulation 
Total elapsed time: 14.473417615983635. Arrivals time: 0.32879514450905845 Scheduler time: 14.033968935254961 Scheduler overhead time: 0.041724804090335965 Adapter cache time: 0.007768292562104762 Engine time: 0.042507134610787034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.407725817000028,
    "estimated_duration": 3600.0928033412047,
    "input_throughput": 6391.764117481584,
    "output_throughput": 5631.078726966542,
    "total_throughput": 12022.842844448127,
    "itl": 151.8298687443698,
    "ttft": 1244816.771644785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34296554857399314,
    "arrivals": 140843,
    "finished_requests": 92640,
    "scheduler_time": 97.49735607554643
}
#Debug simulation 
Total elapsed time: 14.40785139601212. Arrivals time: 0.3225402486277744 Scheduler time: 13.974287035060115 Scheduler overhead time: 0.04202315985457972 Adapter cache time: 0.007760298729408532 Engine time: 0.04262525128433481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.498699140967801,
    "estimated_duration": 3600.0929287539243,
    "input_throughput": 6391.763894818299,
    "output_throughput": 5631.078530802467,
    "total_throughput": 12022.842425620767,
    "itl": 151.82975554293733,
    "ttft": 1244816.858294474,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3435140512324875,
    "arrivals": 140843,
    "finished_requests": 92640,
    "scheduler_time": 97.49735396601727
}
#Debug simulation 
Total elapsed time: 14.498803105961997. Arrivals time: 0.3291500767227262 Scheduler time: 14.057699338416569 Scheduler overhead time: 0.04237449471838772 Adapter cache time: 0.007854039431549609 Engine time: 0.043001765210647136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 14.466559162014164,
    "estimated_duration": 3600.062104035133,
    "input_throughput": 6391.818622853245,
    "output_throughput": 5631.126745640764,
    "total_throughput": 12022.945368494009,
    "itl": 151.83046571250722,
    "ttft": 1244807.7904843402,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32866471242858114,
    "arrivals": 140843,
    "finished_requests": 92640,
    "scheduler_time": 97.49666235534401
}
#Debug simulation 
Total elapsed time: 14.466692087997217. Arrivals time: 0.3289516407530755 Scheduler time: 14.026702946808655 Scheduler overhead time: 0.0418353698332794 Adapter cache time: 0.00797164934920147 Engine time: 0.04251542984275147 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 14.718785685952753,
    "estimated_duration": 3600.0980277547837,
    "input_throughput": 6391.754841839924,
    "output_throughput": 5631.070555221234,
    "total_throughput": 12022.825397061159,
    "itl": 151.82961930960806,
    "ttft": 1244838.808741383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3479154337570072,
    "arrivals": 140843,
    "finished_requests": 92640,
    "scheduler_time": 97.4974226351708
}
#Debug simulation 
Total elapsed time: 14.718895053956658. Arrivals time: 0.342600850854069 Scheduler time: 14.262482613907196 Scheduler overhead time: 0.04268763092113659 Adapter cache time: 0.008002902439329773 Engine time: 0.04431033233413473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.481067535001785,
    "estimated_duration": 3600.0106996514896,
    "input_throughput": 6391.909891331058,
    "output_throughput": 5631.207152235002,
    "total_throughput": 12023.117043566059,
    "itl": 151.82973365136618,
    "ttft": 1244803.6386906256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3139552809647288,
    "arrivals": 140843,
    "finished_requests": 92640,
    "scheduler_time": 97.4953291340891
}
#Debug simulation 
Total elapsed time: 14.481226755015086. Arrivals time: 0.33512845705263317 Scheduler time: 14.034021533618215 Scheduler overhead time: 0.04218486783793196 Adapter cache time: 0.007920646865386516 Engine time: 0.04324514663312584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 270, 8640, 270, 270, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 270, 8640, 4320, 270, 270, 4320, 8640, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 270, 8640, 4320, 4320, 270, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 270, 8640, 4320, 4320, 4320, 8640, 8640, 270, 270, 4320, 270, 8640, 270, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 270, 270, 8640, 4320, 8640, 270, 4320, 8640, 270, 8640, 4320, 270, 8640, 270, 270, 8640, 270, 270, 4320]
Prompts retrieved: 423360 . Total input tokens: 94371362 . Total output tokens: 84676963
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.5926868810202,
    "estimated_duration": 3600.1411218017497,
    "input_throughput": 6391.779716813882,
    "output_throughput": 5631.296194815222,
    "total_throughput": 12023.075911629105,
    "itl": 151.83128070110348,
    "ttft": 1244771.9451257547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 105,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.35244257006794166,
    "arrivals": 140843,
    "finished_requests": 92643,
    "scheduler_time": 97.4987248900652
}
#Debug simulation 
Total elapsed time: 14.592788378009573. Arrivals time: 0.3351712226285599 Scheduler time: 14.144331958435941 Scheduler overhead time: 0.042837561457417905 Adapter cache time: 0.007961054216139019 Engine time: 0.04357988358242437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 11.257933423970826,
    "estimated_duration": 3600.1164506951836,
    "input_throughput": 6427.387923946678,
    "output_throughput": 5629.745114518808,
    "total_throughput": 12057.133038465487,
    "itl": 151.42016466414802,
    "ttft": 1238428.6750107913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3397141395765353,
    "arrivals": 139377,
    "finished_requests": 92843,
    "scheduler_time": 97.12543021568294
}
#Debug simulation 
Total elapsed time: 11.258051214972511. Arrivals time: 0.3187536137411371 Scheduler time: 10.832048818876501 Scheduler overhead time: 0.040663320280145854 Adapter cache time: 0.007631086278706789 Engine time: 0.04061128216562793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.264528213010635,
    "estimated_duration": 3600.014681640238,
    "input_throughput": 6427.259065915188,
    "output_throughput": 5629.663707584107,
    "total_throughput": 12056.922773499295,
    "itl": 151.42222743546296,
    "ttft": 1238465.0479667604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.36172304098028685,
    "arrivals": 139377,
    "finished_requests": 92837,
    "scheduler_time": 97.12229386704011
}
#Debug simulation 
Total elapsed time: 11.264656426967122. Arrivals time: 0.32713142718421295 Scheduler time: 10.8311752876034 Scheduler overhead time: 0.040050175855867565 Adapter cache time: 0.007641889620572329 Engine time: 0.040282203583046794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.322962417965755,
    "estimated_duration": 3600.0171217331063,
    "input_throughput": 6427.254709516738,
    "output_throughput": 5629.65989179607,
    "total_throughput": 12056.914601312808,
    "itl": 151.42228563498142,
    "ttft": 1238466.1707407914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3624496593140072,
    "arrivals": 139377,
    "finished_requests": 92837,
    "scheduler_time": 97.12237405242875
}
#Debug simulation 
Total elapsed time: 11.32306119898567. Arrivals time: 0.33036717801587656 Scheduler time: 10.885185739549343 Scheduler overhead time: 0.04032962425844744 Adapter cache time: 0.007714241277426481 Engine time: 0.04097679769620299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 11.253119859960862,
    "estimated_duration": 3600.1566805279376,
    "input_throughput": 6427.316101311118,
    "output_throughput": 5629.682205116662,
    "total_throughput": 12056.998306427779,
    "itl": 151.42084252621294,
    "ttft": 1238451.7927004732,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.34701360951643456,
    "arrivals": 139377,
    "finished_requests": 92843,
    "scheduler_time": 97.12662536008253
}
#Debug simulation 
Total elapsed time: 11.253255056974012. Arrivals time: 0.32775944110471755 Scheduler time: 10.818892610550392 Scheduler overhead time: 0.0401998310117051 Adapter cache time: 0.007662642747163773 Engine time: 0.04045726731419563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 11.309540599002503,
    "estimated_duration": 3600.0271527482882,
    "input_throughput": 6427.2368007936,
    "output_throughput": 5629.644205468871,
    "total_throughput": 12056.88100626247,
    "itl": 151.42203970669686,
    "ttft": 1238467.7171664322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3669767956249416,
    "arrivals": 139377,
    "finished_requests": 92837,
    "scheduler_time": 97.12259247444057
}
#Debug simulation 
Total elapsed time: 11.309643653978128. Arrivals time: 0.3175864312797785 Scheduler time: 10.884025969309732 Scheduler overhead time: 0.040529423335101455 Adapter cache time: 0.00768389058066532 Engine time: 0.041485456575173885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 11.27829483000096,
    "estimated_duration": 3600.0388432598306,
    "input_throughput": 6427.303706270035,
    "output_throughput": 5629.626479709972,
    "total_throughput": 12056.930185980007,
    "itl": 151.41993229520736,
    "ttft": 1238458.7018317278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3318955827341419,
    "arrivals": 139377,
    "finished_requests": 92838,
    "scheduler_time": 97.12314824645537
}
#Debug simulation 
Total elapsed time: 11.278416130982805. Arrivals time: 0.3174004449392669 Scheduler time: 10.854467752855271 Scheduler overhead time: 0.04005537141347304 Adapter cache time: 0.007680580543819815 Engine time: 0.04046141740400344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 135, 8640, 135, 135, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 135, 8640, 4320, 135, 135, 4320, 8640, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 135, 8640, 4320, 4320, 135, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 135, 8640, 4320, 4320, 4320, 8640, 8640, 135, 135, 4320, 135, 8640, 135, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 135, 135, 8640, 4320, 8640, 135, 4320, 8640, 135, 8640, 4320, 135, 8640, 135, 135, 8640, 135, 135, 4320]
Prompts retrieved: 419040 . Total input tokens: 93435824 . Total output tokens: 83813115
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 11.27224587998353,
    "estimated_duration": 3600.0517576014795,
    "input_throughput": 6427.280649824869,
    "output_throughput": 5629.606284744841,
    "total_throughput": 12056.886934569711,
    "itl": 151.4213418496796,
    "ttft": 1238466.5681732616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.371629685722291,
    "arrivals": 139377,
    "finished_requests": 92838,
    "scheduler_time": 97.12328986174066
}
#Debug simulation 
Total elapsed time: 11.27237643202534. Arrivals time: 0.32863665459444746 Scheduler time: 10.837105459359009 Scheduler overhead time: 0.039963228919077665 Adapter cache time: 0.007616271497681737 Engine time: 0.040753542503807694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.811690912989434,
    "estimated_duration": 3600.0256810285864,
    "input_throughput": 6374.687580962779,
    "output_throughput": 5634.377028722905,
    "total_throughput": 12009.064609685684,
    "itl": 152.31364881043183,
    "ttft": 1234072.8786371448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23871804402675456,
    "arrivals": 138774,
    "finished_requests": 92820,
    "scheduler_time": 97.15070311861652
}
#Debug simulation 
Total elapsed time: 8.811792291002348. Arrivals time: 0.30656561703654006 Scheduler time: 8.401195699349046 Scheduler overhead time: 0.039231443020980805 Adapter cache time: 0.007002162572462112 Engine time: 0.03959610330639407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.803118114999961,
    "estimated_duration": 3600.129576905037,
    "input_throughput": 6374.649164636264,
    "output_throughput": 5634.417474894976,
    "total_throughput": 12009.06663953124,
    "itl": 152.31455541764,
    "ttft": 1234047.5342955012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2520193076506257,
    "arrivals": 138774,
    "finished_requests": 92824,
    "scheduler_time": 97.15371138111813
}
#Debug simulation 
Total elapsed time: 8.803232017031405. Arrivals time: 0.3011210010154173 Scheduler time: 8.39824731380213 Scheduler overhead time: 0.03927267127437517 Adapter cache time: 0.007031379907857627 Engine time: 0.039419303415343165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.749644685012754,
    "estimated_duration": 3600.129786741659,
    "input_throughput": 6374.648793084424,
    "output_throughput": 5634.417146488169,
    "total_throughput": 12009.065939572594,
    "itl": 152.31445739982857,
    "ttft": 1234047.5376630656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.252907854951918,
    "arrivals": 138774,
    "finished_requests": 92824,
    "scheduler_time": 97.15368693991825
}
#Debug simulation 
Total elapsed time: 8.74977268197108. Arrivals time: 0.3030342705314979 Scheduler time: 8.342802587139886 Scheduler overhead time: 0.03935113037005067 Adapter cache time: 0.006957905658055097 Engine time: 0.03953239863039926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.786929758964106,
    "estimated_duration": 3600.041254539371,
    "input_throughput": 6374.687226448566,
    "output_throughput": 5634.40737642196,
    "total_throughput": 12009.094602870526,
    "itl": 152.31331436488094,
    "ttft": 1234051.3488392113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24303021064493818,
    "arrivals": 138774,
    "finished_requests": 92821,
    "scheduler_time": 97.15106865882778
}
#Debug simulation 
Total elapsed time: 8.787031420972198. Arrivals time: 0.3029406381538138 Scheduler time: 8.380222935578786 Scheduler overhead time: 0.039400271081831306 Adapter cache time: 0.007039891090244055 Engine time: 0.03931097057648003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.817447246983647,
    "estimated_duration": 3600.138628024096,
    "input_throughput": 6374.633138112146,
    "output_throughput": 5634.403309389517,
    "total_throughput": 12009.036447501663,
    "itl": 152.31428887029344,
    "ttft": 1234048.8693938563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.25567443825304487,
    "arrivals": 138774,
    "finished_requests": 92824,
    "scheduler_time": 97.1539297760656
}
#Debug simulation 
Total elapsed time: 8.817572305968497. Arrivals time: 0.30831482412759215 Scheduler time: 8.405305480468087 Scheduler overhead time: 0.039208641392178833 Adapter cache time: 0.007001800637226552 Engine time: 0.0396413091220893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.805439927033149,
    "estimated_duration": 3600.1499837289166,
    "input_throughput": 6374.613031046445,
    "output_throughput": 5634.385537179716,
    "total_throughput": 12008.998568226161,
    "itl": 152.31346257091099,
    "ttft": 1234050.1973746524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.23322392300236994,
    "arrivals": 138774,
    "finished_requests": 92824,
    "scheduler_time": 97.15424955282978
}
#Debug simulation 
Total elapsed time: 8.805570174998138. Arrivals time: 0.30545921286102384 Scheduler time: 8.395812605915125 Scheduler overhead time: 0.03957175766117871 Adapter cache time: 0.006996591109782457 Engine time: 0.03958919853903353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 66, 8640, 66, 66, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 66, 8640, 4320, 66, 66, 4320, 8640, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 66, 8640, 4320, 4320, 66, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 66, 8640, 4320, 4320, 4320, 8640, 8640, 66, 66, 4320, 66, 8640, 66, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 66, 66, 8640, 4320, 8640, 66, 4320, 8640, 66, 8640, 4320, 66, 8640, 66, 66, 8640, 66, 66, 4320]
Prompts retrieved: 416832 . Total input tokens: 92923418 . Total output tokens: 83384390
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.76538969395915,
    "estimated_duration": 3600.148890435161,
    "input_throughput": 6374.614966889888,
    "output_throughput": 5634.387248230762,
    "total_throughput": 12009.00221512065,
    "itl": 152.31427701848943,
    "ttft": 1234052.22669008,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 78,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2586925291270014,
    "arrivals": 138774,
    "finished_requests": 92824,
    "scheduler_time": 97.1542422129202
}
#Debug simulation 
Total elapsed time: 8.765487916010898. Arrivals time: 0.31552720605395734 Scheduler time: 8.346294731076341 Scheduler overhead time: 0.03935442504007369 Adapter cache time: 0.0069647704367525876 Engine time: 0.039251998998224735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.928740345989354,
    "estimated_duration": 3600.021890213295,
    "input_throughput": 6384.232291053729,
    "output_throughput": 5634.418794825218,
    "total_throughput": 12018.651085878948,
    "itl": 152.00772952710608,
    "ttft": 1232101.8598148571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.25095999500248556,
    "arrivals": 138381,
    "finished_requests": 92647,
    "scheduler_time": 96.98104726973698
}
#Debug simulation 
Total elapsed time: 7.928861922991928. Arrivals time: 0.30134283303050324 Scheduler time: 7.52375625167042 Scheduler overhead time: 0.03930408169981092 Adapter cache time: 0.007029063883237541 Engine time: 0.03928192728199065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.919926990987733,
    "estimated_duration": 3600.0803303061775,
    "input_throughput": 6384.355317439612,
    "output_throughput": 5634.490383239545,
    "total_throughput": 12018.845700679156,
    "itl": 152.0084028273691,
    "ttft": 1232065.966121836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.26438810414867475,
    "arrivals": 138381,
    "finished_requests": 92651,
    "scheduler_time": 96.98271930812254
}
#Debug simulation 
Total elapsed time: 7.920060630014632. Arrivals time: 0.2981935437419452 Scheduler time: 7.518729918869212 Scheduler overhead time: 0.03868230961961672 Adapter cache time: 0.0070430541527457535 Engine time: 0.03944206907181069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.959879912959877,
    "estimated_duration": 3600.1091071675223,
    "input_throughput": 6384.335950885525,
    "output_throughput": 5634.445900435346,
    "total_throughput": 12018.781851320871,
    "itl": 152.0078755251281,
    "ttft": 1232082.1381412477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.26541917784139507,
    "arrivals": 138381,
    "finished_requests": 92652,
    "scheduler_time": 96.98360892161442
}
#Debug simulation 
Total elapsed time: 7.959977855964098. Arrivals time: 0.2982026564422995 Scheduler time: 7.558043156401254 Scheduler overhead time: 0.03890210570534691 Adapter cache time: 0.007037327159196138 Engine time: 0.03984646371100098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.931888339051511,
    "estimated_duration": 3600.052807031656,
    "input_throughput": 6384.177741812192,
    "output_throughput": 5634.403739962039,
    "total_throughput": 12018.581481774232,
    "itl": 152.00856087140235,
    "ttft": 1232103.9334660752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2549904118245469,
    "arrivals": 138381,
    "finished_requests": 92648,
    "scheduler_time": 96.98202126179959
}
#Debug simulation 
Total elapsed time: 7.932009573036339. Arrivals time: 0.3029272186686285 Scheduler time: 7.5252760228468105 Scheduler overhead time: 0.03928231482859701 Adapter cache time: 0.0069900936796329916 Engine time: 0.0394081020494923 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.930711495981086,
    "estimated_duration": 3600.1324145217895,
    "input_throughput": 6384.294618522535,
    "output_throughput": 5634.409422880751,
    "total_throughput": 12018.704041403285,
    "itl": 152.00797470178733,
    "ttft": 1232082.296551159,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2683115149289368,
    "arrivals": 138381,
    "finished_requests": 92652,
    "scheduler_time": 96.98432885377059
}
#Debug simulation 
Total elapsed time: 7.930842971953098. Arrivals time: 0.2958044953411445 Scheduler time: 7.5318325341213495 Scheduler overhead time: 0.03870476217707619 Adapter cache time: 0.0070157526060938835 Engine time: 0.039562682912219316 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.952672167972196,
    "estimated_duration": 3600.1671559653328,
    "input_throughput": 6384.233010380067,
    "output_throughput": 5634.355051095113,
    "total_throughput": 12018.58806147518,
    "itl": 152.00735589709072,
    "ttft": 1232098.5036391388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.24518412418197866,
    "arrivals": 138381,
    "finished_requests": 92652,
    "scheduler_time": 96.98532370515336
}
#Debug simulation 
Total elapsed time: 7.952775886980817. Arrivals time: 0.2984455061960034 Scheduler time: 7.550732248404529 Scheduler overhead time: 0.03899683617055416 Adapter cache time: 0.0070364304119721055 Engine time: 0.03959063411457464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 4320, 8640, 4320, 4320, 4320, 4320, 8640, 4320, 8640, 4320, 33, 8640, 33, 33, 8640, 4320, 8640, 4320, 8640, 8640, 4320, 33, 8640, 4320, 33, 33, 4320, 8640, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 33, 8640, 4320, 4320, 33, 8640, 8640, 4320, 8640, 8640, 4320, 8640, 33, 8640, 4320, 4320, 4320, 8640, 8640, 33, 33, 4320, 33, 8640, 33, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 4320, 8640, 8640, 33, 33, 8640, 4320, 8640, 33, 4320, 8640, 33, 8640, 4320, 33, 8640, 33, 33, 8640, 33, 33, 4320]
Prompts retrieved: 415776 . Total input tokens: 92702535 . Total output tokens: 83169576
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.000679392018355,
    "estimated_duration": 3600.1439437281365,
    "input_throughput": 6384.274173270571,
    "output_throughput": 5634.3913790830875,
    "total_throughput": 12018.665552353657,
    "itl": 152.0080542572462,
    "ttft": 1232083.400994218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 82,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2713296058028933,
    "arrivals": 138381,
    "finished_requests": 92652,
    "scheduler_time": 96.98460533271256
}
#Debug simulation 
Total elapsed time: 8.000798467022832. Arrivals time: 0.2990647785481997 Scheduler time: 7.59871501615271 Scheduler overhead time: 0.0388192412792705 Adapter cache time: 0.007067077502142638 Engine time: 0.03916823264444247 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.533503873972222,
    "estimated_duration": 3600.058281541944,
    "input_throughput": 6352.445213804952,
    "output_throughput": 5643.641411076774,
    "total_throughput": 11996.086624881726,
    "itl": 151.66124523099606,
    "ttft": 784826.7939421912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6343004552601113,
    "arrivals": 109384,
    "finished_requests": 92199,
    "scheduler_time": 86.94115665707304
}
#Debug simulation 
Total elapsed time: 8.533628534991294. Arrivals time: 0.26779322302900255 Scheduler time: 8.156335484003648 Scheduler overhead time: 0.0392468289937824 Adapter cache time: 0.012776388262864202 Engine time: 0.03931854304391891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.564431438979227,
    "estimated_duration": 3600.0701350551944,
    "input_throughput": 6352.118470505686,
    "output_throughput": 5642.9508975909275,
    "total_throughput": 11995.069368096612,
    "itl": 151.66280709433317,
    "ttft": 784977.8421395562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7564476269879472,
    "arrivals": 109384,
    "finished_requests": 92196,
    "scheduler_time": 86.94042436786502
}
#Debug simulation 
Total elapsed time: 8.564535197976511. Arrivals time: 0.27022743283305317 Scheduler time: 8.184461606200784 Scheduler overhead time: 0.039146187191363424 Adapter cache time: 0.013061216857749969 Engine time: 0.03952115512220189 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.497602859977633,
    "estimated_duration": 3600.0725003185203,
    "input_throughput": 6352.114297136161,
    "output_throughput": 5642.947190147589,
    "total_throughput": 11995.06148728375,
    "itl": 151.66264094126092,
    "ttft": 784978.5851768991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7571028356067946,
    "arrivals": 109384,
    "finished_requests": 92196,
    "scheduler_time": 86.94048500722536
}
#Debug simulation 
Total elapsed time: 8.497698922001291. Arrivals time: 0.26988407684257254 Scheduler time: 8.118149766756687 Scheduler overhead time: 0.03912299533840269 Adapter cache time: 0.012824072444345802 Engine time: 0.039572385838255286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.548312808969058,
    "estimated_duration": 3600.0028509326958,
    "input_throughput": 6352.58385811416,
    "output_throughput": 5643.893586010901,
    "total_throughput": 11996.477444125061,
    "itl": 151.66640627980073,
    "ttft": 784755.5098373151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 536,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6803000685712253,
    "arrivals": 109384,
    "finished_requests": 92200,
    "scheduler_time": 86.9390747719529
}
#Debug simulation 
Total elapsed time: 8.54844287398737. Arrivals time: 0.261243827175349 Scheduler time: 8.177128447860014 Scheduler overhead time: 0.03925146511755884 Adapter cache time: 0.012880923051852733 Engine time: 0.03961957845604047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.550747205968946,
    "estimated_duration": 3600.1482887715474,
    "input_throughput": 6352.708323524085,
    "output_throughput": 5643.27865698346,
    "total_throughput": 11995.986980507545,
    "itl": 151.66741386825606,
    "ttft": 784924.6075134312,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7842853692546519,
    "arrivals": 109384,
    "finished_requests": 92198,
    "scheduler_time": 86.94195590957894
}
#Debug simulation 
Total elapsed time: 8.550845541001763. Arrivals time: 0.26295055652735755 Scheduler time: 8.177231875713915 Scheduler overhead time: 0.039465135196223855 Adapter cache time: 0.012907133321277797 Engine time: 0.03990367357619107 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.614984588988591,
    "estimated_duration": 3600.1443263540077,
    "input_throughput": 6352.8875308070155,
    "output_throughput": 5643.655964364275,
    "total_throughput": 11996.54349517129,
    "itl": 151.6605388150643,
    "ttft": 784717.4485657654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.599676907772644,
    "arrivals": 109384,
    "finished_requests": 92203,
    "scheduler_time": 86.94341673071713
}
#Debug simulation 
Total elapsed time: 8.615085338009521. Arrivals time: 0.2689542380394414 Scheduler time: 8.236046780832112 Scheduler overhead time: 0.039412255049683154 Adapter cache time: 0.012851518928073347 Engine time: 0.039608535764273256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 540, 8640, 540, 540, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 540, 8640, 1080, 540, 540, 1080, 8640, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 8640, 1080, 1080, 540, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 540, 8640, 1080, 1080, 1080, 8640, 8640, 540, 540, 1080, 540, 8640, 540, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 540, 540, 8640, 1080, 8640, 540, 1080, 8640, 540, 8640, 1080, 540, 8640, 540, 540, 8640, 540, 540, 1080]
Prompts retrieved: 328320 . Total input tokens: 73232281 . Total output tokens: 65736162
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.513291859999299,
    "estimated_duration": 3600.0995218206367,
    "input_throughput": 6351.396638178606,
    "output_throughput": 5642.711785291611,
    "total_throughput": 11994.108423470218,
    "itl": 151.67231237983114,
    "ttft": 785279.3097786121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 532,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7983335232734639,
    "arrivals": 109384,
    "finished_requests": 92185,
    "scheduler_time": 86.94085099064982
}
#Debug simulation 
Total elapsed time: 8.513420954986941. Arrivals time: 0.2625803766422905 Scheduler time: 8.140559086052235 Scheduler overhead time: 0.03927382384426892 Adapter cache time: 0.013031374255660921 Engine time: 0.03967540740268305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.7777073250035755,
    "estimated_duration": 3600.0226197899615,
    "input_throughput": 6429.538768106532,
    "output_throughput": 5635.79847761727,
    "total_throughput": 12065.337245723802,
    "itl": 150.4892776390652,
    "ttft": 642473.5900626455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8179297198960829,
    "arrivals": 106465,
    "finished_requests": 92700,
    "scheduler_time": 84.87809078618046
}
#Debug simulation 
Total elapsed time: 7.777805929013994. Arrivals time: 0.25451341638108715 Scheduler time: 7.41236745583592 Scheduler overhead time: 0.039677996071986854 Adapter cache time: 0.013459096546284854 Engine time: 0.03961705253459513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.798589498968795,
    "estimated_duration": 3600.1592159128986,
    "input_throughput": 6429.013721864232,
    "output_throughput": 5635.767693361616,
    "total_throughput": 12064.781415225849,
    "itl": 150.49806581515043,
    "ttft": 642567.145961184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.954646029330335,
    "arrivals": 106465,
    "finished_requests": 92701,
    "scheduler_time": 84.88110580273099
}
#Debug simulation 
Total elapsed time: 7.798686694994103. Arrivals time: 0.2562253473442979 Scheduler time: 7.432000090833753 Scheduler overhead time: 0.03942362667294219 Adapter cache time: 0.013370814092922956 Engine time: 0.03948599728755653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.859853631001897,
    "estimated_duration": 3600.1613407551004,
    "input_throughput": 6429.009927412157,
    "output_throughput": 5635.76436708929,
    "total_throughput": 12064.774294501447,
    "itl": 150.4979407691566,
    "ttft": 642568.8326789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9552273512818044,
    "arrivals": 106465,
    "finished_requests": 92701,
    "scheduler_time": 84.88118644345218
}
#Debug simulation 
Total elapsed time: 7.859981601999607. Arrivals time: 0.25614531931933016 Scheduler time: 7.491714191972278 Scheduler overhead time: 0.040136605442967266 Adapter cache time: 0.013414262211881578 Engine time: 0.040019634761847556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.803022467996925,
    "estimated_duration": 3600.105098321831,
    "input_throughput": 6428.457883295696,
    "output_throughput": 5635.641862082737,
    "total_throughput": 12064.099745378433,
    "itl": 150.4903524953761,
    "ttft": 642584.0058536377,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8661107282945801,
    "arrivals": 106465,
    "finished_requests": 92698,
    "scheduler_time": 84.8795470690301
}
#Debug simulation 
Total elapsed time: 7.803118527983315. Arrivals time: 0.2547879330813885 Scheduler time: 7.437802467436995 Scheduler overhead time: 0.03938293072860688 Adapter cache time: 0.01336432876996696 Engine time: 0.0396126551204361 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.79067238396965,
    "estimated_duration": 3600.1604416316877,
    "input_throughput": 6429.292631610996,
    "output_throughput": 5635.582727197705,
    "total_throughput": 12064.8753588087,
    "itl": 150.49735030129514,
    "ttft": 642590.7664964541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9835219532251385,
    "arrivals": 106465,
    "finished_requests": 92700,
    "scheduler_time": 84.88029531654556
}
#Debug simulation 
Total elapsed time: 7.790767913975287. Arrivals time: 0.2544543829280883 Scheduler time: 7.425826313032303 Scheduler overhead time: 0.039272449794225395 Adapter cache time: 0.013446400116663426 Engine time: 0.039453326317016035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.773692810034845,
    "estimated_duration": 3600.00951347893,
    "input_throughput": 6429.281065325014,
    "output_throughput": 5636.002050559234,
    "total_throughput": 12065.28311588425,
    "itl": 150.49020488549647,
    "ttft": 642417.5323704184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7760898751718661,
    "arrivals": 106465,
    "finished_requests": 92701,
    "scheduler_time": 84.87876766882351
}
#Debug simulation 
Total elapsed time: 7.773822579998523. Arrivals time: 0.2541120675741695 Scheduler time: 7.408940858731512 Scheduler overhead time: 0.039307550876401365 Adapter cache time: 0.013425845943856984 Engine time: 0.03982902888674289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 270, 8640, 270, 270, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 270, 8640, 1080, 270, 270, 1080, 8640, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 8640, 1080, 1080, 270, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 270, 8640, 1080, 1080, 1080, 8640, 8640, 270, 270, 1080, 270, 8640, 270, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 270, 270, 8640, 1080, 8640, 270, 1080, 8640, 270, 8640, 1080, 270, 8640, 270, 270, 8640, 270, 270, 1080]
Prompts retrieved: 319680 . Total input tokens: 71285179 . Total output tokens: 64022908
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.829349704028573,
    "estimated_duration": 3600.0775087750476,
    "input_throughput": 6428.163266927604,
    "output_throughput": 5635.631996963138,
    "total_throughput": 12063.795263890743,
    "itl": 150.50089604778606,
    "ttft": 642768.3258379862,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0019772019609734,
    "arrivals": 106465,
    "finished_requests": 92692,
    "scheduler_time": 84.87936260583095
}
#Debug simulation 
Total elapsed time: 7.829445555980783. Arrivals time: 0.2543085209908895 Scheduler time: 7.464679243625142 Scheduler overhead time: 0.03943420428549871 Adapter cache time: 0.013213800149969757 Engine time: 0.039613611181266606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.282881481980439,
    "estimated_duration": 3600.050462906954,
    "input_throughput": 6364.48634153276,
    "output_throughput": 5643.0842315459695,
    "total_throughput": 12007.570573078729,
    "itl": 151.39120500761078,
    "ttft": 596000.8731096571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9954380090441888,
    "arrivals": 105012,
    "finished_requests": 92559,
    "scheduler_time": 84.50329129717058
}
#Debug simulation 
Total elapsed time: 7.2829827389796264. Arrivals time: 0.2584161007544026 Scheduler time: 6.9143194039934315 Scheduler overhead time: 0.03888875723350793 Adapter cache time: 0.014070162258576602 Engine time: 0.039283192076254636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.23085059603909,
    "estimated_duration": 3600.1662573899034,
    "input_throughput": 6364.751614724764,
    "output_throughput": 5642.628297596401,
    "total_throughput": 12007.379912321167,
    "itl": 151.39731994460303,
    "ttft": 596050.8344024854,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 649,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1399371567904137,
    "arrivals": 105012,
    "finished_requests": 92560,
    "scheduler_time": 84.50522698951652
}
#Debug simulation 
Total elapsed time: 7.230980868043844. Arrivals time: 0.2470854289131239 Scheduler time: 6.873619286518078 Scheduler overhead time: 0.03893991815857589 Adapter cache time: 0.014034014893695712 Engine time: 0.0393599501112476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.237542152986862,
    "estimated_duration": 3600.149573960507,
    "input_throughput": 6364.311129105145,
    "output_throughput": 5642.928879105192,
    "total_throughput": 12007.240008210338,
    "itl": 151.39950335989963,
    "ttft": 596089.1476462637,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.149625561721629,
    "arrivals": 105012,
    "finished_requests": 92559,
    "scheduler_time": 84.50457708159625
}
#Debug simulation 
Total elapsed time: 7.237644004984759. Arrivals time: 0.24565406155306846 Scheduler time: 6.881806806661189 Scheduler overhead time: 0.03858872567070648 Adapter cache time: 0.014108210452832282 Engine time: 0.03933349600993097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.312379764975049,
    "estimated_duration": 3600.1421320777854,
    "input_throughput": 6364.442335718578,
    "output_throughput": 5643.064427646617,
    "total_throughput": 12007.506763365194,
    "itl": 151.39438591884016,
    "ttft": 596014.3030496805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0488014546572115,
    "arrivals": 105012,
    "finished_requests": 92560,
    "scheduler_time": 84.50502393124141
}
#Debug simulation 
Total elapsed time: 7.312477305997163. Arrivals time: 0.2507277120021172 Scheduler time: 6.950691021047533 Scheduler overhead time: 0.039185117406304926 Adapter cache time: 0.014225357619579881 Engine time: 0.03958341106772423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.294108544010669,
    "estimated_duration": 3600.0162576699736,
    "input_throughput": 6364.451813567459,
    "output_throughput": 5642.958127402525,
    "total_throughput": 12007.409940969985,
    "itl": 151.39977827933964,
    "ttft": 596132.8387741004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.180686746966096,
    "arrivals": 105012,
    "finished_requests": 92557,
    "scheduler_time": 84.5008762704893
}
#Debug simulation 
Total elapsed time: 7.29420887096785. Arrivals time: 0.2582153289113194 Scheduler time: 6.925216344243381 Scheduler overhead time: 0.039103777264244854 Adapter cache time: 0.014144705957733095 Engine time: 0.039347940240986645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.261650166998152,
    "estimated_duration": 3600.1496605627763,
    "input_throughput": 6364.479024579834,
    "output_throughput": 5643.063182218991,
    "total_throughput": 12007.542206798826,
    "itl": 151.39057184309252,
    "ttft": 595948.7393512023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9525028425710882,
    "arrivals": 105012,
    "finished_requests": 92561,
    "scheduler_time": 84.50616751012065
}
#Debug simulation 
Total elapsed time: 7.261775748978835. Arrivals time: 0.258157656469848 Scheduler time: 6.893422391265631 Scheduler overhead time: 0.03884651331463829 Adapter cache time: 0.01414113724604249 Engine time: 0.03920171072240919 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 135, 8640, 135, 135, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 135, 8640, 1080, 135, 135, 1080, 8640, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 8640, 1080, 1080, 135, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 135, 8640, 1080, 1080, 1080, 8640, 8640, 135, 135, 1080, 135, 8640, 135, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 135, 135, 8640, 1080, 8640, 135, 1080, 8640, 135, 8640, 1080, 135, 8640, 135, 135, 8640, 135, 135, 1080]
Prompts retrieved: 315360 . Total input tokens: 70338575 . Total output tokens: 63127808
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.281436041987035,
    "estimated_duration": 3600.0634172003897,
    "input_throughput": 6364.368441547553,
    "output_throughput": 5642.884206689302,
    "total_throughput": 12007.252648236854,
    "itl": 151.40033747677595,
    "ttft": 596175.6205540419,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2112449170649056,
    "arrivals": 105012,
    "finished_requests": 92557,
    "scheduler_time": 84.50181860679888
}
#Debug simulation 
Total elapsed time: 7.281532366992906. Arrivals time: 0.25083011348033324 Scheduler time: 6.920149039593525 Scheduler overhead time: 0.03887335298350081 Adapter cache time: 0.014035928004886955 Engine time: 0.03952600707998499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.965926867967937,
    "estimated_duration": 3600.0661206560017,
    "input_throughput": 6364.498104225063,
    "output_throughput": 5641.652769504985,
    "total_throughput": 12006.150873730048,
    "itl": 151.22735532165768,
    "ttft": 577300.2455802746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9984984967881216,
    "arrivals": 104295,
    "finished_requests": 92218,
    "scheduler_time": 84.1812675186535
}
#Debug simulation 
Total elapsed time: 6.966030128009152. Arrivals time: 0.24522570811677724 Scheduler time: 6.610197392583359 Scheduler overhead time: 0.03900217131013051 Adapter cache time: 0.014087656163610518 Engine time: 0.03944126097485423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.943476612039376,
    "estimated_duration": 3600.105007772185,
    "input_throughput": 6364.377691910341,
    "output_throughput": 5641.449056667407,
    "total_throughput": 12005.826748577747,
    "itl": 151.23277999734853,
    "ttft": 577532.1486768625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.141273879690571,
    "arrivals": 104295,
    "finished_requests": 92216,
    "scheduler_time": 84.18074616127065
}
#Debug simulation 
Total elapsed time: 6.943604002997745. Arrivals time: 0.2545338991913013 Scheduler time: 6.578759573574644 Scheduler overhead time: 0.03878743853420019 Adapter cache time: 0.014032615814357996 Engine time: 0.039326822326984257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.9523205300210975,
    "estimated_duration": 3600.115194199771,
    "input_throughput": 6364.359684077538,
    "output_throughput": 5641.433094341427,
    "total_throughput": 12005.792778418965,
    "itl": 151.23288936204852,
    "ttft": 577537.8507364256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1432261507213184,
    "arrivals": 104295,
    "finished_requests": 92216,
    "scheduler_time": 84.18113991495983
}
#Debug simulation 
Total elapsed time: 6.952418757020496. Arrivals time: 0.24767409858759493 Scheduler time: 6.594447853334714 Scheduler overhead time: 0.03887368243886158 Adapter cache time: 0.014205567073076963 Engine time: 0.039178857288789004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.966188243008219,
    "estimated_duration": 3600.150057609948,
    "input_throughput": 6364.349716914613,
    "output_throughput": 5641.521235224159,
    "total_throughput": 12005.870952138772,
    "itl": 151.22979259529734,
    "ttft": 577458.7536426758,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0423938126279837,
    "arrivals": 104295,
    "finished_requests": 92218,
    "scheduler_time": 84.18294645396526
}
#Debug simulation 
Total elapsed time: 6.96628835395677. Arrivals time: 0.24832422158215195 Scheduler time: 6.607143051514868 Scheduler overhead time: 0.03906418656697497 Adapter cache time: 0.013995435845572501 Engine time: 0.0396451071719639 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.935673867992591,
    "estimated_duration": 3600.149336391099,
    "input_throughput": 6364.299327362938,
    "output_throughput": 5641.3795935363005,
    "total_throughput": 12005.67892089924,
    "itl": 151.23379703107815,
    "ttft": 577579.1240162809,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1736585670337116,
    "arrivals": 104295,
    "finished_requests": 92216,
    "scheduler_time": 84.18161407197623
}
#Debug simulation 
Total elapsed time: 6.935770054988097. Arrivals time: 0.2574348457274027 Scheduler time: 6.567717313184403 Scheduler overhead time: 0.038949006877373904 Adapter cache time: 0.014225277991499752 Engine time: 0.03947843698551878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.957119831000455,
    "estimated_duration": 3600.1210610868116,
    "input_throughput": 6364.706522697535,
    "output_throughput": 5641.65417089296,
    "total_throughput": 12006.360693590495,
    "itl": 151.22344770202838,
    "ttft": 577279.4284584628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9525028425710882,
    "arrivals": 104295,
    "finished_requests": 92222,
    "scheduler_time": 84.1830250694108
}
#Debug simulation 
Total elapsed time: 6.957215600006748. Arrivals time: 0.24710085231345147 Scheduler time: 6.596945852274075 Scheduler overhead time: 0.041727268253453076 Adapter cache time: 0.014088937372434884 Engine time: 0.03920304111670703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 66, 8640, 66, 66, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 66, 8640, 1080, 66, 66, 1080, 8640, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 8640, 1080, 1080, 66, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 66, 8640, 1080, 1080, 1080, 8640, 8640, 66, 66, 1080, 66, 8640, 66, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 66, 66, 8640, 1080, 8640, 66, 1080, 8640, 66, 8640, 1080, 66, 8640, 66, 66, 8640, 66, 66, 1080]
Prompts retrieved: 313152 . Total input tokens: 69865127 . Total output tokens: 62689687
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.959935218968894,
    "estimated_duration": 3600.0224518600567,
    "input_throughput": 6364.17864231993,
    "output_throughput": 5641.277317453091,
    "total_throughput": 12005.45595977302,
    "itl": 151.23558551644757,
    "ttft": 577631.4018632811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.201324400044979,
    "arrivals": 104295,
    "finished_requests": 92210,
    "scheduler_time": 84.17821305526225
}
#Debug simulation 
Total elapsed time: 6.96005209494615. Arrivals time: 0.25495224772021174 Scheduler time: 6.5945447402773425 Scheduler overhead time: 0.0388221699395217 Adapter cache time: 0.014155016862787306 Engine time: 0.03945460316026583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.795550196024124,
    "estimated_duration": 3600.104166742831,
    "input_throughput": 6418.055958893182,
    "output_throughput": 5638.919892244928,
    "total_throughput": 12056.97585113811,
    "itl": 150.1721054131069,
    "ttft": 528310.9764000134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8056877689203514,
    "arrivals": 103971,
    "finished_requests": 92929,
    "scheduler_time": 83.53842821907143
}
#Debug simulation 
Total elapsed time: 6.795649383042473. Arrivals time: 0.24474351410754025 Scheduler time: 6.44091860007029 Scheduler overhead time: 0.03890921809943393 Adapter cache time: 0.013479628250934184 Engine time: 0.0394734397996217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.75008720200276,
    "estimated_duration": 3600.134041383755,
    "input_throughput": 6417.863539080686,
    "output_throughput": 5638.661996095421,
    "total_throughput": 12056.525535176108,
    "itl": 150.17707134919152,
    "ttft": 528485.2445375742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9287935873237514,
    "arrivals": 103971,
    "finished_requests": 92926,
    "scheduler_time": 83.5381709517087
}
#Debug simulation 
Total elapsed time: 6.750208981044125. Arrivals time: 0.25175791315268725 Scheduler time: 6.388984870864078 Scheduler overhead time: 0.038755060464609414 Adapter cache time: 0.013603489787783474 Engine time: 0.03911448421422392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.741448019980453,
    "estimated_duration": 3600.1381608420274,
    "input_throughput": 6417.8561954400075,
    "output_throughput": 5638.655544056147,
    "total_throughput": 12056.511739496154,
    "itl": 150.1771602730405,
    "ttft": 528486.6214039186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9315868610702576,
    "arrivals": 103971,
    "finished_requests": 92926,
    "scheduler_time": 83.53827455558228
}
#Debug simulation 
Total elapsed time: 6.741570253972895. Arrivals time: 0.248944420251064 Scheduler time: 6.382980187074281 Scheduler overhead time: 0.038753433735109866 Adapter cache time: 0.01359024370322004 Engine time: 0.03927382337860763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.779580349044409,
    "estimated_duration": 3600.1587680157054,
    "input_throughput": 6417.958620401378,
    "output_throughput": 5638.834370404477,
    "total_throughput": 12056.792990805856,
    "itl": 150.17372723346236,
    "ttft": 528384.5204749769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8438057610881413,
    "arrivals": 103971,
    "finished_requests": 92929,
    "scheduler_time": 83.53936134998857
}
#Debug simulation 
Total elapsed time: 6.779676302045118. Arrivals time: 0.24581397086149082 Scheduler time: 6.424064941238612 Scheduler overhead time: 0.03879328281618655 Adapter cache time: 0.013635220529977232 Engine time: 0.0394006670685485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.789943954965565,
    "estimated_duration": 3600.0373560070893,
    "input_throughput": 6417.805904554759,
    "output_throughput": 5638.772043886543,
    "total_throughput": 12056.577948441301,
    "itl": 150.1801081053353,
    "ttft": 528525.8130887107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.95774364864454,
    "arrivals": 103971,
    "finished_requests": 92924,
    "scheduler_time": 83.53544558649138
}
#Debug simulation 
Total elapsed time: 6.790047789982054. Arrivals time: 0.2448577675386332 Scheduler time: 6.435099796392024 Scheduler overhead time: 0.03898711898364127 Adapter cache time: 0.013556145422626287 Engine time: 0.03940888011129573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.8160359460162,
    "estimated_duration": 3600.0438937452623,
    "input_throughput": 6418.135078892719,
    "output_throughput": 5638.925412901215,
    "total_throughput": 12057.060491793934,
    "itl": 150.17082070914944,
    "ttft": 528325.8238827069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7641296739922578,
    "arrivals": 103971,
    "finished_requests": 92928,
    "scheduler_time": 83.53722030234292
}
#Debug simulation 
Total elapsed time: 6.816157138033304. Arrivals time: 0.2489594474900514 Scheduler time: 6.457149608060718 Scheduler overhead time: 0.038862979563418776 Adapter cache time: 0.013598899997305125 Engine time: 0.039544209314044565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 8640, 1080, 1080, 1080, 1080, 8640, 1080, 8640, 1080, 33, 8640, 33, 33, 8640, 1080, 8640, 1080, 8640, 8640, 1080, 33, 8640, 1080, 33, 33, 1080, 8640, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 8640, 1080, 1080, 33, 8640, 8640, 1080, 8640, 8640, 1080, 8640, 33, 8640, 1080, 1080, 1080, 8640, 8640, 33, 33, 1080, 33, 8640, 33, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 1080, 8640, 8640, 33, 33, 8640, 1080, 8640, 33, 1080, 8640, 33, 8640, 1080, 33, 8640, 33, 33, 8640, 33, 33, 1080]
Prompts retrieved: 312096 . Total input tokens: 69630651 . Total output tokens: 62481129
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.817311065969989,
    "estimated_duration": 3600.0742242422207,
    "input_throughput": 6417.740180027325,
    "output_throughput": 5638.714297417827,
    "total_throughput": 12056.454477445151,
    "itl": 150.18108491909368,
    "ttft": 528539.5699333647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9822656369954292,
    "arrivals": 103971,
    "finished_requests": 92924,
    "scheduler_time": 83.53619907670158
}
#Debug simulation 
Total elapsed time: 6.817406182992272. Arrivals time: 0.2470726736355573 Scheduler time: 6.460217839921825 Scheduler overhead time: 0.03914373408770189 Adapter cache time: 0.013520271284505725 Engine time: 0.03942926466697827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.146370677044615,
    "estimated_duration": 3600.081437557542,
    "input_throughput": 6335.132800627226,
    "output_throughput": 5642.000702567537,
    "total_throughput": 11977.133503194764,
    "itl": 151.04688876850562,
    "ttft": 421550.8499858833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.060487743932824,
    "arrivals": 100828,
    "finished_requests": 92353,
    "scheduler_time": 82.44173194997371
}
#Debug simulation 
Total elapsed time: 7.1464636370074. Arrivals time: 0.24030194571241736 Scheduler time: 6.791675263957586 Scheduler overhead time: 0.03930814698105678 Adapter cache time: 0.017717494687531143 Engine time: 0.039408313925378025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.189836297009606,
    "estimated_duration": 3600.1158970938077,
    "input_throughput": 6334.851891410023,
    "output_throughput": 5641.672540707866,
    "total_throughput": 11976.524432117889,
    "itl": 151.05749145040278,
    "ttft": 421838.9906942181,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.28600318851882,
    "arrivals": 100828,
    "finished_requests": 92349,
    "scheduler_time": 82.44061526776554
}
#Debug simulation 
Total elapsed time: 7.189970517996699. Arrivals time: 0.23816229600924999 Scheduler time: 6.837150417151861 Scheduler overhead time: 0.03929226013133302 Adapter cache time: 0.0177501467987895 Engine time: 0.03959131968440488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.1744877159944735,
    "estimated_duration": 3600.121078972462,
    "input_throughput": 6334.8427732628625,
    "output_throughput": 5641.664420296949,
    "total_throughput": 11976.507193559812,
    "itl": 151.05743774755103,
    "ttft": 421843.0399878283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.288368821199942,
    "arrivals": 100828,
    "finished_requests": 92349,
    "scheduler_time": 82.4407870816622
}
#Debug simulation 
Total elapsed time: 7.174612290982623. Arrivals time: 0.23715707944938913 Scheduler time: 6.822817436477635 Scheduler overhead time: 0.03932541189715266 Adapter cache time: 0.01769126846920699 Engine time: 0.039516988734249026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.177211234986316,
    "estimated_duration": 3600.091885044399,
    "input_throughput": 6334.985252666331,
    "output_throughput": 5641.940163910428,
    "total_throughput": 11976.92541657676,
    "itl": 151.0525868469672,
    "ttft": 421667.16118323116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1371446095406723,
    "arrivals": 100828,
    "finished_requests": 92351,
    "scheduler_time": 82.44126984170747
}
#Debug simulation 
Total elapsed time: 7.177336908993311. Arrivals time: 0.2420592214912176 Scheduler time: 6.8202188002178445 Scheduler overhead time: 0.03935519530205056 Adapter cache time: 0.01775135612115264 Engine time: 0.039739800442475826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.1789685530238785,
    "estimated_duration": 3600.096103250193,
    "input_throughput": 6334.886721332354,
    "output_throughput": 5641.70355943092,
    "total_throughput": 11976.590280763274,
    "itl": 151.06172003242432,
    "ttft": 421812.4280389458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3331371691636744,
    "arrivals": 100828,
    "finished_requests": 92349,
    "scheduler_time": 82.43982088650453
}
#Debug simulation 
Total elapsed time: 7.179066727054305. Arrivals time: 0.2465693261474371 Scheduler time: 6.817593086219858 Scheduler overhead time: 0.039292724803090096 Adapter cache time: 0.017735165893100202 Engine time: 0.03966054308693856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.15544589998899,
    "estimated_duration": 3600.0096811975977,
    "input_throughput": 6335.259074195853,
    "output_throughput": 5642.113160441007,
    "total_throughput": 11977.37223463686,
    "itl": 151.0451244323524,
    "ttft": 421456.2250297834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1001,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9930403451970085,
    "arrivals": 100828,
    "finished_requests": 92353,
    "scheduler_time": 82.44057977932096
}
#Debug simulation 
Total elapsed time: 7.155569488997571. Arrivals time: 0.24110777181340382 Scheduler time: 6.799934855022002 Scheduler overhead time: 0.039335050678346306 Adapter cache time: 0.01773076324025169 Engine time: 0.03943037544377148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 270, 8640, 270, 270, 8640, 540, 8640, 540, 8640, 8640, 540, 270, 8640, 540, 270, 270, 540, 8640, 270, 540, 270, 270, 540, 540, 540, 270, 270, 8640, 540, 540, 270, 8640, 8640, 540, 8640, 8640, 540, 8640, 270, 8640, 540, 540, 540, 8640, 8640, 270, 270, 540, 270, 8640, 270, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 540, 8640, 8640, 270, 270, 8640, 540, 8640, 270, 540, 8640, 270, 8640, 540, 270, 8640, 270, 270, 8640, 270, 270, 540]
Prompts retrieved: 302400 . Total input tokens: 67462409 . Total output tokens: 60534546
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.162240845966153,
    "estimated_duration": 3600.146925098046,
    "input_throughput": 6334.797294246234,
    "output_throughput": 5641.623917736874,
    "total_throughput": 11976.421211983108,
    "itl": 151.06375722025942,
    "ttft": 421891.1095541234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1000,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3750277659297416,
    "arrivals": 100828,
    "finished_requests": 92349,
    "scheduler_time": 82.44053981874536
}
#Debug simulation 
Total elapsed time: 7.1623388569569215. Arrivals time: 0.23914306447841227 Scheduler time: 6.808332770015113 Scheduler overhead time: 0.03929820010671392 Adapter cache time: 0.017794851097278297 Engine time: 0.03958745772251859 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.840329014987219,
    "estimated_duration": 3600.0460968750804,
    "input_throughput": 6465.498044651195,
    "output_throughput": 5637.621145356198,
    "total_throughput": 12103.119190007394,
    "itl": 149.615362386804,
    "ttft": 312815.4331005579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.094932601382131,
    "arrivals": 99385,
    "finished_requests": 93177,
    "scheduler_time": 81.23338228702464
}
#Debug simulation 
Total elapsed time: 6.840429439034779. Arrivals time: 0.23439142893766984 Scheduler time: 6.48785949696321 Scheduler overhead time: 0.03930725035024807 Adapter cache time: 0.0211411127820611 Engine time: 0.039608143852092326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.876134602003731,
    "estimated_duration": 3600.119579248637,
    "input_throughput": 6464.932480064318,
    "output_throughput": 5637.2921935653185,
    "total_throughput": 12102.224673629637,
    "itl": 149.62946913966164,
    "ttft": 313176.8755439077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1334,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.3744410740071675,
    "arrivals": 99385,
    "finished_requests": 93173,
    "scheduler_time": 81.23282792479917
}
#Debug simulation 
Total elapsed time: 6.876261719036847. Arrivals time: 0.23339981766184792 Scheduler time: 6.525058494647965 Scheduler overhead time: 0.03923417121404782 Adapter cache time: 0.020910784776788205 Engine time: 0.03945964982267469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.876628857047763,
    "estimated_duration": 3600.1508037524254,
    "input_throughput": 6464.876408994043,
    "output_throughput": 5637.2433007102545,
    "total_throughput": 12102.119709704299,
    "itl": 149.63018209392695,
    "ttft": 313174.66033888224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.391264349482894,
    "arrivals": 99385,
    "finished_requests": 93173,
    "scheduler_time": 81.23327632493391
}
#Debug simulation 
Total elapsed time: 6.876727881026454. Arrivals time: 0.23322081752121449 Scheduler time: 6.525676649122033 Scheduler overhead time: 0.039162600762210786 Adapter cache time: 0.021054646756965667 Engine time: 0.03944659460103139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.789585679012816,
    "estimated_duration": 3600.018471984304,
    "input_throughput": 6465.352936695009,
    "output_throughput": 5637.542739833055,
    "total_throughput": 12102.895676528064,
    "itl": 149.62157537793857,
    "ttft": 312930.8284192503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.19436147551978,
    "arrivals": 99385,
    "finished_requests": 93175,
    "scheduler_time": 81.23196361610205
}
#Debug simulation 
Total elapsed time: 6.789686197997071. Arrivals time: 0.23323728406103328 Scheduler time: 6.438631435157731 Scheduler overhead time: 0.03905005566775799 Adapter cache time: 0.021122187899891287 Engine time: 0.03939701325725764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.858454038039781,
    "estimated_duration": 3600.0563388772716,
    "input_throughput": 6464.847993811749,
    "output_throughput": 5637.253723181761,
    "total_throughput": 12102.101716993511,
    "itl": 149.63244258595077,
    "ttft": 313242.78467227163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.45062013667075,
    "arrivals": 99385,
    "finished_requests": 93169,
    "scheduler_time": 81.23060853997421
}
#Debug simulation 
Total elapsed time: 6.858578869025223. Arrivals time: 0.23069125966867432 Scheduler time: 6.509539977821987 Scheduler overhead time: 0.03951423795660958 Adapter cache time: 0.02094748883973807 Engine time: 0.03966946585569531 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.85581874998752,
    "estimated_duration": 3600.093804485009,
    "input_throughput": 6465.489307806986,
    "output_throughput": 5637.56838077815,
    "total_throughput": 12103.057688585135,
    "itl": 149.6119731586644,
    "ttft": 312797.23868541344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.000687294579006,
    "arrivals": 99385,
    "finished_requests": 93179,
    "scheduler_time": 81.23522950200946
}
#Debug simulation 
Total elapsed time: 6.855917654000223. Arrivals time: 0.23281173419672996 Scheduler time: 6.504909981973469 Scheduler overhead time: 0.039416620100382715 Adapter cache time: 0.021039503160864115 Engine time: 0.03957493579946458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.860610882984474,
    "estimated_duration": 3600.1432456539264,
    "input_throughput": 6464.692211371319,
    "output_throughput": 5637.160972552832,
    "total_throughput": 12101.853183924151,
    "itl": 149.63567538469493,
    "ttft": 313332.1893538602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.510227431431428,
    "arrivals": 99385,
    "finished_requests": 93170,
    "scheduler_time": 81.23205309815701
}
#Debug simulation 
Total elapsed time: 6.860711241955869. Arrivals time: 0.2293492007884197 Scheduler time: 6.513906028645579 Scheduler overhead time: 0.03906773048220202 Adapter cache time: 0.02097456401679665 Engine time: 0.03925261867698282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.773022238048725,
    "estimated_duration": 3600.0360003264536,
    "input_throughput": 6368.342704884349,
    "output_throughput": 5669.524970902837,
    "total_throughput": 12037.867675787185,
    "itl": 150.52114514449704,
    "ttft": 293692.3551877636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1344,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.113295527845728,
    "arrivals": 98626,
    "finished_requests": 92819,
    "scheduler_time": 81.51197175956236
}
#Debug simulation 
Total elapsed time: 6.773136961041018. Arrivals time: 0.2317319346475415 Scheduler time: 6.424621723068412 Scheduler overhead time: 0.03840176010271534 Adapter cache time: 0.021530460682697594 Engine time: 0.03902320406632498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.792855239997152,
    "estimated_duration": 3600.012112302447,
    "input_throughput": 6367.693575713756,
    "output_throughput": 5668.910371234178,
    "total_throughput": 12036.603946947933,
    "itl": 150.5321006015945,
    "ttft": 294125.70807849756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.372081492920376,
    "arrivals": 98626,
    "finished_requests": 92808,
    "scheduler_time": 81.5090910123823
}
#Debug simulation 
Total elapsed time: 6.792979802004993. Arrivals time: 0.227595194010064 Scheduler time: 6.447672022390179 Scheduler overhead time: 0.03868247667560354 Adapter cache time: 0.021746209415141493 Engine time: 0.0393787597422488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.769968342967331,
    "estimated_duration": 3600.0185243377073,
    "input_throughput": 6367.6822341399675,
    "output_throughput": 5668.900274271358,
    "total_throughput": 12036.582508411326,
    "itl": 150.5322351276557,
    "ttft": 294161.31074895174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.380497303847167,
    "arrivals": 98626,
    "finished_requests": 92808,
    "scheduler_time": 81.50911170552543
}
#Debug simulation 
Total elapsed time: 6.770068442972843. Arrivals time: 0.23040283826412633 Scheduler time: 6.422822153195739 Scheduler overhead time: 0.03848701895913109 Adapter cache time: 0.02149432571604848 Engine time: 0.03901274228701368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.75007796799764,
    "estimated_duration": 3600.129638903452,
    "input_throughput": 6368.292339323408,
    "output_throughput": 5669.43722788183,
    "total_throughput": 12037.729567205239,
    "itl": 150.5239118663957,
    "ttft": 293718.46110017155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.197462462759514,
    "arrivals": 98626,
    "finished_requests": 92820,
    "scheduler_time": 81.51334904212965
}
#Debug simulation 
Total elapsed time: 6.750199300004169. Arrivals time: 0.2294959873543121 Scheduler time: 6.40364846191369 Scheduler overhead time: 0.03857641475042328 Adapter cache time: 0.021586973511148244 Engine time: 0.03902957768877968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.750038162979763,
    "estimated_duration": 3600.1066444747585,
    "input_throughput": 6367.584703409396,
    "output_throughput": 5668.846513566965,
    "total_throughput": 12036.431216976362,
    "itl": 150.53448345111298,
    "ttft": 294214.05135132227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.42661267340182,
    "arrivals": 98626,
    "finished_requests": 92809,
    "scheduler_time": 81.51089453338822
}
#Debug simulation 
Total elapsed time: 6.750140077958349. Arrivals time: 0.22921302856411785 Scheduler time: 6.403789567004424 Scheduler overhead time: 0.03849451878340915 Adapter cache time: 0.021679420897271484 Engine time: 0.03905698377639055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.723902295983862,
    "estimated_duration": 3600.0818384520626,
    "input_throughput": 6368.589945682506,
    "output_throughput": 5669.7391659230725,
    "total_throughput": 12038.329111605579,
    "itl": 150.5189869209413,
    "ttft": 293457.01809869113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.003677344873908,
    "arrivals": 98626,
    "finished_requests": 92825,
    "scheduler_time": 81.51375506571516
}
#Debug simulation 
Total elapsed time: 6.72400219598785. Arrivals time: 0.22841149097075686 Scheduler time: 6.3784754408407025 Scheduler overhead time: 0.03862186230253428 Adapter cache time: 0.021338907186873257 Engine time: 0.039177891332656145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.763800619053654,
    "estimated_duration": 3600.049480999301,
    "input_throughput": 6367.3235940182485,
    "output_throughput": 5668.62291968702,
    "total_throughput": 12035.946513705268,
    "itl": 150.53860038186596,
    "ttft": 294341.93783216306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1341,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.492503913678242,
    "arrivals": 98626,
    "finished_requests": 92805,
    "scheduler_time": 81.50876903283255
}
#Debug simulation 
Total elapsed time: 6.763924498052802. Arrivals time: 0.2285350423771888 Scheduler time: 6.418277019402012 Scheduler overhead time: 0.038513356004841626 Adapter cache time: 0.021398849901743233 Engine time: 0.039108391327317804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.7467242119601,
    "estimated_duration": 3600.1258497190956,
    "input_throughput": 6563.262782006259,
    "output_throughput": 5718.097883052127,
    "total_throughput": 12281.360665058386,
    "itl": 146.26484973483224,
    "ttft": 189337.53709335107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9992779890541668,
    "arrivals": 98351,
    "finished_requests": 94498,
    "scheduler_time": 81.03232996306735
}
#Debug simulation 
Total elapsed time: 6.746858066995628. Arrivals time: 0.2267459593131207 Scheduler time: 6.403817158541642 Scheduler overhead time: 0.03885013371473178 Adapter cache time: 0.01975478930398822 Engine time: 0.03952051285887137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.7244639149867,
    "estimated_duration": 3600.083447198438,
    "input_throughput": 6562.804820089963,
    "output_throughput": 5717.64496626275,
    "total_throughput": 12280.449786352714,
    "itl": 146.27373325397858,
    "ttft": 189560.4973006056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.184246747887229,
    "arrivals": 98351,
    "finished_requests": 94492,
    "scheduler_time": 81.03012032281616
}
#Debug simulation 
Total elapsed time: 6.724561996001285. Arrivals time: 0.2243693257914856 Scheduler time: 6.384231647360139 Scheduler overhead time: 0.0386484419577755 Adapter cache time: 0.01988519442966208 Engine time: 0.03926555142970756 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.758244319993537,
    "estimated_duration": 3600.1208682052716,
    "input_throughput": 6562.736603834729,
    "output_throughput": 5717.585534916086,
    "total_throughput": 12280.322138750815,
    "itl": 146.27414058753976,
    "ttft": 189622.51068291205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1904012198187104,
    "arrivals": 98351,
    "finished_requests": 94492,
    "scheduler_time": 81.03067554737576
}
#Debug simulation 
Total elapsed time: 6.758348389004823. Arrivals time: 0.2239427519380115 Scheduler time: 6.418753877398558 Scheduler overhead time: 0.038745508645661175 Adapter cache time: 0.01964426034828648 Engine time: 0.03927843022393063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.74811696598772,
    "estimated_duration": 3600.0326341825426,
    "input_throughput": 6563.037172401911,
    "output_throughput": 5717.864833932015,
    "total_throughput": 12280.902006333927,
    "itl": 146.26725603830687,
    "ttft": 189403.68280726115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.066979891494815,
    "arrivals": 98351,
    "finished_requests": 94493,
    "scheduler_time": 81.03016268832489
}
#Debug simulation 
Total elapsed time: 6.748234484985005. Arrivals time: 0.2284021463128738 Scheduler time: 6.4038687130087055 Scheduler overhead time: 0.038930987007915974 Adapter cache time: 0.019655766896903515 Engine time: 0.039293279114644974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.725089184998069,
    "estimated_duration": 3600.0131635064217,
    "input_throughput": 6562.927669127634,
    "output_throughput": 5717.701037501576,
    "total_throughput": 12280.62870662921,
    "itl": 146.2762770457639,
    "ttft": 189502.6723857044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.226955557800828,
    "arrivals": 98351,
    "finished_requests": 94491,
    "scheduler_time": 81.02807338857558
}
#Debug simulation 
Total elapsed time: 6.725186266005039. Arrivals time: 0.22181529231602326 Scheduler time: 6.387918281485327 Scheduler overhead time: 0.038566401693969965 Adapter cache time: 0.019548934535123408 Engine time: 0.0393752254312858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.710382404038683,
    "estimated_duration": 3600.1312594790734,
    "input_throughput": 6563.561797304895,
    "output_throughput": 5718.403168160838,
    "total_throughput": 12281.964965465731,
    "itl": 146.2608995114861,
    "ttft": 189204.8357474743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 982,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.936229389593869,
    "arrivals": 98351,
    "finished_requests": 94501,
    "scheduler_time": 81.03331497208792
}
#Debug simulation 
Total elapsed time: 6.710508295043837. Arrivals time: 0.2190470137866214 Scheduler time: 6.37615214107791 Scheduler overhead time: 0.0386052651447244 Adapter cache time: 0.019570294592995197 Engine time: 0.03918099729344249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.717154141981155,
    "estimated_duration": 3600.046817406996,
    "input_throughput": 6562.866317671263,
    "output_throughput": 5717.647587379401,
    "total_throughput": 12280.513905050662,
    "itl": 146.27710904361797,
    "ttft": 189551.67182315275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.267196769453621,
    "arrivals": 98351,
    "finished_requests": 94491,
    "scheduler_time": 81.0284547590535
}
#Debug simulation 
Total elapsed time: 6.717250863963272. Arrivals time: 0.2198114474886097 Scheduler time: 6.382157367130276 Scheduler overhead time: 0.03856127540348098 Adapter cache time: 0.01953898387728259 Engine time: 0.039280027674976736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.669604847964365,
    "estimated_duration": 3600.127393461301,
    "input_throughput": 6477.186902428058,
    "output_throughput": 5698.848612208295,
    "total_throughput": 12176.035514636353,
    "itl": 147.1234487167773,
    "ttft": 148067.58678416628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1908,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.839410615423861,
    "arrivals": 96609,
    "finished_requests": 93620,
    "scheduler_time": 80.39800431429099
}
#Debug simulation 
Total elapsed time: 6.669703829975333. Arrivals time: 0.21002130227861926 Scheduler time: 6.338197610632051 Scheduler overhead time: 0.038647500332444906 Adapter cache time: 0.02627051342278719 Engine time: 0.038764114666264504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.655495736049488,
    "estimated_duration": 3600.1512339773585,
    "input_throughput": 6476.777080900442,
    "output_throughput": 5698.233120428134,
    "total_throughput": 12175.010201328576,
    "itl": 147.1401732684459,
    "ttft": 148557.54988885322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.228705277847859,
    "arrivals": 96609,
    "finished_requests": 93614,
    "scheduler_time": 80.3949687937728
}
#Debug simulation 
Total elapsed time: 6.655594128998928. Arrivals time: 0.2161575312493369 Scheduler time: 6.317364580056164 Scheduler overhead time: 0.03846026415703818 Adapter cache time: 0.026679373520892113 Engine time: 0.039178826205898076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.657015264965594,
    "estimated_duration": 3600.159214731261,
    "input_throughput": 6476.762723323212,
    "output_throughput": 5698.220488710062,
    "total_throughput": 12174.983212033276,
    "itl": 147.14048731679964,
    "ttft": 148561.0285518907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.238702465053607,
    "arrivals": 96609,
    "finished_requests": 93614,
    "scheduler_time": 80.39502542156298
}
#Debug simulation 
Total elapsed time: 6.657116001006216. Arrivals time: 0.21497251780238003 Scheduler time: 6.32027976232348 Scheduler overhead time: 0.03862300870241597 Adapter cache time: 0.0262221748707816 Engine time: 0.03914235852425918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.6408610960352235,
    "estimated_duration": 3600.0939629242844,
    "input_throughput": 6477.000111702476,
    "output_throughput": 5698.425433134024,
    "total_throughput": 12175.4255448365,
    "itl": 147.1269348272277,
    "ttft": 148196.84714295014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1909,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.971958588680541,
    "arrivals": 96609,
    "finished_requests": 93616,
    "scheduler_time": 80.39610501772077
}
#Debug simulation 
Total elapsed time: 6.640958744043019. Arrivals time: 0.2128427503630519 Scheduler time: 6.30622835905524 Scheduler overhead time: 0.03849564923439175 Adapter cache time: 0.02619488147320226 Engine time: 0.039260888705030084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.660089241049718,
    "estimated_duration": 3600.0542857788314,
    "input_throughput": 6476.633725248339,
    "output_throughput": 5698.159075276859,
    "total_throughput": 12174.792800525198,
    "itl": 147.1479828377603,
    "ttft": 148538.504631717,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.329155707545477,
    "arrivals": 96609,
    "finished_requests": 93610,
    "scheduler_time": 80.39175688339053
}
#Debug simulation 
Total elapsed time: 6.660186306049582. Arrivals time: 0.21354313666233793 Scheduler time: 6.324230353988241 Scheduler overhead time: 0.03873009234666824 Adapter cache time: 0.026541397906839848 Engine time: 0.03926384134683758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.689750774006825,
    "estimated_duration": 3600.140107840117,
    "input_throughput": 6477.461238026805,
    "output_throughput": 5699.083198267346,
    "total_throughput": 12176.54443629415,
    "itl": 147.12136877009553,
    "ttft": 147976.05954472083,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1910,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.710996063262989,
    "arrivals": 96609,
    "finished_requests": 93624,
    "scheduler_time": 80.39865952068435
}
#Debug simulation 
Total elapsed time: 6.6898572070058435. Arrivals time: 0.2150347547722049 Scheduler time: 6.3524200090323575 Scheduler overhead time: 0.038706602703314275 Adapter cache time: 0.02620029909303412 Engine time: 0.03951636829879135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.70420550898416,
    "estimated_duration": 3600.153378143463,
    "input_throughput": 6476.455459245955,
    "output_throughput": 5698.002236387648,
    "total_throughput": 12174.457695633604,
    "itl": 147.14997314054835,
    "ttft": 148790.4863893673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1907,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.400799095742231,
    "arrivals": 96609,
    "finished_requests": 93610,
    "scheduler_time": 80.39371072085281
}
#Debug simulation 
Total elapsed time: 6.70431753603043. Arrivals time: 0.2153094873065129 Scheduler time: 6.36621328711044 Scheduler overhead time: 0.03866889624623582 Adapter cache time: 0.026531728159170598 Engine time: 0.03962495259474963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.756803943018895,
    "estimated_duration": 3600.0744000534587,
    "input_throughput": 6553.437617747472,
    "output_throughput": 5800.4117914035105,
    "total_throughput": 12353.849409150984,
    "itl": 133.28979618582298,
    "ttft": 34662.2134690993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.303045767969565,
    "arrivals": 95912,
    "finished_requests": 95020,
    "scheduler_time": 80.28190460778333
}
#Debug simulation 
Total elapsed time: 6.756933177995961. Arrivals time: 0.20594634814187884 Scheduler time: 6.424293862422928 Scheduler overhead time: 0.041231925948522985 Adapter cache time: 0.02414093556581065 Engine time: 0.04214439424686134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.727696207992267,
    "estimated_duration": 3600.025148941036,
    "input_throughput": 6553.382830378226,
    "output_throughput": 5800.34253542433,
    "total_throughput": 12353.725365802555,
    "itl": 133.39450272449952,
    "ttft": 34684.8193562791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.59202743796394,
    "arrivals": 95912,
    "finished_requests": 95019,
    "scheduler_time": 80.28537600454821
}
#Debug simulation 
Total elapsed time: 6.727815750986338. Arrivals time: 0.20664405531715602 Scheduler time: 6.395866833801847 Scheduler overhead time: 0.040925024542957544 Adapter cache time: 0.023915369587484747 Engine time: 0.04136094293789938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.726498347008601,
    "estimated_duration": 3600.113870272035,
    "input_throughput": 6553.417989030786,
    "output_throughput": 5800.403751790797,
    "total_throughput": 12353.821740821584,
    "itl": 133.39787366605685,
    "ttft": 34796.37443356605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.600263698957802,
    "arrivals": 95912,
    "finished_requests": 95021,
    "scheduler_time": 80.28738580741826
}
#Debug simulation 
Total elapsed time: 6.726608655008022. Arrivals time: 0.20248530543176457 Scheduler time: 6.397634025081061 Scheduler overhead time: 0.04138373350724578 Adapter cache time: 0.02408076066058129 Engine time: 0.041757323080673814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.754075910022948,
    "estimated_duration": 3600.1379901871414,
    "input_throughput": 6553.374082967745,
    "output_throughput": 5800.364890712011,
    "total_throughput": 12353.738973679758,
    "itl": 133.33574016305542,
    "ttft": 34821.85988095922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.400117521362771,
    "arrivals": 95912,
    "finished_requests": 95021,
    "scheduler_time": 80.28579705489007
}
#Debug simulation 
Total elapsed time: 6.754186085017864. Arrivals time: 0.20637038454879075 Scheduler time: 6.4216561012435704 Scheduler overhead time: 0.041441874753218144 Adapter cache time: 0.023877614818047732 Engine time: 0.04169953387463465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.734606096986681,
    "estimated_duration": 3600.004465967854,
    "input_throughput": 6553.363536913642,
    "output_throughput": 5800.186415709422,
    "total_throughput": 12353.549952623065,
    "itl": 133.41981976581957,
    "ttft": 34726.697357098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.657078982442586,
    "arrivals": 95912,
    "finished_requests": 95018,
    "scheduler_time": 80.28616778485265
}
#Debug simulation 
Total elapsed time: 6.734692488971632. Arrivals time: 0.20342974638333544 Scheduler time: 6.405400962161366 Scheduler overhead time: 0.04130364756565541 Adapter cache time: 0.023886366339866072 Engine time: 0.04146996344206855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.70363077201182,
    "estimated_duration": 3600.0029036021615,
    "input_throughput": 6553.423325407185,
    "output_throughput": 5800.378377224669,
    "total_throughput": 12353.801702631854,
    "itl": 133.25409396579883,
    "ttft": 34657.72006839835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1407,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2070007649272485,
    "arrivals": 95912,
    "finished_requests": 95019,
    "scheduler_time": 80.2793040737408
}
#Debug simulation 
Total elapsed time: 6.70371932501439. Arrivals time: 0.20497748150955886 Scheduler time: 6.372941889509093 Scheduler overhead time: 0.04107765218941495 Adapter cache time: 0.0239888301002793 Engine time: 0.04162063240073621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.7425548559986055,
    "estimated_duration": 3600.1300250040367,
    "input_throughput": 6553.388582117544,
    "output_throughput": 5800.377723850845,
    "total_throughput": 12353.76630596839,
    "itl": 133.44096427885256,
    "ttft": 34841.20806649147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.721687256880095,
    "arrivals": 95912,
    "finished_requests": 95021,
    "scheduler_time": 80.28955492557277
}
#Debug simulation 
Total elapsed time: 6.742645427992102. Arrivals time: 0.2045329890679568 Scheduler time: 6.412235243536998 Scheduler overhead time: 0.04135220102034509 Adapter cache time: 0.023750057618599385 Engine time: 0.04166446236195043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.656221022014506,
    "estimated_duration": 3600.03665705426,
    "input_throughput": 6541.355059220184,
    "output_throughput": 5770.596796366701,
    "total_throughput": 12311.951855586884,
    "itl": 110.91815335305466,
    "ttft": 25477.072684249226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 957,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.928886770943711,
    "arrivals": 95515,
    "finished_requests": 94840,
    "scheduler_time": 78.61844808492737
}
#Debug simulation 
Total elapsed time: 6.656306509976275. Arrivals time: 0.20823223429033533 Scheduler time: 6.306984571157955 Scheduler overhead time: 0.04766319884220138 Adapter cache time: 0.02352246578084305 Engine time: 0.04798418207792565 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.682576739054639,
    "estimated_duration": 3600.09363003544,
    "input_throughput": 6541.459867466883,
    "output_throughput": 5770.551306410187,
    "total_throughput": 12312.01117387707,
    "itl": 110.9659544447721,
    "ttft": 25589.357638661237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1073226308566544,
    "arrivals": 95515,
    "finished_requests": 94842,
    "scheduler_time": 78.62238331277833
}
#Debug simulation 
Total elapsed time: 6.682667854009196. Arrivals time: 0.20718515297630802 Scheduler time: 6.333979060174897 Scheduler overhead time: 0.047660396608989686 Adapter cache time: 0.023638187150936574 Engine time: 0.047999664093367755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.702491089003161,
    "estimated_duration": 3600.098762037764,
    "input_throughput": 6541.587483191652,
    "output_throughput": 5770.569468555618,
    "total_throughput": 12312.15695174727,
    "itl": 110.96627981883182,
    "ttft": 25551.606686100742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.114987743589998,
    "arrivals": 95515,
    "finished_requests": 94843,
    "scheduler_time": 78.62228999161698
}
#Debug simulation 
Total elapsed time: 6.702576345996931. Arrivals time: 0.20826367021072656 Scheduler time: 6.353107900940813 Scheduler overhead time: 0.04752256802748889 Adapter cache time: 0.023657465062569827 Engine time: 0.047907957748975605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.726534119981807,
    "estimated_duration": 3600.0609716575614,
    "input_throughput": 6541.434210531487,
    "output_throughput": 5770.558377636295,
    "total_throughput": 12311.992588167783,
    "itl": 110.93067184210346,
    "ttft": 25514.53815667346,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9843354400060766,
    "arrivals": 95515,
    "finished_requests": 94841,
    "scheduler_time": 78.61985811597104
}
#Debug simulation 
Total elapsed time: 6.726621443987824. Arrivals time: 0.2175605222582817 Scheduler time: 6.367244946712162 Scheduler overhead time: 0.047335738490801305 Adapter cache time: 0.0235715780290775 Engine time: 0.048679074563551694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.69003449997399,
    "estimated_duration": 3600.0146970210935,
    "input_throughput": 6541.2960728982325,
    "output_throughput": 5770.631441363329,
    "total_throughput": 12311.92751426156,
    "itl": 110.96726399859476,
    "ttft": 25514.812703151787,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1529653870873187,
    "arrivals": 95515,
    "finished_requests": 94839,
    "scheduler_time": 78.62057137527795
}
#Debug simulation 
Total elapsed time: 6.690125663997605. Arrivals time: 0.20753401378169656 Scheduler time: 6.341832721431274 Scheduler overhead time: 0.04744853108422831 Adapter cache time: 0.02355273236753419 Engine time: 0.04778094368521124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.7061153129907325,
    "estimated_duration": 3600.0462137380373,
    "input_throughput": 6541.461026287153,
    "output_throughput": 5770.582033287109,
    "total_throughput": 12312.043059574262,
    "itl": 110.90352236713942,
    "ttft": 25514.250266677147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 956,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8584880819264153,
    "arrivals": 95515,
    "finished_requests": 94841,
    "scheduler_time": 78.61811707040778
}
#Debug simulation 
Total elapsed time: 6.706207241979428. Arrivals time: 0.2076306549133733 Scheduler time: 6.356627836881671 Scheduler overhead time: 0.04761770647019148 Adapter cache time: 0.0236696622450836 Engine time: 0.0485666990862228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.703150279005058,
    "estimated_duration": 3600.0302227628813,
    "input_throughput": 6541.366750506606,
    "output_throughput": 5770.607110086008,
    "total_throughput": 12311.973860592614,
    "itl": 110.97050503414101,
    "ttft": 25477.459537874747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 955,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1885282806679953,
    "arrivals": 95515,
    "finished_requests": 94840,
    "scheduler_time": 78.62096366064434
}
#Debug simulation 
Total elapsed time: 6.7032322159502655. Arrivals time: 0.20794675167417154 Scheduler time: 6.353975320933387 Scheduler overhead time: 0.047738827648572624 Adapter cache time: 0.023507244826760143 Engine time: 0.0480365797993727 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.660663409973495,
    "estimated_duration": 3600.057861028186,
    "input_throughput": 6481.87470890688,
    "output_throughput": 5712.845958016389,
    "total_throughput": 12194.72066692327,
    "itl": 88.84106419953652,
    "ttft": 20999.649533527838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.170665302714407,
    "arrivals": 94463,
    "finished_requests": 93914,
    "scheduler_time": 76.26757927365847
}
#Debug simulation 
Total elapsed time: 6.660750731010921. Arrivals time: 0.20851151423994452 Scheduler time: 6.288752973196097 Scheduler overhead time: 0.05668860988225788 Adapter cache time: 0.023136996664106846 Engine time: 0.057238560810219496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.6449130400433205,
    "estimated_duration": 3600.06422116128,
    "input_throughput": 6481.863257559539,
    "output_throughput": 5712.835865290703,
    "total_throughput": 12194.699122850243,
    "itl": 88.87017301641973,
    "ttft": 20999.45923913983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3902463535219525,
    "arrivals": 94463,
    "finished_requests": 93914,
    "scheduler_time": 76.27004616639574
}
#Debug simulation 
Total elapsed time: 6.644997685041744. Arrivals time: 0.2094784607179463 Scheduler time: 6.272210378316231 Scheduler overhead time: 0.056701260909903795 Adapter cache time: 0.02302148670423776 Engine time: 0.05733381357276812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.66958720801631,
    "estimated_duration": 3600.074438999145,
    "input_throughput": 6481.845416087393,
    "output_throughput": 5712.868261056778,
    "total_throughput": 12194.713677144171,
    "itl": 88.86987661994598,
    "ttft": 20961.18170859659,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.394554733410435,
    "arrivals": 94463,
    "finished_requests": 93916,
    "scheduler_time": 76.27028350247463
}
#Debug simulation 
Total elapsed time: 6.6696736789890565. Arrivals time: 0.2087786677875556 Scheduler time: 6.2972655481426045 Scheduler overhead time: 0.056748297123704106 Adapter cache time: 0.02300927141914144 Engine time: 0.057497227913700044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.680147414968815,
    "estimated_duration": 3600.0511858311525,
    "input_throughput": 6481.886727566782,
    "output_throughput": 5712.856550746998,
    "total_throughput": 12194.743278313781,
    "itl": 88.8502703255706,
    "ttft": 20999.510864392767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1035,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2405705839069223,
    "arrivals": 94463,
    "finished_requests": 93914,
    "scheduler_time": 76.26825367357678
}
#Debug simulation 
Total elapsed time: 6.68024992197752. Arrivals time: 0.20892574335448444 Scheduler time: 6.307581837230828 Scheduler overhead time: 0.05688954395009205 Adapter cache time: 0.023123471590224653 Engine time: 0.05743733426788822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.670588402019348,
    "estimated_duration": 3600.0214274584814,
    "input_throughput": 6481.640587476506,
    "output_throughput": 5712.766830534979,
    "total_throughput": 12194.407418011484,
    "itl": 88.87359596592889,
    "ttft": 21038.05411212682,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1035,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4366568238846944,
    "arrivals": 94463,
    "finished_requests": 93912,
    "scheduler_time": 76.26941019000232
}
#Debug simulation 
Total elapsed time: 6.670681932999287. Arrivals time: 0.20846080308547243 Scheduler time: 6.2977935544913635 Scheduler overhead time: 0.057006427843589336 Adapter cache time: 0.02304407808696851 Engine time: 0.058018523443024606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.676116520015057,
    "estimated_duration": 3600.043107638347,
    "input_throughput": 6481.901272373375,
    "output_throughput": 5712.8693699148,
    "total_throughput": 12194.770642288175,
    "itl": 88.83392115075641,
    "ttft": 20999.476740085895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1035,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.094702055223679,
    "arrivals": 94463,
    "finished_requests": 93914,
    "scheduler_time": 76.26672238756362
}
#Debug simulation 
Total elapsed time: 6.6762015640269965. Arrivals time: 0.20906827365979552 Scheduler time: 6.3038628762587905 Scheduler overhead time: 0.05671695654746145 Adapter cache time: 0.022959838272072375 Engine time: 0.057234581327065825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.648495986009948,
    "estimated_duration": 3600.0644672839626,
    "input_throughput": 6481.86281441926,
    "output_throughput": 5712.8354747258945,
    "total_throughput": 12194.698289145153,
    "itl": 88.8794064080697,
    "ttft": 20999.673124591918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1035,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4815509256348465,
    "arrivals": 94463,
    "finished_requests": 93914,
    "scheduler_time": 76.27085915523378
}
#Debug simulation 
Total elapsed time: 6.648581242014188. Arrivals time: 0.20876651356229559 Scheduler time: 6.276092619809788 Scheduler overhead time: 0.056753469922114164 Adapter cache time: 0.023031242424622178 Engine time: 0.05765664391219616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.64699020201806,
    "estimated_duration": 3600.0091734362613,
    "input_throughput": 6454.4738306376985,
    "output_throughput": 5706.400736860155,
    "total_throughput": 12160.874567497853,
    "itl": 84.18823372368209,
    "ttft": 21994.030278882514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0903131291061072,
    "arrivals": 94079,
    "finished_requests": 93503,
    "scheduler_time": 75.80104013673028
}
#Debug simulation 
Total elapsed time: 6.647077593021095. Arrivals time: 0.21033479494508356 Scheduler time: 6.2700382227194495 Scheduler overhead time: 0.05909096379764378 Adapter cache time: 0.021094818657729775 Engine time: 0.059310919721610844 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.6378208009991795,
    "estimated_duration": 3600.0624489814218,
    "input_throughput": 6454.561921995124,
    "output_throughput": 5706.374622976996,
    "total_throughput": 12160.93654497212,
    "itl": 84.20188990398347,
    "ttft": 21993.589808997032,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.228932411945431,
    "arrivals": 94079,
    "finished_requests": 93505,
    "scheduler_time": 75.80343152465753
}
#Debug simulation 
Total elapsed time: 6.63791091600433. Arrivals time: 0.20817444642307237 Scheduler time: 6.262084332644008 Scheduler overhead time: 0.05928125017089769 Adapter cache time: 0.02118273841915652 Engine time: 0.059830003418028355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.655951909022406,
    "estimated_duration": 3600.0662033817957,
    "input_throughput": 6454.555190727329,
    "output_throughput": 5706.36867197115,
    "total_throughput": 12160.92386269848,
    "itl": 84.2020344010068,
    "ttft": 21993.77648385303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.232845478709791,
    "arrivals": 94079,
    "finished_requests": 93505,
    "scheduler_time": 75.80348989543035
}
#Debug simulation 
Total elapsed time: 6.656037280044984. Arrivals time: 0.20924794051097706 Scheduler time: 6.2802380421198905 Scheduler overhead time: 0.05887055996572599 Adapter cache time: 0.021022545581217855 Engine time: 0.05931386660085991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.686777182971127,
    "estimated_duration": 3600.058823838737,
    "input_throughput": 6454.469534256939,
    "output_throughput": 5706.350369601689,
    "total_throughput": 12160.819903858628,
    "itl": 84.19354021127725,
    "ttft": 22032.067271434153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1300523448828446,
    "arrivals": 94079,
    "finished_requests": 93504,
    "scheduler_time": 75.80302018255024
}
#Debug simulation 
Total elapsed time: 6.686867050011642. Arrivals time: 0.20996006164932624 Scheduler time: 6.309108150016982 Scheduler overhead time: 0.05919089907547459 Adapter cache time: 0.021175112458877265 Engine time: 0.060061358904931694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.616703430016059,
    "estimated_duration": 3600.059370941462,
    "input_throughput": 6454.468553368152,
    "output_throughput": 5706.349502404925,
    "total_throughput": 12160.818055773078,
    "itl": 84.20641162958384,
    "ttft": 22032.044916837807,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.263277895022187,
    "arrivals": 94079,
    "finished_requests": 93504,
    "scheduler_time": 75.8039279240634
}
#Debug simulation 
Total elapsed time: 6.616791878012009. Arrivals time: 0.20855197391938418 Scheduler time: 6.241649951145519 Scheduler overhead time: 0.05886857636505738 Adapter cache time: 0.021077670739032328 Engine time: 0.05936360644409433 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.679798875004053,
    "estimated_duration": 3600.023881178968,
    "input_throughput": 6454.447461162511,
    "output_throughput": 5706.377423605413,
    "total_throughput": 12160.824884767924,
    "itl": 84.18455274173986,
    "ttft": 21994.219524110908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0422043514181505,
    "arrivals": 94079,
    "finished_requests": 93503,
    "scheduler_time": 75.80134078149005
}
#Debug simulation 
Total elapsed time: 6.679882680007722. Arrivals time: 0.20896062883548439 Scheduler time: 6.303368795954157 Scheduler overhead time: 0.05918366991681978 Adapter cache time: 0.021210700273513794 Engine time: 0.05977920431178063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.632403995958157,
    "estimated_duration": 3600.0796329214577,
    "input_throughput": 6454.531113008565,
    "output_throughput": 5706.34738524635,
    "total_throughput": 12160.878498254915,
    "itl": 84.20864710702205,
    "ttft": 21993.810521837495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 684,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.293821479231123,
    "arrivals": 94079,
    "finished_requests": 93505,
    "scheduler_time": 75.80432675120265
}
#Debug simulation 
Total elapsed time: 6.632488956965972. Arrivals time: 0.2096593827009201 Scheduler time: 6.254978822660632 Scheduler overhead time: 0.05928665027022362 Adapter cache time: 0.021101153339259326 Engine time: 0.060136137530207634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.600164496048819,
    "estimated_duration": 3600.0668907762815,
    "input_throughput": 6442.985284364655,
    "output_throughput": 5679.213364724824,
    "total_throughput": 12122.19864908948,
    "itl": 74.62825607197937,
    "ttft": 15852.609036329746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6526633817237084,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.31265662780412
}
#Debug simulation 
Total elapsed time: 6.600249067007098. Arrivals time: 0.2093944985535927 Scheduler time: 6.211210134264547 Scheduler overhead time: 0.06479354988550767 Adapter cache time: 0.018588055158033967 Engine time: 0.06603736832039431 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.763068155036308,
    "estimated_duration": 3600.046685701647,
    "input_throughput": 6443.021445284194,
    "output_throughput": 5679.24523901422,
    "total_throughput": 12122.266684298413,
    "itl": 74.63580269134633,
    "ttft": 15852.875457874827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7653988317516698,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.31311987629722
}
#Debug simulation 
Total elapsed time: 6.763169425015803. Arrivals time: 0.21044709405396134 Scheduler time: 6.37188085046364 Scheduler overhead time: 0.06533663114532828 Adapter cache time: 0.018776711134705693 Engine time: 0.06634768686490133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.64389296999434,
    "estimated_duration": 3600.013943569509,
    "input_throughput": 6443.080044573762,
    "output_throughput": 5679.296891758063,
    "total_throughput": 12122.376936331826,
    "itl": 74.63670470201511,
    "ttft": 15814.310603516326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7679445038177182,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.3126674534297
}
#Debug simulation 
Total elapsed time: 6.643982245994266. Arrivals time: 0.21110886061796919 Scheduler time: 6.252651230897754 Scheduler overhead time: 0.06527689739596099 Adapter cache time: 0.018839210155420005 Engine time: 0.0660543188569136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.6046757730073296,
    "estimated_duration": 3600.002380439143,
    "input_throughput": 6443.100739608554,
    "output_throughput": 5679.315133537764,
    "total_throughput": 12122.41587314632,
    "itl": 74.62966265308405,
    "ttft": 15814.202176345392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.682862577426703,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.311470498403
}
#Debug simulation 
Total elapsed time: 6.60476032103179. Arrivals time: 0.21004553569946438 Scheduler time: 6.21405986440368 Scheduler overhead time: 0.06538837892003357 Adapter cache time: 0.01866997010074556 Engine time: 0.06655640818644315 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.669234786008019,
    "estimated_duration": 3600.0758300389743,
    "input_throughput": 6443.030117993067,
    "output_throughput": 5679.200929436716,
    "total_throughput": 12122.231047429783,
    "itl": 74.63752529322171,
    "ttft": 15814.104431844673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7903032498247946,
    "arrivals": 93393,
    "finished_requests": 92986,
    "scheduler_time": 74.3139581830591
}
#Debug simulation 
Total elapsed time: 6.669320656976197. Arrivals time: 0.21067603019764647 Scheduler time: 6.277251850231551 Scheduler overhead time: 0.06566683418350294 Adapter cache time: 0.018687603354919702 Engine time: 0.06671503616962582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.660109422984533,
    "estimated_duration": 3600.058895156063,
    "input_throughput": 6442.9995940370545,
    "output_throughput": 5679.225978083251,
    "total_throughput": 12122.225572120306,
    "itl": 74.62500675306498,
    "ttft": 15852.678734556575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6116371089522523,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.31203130209992
}
#Debug simulation 
Total elapsed time: 6.6601950990152545. Arrivals time: 0.21094373927917331 Scheduler time: 6.268561314791441 Scheduler overhead time: 0.06525458849500865 Adapter cache time: 0.018727949529420584 Engine time: 0.06627949484391138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.649970869999379,
    "estimated_duration": 3600.062013048274,
    "input_throughput": 6442.99401397255,
    "output_throughput": 5679.221059497299,
    "total_throughput": 12122.21507346985,
    "itl": 74.63901804894257,
    "ttft": 15852.886422864329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 540,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.814347651004788,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.31385238846696
}
#Debug simulation 
Total elapsed time: 6.650053571036551. Arrivals time: 0.21106081595644355 Scheduler time: 6.257380489434581 Scheduler overhead time: 0.06564186001196504 Adapter cache time: 0.018771085131447762 Engine time: 0.06696706666843966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.205583234957885,
    "estimated_duration": 3600.035466742199,
    "input_throughput": 4404.414663822384,
    "output_throughput": 3859.2325348873887,
    "total_throughput": 8263.647198709772,
    "itl": 61.58041172115683,
    "ttft": 18011.01956071114,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.221249572469317,
    "arrivals": 63713,
    "finished_requests": 63435,
    "scheduler_time": 46.00742895163643
}
#Debug simulation 
Total elapsed time: 5.205668817972764. Arrivals time: 0.1610559054533951 Scheduler time: 4.81970310700126 Scheduler overhead time: 0.07581420172937214 Adapter cache time: 0.041108363308012486 Engine time: 0.07337020355043933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.197327893984038,
    "estimated_duration": 3600.051051194081,
    "input_throughput": 4404.405597176402,
    "output_throughput": 3859.029719979111,
    "total_throughput": 8263.435317155514,
    "itl": 61.60244818186074,
    "ttft": 18006.053374415387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3028,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.928266274426111,
    "arrivals": 63713,
    "finished_requests": 63435,
    "scheduler_time": 46.01048675475827
}
#Debug simulation 
Total elapsed time: 5.197413821006194. Arrivals time: 0.15773897903272882 Scheduler time: 4.813840602175333 Scheduler overhead time: 0.0758036645129323 Adapter cache time: 0.041441999608650804 Engine time: 0.07376156561076641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.284712664026301,
    "estimated_duration": 3600.0325934631182,
    "input_throughput": 4404.300124612869,
    "output_throughput": 3859.3970024683726,
    "total_throughput": 8263.697127081241,
    "itl": 61.60581535128996,
    "ttft": 18012.367357342264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3022,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.91854910429533,
    "arrivals": 63713,
    "finished_requests": 63435,
    "scheduler_time": 46.01151799113154
}
#Debug simulation 
Total elapsed time: 5.28479804500239. Arrivals time: 0.16534708347171545 Scheduler time: 4.889239565061871 Scheduler overhead time: 0.07847409375244752 Adapter cache time: 0.041418811364565045 Engine time: 0.07482896151486784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.276956767949741,
    "estimated_duration": 3600.0195994172263,
    "input_throughput": 4404.436298782037,
    "output_throughput": 3859.370655162305,
    "total_throughput": 8263.806953944342,
    "itl": 61.5924086557815,
    "ttft": 17945.349720182126,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3039,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.513744953977898,
    "arrivals": 63713,
    "finished_requests": 63435,
    "scheduler_time": 46.0086514612342
}
#Debug simulation 
Total elapsed time: 5.277042030997109. Arrivals time: 0.16083546337904409 Scheduler time: 4.890530290955212 Scheduler overhead time: 0.07597664324566722 Adapter cache time: 0.04154711193405092 Engine time: 0.07332273275824264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.201524080999661,
    "estimated_duration": 3600.016989648982,
    "input_throughput": 4404.319214489595,
    "output_throughput": 3859.4137305320673,
    "total_throughput": 8263.732945021662,
    "itl": 61.61145088012737,
    "ttft": 17957.979025427714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.063514048251813,
    "arrivals": 63713,
    "finished_requests": 63435,
    "scheduler_time": 46.012288102109
}
#Debug simulation 
Total elapsed time: 5.201609017967712. Arrivals time: 0.16097291390178725 Scheduler time: 4.814743265160359 Scheduler overhead time: 0.0757622389937751 Adapter cache time: 0.041389210848137736 Engine time: 0.07403383479686454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.225985747005325,
    "estimated_duration": 3600.0548273743225,
    "input_throughput": 4404.272923688832,
    "output_throughput": 3859.3731668618693,
    "total_throughput": 8263.646090550701,
    "itl": 61.576405691896674,
    "ttft": 18012.389482064405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3029,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.056862343258718,
    "arrivals": 63713,
    "finished_requests": 63435,
    "scheduler_time": 46.006529444315355
}
#Debug simulation 
Total elapsed time: 5.226071119017433. Arrivals time: 0.1609188435249962 Scheduler time: 4.837919550656807 Scheduler overhead time: 0.07641326187876984 Adapter cache time: 0.04138699505710974 Engine time: 0.07438753329915926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.292161205026787,
    "estimated_duration": 3600.035395771288,
    "input_throughput": 4404.296696255959,
    "output_throughput": 3859.393998270202,
    "total_throughput": 8263.690694526162,
    "itl": 61.61191244613435,
    "ttft": 18012.592406276115,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.161673545017308,
    "arrivals": 63713,
    "finished_requests": 63435,
    "scheduler_time": 46.01299821232933
}
#Debug simulation 
Total elapsed time: 5.292244045995176. Arrivals time: 0.15993968211114407 Scheduler time: 4.904898051812779 Scheduler overhead time: 0.07681184046668932 Adapter cache time: 0.041219437203835696 Engine time: 0.0743995567318052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.621577690006234,
    "estimated_duration": 3600.0244874843306,
    "input_throughput": 4201.847807588237,
    "output_throughput": 3707.4475594266614,
    "total_throughput": 7909.295367014898,
    "itl": 58.46530306273902,
    "ttft": 15031.183458703483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.581665115306622,
    "arrivals": 60841,
    "finished_requests": 60596,
    "scheduler_time": 43.10152175578261
}
#Debug simulation 
Total elapsed time: 4.621661782031879. Arrivals time: 0.15348372515290976 Scheduler time: 4.233354074473027 Scheduler overhead time: 0.07487600663444027 Adapter cache time: 0.05205988750094548 Engine time: 0.07326202932745218 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.597770160995424,
    "estimated_duration": 3600.008279312991,
    "input_throughput": 4201.66617030297,
    "output_throughput": 3707.3773070730276,
    "total_throughput": 7909.043477375998,
    "itl": 58.496645532600475,
    "ttft": 15150.858607995755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.439451362644936,
    "arrivals": 60841,
    "finished_requests": 60593,
    "scheduler_time": 43.10730823344761
}
#Debug simulation 
Total elapsed time: 4.597854676016141. Arrivals time: 0.15363824024097994 Scheduler time: 4.209902439499274 Scheduler overhead time: 0.07514124846784398 Adapter cache time: 0.051828107272740453 Engine time: 0.07280694850487635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.598655784968287,
    "estimated_duration": 3600.0101328989626,
    "input_throughput": 4201.664006934207,
    "output_throughput": 3707.375398205465,
    "total_throughput": 7909.0394051396715,
    "itl": 58.4978872886564,
    "ttft": 15151.047598715792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.459892111624539,
    "arrivals": 60841,
    "finished_requests": 60593,
    "scheduler_time": 43.10747083648538
}
#Debug simulation 
Total elapsed time: 4.598741700989194. Arrivals time: 0.15313316840911284 Scheduler time: 4.211117954051588 Scheduler overhead time: 0.07525492738932371 Adapter cache time: 0.05192896199878305 Engine time: 0.0725220171152614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.629982887010556,
    "estimated_duration": 3600.0586633182934,
    "input_throughput": 4201.807918890179,
    "output_throughput": 3707.4123641356773,
    "total_throughput": 7909.220283025857,
    "itl": 58.47652403650591,
    "ttft": 15031.475970609466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.873806612736836,
    "arrivals": 60841,
    "finished_requests": 60596,
    "scheduler_time": 43.10398694589757
}
#Debug simulation 
Total elapsed time: 4.630067624035291. Arrivals time: 0.15127358969766647 Scheduler time: 4.243751618079841 Scheduler overhead time: 0.07525410677772015 Adapter cache time: 0.05191050941357389 Engine time: 0.07328805286670104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.614494763023686,
    "estimated_duration": 3600.008793069886,
    "input_throughput": 4201.665570683611,
    "output_throughput": 3707.3767779935824,
    "total_throughput": 7909.042348677193,
    "itl": 58.503583388118145,
    "ttft": 15150.916518154221,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.629523127413323,
    "arrivals": 60841,
    "finished_requests": 60593,
    "scheduler_time": 43.10860252428531
}
#Debug simulation 
Total elapsed time: 4.614578326989431. Arrivals time: 0.15368741162819788 Scheduler time: 4.226299800269771 Scheduler overhead time: 0.07510377111611888 Adapter cache time: 0.05171220167540014 Engine time: 0.07330053573241457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.598123556992505,
    "estimated_duration": 3600.0233158677,
    "input_throughput": 4201.849175066816,
    "output_throughput": 3707.448766004185,
    "total_throughput": 7909.297941071001,
    "itl": 58.45452887458557,
    "ttft": 15029.456529184972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.307047013818233,
    "arrivals": 60841,
    "finished_requests": 60596,
    "scheduler_time": 43.09953631294533
}
#Debug simulation 
Total elapsed time: 4.598208901006728. Arrivals time: 0.15292317152488977 Scheduler time: 4.211522904282901 Scheduler overhead time: 0.0748544511734508 Adapter cache time: 0.051685423764865845 Engine time: 0.07280986109981313 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.632804666005541,
    "estimated_duration": 3600.0291782341747,
    "input_throughput": 4201.842332683459,
    "output_throughput": 3707.442728713298,
    "total_throughput": 7909.285061396757,
    "itl": 58.509016073816376,
    "ttft": 15033.031386352339,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.805593014284074,
    "arrivals": 60841,
    "finished_requests": 60596,
    "scheduler_time": 43.11010716959812
}
#Debug simulation 
Total elapsed time: 4.632891480985563. Arrivals time: 0.15681741363368928 Scheduler time: 4.24092364491662 Scheduler overhead time: 0.0753170742536895 Adapter cache time: 0.051749448000919074 Engine time: 0.07347905600909144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.310150568024255,
    "estimated_duration": 3600.0441779524913,
    "input_throughput": 4114.376176467985,
    "output_throughput": 3590.0015003011877,
    "total_throughput": 7704.3776767691725,
    "itl": 53.83355353897751,
    "ttft": 14172.585246159186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3268,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.00167394717197,
    "arrivals": 59397,
    "finished_requests": 59165,
    "scheduler_time": 40.41732391749211
}
#Debug simulation 
Total elapsed time: 4.31023543397896. Arrivals time: 0.14402155129937455 Scheduler time: 3.932542864466086 Scheduler overhead time: 0.07468719646567479 Adapter cache time: 0.05219299625605345 Engine time: 0.07184133399277925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.324919647013303,
    "estimated_duration": 3600.044860620909,
    "input_throughput": 4114.375396268076,
    "output_throughput": 3590.00081953727,
    "total_throughput": 7704.376215805345,
    "itl": 53.857187868499004,
    "ttft": 14172.637672292478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.651319967408325,
    "arrivals": 59397,
    "finished_requests": 59165,
    "scheduler_time": 40.42253179579719
}
#Debug simulation 
Total elapsed time: 4.325005148013588. Arrivals time: 0.14796733454568312 Scheduler time: 3.9395412112935446 Scheduler overhead time: 0.07628719310741872 Adapter cache time: 0.052980925887823105 Engine time: 0.07325027557089925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.363375205022749,
    "estimated_duration": 3600.022342501505,
    "input_throughput": 4114.401131662923,
    "output_throughput": 3590.0232749721044,
    "total_throughput": 7704.4244066350275,
    "itl": 53.858209746900165,
    "ttft": 14112.357454991858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.686182057763864,
    "arrivals": 59397,
    "finished_requests": 59165,
    "scheduler_time": 40.42259508690114
}
#Debug simulation 
Total elapsed time: 4.3634593290043995. Arrivals time: 0.14723974745720625 Scheduler time: 3.9810759635292925 Scheduler overhead time: 0.07473559671780095 Adapter cache time: 0.052478263911325485 Engine time: 0.0730446603265591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.352083728997968,
    "estimated_duration": 3600.049017205037,
    "input_throughput": 4114.370645847348,
    "output_throughput": 3589.9966745547,
    "total_throughput": 7704.367320402048,
    "itl": 53.84148836342652,
    "ttft": 14172.641207987097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3273,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.219137057443328,
    "arrivals": 59397,
    "finished_requests": 59165,
    "scheduler_time": 40.419113129688704
}
#Debug simulation 
Total elapsed time: 4.352171260979958. Arrivals time: 0.14795211161253974 Scheduler time: 3.9691800380824134 Scheduler overhead time: 0.07437088462756947 Adapter cache time: 0.052451399562414736 Engine time: 0.07320204039569944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.332929943979252,
    "estimated_duration": 3600.050524067216,
    "input_throughput": 4114.368923707763,
    "output_throughput": 3589.9951719007304,
    "total_throughput": 7704.364095608494,
    "itl": 53.86379594631565,
    "ttft": 14172.73625099147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3269,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.810279360785508,
    "arrivals": 59397,
    "finished_requests": 59165,
    "scheduler_time": 40.42399105013635
}
#Debug simulation 
Total elapsed time: 4.333008868969046. Arrivals time: 0.14607251522829756 Scheduler time: 3.9517106956336647 Scheduler overhead time: 0.07496572990203276 Adapter cache time: 0.05271585431182757 Engine time: 0.0727527875569649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.315088291012216,
    "estimated_duration": 3600.0219561382282,
    "input_throughput": 4114.401573230648,
    "output_throughput": 3590.023660262298,
    "total_throughput": 7704.425233492946,
    "itl": 53.82389053750409,
    "ttft": 14112.065356960808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.780454514625234,
    "arrivals": 59397,
    "finished_requests": 59165,
    "scheduler_time": 40.41524280110425
}
#Debug simulation 
Total elapsed time: 4.315167154010851. Arrivals time: 0.14569652354111895 Scheduler time: 3.933683678507805 Scheduler overhead time: 0.07500923186307773 Adapter cache time: 0.052364146104082465 Engine time: 0.07345895154867321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.352337894029915,
    "estimated_duration": 3600.049148593439,
    "input_throughput": 4114.370495688125,
    "output_throughput": 3589.9965435331765,
    "total_throughput": 7704.367039221302,
    "itl": 53.86807902223329,
    "ttft": 14172.9245329264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.959933464899029,
    "arrivals": 59397,
    "finished_requests": 59165,
    "scheduler_time": 40.42511084186177
}
#Debug simulation 
Total elapsed time: 4.352422425989062. Arrivals time: 0.1468129747081548 Scheduler time: 3.9707222696160898 Scheduler overhead time: 0.07438962371088564 Adapter cache time: 0.05229218362364918 Engine time: 0.07329016196308658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.26218003599206,
    "estimated_duration": 3600.0126324394264,
    "input_throughput": 4085.62094128915,
    "output_throughput": 3562.662220801472,
    "total_throughput": 7648.283162090622,
    "itl": 52.16446032084229,
    "ttft": 13155.577977636467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2116,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.475992066161896,
    "arrivals": 58689,
    "finished_requests": 58476,
    "scheduler_time": 39.63713254897879
}
#Debug simulation 
Total elapsed time: 4.262257751019206. Arrivals time: 0.14458208164433017 Scheduler time: 3.8847086665336974 Scheduler overhead time: 0.07526014663744718 Adapter cache time: 0.047801796230487525 Engine time: 0.0744402629788965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.277629352000076,
    "estimated_duration": 3600.0334751962578,
    "input_throughput": 4085.878951222284,
    "output_throughput": 3562.9610358833515,
    "total_throughput": 7648.839987105635,
    "itl": 51.99565027012688,
    "ttft": 13032.601823643188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.960804906198487,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.5976789425215
}
#Debug simulation 
Total elapsed time: 4.2777231319923885. Arrivals time: 0.14430621976498514 Scheduler time: 3.8996710084029473 Scheduler overhead time: 0.07631039171246812 Adapter cache time: 0.0476084005786106 Engine time: 0.07414784393040463 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.249904892989434,
    "estimated_duration": 3600.0278140785554,
    "input_throughput": 4085.885376350882,
    "output_throughput": 3562.9666387127836,
    "total_throughput": 7648.852015063665,
    "itl": 52.166600842521866,
    "ttft": 13033.139120322898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.925122403707313,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.639949675141345
}
#Debug simulation 
Total elapsed time: 4.249997068021912. Arrivals time: 0.1442310637794435 Scheduler time: 3.875381299352739 Scheduler overhead time: 0.07508650445379317 Adapter cache time: 0.04646653885720298 Engine time: 0.0735104171326384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.307567077979911,
    "estimated_duration": 3600.032770110225,
    "input_throughput": 4085.879751463938,
    "output_throughput": 3562.961733708683,
    "total_throughput": 7648.841485172621,
    "itl": 52.15721926248264,
    "ttft": 13032.995241690112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.6470794861202736,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.637674318001
}
#Debug simulation 
Total elapsed time: 4.307650421978906. Arrivals time: 0.14564484724542126 Scheduler time: 3.9286881735315546 Scheduler overhead time: 0.07568492495920509 Adapter cache time: 0.04666179732885212 Engine time: 0.07549769931938499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.307939767022617,
    "estimated_duration": 3599.9919731717437,
    "input_throughput": 4085.8593879143295,
    "output_throughput": 3562.9034996706905,
    "total_throughput": 7648.76288758502,
    "itl": 52.17062894351908,
    "ttft": 13094.416519928562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.029807508233795,
    "arrivals": 58689,
    "finished_requests": 58477,
    "scheduler_time": 39.64037878396648
}
#Debug simulation 
Total elapsed time: 4.3080231780186296. Arrivals time: 0.14437435957370326 Scheduler time: 3.931855816685129 Scheduler overhead time: 0.07590614893706515 Adapter cache time: 0.0466730137122795 Engine time: 0.07381805160548538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.285272181965411,
    "estimated_duration": 3600.039632601522,
    "input_throughput": 4085.871962851285,
    "output_throughput": 3562.954941896263,
    "total_throughput": 7648.826904747548,
    "itl": 51.97182144810301,
    "ttft": 13032.448577239247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.392727530500661,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.59202719698622
}
#Debug simulation 
Total elapsed time: 4.285360509995371. Arrivals time: 0.1458657297771424 Scheduler time: 3.9061686450149864 Scheduler overhead time: 0.07603655447019264 Adapter cache time: 0.047407461039256305 Engine time: 0.07418778719147667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.2969074040302075,
    "estimated_duration": 3600.0209757794255,
    "input_throughput": 4085.8931375574416,
    "output_throughput": 3562.97340662659,
    "total_throughput": 7648.866544184032,
    "itl": 52.169661643062696,
    "ttft": 13033.054141205754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2129,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.10933337111001,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.64038517475871
}
#Debug simulation 
Total elapsed time: 4.296986253000796. Arrivals time: 0.14599304919829592 Scheduler time: 3.918526629859116 Scheduler overhead time: 0.07565374177647755 Adapter cache time: 0.04687915672548115 Engine time: 0.07441852812189609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.276985311007593,
    "estimated_duration": 3599.2686620909917,
    "input_throughput": 4038.171463298385,
    "output_throughput": 3562.990763948645,
    "total_throughput": 7601.1622272470295,
    "itl": 50.98075263594243,
    "ttft": 12053.857241619708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1296,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9663921161369506,
    "arrivals": 58348,
    "finished_requests": 58154,
    "scheduler_time": 39.32452019836271
}
#Debug simulation 
Total elapsed time: 4.277068976021837. Arrivals time: 0.14416832657298073 Scheduler time: 3.900835890788585 Scheduler overhead time: 0.07665857148822397 Adapter cache time: 0.04471448319964111 Engine time: 0.07452569651650265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.246049332024995,
    "estimated_duration": 3599.26545332881,
    "input_throughput": 4038.175063347351,
    "output_throughput": 3562.9939403717694,
    "total_throughput": 7601.16900371912,
    "itl": 50.9883735485201,
    "ttft": 12053.934987097298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1293,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.1905597141501305,
    "arrivals": 58348,
    "finished_requests": 58154,
    "scheduler_time": 39.32645020396988
}
#Debug simulation 
Total elapsed time: 4.24613327201223. Arrivals time: 0.14368646108778194 Scheduler time: 3.8707427980261855 Scheduler overhead time: 0.07639739330625162 Adapter cache time: 0.04463614447740838 Engine time: 0.07479187095304951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.262118017999455,
    "estimated_duration": 3599.2728822317854,
    "input_throughput": 4038.166728549817,
    "output_throughput": 3562.986586348568,
    "total_throughput": 7601.153314898385,
    "itl": 50.98957357153807,
    "ttft": 12053.893459094545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1298,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.218936471342981,
    "arrivals": 58348,
    "finished_requests": 58154,
    "scheduler_time": 39.326716424173554
}
#Debug simulation 
Total elapsed time: 4.262204366037622. Arrivals time: 0.14427046908531338 Scheduler time: 3.885829247883521 Scheduler overhead time: 0.07641873089596629 Adapter cache time: 0.04483768483623862 Engine time: 0.07500518130837008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.3284472720115446,
    "estimated_duration": 3599.281065056825,
    "input_throughput": 4038.157547935349,
    "output_throughput": 3562.9784860376094,
    "total_throughput": 7601.136033972958,
    "itl": 50.98361172717578,
    "ttft": 12053.867788732116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.04290797500633,
    "arrivals": 58348,
    "finished_requests": 58154,
    "scheduler_time": 39.32529015788156
}
#Debug simulation 
Total elapsed time: 4.328533340012655. Arrivals time: 0.14510784402955323 Scheduler time: 3.9507370779756457 Scheduler overhead time: 0.07654884830117226 Adapter cache time: 0.04498862539185211 Engine time: 0.0749723135959357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.258066975977272,
    "estimated_duration": 3599.2872367125206,
    "input_throughput": 4038.150623753868,
    "output_throughput": 3562.9723766401034,
    "total_throughput": 7601.123000393971,
    "itl": 50.99078318852977,
    "ttft": 12053.788925704814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1294,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.251982320807862,
    "arrivals": 58348,
    "finished_requests": 58154,
    "scheduler_time": 39.32711987727386
}
#Debug simulation 
Total elapsed time: 4.258154058945365. Arrivals time: 0.14526278706034645 Scheduler time: 3.8802199421916157 Scheduler overhead time: 0.07669777743285522 Adapter cache time: 0.04476709588197991 Engine time: 0.07511223835172132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.247561380965635,
    "estimated_duration": 3599.2847696445156,
    "input_throughput": 4038.1533916349445,
    "output_throughput": 3562.9748188184017,
    "total_throughput": 7601.128210453346,
    "itl": 50.97799393386408,
    "ttft": 12053.87311548851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.8721151318982168,
    "arrivals": 58348,
    "finished_requests": 58154,
    "scheduler_time": 39.32401827230768
}
#Debug simulation 
Total elapsed time: 4.247650092991535. Arrivals time: 0.1431589667336084 Scheduler time: 3.8725559872109443 Scheduler overhead time: 0.07644275116035715 Adapter cache time: 0.044446738029364496 Engine time: 0.07525746349710971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_96_slots_64_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.239341977983713,
    "estimated_duration": 3599.285389555592,
    "input_throughput": 4038.152696136882,
    "output_throughput": 3562.974205161157,
    "total_throughput": 7601.126901298039,
    "itl": 50.99188285411429,
    "ttft": 12054.013092772931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.309442927502123,
    "arrivals": 58348,
    "finished_requests": 58154,
    "scheduler_time": 39.327498372828146
}
#Debug simulation 
Total elapsed time: 4.239429646986537. Arrivals time: 0.1439081752905622 Scheduler time: 3.863535616255831 Scheduler overhead time: 0.07646796276094392 Adapter cache time: 0.04464712901972234 Engine time: 0.0748668996966444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.071175145043526,
    "estimated_duration": 3600.0223467209253,
    "input_throughput": 3799.8028019075596,
    "output_throughput": 3334.922354283567,
    "total_throughput": 7134.725156191127,
    "itl": 46.93281288212363,
    "ttft": 11068.1318656462,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.560241701099098,
    "arrivals": 55037,
    "finished_requests": 54869,
    "scheduler_time": 34.911816143528
}
#Debug simulation 
Total elapsed time: 4.071259368036408. Arrivals time: 0.14292612683493644 Scheduler time: 3.665477203729097 Scheduler overhead time: 0.08204176236176863 Adapter cache time: 0.06277324602706358 Engine time: 0.07960974232992157 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.02918898902135,
    "estimated_duration": 3600.0115962566715,
    "input_throughput": 3799.8141489943955,
    "output_throughput": 3334.932313130254,
    "total_throughput": 7134.74646212465,
    "itl": 46.957381829778626,
    "ttft": 11068.127360557537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.393986345353216,
    "arrivals": 55037,
    "finished_requests": 54869,
    "scheduler_time": 34.91906164287898
}
#Debug simulation 
Total elapsed time: 4.029275981010869. Arrivals time: 0.13716104766353965 Scheduler time: 3.6313026829157025 Scheduler overhead time: 0.08160792459966615 Adapter cache time: 0.062489268952049315 Engine time: 0.07849710941081867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.041296186973341,
    "estimated_duration": 3600.00694620389,
    "input_throughput": 3799.8190571339123,
    "output_throughput": 3334.936620791742,
    "total_throughput": 7134.755677925655,
    "itl": 46.97239801494531,
    "ttft": 11068.162324599429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.423781755509745,
    "arrivals": 55037,
    "finished_requests": 54869,
    "scheduler_time": 34.92304824698676
}
#Debug simulation 
Total elapsed time: 4.041377058019862. Arrivals time: 0.13859939464600757 Scheduler time: 3.6418818634701893 Scheduler overhead time: 0.08090127626201138 Adapter cache time: 0.06232969096163288 Engine time: 0.07946269604144618 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.044350306037813,
    "estimated_duration": 3600.030967070191,
    "input_throughput": 3799.7937032004675,
    "output_throughput": 3334.914368742406,
    "total_throughput": 7134.708071942873,
    "itl": 46.954115115912934,
    "ttft": 11068.1967247392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.835027949726962,
    "arrivals": 55037,
    "finished_requests": 54869,
    "scheduler_time": 34.91811178152086
}
#Debug simulation 
Total elapsed time: 4.044434208015446. Arrivals time: 0.13885622040834278 Scheduler time: 3.6430469162296504 Scheduler overhead time: 0.08200582885183394 Adapter cache time: 0.06271859252592549 Engine time: 0.07945429510436952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_96_slots_64_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.062163746042643,
    "estimated_duration": 3599.995362790242,
    "input_throughput": 3799.831283504085,
    "output_throughput": 3334.9473513473336,
    "total_throughput": 7134.778634851419,
    "itl": 46.977813260375136,
    "ttft": 11068.215143412057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.595687181538898,
    "arrivals": 55037,
    "finished_requests": 54869,
    "scheduler_time": 34.924493903332355
}
#Debug simulation 
Total elapsed time: 4.0622509640525095. Arrivals time: 0.14005471189739183 Scheduler time: 3.661182237556204 Scheduler overhead time: 0.08100211940472946 Adapter cache time: 0.0625298271770589 Engine time: 0.07908137183403596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_96_slots_64_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.053922662977129,
    "estimated_duration": 3600.018998971498,
    "input_throughput": 3799.8063354410374,
    "output_throughput": 3334.9254555128673,
    "total_throughput": 7134.731790953904,
    "itl": 46.92405162817802,
    "ttft": 11068.12103133916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4103,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.268176359984494,
    "arrivals": 55037,
    "finished_requests": 54869,
    "scheduler_time": 34.909242595154716
}
#Debug simulation 
Total elapsed time: 4.054008056002203. Arrivals time: 0.1375224141520448 Scheduler time: 3.6536065102554858 Scheduler overhead time: 0.08158639475004748 Adapter cache time: 0.06328432832378894 Engine time: 0.07946317899040878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_96_slots_64_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.060058127040975,
    "estimated_duration": 3600.041303399486,
    "input_throughput": 3799.7827933481462,
    "output_throughput": 3334.904793637517,
    "total_throughput": 7134.687586985663,
    "itl": 46.968954017673944,
    "ttft": 11068.180320028998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.769478914364274,
    "arrivals": 55037,
    "finished_requests": 54869,
    "scheduler_time": 34.92257985238761
}
#Debug simulation 
Total elapsed time: 4.06014066102216. Arrivals time: 0.13771096686832607 Scheduler time: 3.661291411262937 Scheduler overhead time: 0.08148521208204329 Adapter cache time: 0.06264167663175613 Engine time: 0.07859843119513243 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_96_slots_64_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.973149606026709,
    "estimated_duration": 3600.007476621867,
    "input_throughput": 3698.9570400824746,
    "output_throughput": 3239.052439674917,
    "total_throughput": 6938.009479757391,
    "itl": 43.098033278390574,
    "ttft": 8149.550150222762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.131715935629535,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.2402610086351
}
#Debug simulation 
Total elapsed time: 3.9732324319775216. Arrivals time: 0.1390124352183193 Scheduler time: 3.563479759322945 Scheduler overhead time: 0.08915111649548635 Adapter cache time: 0.05660082784015685 Engine time: 0.08387222437886521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_96_slots_64_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9617713429615833,
    "estimated_duration": 3600.0389171172637,
    "input_throughput": 3698.924735697864,
    "output_throughput": 3239.024151810351,
    "total_throughput": 6937.948887508215,
    "itl": 43.111429179275234,
    "ttft": 8216.635078320303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2657,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.668594537831142,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.24511670306213
}
#Debug simulation 
Total elapsed time: 3.9618534379987977. Arrivals time: 0.1349275617976673 Scheduler time: 3.557504311960656 Scheduler overhead time: 0.08709223265759647 Adapter cache time: 0.05659149884013459 Engine time: 0.08446117717539892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_96_slots_64_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.955125976994168,
    "estimated_duration": 3600.018444274078,
    "input_throughput": 3698.9457710084444,
    "output_throughput": 3239.042571725294,
    "total_throughput": 6937.988342733738,
    "itl": 43.11183007291113,
    "ttft": 8216.760155543456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.687950155325082,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.245014652016245
}
#Debug simulation 
Total elapsed time: 3.955211420019623. Arrivals time: 0.13567508204141632 Scheduler time: 3.551305016328115 Scheduler overhead time: 0.08733848296105862 Adapter cache time: 0.056191105395555496 Engine time: 0.083847162197344 
