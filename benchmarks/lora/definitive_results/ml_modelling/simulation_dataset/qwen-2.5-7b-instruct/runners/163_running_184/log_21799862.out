INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 99.72761340299621,
    "estimated_duration": 3600.1214892403127,
    "input_throughput": 7372.4031478728575,
    "output_throughput": 6533.5817333663035,
    "total_throughput": 13905.984881239161,
    "itl": 97.18565717199074,
    "ttft": 2007620.444668364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9128048399580015,
    "arrivals": 1404624,
    "finished_requests": 107299,
    "scheduler_time": 313.66047374903036
}
#Debug simulation 
Total elapsed time: 99.72782920813188. Arrivals time: 0.5527484361082315 Scheduler time: 98.95484809437767 Scheduler overhead time: 0.08427548687905073 Adapter cache time: 0.019691271241754293 Engine time: 0.08219745056703687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 101.05763095291331,
    "estimated_duration": 3600.0013352695537,
    "input_throughput": 7238.183426409458,
    "output_throughput": 6443.250665700989,
    "total_throughput": 13681.434092110447,
    "itl": 95.21212885977377,
    "ttft": 2003118.9079659749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.937355142890016,
    "arrivals": 1404624,
    "finished_requests": 105268,
    "scheduler_time": 321.2302676643959
}
#Debug simulation 
Total elapsed time: 101.05782587919384. Arrivals time: 0.5480240024626255 Scheduler time: 100.28544319421053 Scheduler overhead time: 0.08613376598805189 Adapter cache time: 0.01966139441356063 Engine time: 0.08402379602193832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 101.03827062062919,
    "estimated_duration": 3600.0050443930245,
    "input_throughput": 7238.17596883212,
    "output_throughput": 6443.244027151326,
    "total_throughput": 13681.419995983446,
    "itl": 95.21273645826328,
    "ttft": 2003120.494178495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.940380170121801,
    "arrivals": 1404624,
    "finished_requests": 105268,
    "scheduler_time": 321.23065164486604
}
#Debug simulation 
Total elapsed time: 101.03843770176172. Arrivals time: 0.5391500215046108 Scheduler time: 100.27612094162032 Scheduler overhead time: 0.08643988473340869 Adapter cache time: 0.01965782605111599 Engine time: 0.08261277293786407 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 101.32170516392216,
    "estimated_duration": 3600.0204777522968,
    "input_throughput": 7238.255493554706,
    "output_throughput": 6443.511958710608,
    "total_throughput": 13681.767452265314,
    "itl": 95.21012031418309,
    "ttft": 2003085.8468122974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8544102932466082,
    "arrivals": 1404624,
    "finished_requests": 105270,
    "scheduler_time": 321.2464479047105
}
#Debug simulation 
Total elapsed time: 101.32186384871602. Arrivals time: 0.6368149844929576 Scheduler time: 100.45941034518182 Scheduler overhead time: 0.08653238182887435 Adapter cache time: 0.019983496982604265 Engine time: 0.08420492196455598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 101.21329090325162,
    "estimated_duration": 3600.030223024017,
    "input_throughput": 7238.125344989961,
    "output_throughput": 6443.198963067499,
    "total_throughput": 13681.32430805746,
    "itl": 95.21311580703883,
    "ttft": 2003128.9265214885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9659081887640095,
    "arrivals": 1404624,
    "finished_requests": 105268,
    "scheduler_time": 321.2307024115603
}
#Debug simulation 
Total elapsed time: 101.21345042716712. Arrivals time: 0.5445131058804691 Scheduler time: 100.44641417870298 Scheduler overhead time: 0.08575125131756067 Adapter cache time: 0.01977038849145174 Engine time: 0.08253741916269064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 100.16034425608814,
    "estimated_duration": 3600.0768592208988,
    "input_throughput": 7372.494543281478,
    "output_throughput": 6533.662729936934,
    "total_throughput": 13906.157273218412,
    "itl": 97.1851732764117,
    "ttft": 2007604.3806669144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 625,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8687814343138303,
    "arrivals": 1404624,
    "finished_requests": 107299,
    "scheduler_time": 313.65996717373616
}
#Debug simulation 
Total elapsed time: 100.16050989413634. Arrivals time: 0.559568740427494 Scheduler time: 99.3785071442835 Scheduler overhead time: 0.0857162824831903 Adapter cache time: 0.01969752972945571 Engine time: 0.08279301086440682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.05_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  3.2 ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 540, 34560, 34560, 4320, 4320, 4320, 4320, 540, 4320, 540, 4320, 540, 4320, 4320, 34560, 4320, 34560, 34560, 540, 34560, 4320, 4320, 34560, 34560, 4320, 540, 540, 4320, 34560, 34560, 4320, 4320, 540, 540, 4320, 34560, 34560, 540, 34560, 4320, 540, 4320, 34560, 540, 4320, 34560, 34560, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 34560, 4320, 34560, 34560, 540, 34560, 540, 34560, 4320, 540, 540, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 540, 4320, 4320, 540, 34560, 4320, 34560, 34560, 4320, 540, 4320, 4320, 4320, 540, 34560, 4320, 34560, 540, 34560, 540, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 4320, 540, 4320, 540, 34560, 540, 540, 540, 540, 34560, 4320, 4320, 34560, 4320, 4320, 540, 4320, 34560, 4320, 540, 540, 4320, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 4320, 34560, 4320, 4320, 4320, 540, 34560, 540, 34560, 4320, 540, 4320, 540, 540, 4320, 540, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 540, 540, 34560, 4320, 34560, 4320, 34560, 4320, 540, 4320, 540, 540, 540, 34560, 34560, 4320, 4320, 540, 540, 4320, 540, 34560, 540, 540, 4320, 540, 34560, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 540, 4320, 34560, 4320, 4320, 34560, 4320, 540, 4320, 540, 34560, 4320, 4320, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 4320, 540, 4320, 540, 4320, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 4320, 4320, 34560, 540, 34560, 540, 540, 540, 34560, 4320, 34560, 34560, 540, 4320, 4320, 4320, 540, 4320, 540, 4320, 4320, 34560, 540, 540, 4320, 540, 4320, 4320, 540, 34560, 34560, 34560, 540, 4320, 4320, 4320, 4320, 540, 4320, 540, 34560, 540, 540, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 4320, 34560, 4320, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 4217400 . Total input tokens: 938962823 . Total output tokens: 843412388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 101.23310316260904,
    "estimated_duration": 3600.02075324065,
    "input_throughput": 7238.144384735479,
    "output_throughput": 6443.215911774895,
    "total_throughput": 13681.360296510375,
    "itl": 95.21352302329528,
    "ttft": 2003137.7429544216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9909331922605582,
    "arrivals": 1404624,
    "finished_requests": 105268,
    "scheduler_time": 321.2253101687764
}
#Debug simulation 
Total elapsed time: 101.23326500458643. Arrivals time: 0.6337077058851719 Scheduler time: 100.37494735373184 Scheduler overhead time: 0.0868565016426146 Adapter cache time: 0.019808736629784107 Engine time: 0.08340855408459902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 100.29794056992978,
    "estimated_duration": 3600.113939401099,
    "input_throughput": 7302.2344410503065,
    "output_throughput": 6427.898224757208,
    "total_throughput": 13730.132665807514,
    "itl": 94.01683056897492,
    "ttft": 2004400.7378603164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7659014282492242,
    "arrivals": 1395198,
    "finished_requests": 106531,
    "scheduler_time": 319.8570647876513
}
#Debug simulation 
Total elapsed time: 100.29810895211995. Arrivals time: 0.9642993756569922 Scheduler time: 99.11057254392654 Scheduler overhead time: 0.08536104019731283 Adapter cache time: 0.019151076674461365 Engine time: 0.08425860898569226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 100.48539175931364,
    "estimated_duration": 3600.1001794004624,
    "input_throughput": 7301.6393128197915,
    "output_throughput": 6427.522526290793,
    "total_throughput": 13729.161839110586,
    "itl": 94.01791680997134,
    "ttft": 2004421.64632052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8829768130765356,
    "arrivals": 1395198,
    "finished_requests": 106523,
    "scheduler_time": 319.8482677873385
}
#Debug simulation 
Total elapsed time: 100.4855513270013. Arrivals time: 0.6431273533962667 Scheduler time: 99.62100842781365 Scheduler overhead time: 0.08528800588101149 Adapter cache time: 0.019346616696566343 Engine time: 0.0822984459809959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.75510637834668,
    "estimated_duration": 3600.103301146084,
    "input_throughput": 7301.632981373538,
    "output_throughput": 6427.516952814528,
    "total_throughput": 13729.149934188066,
    "itl": 94.01795087518309,
    "ttft": 2004422.8715641873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8862879086285946,
    "arrivals": 1395198,
    "finished_requests": 106523,
    "scheduler_time": 319.8482785145436
}
#Debug simulation 
Total elapsed time: 99.75527528906241. Arrivals time: 0.5755924172699451 Scheduler time: 98.95528094796464 Scheduler overhead time: 0.08657315792515874 Adapter cache time: 0.019613621290773153 Engine time: 0.0836216015741229 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 99.41354205273092,
    "estimated_duration": 3600.019684708793,
    "input_throughput": 7301.8025739285185,
    "output_throughput": 6427.666242572721,
    "total_throughput": 13729.46881650124,
    "itl": 94.01672793364406,
    "ttft": 2004392.2118458233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8037093212990924,
    "arrivals": 1395198,
    "finished_requests": 106523,
    "scheduler_time": 319.84794093464393
}
#Debug simulation 
Total elapsed time: 99.41370602371171. Arrivals time: 0.5702164433896542 Scheduler time: 98.61999861802906 Scheduler overhead time: 0.08632902195677161 Adapter cache time: 0.0194989163428545 Engine time: 0.08335564704611897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 100.00797260692343,
    "estimated_duration": 3600.1277104926316,
    "input_throughput": 7301.583475327048,
    "output_throughput": 6427.473373391419,
    "total_throughput": 13729.056848718466,
    "itl": 94.01830743884345,
    "ttft": 2004431.650302669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9106841431930701,
    "arrivals": 1395198,
    "finished_requests": 106523,
    "scheduler_time": 319.8483916651277
}
#Debug simulation 
Total elapsed time: 100.00813846383244. Arrivals time: 0.5721644391305745 Scheduler time: 99.21196582587436 Scheduler overhead time: 0.08614953607320786 Adapter cache time: 0.019528985023498535 Engine time: 0.08367035305127501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.6607177760452,
    "estimated_duration": 3600.0196183210014,
    "input_throughput": 7211.388201297611,
    "output_throughput": 6374.037486690698,
    "total_throughput": 13585.425687988309,
    "itl": 93.25927870572849,
    "ttft": 2004596.248161207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 537,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6056570083624482,
    "arrivals": 1395198,
    "finished_requests": 105069,
    "scheduler_time": 325.15763435348487
}
#Debug simulation 
Total elapsed time: 105.66088361805305. Arrivals time: 0.5584824047982693 Scheduler time: 104.87805035477504 Scheduler overhead time: 0.08685316890478134 Adapter cache time: 0.019385465886443853 Engine time: 0.08351553697139025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.025_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   3.2  ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 270, 34560, 34560, 4320, 4320, 4320, 4320, 270, 4320, 270, 4320, 270, 4320, 4320, 34560, 4320, 34560, 34560, 270, 34560, 4320, 4320, 34560, 34560, 4320, 270, 270, 4320, 34560, 34560, 4320, 4320, 270, 270, 4320, 34560, 34560, 270, 34560, 4320, 270, 4320, 34560, 270, 4320, 34560, 34560, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 34560, 4320, 34560, 34560, 270, 34560, 270, 34560, 4320, 270, 270, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 270, 4320, 4320, 270, 34560, 4320, 34560, 34560, 4320, 270, 4320, 4320, 4320, 270, 34560, 4320, 34560, 270, 34560, 270, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 4320, 270, 4320, 270, 34560, 270, 270, 270, 270, 34560, 4320, 4320, 34560, 4320, 4320, 270, 4320, 34560, 4320, 270, 270, 4320, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 4320, 34560, 4320, 4320, 4320, 270, 34560, 270, 34560, 4320, 270, 4320, 270, 270, 4320, 270, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 270, 270, 34560, 4320, 34560, 4320, 34560, 4320, 270, 4320, 270, 270, 270, 34560, 34560, 4320, 4320, 270, 270, 4320, 270, 34560, 270, 270, 4320, 270, 34560, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 270, 4320, 34560, 4320, 4320, 34560, 4320, 270, 4320, 270, 34560, 4320, 4320, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 4320, 270, 4320, 270, 4320, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 4320, 4320, 34560, 270, 34560, 270, 270, 270, 34560, 4320, 34560, 34560, 270, 4320, 4320, 4320, 270, 4320, 270, 4320, 4320, 34560, 270, 270, 4320, 270, 4320, 4320, 270, 34560, 34560, 34560, 270, 4320, 4320, 4320, 4320, 270, 4320, 270, 34560, 270, 270, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 4320, 34560, 4320, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 4188780 . Total input tokens: 932625725 . Total output tokens: 837627795
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.68453525658697,
    "estimated_duration": 3600.0207640099434,
    "input_throughput": 7301.735385192738,
    "output_throughput": 6427.53876070035,
    "total_throughput": 13729.274145893089,
    "itl": 94.0184497058938,
    "ttft": 2004382.4838740523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 577,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9348288701847154,
    "arrivals": 1395198,
    "finished_requests": 106522,
    "scheduler_time": 319.8392388020883
}
#Debug simulation 
Total elapsed time: 99.68469712883234. Arrivals time: 0.5628886753693223 Scheduler time: 98.89816583460197 Scheduler overhead time: 0.08579293917864561 Adapter cache time: 0.01924774283543229 Engine time: 0.08418450644239783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.96827332675457,
    "estimated_duration": 3600.0282853737867,
    "input_throughput": 7556.646738172899,
    "output_throughput": 6670.9231417903975,
    "total_throughput": 14227.569879963297,
    "itl": 98.04689524112831,
    "ttft": 2000882.9938391324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7199941120902313,
    "arrivals": 1390337,
    "finished_requests": 109963,
    "scheduler_time": 305.73702327552394
}
#Debug simulation 
Total elapsed time: 103.96844323072582. Arrivals time: 0.5874686567112803 Scheduler time: 103.16330127418041 Scheduler overhead time: 0.08411968406289816 Adapter cache time: 0.019029782619327307 Engine time: 0.08147936593741179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.26640859711915,
    "estimated_duration": 3600.037910252943,
    "input_throughput": 7598.269985461922,
    "output_throughput": 6704.866615780735,
    "total_throughput": 14303.136601242657,
    "itl": 98.8906145489082,
    "ttft": 1996298.0256543541,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8292857908341167,
    "arrivals": 1390337,
    "finished_requests": 110474,
    "scheduler_time": 303.62603238178485
}
#Debug simulation 
Total elapsed time: 107.26657845778391. Arrivals time: 0.5875939843244851 Scheduler time: 106.45954463584349 Scheduler overhead time: 0.08487984025850892 Adapter cache time: 0.01921712141484022 Engine time: 0.08186286920681596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 106.95734420325607,
    "estimated_duration": 3600.0411683303346,
    "input_throughput": 7598.263108942879,
    "output_throughput": 6704.8605478017,
    "total_throughput": 14303.12365674458,
    "itl": 98.89068006161455,
    "ttft": 1996299.4972431138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8321873557381445,
    "arrivals": 1390337,
    "finished_requests": 110474,
    "scheduler_time": 303.62608877850425
}
#Debug simulation 
Total elapsed time: 106.95751869631931. Arrivals time: 0.5854408359155059 Scheduler time: 106.15279705636203 Scheduler overhead time: 0.085189588367939 Adapter cache time: 0.018932251259684563 Engine time: 0.08171232044696808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 104.05040994333103,
    "estimated_duration": 3600.024493896301,
    "input_throughput": 7396.751062429586,
    "output_throughput": 6535.8896973876435,
    "total_throughput": 13932.64075981723,
    "itl": 95.74211586705901,
    "ttft": 1992953.1351188992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7290879469923592,
    "arrivals": 1390337,
    "finished_requests": 107634,
    "scheduler_time": 313.54715011751745
}
#Debug simulation 
Total elapsed time: 104.05057844007388. Arrivals time: 0.5642762817442417 Scheduler time: 103.26430851174518 Scheduler overhead time: 0.08536393055692315 Adapter cache time: 0.01950747473165393 Engine time: 0.08281811885535717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 106.92680274881423,
    "estimated_duration": 3600.0650801295164,
    "input_throughput": 7598.2126409270095,
    "output_throughput": 6704.816013807066,
    "total_throughput": 14303.028654734077,
    "itl": 98.89105286257512,
    "ttft": 1996308.5163753484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.855954821370546,
    "arrivals": 1390337,
    "finished_requests": 110474,
    "scheduler_time": 303.6262331120759
}
#Debug simulation 
Total elapsed time: 106.92697967682034. Arrivals time: 0.5939927417784929 Scheduler time: 106.11382899712771 Scheduler overhead time: 0.08402294339612126 Adapter cache time: 0.019298069179058075 Engine time: 0.08192157838493586 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.47070667287335,
    "estimated_duration": 3600.114883356955,
    "input_throughput": 7556.767459218488,
    "output_throughput": 6671.033780345821,
    "total_throughput": 14227.801239564309,
    "itl": 98.04712628714144,
    "ttft": 2000942.3563997534,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.680408265735,
    "arrivals": 1390337,
    "finished_requests": 109966,
    "scheduler_time": 305.74577049445185
}
#Debug simulation 
Total elapsed time: 104.4708765600808. Arrivals time: 0.5819066190160811 Scheduler time: 103.67058482812718 Scheduler overhead time: 0.08445801073685288 Adapter cache time: 0.019208692014217377 Engine time: 0.08101437194272876 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.0125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    3.2   ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 135, 34560, 34560, 4320, 4320, 4320, 4320, 135, 4320, 135, 4320, 135, 4320, 4320, 34560, 4320, 34560, 34560, 135, 34560, 4320, 4320, 34560, 34560, 4320, 135, 135, 4320, 34560, 34560, 4320, 4320, 135, 135, 4320, 34560, 34560, 135, 34560, 4320, 135, 4320, 34560, 135, 4320, 34560, 34560, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 34560, 4320, 34560, 34560, 135, 34560, 135, 34560, 4320, 135, 135, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 135, 4320, 4320, 135, 34560, 4320, 34560, 34560, 4320, 135, 4320, 4320, 4320, 135, 34560, 4320, 34560, 135, 34560, 135, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 4320, 135, 4320, 135, 34560, 135, 135, 135, 135, 34560, 4320, 4320, 34560, 4320, 4320, 135, 4320, 34560, 4320, 135, 135, 4320, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 4320, 34560, 4320, 4320, 4320, 135, 34560, 135, 34560, 4320, 135, 4320, 135, 135, 4320, 135, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 135, 135, 34560, 4320, 34560, 4320, 34560, 4320, 135, 4320, 135, 135, 135, 34560, 34560, 4320, 4320, 135, 135, 4320, 135, 34560, 135, 135, 4320, 135, 34560, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 135, 4320, 34560, 4320, 4320, 34560, 4320, 135, 4320, 135, 34560, 4320, 4320, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 4320, 135, 4320, 135, 4320, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 4320, 4320, 34560, 135, 34560, 135, 135, 135, 34560, 4320, 34560, 34560, 135, 4320, 4320, 4320, 135, 4320, 135, 4320, 4320, 34560, 135, 135, 4320, 135, 4320, 4320, 135, 34560, 34560, 34560, 135, 4320, 4320, 4320, 4320, 135, 4320, 135, 34560, 135, 135, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 4320, 34560, 4320, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 4174470 . Total input tokens: 929407444 . Total output tokens: 834778952
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.05612774798647,
    "estimated_duration": 3600.0888800254247,
    "input_throughput": 7598.162409758845,
    "output_throughput": 6704.77168881162,
    "total_throughput": 14302.934098570464,
    "itl": 98.89146045943662,
    "ttft": 1996317.3270479352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8798480407893619,
    "arrivals": 1390337,
    "finished_requests": 110474,
    "scheduler_time": 303.6263398657493
}
#Debug simulation 
Total elapsed time: 107.05629719281569. Arrivals time: 0.5969570861198008 Scheduler time: 106.23948889831081 Scheduler overhead time: 0.08485994022339582 Adapter cache time: 0.019220092799514532 Engine time: 0.08211905835196376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.67026004893705,
    "estimated_duration": 3600.0860693338695,
    "input_throughput": 7556.872940272193,
    "output_throughput": 6699.551492796053,
    "total_throughput": 14256.424433068245,
    "itl": 97.78695729659164,
    "ttft": 2005585.0137551078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 530,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6220585042843798,
    "arrivals": 1387991,
    "finished_requests": 110414,
    "scheduler_time": 304.19195935750827
}
#Debug simulation 
Total elapsed time: 103.67043427191675. Arrivals time: 0.5878699254244566 Scheduler time: 102.86473218211904 Scheduler overhead time: 0.08393767476081848 Adapter cache time: 0.018945328425616026 Engine time: 0.08137095207348466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.0632947939448,
    "estimated_duration": 3600.0900941080736,
    "input_throughput": 7522.713957721024,
    "output_throughput": 6672.6549536398525,
    "total_throughput": 14195.368911360876,
    "itl": 97.7707300678258,
    "ttft": 2010776.3262351842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7300567065971035,
    "arrivals": 1387991,
    "finished_requests": 109926,
    "scheduler_time": 305.5696041905013
}
#Debug simulation 
Total elapsed time: 103.0634590969421. Arrivals time: 0.5924796955659986 Scheduler time: 102.25323136383668 Scheduler overhead time: 0.08309057215228677 Adapter cache time: 0.01874439511448145 Engine time: 0.08246001368388534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.9640315589495,
    "estimated_duration": 3600.092363013804,
    "input_throughput": 7522.709216640216,
    "output_throughput": 6672.650748296341,
    "total_throughput": 14195.359964936557,
    "itl": 97.7707838373416,
    "ttft": 2010777.0805711625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7324423115141796,
    "arrivals": 1387991,
    "finished_requests": 109926,
    "scheduler_time": 305.56958752987
}
#Debug simulation 
Total elapsed time: 102.9641980449669. Arrivals time: 0.5816285107284784 Scheduler time: 102.16417546803132 Scheduler overhead time: 0.08433995209634304 Adapter cache time: 0.018753114622086287 Engine time: 0.08222276577726007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 101.9927598410286,
    "estimated_duration": 3600.1068048620286,
    "input_throughput": 7452.547508803211,
    "output_throughput": 6603.82768863746,
    "total_throughput": 14056.375197440671,
    "itl": 96.07544163658658,
    "ttft": 2008903.113852778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 525,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6441407527797784,
    "arrivals": 1387991,
    "finished_requests": 108852,
    "scheduler_time": 309.60857258433884
}
#Debug simulation 
Total elapsed time: 101.99293033080176. Arrivals time: 0.581711117643863 Scheduler time: 101.19204016588628 Scheduler overhead time: 0.08442492876201868 Adapter cache time: 0.019061177968978882 Engine time: 0.08256466127932072 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 102.97308554733172,
    "estimated_duration": 3600.1156045694647,
    "input_throughput": 7522.660651681704,
    "output_throughput": 6672.607671128603,
    "total_throughput": 14195.268322810307,
    "itl": 97.77121493761274,
    "ttft": 2010786.1884892029,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.754952239282433,
    "arrivals": 1387991,
    "finished_requests": 109926,
    "scheduler_time": 305.56971892630247
}
#Debug simulation 
Total elapsed time: 102.97325542615727. Arrivals time: 0.5877730087377131 Scheduler time: 102.16667053243145 Scheduler overhead time: 0.08414369309321046 Adapter cache time: 0.01873517781496048 Engine time: 0.08212241716682911 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.16358747705817,
    "estimated_duration": 3600.04842360196,
    "input_throughput": 7556.951962546148,
    "output_throughput": 6699.621550053549,
    "total_throughput": 14256.573512599698,
    "itl": 97.78628732425173,
    "ttft": 2005570.5247478667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 530,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5847266562981337,
    "arrivals": 1387991,
    "finished_requests": 110414,
    "scheduler_time": 304.19174551208005
}
#Debug simulation 
Total elapsed time: 103.16376161715016. Arrivals time: 0.5803129053674638 Scheduler time: 102.36669747484848 Scheduler overhead time: 0.08428455516695976 Adapter cache time: 0.01876122783869505 Engine time: 0.08125416096299887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     3.2    ]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 66, 34560, 34560, 4320, 4320, 4320, 4320, 66, 4320, 66, 4320, 66, 4320, 4320, 34560, 4320, 34560, 34560, 66, 34560, 4320, 4320, 34560, 34560, 4320, 66, 66, 4320, 34560, 34560, 4320, 4320, 66, 66, 4320, 34560, 34560, 66, 34560, 4320, 66, 4320, 34560, 66, 4320, 34560, 34560, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 34560, 4320, 34560, 34560, 66, 34560, 66, 34560, 4320, 66, 66, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 66, 4320, 4320, 66, 34560, 4320, 34560, 34560, 4320, 66, 4320, 4320, 4320, 66, 34560, 4320, 34560, 66, 34560, 66, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 4320, 66, 4320, 66, 34560, 66, 66, 66, 66, 34560, 4320, 4320, 34560, 4320, 4320, 66, 4320, 34560, 4320, 66, 66, 4320, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 4320, 34560, 4320, 4320, 4320, 66, 34560, 66, 34560, 4320, 66, 4320, 66, 66, 4320, 66, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 66, 66, 34560, 4320, 34560, 4320, 34560, 4320, 66, 4320, 66, 66, 66, 34560, 34560, 4320, 4320, 66, 66, 4320, 66, 34560, 66, 66, 4320, 66, 34560, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 66, 4320, 34560, 4320, 4320, 34560, 4320, 66, 4320, 66, 34560, 4320, 4320, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 4320, 66, 4320, 66, 4320, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 4320, 4320, 34560, 66, 34560, 66, 66, 66, 34560, 4320, 34560, 34560, 66, 4320, 4320, 4320, 66, 4320, 66, 4320, 4320, 34560, 66, 66, 4320, 66, 4320, 4320, 66, 34560, 34560, 34560, 66, 4320, 4320, 4320, 4320, 66, 4320, 66, 34560, 66, 66, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 4320, 34560, 4320, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 4167156 . Total input tokens: 927782276 . Total output tokens: 833313298
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.09382353816181,
    "estimated_duration": 3600.0107468111732,
    "input_throughput": 7522.449210460771,
    "output_throughput": 6672.515081038992,
    "total_throughput": 14194.964291499764,
    "itl": 97.77079869362177,
    "ttft": 2010748.7925264165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 529,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7780909359827608,
    "arrivals": 1387991,
    "finished_requests": 109921,
    "scheduler_time": 305.5607596991186
}
#Debug simulation 
Total elapsed time: 103.09399290941656. Arrivals time: 0.5925497049465775 Scheduler time: 102.28261180501431 Scheduler overhead time: 0.08462751843035221 Adapter cache time: 0.018643651623278856 Engine time: 0.08229712583124638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 102.77007816592231,
    "estimated_duration": 3600.087171888407,
    "input_throughput": 7564.021563876758,
    "output_throughput": 6721.334469050477,
    "total_throughput": 14285.356032927235,
    "itl": 98.05348670189902,
    "ttft": 2018211.7077179207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5394253351981926,
    "arrivals": 1386791,
    "finished_requests": 110433,
    "scheduler_time": 302.6583679960867
}
#Debug simulation 
Total elapsed time: 102.77025070786476. Arrivals time: 0.5850163232535124 Scheduler time: 101.96771325403824 Scheduler overhead time: 0.08339230250567198 Adapter cache time: 0.01895796973258257 Engine time: 0.08203352196142077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.81366388918832,
    "estimated_duration": 3600.065393098796,
    "input_throughput": 7563.96843574022,
    "output_throughput": 6721.156245212676,
    "total_throughput": 14285.124680952897,
    "itl": 98.05480112171988,
    "ttft": 2018141.4753200435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6416919206501976,
    "arrivals": 1386791,
    "finished_requests": 110431,
    "scheduler_time": 302.6498584984607
}
#Debug simulation 
Total elapsed time: 102.81383286602795. Arrivals time: 0.5974213774316013 Scheduler time: 101.99926918232813 Scheduler overhead time: 0.08368019945919514 Adapter cache time: 0.018616780638694763 Engine time: 0.08150322828441858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 103.14381195232272,
    "estimated_duration": 3600.068194452956,
    "input_throughput": 7563.962549919925,
    "output_throughput": 6721.151015217579,
    "total_throughput": 14285.113565137503,
    "itl": 98.05484727456061,
    "ttft": 2018142.6045191425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6445423865877191,
    "arrivals": 1386791,
    "finished_requests": 110431,
    "scheduler_time": 302.6499094252383
}
#Debug simulation 
Total elapsed time: 103.14398814644665. Arrivals time: 0.595571091864258 Scheduler time: 102.3333139559254 Scheduler overhead time: 0.08220440428704023 Adapter cache time: 0.01875380612909794 Engine time: 0.0810338044539094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 102.87672101892531,
    "estimated_duration": 3600.121779632541,
    "input_throughput": 7563.948851413421,
    "output_throughput": 6721.269857285159,
    "total_throughput": 14285.21870869858,
    "itl": 98.05410544761953,
    "ttft": 2018225.1819591876,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5734565024706473,
    "arrivals": 1386791,
    "finished_requests": 110433,
    "scheduler_time": 302.658644457147
}
#Debug simulation 
Total elapsed time: 102.8768849549815. Arrivals time: 0.5677424562163651 Scheduler time: 102.09278611652553 Scheduler overhead time: 0.08365375781431794 Adapter cache time: 0.018504757434129715 Engine time: 0.08095369907096028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 102.52295040898025,
    "estimated_duration": 3600.0886542276667,
    "input_throughput": 7563.919562931394,
    "output_throughput": 6721.112818037238,
    "total_throughput": 14285.03238096863,
    "itl": 98.05518148662773,
    "ttft": 2018150.1244582424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6655432689189955,
    "arrivals": 1386791,
    "finished_requests": 110431,
    "scheduler_time": 302.64996854912033
}
#Debug simulation 
Total elapsed time: 102.52311965776607. Arrivals time: 0.5895866686478257 Scheduler time: 101.7153858919628 Scheduler overhead time: 0.08416780503466725 Adapter cache time: 0.018576394766569138 Engine time: 0.08216326963156462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.1766662420705,
    "estimated_duration": 3600.051208667029,
    "input_throughput": 7564.097125741364,
    "output_throughput": 6721.401612773012,
    "total_throughput": 14285.498738514376,
    "itl": 98.05283489716435,
    "ttft": 2018197.6760838737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5039952983357778,
    "arrivals": 1386791,
    "finished_requests": 110433,
    "scheduler_time": 302.65803488865015
}
#Debug simulation 
Total elapsed time: 103.17683842638507. Arrivals time: 0.9760967674665153 Scheduler time: 101.98414289345965 Scheduler overhead time: 0.08351553464308381 Adapter cache time: 0.018620583228766918 Engine time: 0.0813450962305069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 4.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [4320, 34560, 34560, 33, 34560, 34560, 4320, 4320, 4320, 4320, 33, 4320, 33, 4320, 33, 4320, 4320, 34560, 4320, 34560, 34560, 33, 34560, 4320, 4320, 34560, 34560, 4320, 33, 33, 4320, 34560, 34560, 4320, 4320, 33, 33, 4320, 34560, 34560, 33, 34560, 4320, 33, 4320, 34560, 33, 4320, 34560, 34560, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 34560, 4320, 34560, 34560, 33, 34560, 33, 34560, 4320, 33, 33, 4320, 4320, 34560, 4320, 34560, 34560, 34560, 33, 4320, 4320, 33, 34560, 4320, 34560, 34560, 4320, 33, 4320, 4320, 4320, 33, 34560, 4320, 34560, 33, 34560, 33, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 4320, 33, 4320, 33, 34560, 33, 33, 33, 33, 34560, 4320, 4320, 34560, 4320, 4320, 33, 4320, 34560, 4320, 33, 33, 4320, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 4320, 34560, 4320, 4320, 4320, 33, 34560, 33, 34560, 4320, 33, 4320, 33, 33, 4320, 33, 4320, 34560, 34560, 34560, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 33, 33, 34560, 4320, 34560, 4320, 34560, 4320, 33, 4320, 33, 33, 33, 34560, 34560, 4320, 4320, 33, 33, 4320, 33, 34560, 33, 33, 4320, 33, 34560, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 33, 4320, 34560, 4320, 4320, 34560, 4320, 33, 4320, 33, 34560, 4320, 4320, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 4320, 33, 4320, 33, 4320, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 4320, 4320, 34560, 33, 34560, 33, 33, 33, 34560, 4320, 34560, 34560, 33, 4320, 4320, 4320, 33, 4320, 33, 4320, 4320, 34560, 33, 33, 4320, 33, 4320, 4320, 33, 34560, 34560, 34560, 33, 4320, 4320, 4320, 4320, 33, 4320, 33, 34560, 33, 33, 34560, 4320, 34560, 4320, 4320, 4320, 4320, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 4320, 34560, 4320, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 4163658 . Total input tokens: 927012570 . Total output tokens: 832614401
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.89230949105695,
    "estimated_duration": 3600.1094770385125,
    "input_throughput": 7563.875813687845,
    "output_throughput": 6721.073943535844,
    "total_throughput": 14284.949757223689,
    "itl": 98.05561740919902,
    "ttft": 2018157.8303823788,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.686921412609516,
    "arrivals": 1386791,
    "finished_requests": 110431,
    "scheduler_time": 302.650213524941
}
#Debug simulation 
Total elapsed time: 102.89247625786811. Arrivals time: 0.5844225478358567 Scheduler time: 102.09064581012353 Scheduler overhead time: 0.08322339784353971 Adapter cache time: 0.018967597279697657 Engine time: 0.08137365337461233 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 107.41008911607787,
    "estimated_duration": 3600.019502787356,
    "input_throughput": 7378.85113662093,
    "output_throughput": 6590.610129092252,
    "total_throughput": 13969.461265713182,
    "itl": 104.10911759425159,
    "ttft": 1979753.87547633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7077521611145,
    "arrivals": 1289387,
    "finished_requests": 107500,
    "scheduler_time": 313.02936996524414
}
#Debug simulation 
Total elapsed time: 107.41025401325896. Arrivals time: 0.5731811318546534 Scheduler time: 106.61243013571948 Scheduler overhead time: 0.08632094506174326 Adapter cache time: 0.01966942334547639 Engine time: 0.08449470065534115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.34256072202697,
    "estimated_duration": 3600.021932232232,
    "input_throughput": 7373.040636877916,
    "output_throughput": 6585.013493320782,
    "total_throughput": 13958.054130198698,
    "itl": 104.24535835496081,
    "ttft": 1962744.4138583406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0085778715834075,
    "arrivals": 1289387,
    "finished_requests": 107474,
    "scheduler_time": 313.2571560051702
}
#Debug simulation 
Total elapsed time: 105.34272453002632. Arrivals time: 0.5744631453417242 Scheduler time: 104.5428937827237 Scheduler overhead time: 0.08645687671378255 Adapter cache time: 0.020382737275213003 Engine time: 0.0844487245194614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.56979142734781,
    "estimated_duration": 3600.025946888888,
    "input_throughput": 7373.0324146519915,
    "output_throughput": 6585.006149882528,
    "total_throughput": 13958.03856453452,
    "itl": 104.24554677422924,
    "ttft": 1962745.830032497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0124045886099458,
    "arrivals": 1289387,
    "finished_requests": 107474,
    "scheduler_time": 313.25724390619297
}
#Debug simulation 
Total elapsed time: 105.56995745236054. Arrivals time: 0.5792702175676823 Scheduler time: 104.764872668311 Scheduler overhead time: 0.08605484059080482 Adapter cache time: 0.019934785086661577 Engine time: 0.08498777681961656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 105.17667238181457,
    "estimated_duration": 3600.0483197865715,
    "input_throughput": 7373.101037036534,
    "output_throughput": 6584.966337731105,
    "total_throughput": 13958.06737476764,
    "itl": 104.2429555618984,
    "ttft": 1962859.3388137885,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9244072359846776,
    "arrivals": 1289387,
    "finished_requests": 107476,
    "scheduler_time": 313.26959371340894
}
#Debug simulation 
Total elapsed time: 105.17683540889993. Arrivals time: 0.5722639453597367 Scheduler time: 104.38060227874666 Scheduler overhead time: 0.08607587683945894 Adapter cache time: 0.0199683322571218 Engine time: 0.0839465856552124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 105.55575103173032,
    "estimated_duration": 3600.0519676536396,
    "input_throughput": 7372.979123215176,
    "output_throughput": 6584.958554209617,
    "total_throughput": 13957.937677424794,
    "itl": 104.24587374910949,
    "ttft": 1962754.2411356922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0383098686113983,
    "arrivals": 1289387,
    "finished_requests": 107474,
    "scheduler_time": 313.25735939096495
}
#Debug simulation 
Total elapsed time: 105.55591300781816. Arrivals time: 0.576911402400583 Scheduler time: 104.75173808913678 Scheduler overhead time: 0.0877604759298265 Adapter cache time: 0.02017124556005001 Engine time: 0.08448607567697763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 107.26940882811323,
    "estimated_duration": 3600.016042876106,
    "input_throughput": 7378.858228303233,
    "output_throughput": 6590.616463210172,
    "total_throughput": 13969.474691513406,
    "itl": 104.10868025878605,
    "ttft": 1979739.895090122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 558,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6684480645553916,
    "arrivals": 1289387,
    "finished_requests": 107500,
    "scheduler_time": 313.0347110662738
}
#Debug simulation 
Total elapsed time: 107.26956783700734. Arrivals time: 0.5651378026232123 Scheduler time: 106.4805048299022 Scheduler overhead time: 0.08584152953699231 Adapter cache time: 0.019803260918706656 Engine time: 0.0844470146112144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.05_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  3.2 ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 540, 34560, 34560, 1080, 1080, 1080, 1080, 540, 1080, 540, 1080, 540, 1080, 1080, 34560, 1080, 34560, 34560, 540, 34560, 1080, 1080, 34560, 34560, 1080, 540, 540, 1080, 34560, 34560, 1080, 1080, 540, 540, 1080, 34560, 34560, 540, 34560, 1080, 540, 1080, 34560, 540, 1080, 34560, 34560, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 34560, 1080, 34560, 34560, 540, 34560, 540, 34560, 1080, 540, 540, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 540, 1080, 1080, 540, 34560, 1080, 34560, 34560, 1080, 540, 1080, 1080, 1080, 540, 34560, 1080, 34560, 540, 34560, 540, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 1080, 540, 1080, 540, 34560, 540, 540, 540, 540, 34560, 1080, 1080, 34560, 1080, 1080, 540, 1080, 34560, 1080, 540, 540, 1080, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 1080, 34560, 1080, 1080, 1080, 540, 34560, 540, 34560, 1080, 540, 1080, 540, 540, 1080, 540, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 540, 540, 34560, 1080, 34560, 1080, 34560, 1080, 540, 1080, 540, 540, 540, 34560, 34560, 1080, 1080, 540, 540, 1080, 540, 34560, 540, 540, 1080, 540, 34560, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 540, 1080, 34560, 1080, 1080, 34560, 1080, 540, 1080, 540, 34560, 1080, 1080, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 1080, 540, 1080, 540, 1080, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 1080, 1080, 34560, 540, 34560, 540, 540, 540, 34560, 1080, 34560, 34560, 540, 1080, 1080, 1080, 540, 1080, 540, 1080, 1080, 34560, 540, 540, 1080, 540, 1080, 1080, 540, 34560, 34560, 34560, 540, 1080, 1080, 1080, 1080, 540, 1080, 540, 34560, 540, 540, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 1080, 34560, 1080, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 3870720 . Total input tokens: 861711791 . Total output tokens: 773992206
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.96859720908105,
    "estimated_duration": 3600.0221775052673,
    "input_throughput": 7373.012634714849,
    "output_throughput": 6584.9827670861105,
    "total_throughput": 13957.99540180096,
    "itl": 104.24824130737879,
    "ttft": 1962646.2989777382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0637121334671944,
    "arrivals": 1289387,
    "finished_requests": 107471,
    "scheduler_time": 313.25117719930677
}
#Debug simulation 
Total elapsed time: 105.9687565183267. Arrivals time: 0.5742257027886808 Scheduler time: 105.16946199070662 Scheduler overhead time: 0.08643503347411752 Adapter cache time: 0.02005447307601571 Engine time: 0.08416003547608852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.79619440529495,
    "estimated_duration": 3600.0356257796934,
    "input_throughput": 7305.032709031682,
    "output_throughput": 6524.62043203053,
    "total_throughput": 13829.653141062212,
    "itl": 103.12184551721488,
    "ttft": 1983335.956453269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7352965508098956,
    "arrivals": 1279697,
    "finished_requests": 107270,
    "scheduler_time": 315.9436943505598
}
#Debug simulation 
Total elapsed time: 105.79635387007147. Arrivals time: 0.5719614746049047 Scheduler time: 104.99926687823609 Scheduler overhead time: 0.08683473570272326 Adapter cache time: 0.01976716425269842 Engine time: 0.08481030538678169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.73186813201755,
    "estimated_duration": 3600.062655863017,
    "input_throughput": 7450.339497930275,
    "output_throughput": 6627.451042037599,
    "total_throughput": 14077.790539967875,
    "itl": 104.8805511570504,
    "ttft": 1981701.133872127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9468637721589812,
    "arrivals": 1279697,
    "finished_requests": 109441,
    "scheduler_time": 308.030419759865
}
#Debug simulation 
Total elapsed time: 104.73203597730026. Arrivals time: 0.5809730333276093 Scheduler time: 103.92600118089467 Scheduler overhead time: 0.0863651498220861 Adapter cache time: 0.020188369322568178 Engine time: 0.08423178177326918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.738837744575,
    "estimated_duration": 3600.0662273211415,
    "input_throughput": 7450.332106795265,
    "output_throughput": 6627.444467251922,
    "total_throughput": 14077.776574047188,
    "itl": 104.88063216982648,
    "ttft": 1981702.1112905655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.950530760549021,
    "arrivals": 1279697,
    "finished_requests": 109441,
    "scheduler_time": 308.03042426815756
}
#Debug simulation 
Total elapsed time: 104.73899957956746. Arrivals time: 0.5778025123290718 Scheduler time: 103.93800058215857 Scheduler overhead time: 0.08579974109306931 Adapter cache time: 0.020041502080857754 Engine time: 0.08394380565732718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 104.81546323001385,
    "estimated_duration": 3600.1117357220037,
    "input_throughput": 7450.265705328416,
    "output_throughput": 6627.436799601156,
    "total_throughput": 14077.702504929572,
    "itl": 104.87960887416719,
    "ttft": 1981694.0881645994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8680048756999783,
    "arrivals": 1279697,
    "finished_requests": 109442,
    "scheduler_time": 308.0391056259131
}
#Debug simulation 
Total elapsed time: 104.81562863709405. Arrivals time: 0.5858230399899185 Scheduler time: 104.0044621550478 Scheduler overhead time: 0.08731944300234318 Adapter cache time: 0.020124408416450024 Engine time: 0.08430548710748553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 104.75499981967732,
    "estimated_duration": 3600.089493601046,
    "input_throughput": 7450.283957572173,
    "output_throughput": 6627.401636100558,
    "total_throughput": 14077.685593672732,
    "itl": 104.88089275877819,
    "ttft": 1981709.8934991441,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9748012413270812,
    "arrivals": 1279697,
    "finished_requests": 109441,
    "scheduler_time": 308.0305204916877
}
#Debug simulation 
Total elapsed time: 104.75516135664657. Arrivals time: 0.57957246247679 Scheduler time: 103.95062082307413 Scheduler overhead time: 0.08665796276181936 Adapter cache time: 0.020073775202035904 Engine time: 0.0842074123211205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 106.00456037605181,
    "estimated_duration": 3600.1017647481513,
    "input_throughput": 7304.928782156173,
    "output_throughput": 6524.501121051834,
    "total_throughput": 13829.429903208007,
    "itl": 103.12087154152316,
    "ttft": 1983368.2731550161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6953585172095103,
    "arrivals": 1279697,
    "finished_requests": 107271,
    "scheduler_time": 315.9518422651819
}
#Debug simulation 
Total elapsed time: 106.00472390512004. Arrivals time: 0.5718166548758745 Scheduler time: 105.20810956368223 Scheduler overhead time: 0.08607318811118603 Adapter cache time: 0.019574102945625782 Engine time: 0.08487582579255104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.025_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   3.2  ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 270, 34560, 34560, 1080, 1080, 1080, 1080, 270, 1080, 270, 1080, 270, 1080, 1080, 34560, 1080, 34560, 34560, 270, 34560, 1080, 1080, 34560, 34560, 1080, 270, 270, 1080, 34560, 34560, 1080, 1080, 270, 270, 1080, 34560, 34560, 270, 34560, 1080, 270, 1080, 34560, 270, 1080, 34560, 34560, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 34560, 1080, 34560, 34560, 270, 34560, 270, 34560, 1080, 270, 270, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 270, 1080, 1080, 270, 34560, 1080, 34560, 34560, 1080, 270, 1080, 1080, 1080, 270, 34560, 1080, 34560, 270, 34560, 270, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 1080, 270, 1080, 270, 34560, 270, 270, 270, 270, 34560, 1080, 1080, 34560, 1080, 1080, 270, 1080, 34560, 1080, 270, 270, 1080, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 1080, 34560, 1080, 1080, 1080, 270, 34560, 270, 34560, 1080, 270, 1080, 270, 270, 1080, 270, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 270, 270, 34560, 1080, 34560, 1080, 34560, 1080, 270, 1080, 270, 270, 270, 34560, 34560, 1080, 1080, 270, 270, 1080, 270, 34560, 270, 270, 1080, 270, 34560, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 270, 1080, 34560, 1080, 1080, 34560, 1080, 270, 1080, 270, 34560, 1080, 1080, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 1080, 270, 1080, 270, 1080, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 1080, 1080, 34560, 270, 34560, 270, 270, 270, 34560, 1080, 34560, 34560, 270, 1080, 1080, 1080, 270, 1080, 270, 1080, 1080, 34560, 270, 270, 1080, 270, 1080, 1080, 270, 34560, 34560, 34560, 270, 1080, 1080, 1080, 1080, 270, 1080, 270, 34560, 270, 270, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 1080, 34560, 1080, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3842100 . Total input tokens: 855348001 . Total output tokens: 768210081
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.86788164824247,
    "estimated_duration": 3600.115521200648,
    "input_throughput": 7450.2300945762145,
    "output_throughput": 6627.353722261358,
    "total_throughput": 14077.583816837572,
    "itl": 104.88121755578781,
    "ttft": 1981719.5810390203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0003292599692895,
    "arrivals": 1279697,
    "finished_requests": 109441,
    "scheduler_time": 308.03071995692835
}
#Debug simulation 
Total elapsed time: 104.86805020505562. Arrivals time: 0.6710686702281237 Scheduler time: 103.97165649197996 Scheduler overhead time: 0.08635020954534411 Adapter cache time: 0.01992589747533202 Engine time: 0.08491638163104653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.63125610304996,
    "estimated_duration": 3600.032434485058,
    "input_throughput": 7574.52870112834,
    "output_throughput": 6679.157045827944,
    "total_throughput": 14253.685746956284,
    "itl": 104.54279188509027,
    "ttft": 1978749.096281058,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7444780140416942,
    "arrivals": 1274994,
    "finished_requests": 110081,
    "scheduler_time": 304.9551460412233
}
#Debug simulation 
Total elapsed time: 105.63142505986616. Arrivals time: 0.5789849497377872 Scheduler time: 104.82970058172941 Scheduler overhead time: 0.08544876612722874 Adapter cache time: 0.019376571755856276 Engine time: 0.08378481771796942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.59144908702001,
    "estimated_duration": 3600.0178350212154,
    "input_throughput": 7574.116087633025,
    "output_throughput": 6678.999133307989,
    "total_throughput": 14253.115220941014,
    "itl": 104.54443084118745,
    "ttft": 1978785.261592628,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.860412079738459,
    "arrivals": 1274994,
    "finished_requests": 110078,
    "scheduler_time": 304.94655085825383
}
#Debug simulation 
Total elapsed time: 105.5916051780805. Arrivals time: 0.5725724496878684 Scheduler time: 104.79855844471604 Scheduler overhead time: 0.08446310786530375 Adapter cache time: 0.01949839061126113 Engine time: 0.08345724968239665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.74985976004973,
    "estimated_duration": 3600.0212994293906,
    "input_throughput": 7574.108798834567,
    "output_throughput": 6678.99270590735,
    "total_throughput": 14253.101504741917,
    "itl": 104.54446936069769,
    "ttft": 1978786.6435540705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8636342867091413,
    "arrivals": 1274994,
    "finished_requests": 110078,
    "scheduler_time": 304.94659298227396
}
#Debug simulation 
Total elapsed time: 105.7500214241445. Arrivals time: 0.5783204766921699 Scheduler time: 104.94992491556332 Scheduler overhead time: 0.08505503367632627 Adapter cache time: 0.019411219283938408 Engine time: 0.08349029859527946 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 106.24786019185558,
    "estimated_duration": 3600.0693327165754,
    "input_throughput": 7574.451067425258,
    "output_throughput": 6679.088589067742,
    "total_throughput": 14253.539656493,
    "itl": 104.54328404712324,
    "ttft": 1978762.0580967919,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7819617785978965,
    "arrivals": 1274994,
    "finished_requests": 110081,
    "scheduler_time": 304.9552607781735
}
#Debug simulation 
Total elapsed time: 106.24802659079432. Arrivals time: 0.5665297671221197 Scheduler time: 105.46091303462163 Scheduler overhead time: 0.08461107732728124 Adapter cache time: 0.01954886456951499 Engine time: 0.08292485540732741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 105.625622889027,
    "estimated_duration": 3600.045866117957,
    "input_throughput": 7574.05711316751,
    "output_throughput": 6678.947128506438,
    "total_throughput": 14253.004241673947,
    "itl": 104.54479027914576,
    "ttft": 1978795.5066771938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.887779013700787,
    "arrivals": 1274994,
    "finished_requests": 110078,
    "scheduler_time": 304.94671482812726
}
#Debug simulation 
Total elapsed time: 105.62579206191003. Arrivals time: 0.5744996112771332 Scheduler time: 104.82733193878084 Scheduler overhead time: 0.08613261999562383 Adapter cache time: 0.01937419967725873 Engine time: 0.08404667722061276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 106.11791353020817,
    "estimated_duration": 3600.122086569145,
    "input_throughput": 7574.340354103509,
    "output_throughput": 6679.025716851389,
    "total_throughput": 14253.366070954899,
    "itl": 104.54221406387073,
    "ttft": 1978803.1142055755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7043286680942165,
    "arrivals": 1274994,
    "finished_requests": 110082,
    "scheduler_time": 304.9639094717656
}
#Debug simulation 
Total elapsed time: 106.11807870306075. Arrivals time: 0.5809908667579293 Scheduler time: 105.31575222499669 Scheduler overhead time: 0.08504352997988462 Adapter cache time: 0.019457988440990448 Engine time: 0.08341409172862768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.0125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    3.2   ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 135, 34560, 34560, 1080, 1080, 1080, 1080, 135, 1080, 135, 1080, 135, 1080, 1080, 34560, 1080, 34560, 34560, 135, 34560, 1080, 1080, 34560, 34560, 1080, 135, 135, 1080, 34560, 34560, 1080, 1080, 135, 135, 1080, 34560, 34560, 135, 34560, 1080, 135, 1080, 34560, 135, 1080, 34560, 34560, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 34560, 1080, 34560, 34560, 135, 34560, 135, 34560, 1080, 135, 135, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 135, 1080, 1080, 135, 34560, 1080, 34560, 34560, 1080, 135, 1080, 1080, 1080, 135, 34560, 1080, 34560, 135, 34560, 135, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 1080, 135, 1080, 135, 34560, 135, 135, 135, 135, 34560, 1080, 1080, 34560, 1080, 1080, 135, 1080, 34560, 1080, 135, 135, 1080, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 1080, 34560, 1080, 1080, 1080, 135, 34560, 135, 34560, 1080, 135, 1080, 135, 135, 1080, 135, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 135, 135, 34560, 1080, 34560, 1080, 34560, 1080, 135, 1080, 135, 135, 135, 34560, 34560, 1080, 1080, 135, 135, 1080, 135, 34560, 135, 135, 1080, 135, 34560, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 135, 1080, 34560, 1080, 1080, 34560, 1080, 135, 1080, 135, 34560, 1080, 1080, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 1080, 135, 1080, 135, 1080, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 1080, 1080, 34560, 135, 34560, 135, 135, 135, 34560, 1080, 34560, 34560, 135, 1080, 1080, 1080, 135, 1080, 135, 1080, 1080, 34560, 135, 135, 1080, 135, 1080, 1080, 135, 34560, 34560, 34560, 135, 1080, 1080, 1080, 1080, 135, 1080, 135, 34560, 135, 135, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 1080, 34560, 1080, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3827790 . Total input tokens: 852187705 . Total output tokens: 765340010
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 106.39053998701274,
    "estimated_duration": 3600.0698164472133,
    "input_throughput": 7574.006724933138,
    "output_throughput": 6678.90269520626,
    "total_throughput": 14252.909420139398,
    "itl": 104.54513044744316,
    "ttft": 1978804.0872910472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9116722331196028,
    "arrivals": 1274994,
    "finished_requests": 110078,
    "scheduler_time": 304.94677193798805
}
#Debug simulation 
Total elapsed time: 106.39069683430716. Arrivals time: 0.5777509254403412 Scheduler time: 105.591722978279 Scheduler overhead time: 0.08495241310447454 Adapter cache time: 0.01964046759530902 Engine time: 0.0834189378656447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 113.94829919515178,
    "estimated_duration": 3600.1069926111986,
    "input_throughput": 7392.183358611112,
    "output_throughput": 6564.819614668716,
    "total_throughput": 13957.002973279828,
    "itl": 103.87195401627552,
    "ttft": 1978876.930668905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5394253351981926,
    "arrivals": 1272675,
    "finished_requests": 107898,
    "scheduler_time": 311.8742860999691
}
#Debug simulation 
Total elapsed time: 113.94845536816865. Arrivals time: 0.5850999900139868 Scheduler time: 113.13992849830538 Scheduler overhead time: 0.08576914481818676 Adapter cache time: 0.019254638347774744 Engine time: 0.08444231515750289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 106.94056186685339,
    "estimated_duration": 3600.070588241721,
    "input_throughput": 7483.152715946459,
    "output_throughput": 6644.291941976204,
    "total_throughput": 14127.444657922662,
    "itl": 103.94174802516856,
    "ttft": 1973791.864326679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7066747826221462,
    "arrivals": 1272675,
    "finished_requests": 109144,
    "scheduler_time": 307.2548125791271
}
#Debug simulation 
Total elapsed time: 106.94072323292494. Arrivals time: 0.5786220179870725 Scheduler time: 106.13813281618059 Scheduler overhead time: 0.08640768518671393 Adapter cache time: 0.019340583588927984 Engine time: 0.08442753367125988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 106.88362109195441,
    "estimated_duration": 3600.0731505539397,
    "input_throughput": 7483.147389895338,
    "output_throughput": 6644.287212974955,
    "total_throughput": 14127.434602870293,
    "itl": 103.94178176193363,
    "ttft": 1973792.9080245283,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.70911419460551,
    "arrivals": 1272675,
    "finished_requests": 109144,
    "scheduler_time": 307.2548354407563
}
#Debug simulation 
Total elapsed time: 106.88378111319616. Arrivals time: 0.5794367059133947 Scheduler time: 106.08033003238961 Scheduler overhead time: 0.08601918071508408 Adapter cache time: 0.019202531781047583 Engine time: 0.08461137721315026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 107.05511832097545,
    "estimated_duration": 3600.123101925009,
    "input_throughput": 7483.21077842998,
    "output_throughput": 6644.489736256323,
    "total_throughput": 14127.700514686303,
    "itl": 103.94148417412806,
    "ttft": 1973780.107872647,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6343534112581908,
    "arrivals": 1272675,
    "finished_requests": 109148,
    "scheduler_time": 307.263611563377
}
#Debug simulation 
Total elapsed time: 107.05528754089028. Arrivals time: 0.5737787554971874 Scheduler time: 106.25878731254488 Scheduler overhead time: 0.08642734959721565 Adapter cache time: 0.01931038498878479 Engine time: 0.08321381313726306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 107.00151452189311,
    "estimated_duration": 3600.0952553606553,
    "input_throughput": 7483.101442909232,
    "output_throughput": 6644.246416642028,
    "total_throughput": 14127.34785955126,
    "itl": 103.94215519014709,
    "ttft": 1973800.08364458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 522,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7313726148009336,
    "arrivals": 1272675,
    "finished_requests": 109144,
    "scheduler_time": 307.2550819816191
}
#Debug simulation 
Total elapsed time: 107.00167160388082. Arrivals time: 0.5763420732691884 Scheduler time: 106.20136821595952 Scheduler overhead time: 0.08616134710609913 Adapter cache time: 0.019436404574662447 Engine time: 0.08398412028327584 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 109.28733347123489,
    "estimated_duration": 3600.0717729920793,
    "input_throughput": 7392.255676581077,
    "output_throughput": 6564.883838512294,
    "total_throughput": 13957.13951509337,
    "itl": 103.87152959482206,
    "ttft": 1978864.5635430808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5039952983357778,
    "arrivals": 1272675,
    "finished_requests": 107898,
    "scheduler_time": 311.87409636330574
}
#Debug simulation 
Total elapsed time: 109.28749587293714. Arrivals time: 0.5555359534919262 Scheduler time: 108.50697610154748 Scheduler overhead time: 0.08685831353068352 Adapter cache time: 0.01937086693942547 Engine time: 0.08446893794462085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     3.2    ]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 66, 34560, 34560, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 34560, 1080, 34560, 34560, 66, 34560, 1080, 1080, 34560, 34560, 1080, 66, 66, 1080, 34560, 34560, 1080, 1080, 66, 66, 1080, 34560, 34560, 66, 34560, 1080, 66, 1080, 34560, 66, 1080, 34560, 34560, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 34560, 1080, 34560, 34560, 66, 34560, 66, 34560, 1080, 66, 66, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 66, 1080, 1080, 66, 34560, 1080, 34560, 34560, 1080, 66, 1080, 1080, 1080, 66, 34560, 1080, 34560, 66, 34560, 66, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 1080, 66, 1080, 66, 34560, 66, 66, 66, 66, 34560, 1080, 1080, 34560, 1080, 1080, 66, 1080, 34560, 1080, 66, 66, 1080, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 1080, 34560, 1080, 1080, 1080, 66, 34560, 66, 34560, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 66, 66, 34560, 1080, 34560, 1080, 34560, 1080, 66, 1080, 66, 66, 66, 34560, 34560, 1080, 1080, 66, 66, 1080, 66, 34560, 66, 66, 1080, 66, 34560, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 66, 1080, 34560, 1080, 1080, 34560, 1080, 66, 1080, 66, 34560, 1080, 1080, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 1080, 66, 1080, 66, 1080, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 1080, 1080, 34560, 66, 34560, 66, 66, 66, 34560, 1080, 34560, 34560, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 34560, 66, 66, 1080, 66, 1080, 1080, 66, 34560, 34560, 34560, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 34560, 66, 66, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 1080, 34560, 1080, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3820476 . Total input tokens: 850558203 . Total output tokens: 763895520
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 105.25334053765982,
    "estimated_duration": 3600.125006050977,
    "input_throughput": 7595.9006851254835,
    "output_throughput": 6755.199322002554,
    "total_throughput": 14351.100007128038,
    "itl": 105.04855143033285,
    "ttft": 1981264.1159114514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 534,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7923825276643008,
    "arrivals": 1272675,
    "finished_requests": 110905,
    "scheduler_time": 300.7318659178477
}
#Debug simulation 
Total elapsed time: 105.25358289759606. Arrivals time: 0.5737198884598911 Scheduler time: 104.45777102420107 Scheduler overhead time: 0.08535934332758188 Adapter cache time: 0.019148226361721754 Engine time: 0.08421789295971394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.2238217019476,
    "estimated_duration": 3600.0612742079184,
    "input_throughput": 7669.353629564195,
    "output_throughput": 6771.907515758577,
    "total_throughput": 14441.261145322771,
    "itl": 104.97119733959829,
    "ttft": 1975355.113365761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5914536268450512,
    "arrivals": 1271499,
    "finished_requests": 111830,
    "scheduler_time": 299.77949758691545
}
#Debug simulation 
Total elapsed time: 105.22398195415735. Arrivals time: 0.5875040031969547 Scheduler time: 104.41463485639542 Scheduler overhead time: 0.08482660772278905 Adapter cache time: 0.01926675485447049 Engine time: 0.08427965641021729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.63348010694608,
    "estimated_duration": 3600.018147159558,
    "input_throughput": 7541.597539285037,
    "output_throughput": 6670.276098176487,
    "total_throughput": 14211.873637461524,
    "itl": 103.5851225405296,
    "ttft": 1973457.7032829723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6331303650839315,
    "arrivals": 1271499,
    "finished_requests": 110004,
    "scheduler_time": 305.7491449041298
}
#Debug simulation 
Total elapsed time: 108.63364822324365. Arrivals time: 0.5739457127638161 Scheduler time: 107.83851161785424 Scheduler overhead time: 0.08515426237136126 Adapter cache time: 0.018975968472659588 Engine time: 0.08348655188456178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.91336834290996,
    "estimated_duration": 3600.020569483685,
    "input_throughput": 7541.592464815788,
    "output_throughput": 6670.27160998804,
    "total_throughput": 14211.864074803827,
    "itl": 103.58514657067974,
    "ttft": 1973458.4790704749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6357490775361756,
    "arrivals": 1271499,
    "finished_requests": 110004,
    "scheduler_time": 305.7491485929417
}
#Debug simulation 
Total elapsed time: 108.91353246476501. Arrivals time: 0.574278854764998 Scheduler time: 108.11594922281802 Scheduler overhead time: 0.08644042164087296 Adapter cache time: 0.018883141223341227 Engine time: 0.08387428428977728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 106.24007131578401,
    "estimated_duration": 3600.018387493476,
    "input_throughput": 7625.596884551954,
    "output_throughput": 6739.677798394015,
    "total_throughput": 14365.274682945968,
    "itl": 105.27186646588443,
    "ttft": 1976247.204282467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 509,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5962999480613451,
    "arrivals": 1271499,
    "finished_requests": 111255,
    "scheduler_time": 301.7855569889578
}
#Debug simulation 
Total elapsed time: 106.24023512005806. Arrivals time: 0.5790536976419389 Scheduler time: 105.4413479808718 Scheduler overhead time: 0.08462349232286215 Adapter cache time: 0.018896799068897963 Engine time: 0.0834656753577292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 108.75174452317879,
    "estimated_duration": 3600.041219489525,
    "input_throughput": 7541.54920588653,
    "output_throughput": 6670.233348996207,
    "total_throughput": 14211.782554882737,
    "itl": 103.58547751295052,
    "ttft": 1973465.6748363874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6561211909353772,
    "arrivals": 1271499,
    "finished_requests": 110004,
    "scheduler_time": 305.7492264082419
}
#Debug simulation 
Total elapsed time: 108.7519116490148. Arrivals time: 0.5716145844198763 Scheduler time: 107.95807045511901 Scheduler overhead time: 0.08498766226693988 Adapter cache time: 0.019059081096202135 Engine time: 0.08458360191434622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.12108518695459,
    "estimated_duration": 3600.0246763374034,
    "input_throughput": 7669.431596255066,
    "output_throughput": 6771.976359007354,
    "total_throughput": 14441.40795526242,
    "itl": 104.97063589299175,
    "ttft": 1975342.2005995403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.554826153349113,
    "arrivals": 1271499,
    "finished_requests": 111830,
    "scheduler_time": 299.77932711264305
}
#Debug simulation 
Total elapsed time: 105.12124385870993. Arrivals time: 0.5764645440503955 Scheduler time: 104.32547660218552 Scheduler overhead time: 0.08452845131978393 Adapter cache time: 0.018769762013107538 Engine time: 0.08276022411882877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.1-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.000e-01 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [1080, 34560, 34560, 33, 34560, 34560, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 34560, 1080, 34560, 34560, 33, 34560, 1080, 1080, 34560, 34560, 1080, 33, 33, 1080, 34560, 34560, 1080, 1080, 33, 33, 1080, 34560, 34560, 33, 34560, 1080, 33, 1080, 34560, 33, 1080, 34560, 34560, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 34560, 1080, 34560, 34560, 33, 34560, 33, 34560, 1080, 33, 33, 1080, 1080, 34560, 1080, 34560, 34560, 34560, 33, 1080, 1080, 33, 34560, 1080, 34560, 34560, 1080, 33, 1080, 1080, 1080, 33, 34560, 1080, 34560, 33, 34560, 33, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 1080, 33, 1080, 33, 34560, 33, 33, 33, 33, 34560, 1080, 1080, 34560, 1080, 1080, 33, 1080, 34560, 1080, 33, 33, 1080, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 1080, 34560, 1080, 1080, 1080, 33, 34560, 33, 34560, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 34560, 34560, 34560, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 33, 33, 34560, 1080, 34560, 1080, 34560, 1080, 33, 1080, 33, 33, 33, 34560, 34560, 1080, 1080, 33, 33, 1080, 33, 34560, 33, 33, 1080, 33, 34560, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 33, 1080, 34560, 1080, 1080, 34560, 1080, 33, 1080, 33, 34560, 1080, 1080, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 1080, 33, 1080, 33, 1080, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 1080, 1080, 34560, 33, 34560, 33, 33, 33, 34560, 1080, 34560, 34560, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 34560, 33, 33, 1080, 33, 1080, 1080, 33, 34560, 34560, 34560, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 34560, 33, 33, 34560, 1080, 34560, 1080, 1080, 1080, 1080, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 1080, 34560, 1080, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3816978 . Total input tokens: 849763650 . Total output tokens: 763207272
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.71461417293176,
    "estimated_duration": 3600.124388017563,
    "input_throughput": 7523.254777014629,
    "output_throughput": 6653.55510485299,
    "total_throughput": 14176.809881867619,
    "itl": 104.16537244940771,
    "ttft": 1972547.5727191393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 497,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6686602995172124,
    "arrivals": 1271499,
    "finished_requests": 109769,
    "scheduler_time": 306.72858586625694
}
#Debug simulation 
Total elapsed time: 108.71477983193472. Arrivals time: 0.5772092598490417 Scheduler time: 107.9157684003003 Scheduler overhead time: 0.08541131811216474 Adapter cache time: 0.01888685068115592 Engine time: 0.08405694365501404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-8/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.59324275981635,
    "estimated_duration": 3600.0117345197723,
    "input_throughput": 7498.602779860393,
    "output_throughput": 6676.273238094356,
    "total_throughput": 14174.87601795475,
    "itl": 106.50387515653495,
    "ttft": 1983518.4373149304,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7995667934324857,
    "arrivals": 1260602,
    "finished_requests": 109524,
    "scheduler_time": 304.97476317825175
}
#Debug simulation 
Total elapsed time: 105.59340925468132. Arrivals time: 0.5530351838096976 Scheduler time: 104.81860432773829 Scheduler overhead time: 0.0850164033472538 Adapter cache time: 0.019692664965987206 Engine time: 0.08353001205250621 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-16/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.20972576085478,
    "estimated_duration": 3600.074888590489,
    "input_throughput": 7439.097193471297,
    "output_throughput": 6636.068898376059,
    "total_throughput": 14075.166091847355,
    "itl": 106.67919143317881,
    "ttft": 1978638.9997368245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8536147885117737,
    "arrivals": 1260602,
    "finished_requests": 108692,
    "scheduler_time": 308.44385550196245
}
#Debug simulation 
Total elapsed time: 108.20988514693454. Arrivals time: 0.578084263484925 Scheduler time: 107.4078000728041 Scheduler overhead time: 0.08588074101135135 Adapter cache time: 0.019894529599696398 Engine time: 0.08456458384171128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-8-32/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.87897153990343,
    "estimated_duration": 3600.0781472333333,
    "input_throughput": 7439.090459906123,
    "output_throughput": 6636.062891679108,
    "total_throughput": 14075.153351585232,
    "itl": 106.67922361291836,
    "ttft": 1978640.230170109,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8568727540224905,
    "arrivals": 1260602,
    "finished_requests": 108692,
    "scheduler_time": 308.4438561792744
}
#Debug simulation 
Total elapsed time: 107.87913622288033. Arrivals time: 0.5555041278712451 Scheduler time: 107.09948442410678 Scheduler overhead time: 0.08618057053536177 Adapter cache time: 0.019822960253804922 Engine time: 0.08446320053189993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-16/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 108.90806544898078,
    "estimated_duration": 3600.0204703981726,
    "input_throughput": 7397.429325465626,
    "output_throughput": 6619.758191920557,
    "total_throughput": 14017.187517386183,
    "itl": 103.77153331990543,
    "ttft": 1989509.6521803623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6081113200541512,
    "arrivals": 1260602,
    "finished_requests": 108029,
    "scheduler_time": 311.2703776262773
}
#Debug simulation 
Total elapsed time: 108.90822687325999. Arrivals time: 0.5664568115025759 Scheduler time: 108.1177791277878 Scheduler overhead time: 0.08665735367685556 Adapter cache time: 0.019315433222800493 Engine time: 0.08377605676651001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_8-16-32/adapters_320_slots_16_rate_3.2-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 107.76400441629812,
    "estimated_duration": 3600.1022367822216,
    "input_throughput": 7439.040682338284,
    "output_throughput": 6636.018487450856,
    "total_throughput": 14075.05916978914,
    "itl": 106.6794504959679,
    "ttft": 1978648.753195858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8807659734413062,
    "arrivals": 1260602,
    "finished_requests": 108692,
    "scheduler_time": 308.4440525087612
}
#Debug simulation 
Total elapsed time: 107.76416676398367. Arrivals time: 0.5564919761382043 Scheduler time: 106.98434498766437 Scheduler overhead time: 0.08507177559658885 Adapter cache time: 0.01986178196966648 Engine time: 0.08450925396755338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_16_rate_3.2-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-16/adapters_320_slots_16_rate_3.2-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.21303225774318,
    "estimated_duration": 3600.0987794319126,
    "input_throughput": 7498.746743904606,
    "output_throughput": 6676.44347352958,
    "total_throughput": 14175.190217434187,
    "itl": 106.50387047956043,
    "ttft": 1983551.1865221635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7581495734024537,
    "arrivals": 1260602,
    "finished_requests": 109529,
    "scheduler_time": 304.9836878896324
}
#Debug simulation 
Total elapsed time: 105.21319363312796. Arrivals time: 0.5730940946377814 Scheduler time: 104.41895778570324 Scheduler overhead time: 0.08449366735294461 Adapter cache time: 0.01965951919555664 Engine time: 0.08291371492668986 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_320_slots_16_rate_3.2-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.025_size_16-16-32/adapters_320_slots_16_rate_3.2-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  3.2  ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 270, 34560, 34560, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 34560, 540, 34560, 34560, 270, 34560, 540, 540, 34560, 34560, 540, 270, 270, 540, 34560, 34560, 540, 540, 270, 270, 540, 34560, 34560, 270, 34560, 540, 270, 540, 34560, 270, 540, 34560, 34560, 540, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 540, 540, 540, 270, 540, 270, 34560, 270, 34560, 540, 34560, 34560, 270, 34560, 270, 34560, 540, 270, 270, 540, 540, 34560, 540, 34560, 34560, 34560, 270, 540, 540, 270, 34560, 540, 34560, 34560, 540, 270, 540, 540, 540, 270, 34560, 540, 34560, 270, 34560, 270, 270, 540, 34560, 34560, 540, 270, 540, 270, 540, 34560, 34560, 540, 270, 540, 270, 34560, 270, 270, 270, 270, 34560, 540, 540, 34560, 540, 540, 270, 540, 34560, 540, 270, 270, 540, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 540, 34560, 540, 540, 540, 270, 34560, 270, 34560, 540, 270, 540, 270, 270, 540, 270, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 270, 270, 34560, 540, 34560, 540, 34560, 540, 270, 540, 270, 270, 270, 34560, 34560, 540, 540, 270, 270, 540, 270, 34560, 270, 270, 540, 270, 34560, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 270, 540, 34560, 540, 540, 34560, 540, 270, 540, 270, 34560, 540, 540, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 540, 270, 540, 270, 540, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 540, 540, 34560, 270, 34560, 270, 270, 270, 34560, 540, 34560, 34560, 270, 540, 540, 540, 270, 540, 270, 540, 540, 34560, 270, 270, 540, 270, 540, 540, 270, 34560, 34560, 34560, 270, 540, 540, 540, 540, 270, 540, 270, 34560, 270, 270, 34560, 540, 34560, 540, 540, 540, 540, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 540, 34560, 540, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 3784320 . Total input tokens: 842539376 . Total output tokens: 756711889
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.61333776405081,
    "estimated_duration": 3600.0055603908595,
    "input_throughput": 7438.913510203698,
    "output_throughput": 6636.084472437932,
    "total_throughput": 14074.997982641631,
    "itl": 106.68016430189132,
    "ttft": 1978629.6151866352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9046591928601222,
    "arrivals": 1260602,
    "finished_requests": 108688,
    "scheduler_time": 308.43531734800234
}
#Debug simulation 
Total elapsed time: 107.61350383982062. Arrivals time: 0.5678463168442249 Scheduler time: 106.82097890460864 Scheduler overhead time: 0.08606230467557907 Adapter cache time: 0.019499164074659348 Engine time: 0.08462774334475398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 104.92508901515976,
    "estimated_duration": 3600.125373217302,
    "input_throughput": 7668.768206071462,
    "output_throughput": 6781.511605575511,
    "total_throughput": 14450.279811646973,
    "itl": 106.73367343811596,
    "ttft": 1984594.4167993374,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6802077714191042,
    "arrivals": 1256018,
    "finished_requests": 111717,
    "scheduler_time": 299.0072434948574
}
#Debug simulation 
Total elapsed time: 104.9253308759071. Arrivals time: 0.5641906331293285 Scheduler time: 104.141571784392 Scheduler overhead time: 0.08426452428102493 Adapter cache time: 0.01910422882065177 Engine time: 0.08328823279589415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.36645791027695,
    "estimated_duration": 3600.082362384783,
    "input_throughput": 7514.614744002488,
    "output_throughput": 6651.334494508067,
    "total_throughput": 14165.949238510555,
    "itl": 105.28238492068888,
    "ttft": 1983300.449746186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7447282458189928,
    "arrivals": 1256018,
    "finished_requests": 109466,
    "scheduler_time": 306.75942373878354
}
#Debug simulation 
Total elapsed time: 108.36661832919344. Arrivals time: 0.5674858749844134 Scheduler time: 107.57693588780239 Scheduler overhead time: 0.08547961851581931 Adapter cache time: 0.01956443442031741 Engine time: 0.08374115824699402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.42524426663294,
    "estimated_duration": 3600.0856395836327,
    "input_throughput": 7514.607903363331,
    "output_throughput": 6651.328439722727,
    "total_throughput": 14165.93634308606,
    "itl": 105.28243788066271,
    "ttft": 1983301.4064799831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7480054446496176,
    "arrivals": 1256018,
    "finished_requests": 109466,
    "scheduler_time": 306.75942373878354
}
#Debug simulation 
Total elapsed time: 108.42548247473314. Arrivals time: 0.5601270985789597 Scheduler time: 107.64145715394989 Scheduler overhead time: 0.08589169336482882 Adapter cache time: 0.019456248730421066 Engine time: 0.08404485322535038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 105.07049160916358,
    "estimated_duration": 3600.0331906856786,
    "input_throughput": 7668.964294949057,
    "output_throughput": 6781.623587017537,
    "total_throughput": 14450.587881966594,
    "itl": 106.73396373373845,
    "ttft": 1984577.8272475936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.717944936449631,
    "arrivals": 1256018,
    "finished_requests": 111716,
    "scheduler_time": 298.9983617975252
}
#Debug simulation 
Total elapsed time: 105.07065716013312. Arrivals time: 0.578160373494029 Scheduler time: 104.27231197338551 Scheduler overhead time: 0.08428136026486754 Adapter cache time: 0.01946814078837633 Engine time: 0.08274063421413302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 108.43108619190753,
    "estimated_duration": 3600.107649260416,
    "input_throughput": 7514.561961934013,
    "output_throughput": 6651.287776052804,
    "total_throughput": 14165.849737986817,
    "itl": 105.28274752553426,
    "ttft": 1983308.934980984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7702638648450415,
    "arrivals": 1256018,
    "finished_requests": 109466,
    "scheduler_time": 306.75947511113094
}
#Debug simulation 
Total elapsed time: 108.43125396920368. Arrivals time: 0.5785246570594609 Scheduler time: 107.62840170226991 Scheduler overhead time: 0.08633685717359185 Adapter cache time: 0.01940344413742423 Engine time: 0.08414553198963404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.0089586158283,
    "estimated_duration": 3600.0854870421217,
    "input_throughput": 7668.853170118339,
    "output_throughput": 6781.58673950243,
    "total_throughput": 14450.439909620769,
    "itl": 106.73267532114325,
    "ttft": 1984579.5009043263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.641537611901273,
    "arrivals": 1256018,
    "finished_requests": 111717,
    "scheduler_time": 299.006527672001
}
#Debug simulation 
Total elapsed time: 105.00911772577092. Arrivals time: 0.572434380184859 Scheduler time: 104.21713199233636 Scheduler overhead time: 0.08470498351380229 Adapter cache time: 0.019193649291992188 Engine time: 0.08262401586398482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.0125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   3.2   ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 135, 34560, 34560, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 34560, 540, 34560, 34560, 135, 34560, 540, 540, 34560, 34560, 540, 135, 135, 540, 34560, 34560, 540, 540, 135, 135, 540, 34560, 34560, 135, 34560, 540, 135, 540, 34560, 135, 540, 34560, 34560, 540, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 540, 540, 540, 135, 540, 135, 34560, 135, 34560, 540, 34560, 34560, 135, 34560, 135, 34560, 540, 135, 135, 540, 540, 34560, 540, 34560, 34560, 34560, 135, 540, 540, 135, 34560, 540, 34560, 34560, 540, 135, 540, 540, 540, 135, 34560, 540, 34560, 135, 34560, 135, 135, 540, 34560, 34560, 540, 135, 540, 135, 540, 34560, 34560, 540, 135, 540, 135, 34560, 135, 135, 135, 135, 34560, 540, 540, 34560, 540, 540, 135, 540, 34560, 540, 135, 135, 540, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 540, 34560, 540, 540, 540, 135, 34560, 135, 34560, 540, 135, 540, 135, 135, 540, 135, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 135, 135, 34560, 540, 34560, 540, 34560, 540, 135, 540, 135, 135, 135, 34560, 34560, 540, 540, 135, 135, 540, 135, 34560, 135, 135, 540, 135, 34560, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 135, 540, 34560, 540, 540, 34560, 540, 135, 540, 135, 34560, 540, 540, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 540, 135, 540, 135, 540, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 540, 540, 34560, 135, 34560, 135, 135, 135, 34560, 540, 34560, 34560, 135, 540, 540, 540, 135, 540, 135, 540, 540, 34560, 135, 135, 540, 135, 540, 540, 135, 34560, 34560, 34560, 135, 540, 540, 540, 540, 135, 540, 135, 34560, 135, 135, 34560, 540, 34560, 540, 540, 540, 540, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 540, 34560, 540, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3770010 . Total input tokens: 839357717 . Total output tokens: 753878560
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.65749348187819,
    "estimated_duration": 3600.002294881557,
    "input_throughput": 7514.499376420547,
    "output_throughput": 6651.323260000256,
    "total_throughput": 14165.822636420802,
    "itl": 105.28346673427207,
    "ttft": 1983266.5016295093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 535,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7926480388268802,
    "arrivals": 1256018,
    "finished_requests": 109462,
    "scheduler_time": 306.7504736703533
}
#Debug simulation 
Total elapsed time: 108.65765507472679. Arrivals time: 0.5815895698033273 Scheduler time: 107.85172497248277 Scheduler overhead time: 0.08607574738562107 Adapter cache time: 0.019536346197128296 Engine time: 0.0845182272605598 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 108.40918037714437,
    "estimated_duration": 3600.0412190506477,
    "input_throughput": 7642.730826080831,
    "output_throughput": 6745.628597664773,
    "total_throughput": 14388.359423745604,
    "itl": 106.30526897236763,
    "ttft": 1980577.847617485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 520,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5914536268450512,
    "arrivals": 1253655,
    "finished_requests": 111241,
    "scheduler_time": 301.2010009037366
}
#Debug simulation 
Total elapsed time: 108.40933875506744. Arrivals time: 0.7226642612367868 Scheduler time: 107.46614561509341 Scheduler overhead time: 0.08436850039288402 Adapter cache time: 0.019012247677892447 Engine time: 0.08335058717057109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.43123809900135,
    "estimated_duration": 3600.1159487846544,
    "input_throughput": 7703.1227311892435,
    "output_throughput": 6798.133545743737,
    "total_throughput": 14501.25627693298,
    "itl": 105.72275400076155,
    "ttft": 1977916.4942008844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7387481452291886,
    "arrivals": 1253655,
    "finished_requests": 112203,
    "scheduler_time": 298.02569520788046
}
#Debug simulation 
Total elapsed time: 104.43139850720763. Arrivals time: 0.5845091044902802 Scheduler time: 103.62540069408715 Scheduler overhead time: 0.08547072159126401 Adapter cache time: 0.01911332132294774 Engine time: 0.08343704277649522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.55079335626215,
    "estimated_duration": 3600.11864139496,
    "input_throughput": 7703.11696984921,
    "output_throughput": 6798.128461265622,
    "total_throughput": 14501.245431114832,
    "itl": 105.72276140749105,
    "ttft": 1977917.2338425806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7419184069521831,
    "arrivals": 1253655,
    "finished_requests": 112203,
    "scheduler_time": 298.02571774934296
}
#Debug simulation 
Total elapsed time: 104.55095450486988. Arrivals time: 0.5802989061921835 Scheduler time: 103.75117059797049 Scheduler overhead time: 0.08416566532105207 Adapter cache time: 0.01923880400136113 Engine time: 0.08286868035793304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 104.89467264804989,
    "estimated_duration": 3600.0422167714187,
    "input_throughput": 7703.280497880013,
    "output_throughput": 6798.272777464475,
    "total_throughput": 14501.553275344488,
    "itl": 105.7216959520189,
    "ttft": 1977890.1535580317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6656095832283524,
    "arrivals": 1253655,
    "finished_requests": 112203,
    "scheduler_time": 298.0254018723614
}
#Debug simulation 
Total elapsed time: 104.89483955409378. Arrivals time: 0.5784966186620295 Scheduler time: 104.09624128555879 Scheduler overhead time: 0.08458413230255246 Adapter cache time: 0.01941134687513113 Engine time: 0.08299425337463617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 104.61618138570338,
    "estimated_duration": 3600.015173601691,
    "input_throughput": 7702.968643950544,
    "output_throughput": 6797.960236238629,
    "total_throughput": 14500.928880189173,
    "itl": 105.72309334120635,
    "ttft": 1977896.8276590623,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7644283347204368,
    "arrivals": 1253655,
    "finished_requests": 112200,
    "scheduler_time": 298.01667644592516
}
#Debug simulation 
Total elapsed time: 104.6163376220502. Arrivals time: 0.567365987226367 Scheduler time: 103.82974154222757 Scheduler overhead time: 0.084586919285357 Adapter cache time: 0.01887213997542858 Engine time: 0.0829707719385624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 108.10947317397222,
    "estimated_duration": 3600.0711911483777,
    "input_throughput": 7588.815484308569,
    "output_throughput": 6696.1578591200805,
    "total_throughput": 14284.973343428648,
    "itl": 105.45758480180837,
    "ttft": 1978316.8935388974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5398759018746027,
    "arrivals": 1253655,
    "finished_requests": 110559,
    "scheduler_time": 304.12828043118486
}
#Debug simulation 
Total elapsed time: 108.10963908815756. Arrivals time: 0.7291124928742647 Scheduler time: 107.15612356178463 Scheduler overhead time: 0.0865972419269383 Adapter cache time: 0.019124909304082394 Engine time: 0.08448231779038906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    3.2    ]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 66, 34560, 34560, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 34560, 540, 34560, 34560, 66, 34560, 540, 540, 34560, 34560, 540, 66, 66, 540, 34560, 34560, 540, 540, 66, 66, 540, 34560, 34560, 66, 34560, 540, 66, 540, 34560, 66, 540, 34560, 34560, 540, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 540, 540, 540, 66, 540, 66, 34560, 66, 34560, 540, 34560, 34560, 66, 34560, 66, 34560, 540, 66, 66, 540, 540, 34560, 540, 34560, 34560, 34560, 66, 540, 540, 66, 34560, 540, 34560, 34560, 540, 66, 540, 540, 540, 66, 34560, 540, 34560, 66, 34560, 66, 66, 540, 34560, 34560, 540, 66, 540, 66, 540, 34560, 34560, 540, 66, 540, 66, 34560, 66, 66, 66, 66, 34560, 540, 540, 34560, 540, 540, 66, 540, 34560, 540, 66, 66, 540, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 540, 34560, 540, 540, 540, 66, 34560, 66, 34560, 540, 66, 540, 66, 66, 540, 66, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 66, 66, 34560, 540, 34560, 540, 34560, 540, 66, 540, 66, 66, 66, 34560, 34560, 540, 540, 66, 66, 540, 66, 34560, 66, 66, 540, 66, 34560, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 66, 540, 34560, 540, 540, 34560, 540, 66, 540, 66, 34560, 540, 540, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 540, 66, 540, 66, 540, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 540, 540, 34560, 66, 34560, 66, 66, 66, 34560, 540, 34560, 34560, 66, 540, 540, 540, 66, 540, 66, 540, 540, 34560, 66, 66, 540, 66, 540, 540, 66, 34560, 34560, 34560, 66, 540, 540, 540, 540, 66, 540, 66, 34560, 66, 66, 34560, 540, 34560, 540, 540, 540, 540, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 540, 34560, 540, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3762696 . Total input tokens: 837742238 . Total output tokens: 752454329
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 104.90080858115107,
    "estimated_duration": 3600.0376688362385,
    "input_throughput": 7702.920511096864,
    "output_throughput": 6797.917758430332,
    "total_throughput": 14500.838269527196,
    "itl": 105.72337607537857,
    "ttft": 1977905.4129684314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 533,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7865610011294455,
    "arrivals": 1253655,
    "finished_requests": 112200,
    "scheduler_time": 298.01683893692075
}
#Debug simulation 
Total elapsed time: 104.90103673376143. Arrivals time: 0.5724836601875722 Scheduler time: 104.1087113628164 Scheduler overhead time: 0.08439302584156394 Adapter cache time: 0.019081749487668276 Engine time: 0.08326181303709745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 109.57718721590936,
    "estimated_duration": 3600.049328044652,
    "input_throughput": 7767.971061437951,
    "output_throughput": 6871.503622822907,
    "total_throughput": 14639.474684260858,
    "itl": 107.23145077479401,
    "ttft": 1975675.5790044123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 481,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4720946048316697,
    "arrivals": 1252442,
    "finished_requests": 113028,
    "scheduler_time": 293.7803431827201
}
#Debug simulation 
Total elapsed time: 109.57735285582021. Arrivals time: 0.9737665271386504 Scheduler time: 108.38490450382233 Scheduler overhead time: 0.08483178960159421 Adapter cache time: 0.01871460396796465 Engine time: 0.08170167962089181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.4111482128501,
    "estimated_duration": 3600.06659617634,
    "input_throughput": 7780.503846720502,
    "output_throughput": 6913.283222714281,
    "total_throughput": 14693.787069434782,
    "itl": 107.23148462457586,
    "ttft": 1973684.2526548617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.556595897250814,
    "arrivals": 1252442,
    "finished_requests": 113335,
    "scheduler_time": 292.94128514829276
}
#Debug simulation 
Total elapsed time: 109.41131424577907. Arrivals time: 0.5822087209671736 Scheduler time: 108.6121184444055 Scheduler overhead time: 0.08353403396904469 Adapter cache time: 0.018682437017560005 Engine time: 0.0822732774540782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.66013366216794,
    "estimated_duration": 3600.069352053588,
    "input_throughput": 7780.497890692595,
    "output_throughput": 6913.2779305495815,
    "total_throughput": 14693.775821242178,
    "itl": 107.23152252842705,
    "ttft": 1973685.3126816982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.559340441618124,
    "arrivals": 1252442,
    "finished_requests": 113335,
    "scheduler_time": 292.941296481151
}
#Debug simulation 
Total elapsed time: 109.66029624408111. Arrivals time: 0.5842973347753286 Scheduler time: 108.8573072841391 Scheduler overhead time: 0.08459865255281329 Adapter cache time: 0.01884899055585265 Engine time: 0.0823843008838594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 107.79545829305425,
    "estimated_duration": 3600.048458338525,
    "input_throughput": 7810.199869636324,
    "output_throughput": 6903.727071349025,
    "total_throughput": 14713.92694098535,
    "itl": 106.38583273296881,
    "ttft": 1978955.9919897753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 470,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4690645082807114,
    "arrivals": 1252442,
    "finished_requests": 113595,
    "scheduler_time": 291.9884517211275
}
#Debug simulation 
Total elapsed time: 107.79561840137467. Arrivals time: 0.577226740308106 Scheduler time: 107.00114959618077 Scheduler overhead time: 0.08384010894224048 Adapter cache time: 0.018652810715138912 Engine time: 0.08199755428358912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 109.69060367904603,
    "estimated_duration": 3600.018049034152,
    "input_throughput": 7780.459047285815,
    "output_throughput": 6913.1067291945965,
    "total_throughput": 14693.565776480411,
    "itl": 107.23234751787709,
    "ttft": 1973699.2027878023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5795868012309109,
    "arrivals": 1252442,
    "finished_requests": 113333,
    "scheduler_time": 292.9343633422033
}
#Debug simulation 
Total elapsed time: 109.6907649259083. Arrivals time: 0.6002890672534704 Scheduler time: 108.87157763633877 Scheduler overhead time: 0.0840222337283194 Adapter cache time: 0.018885361962020397 Engine time: 0.08280548406764865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 108.84183041891083,
    "estimated_duration": 3600.0148721420005,
    "input_throughput": 7768.045409034892,
    "output_throughput": 6871.569390290073,
    "total_throughput": 14639.614799324965,
    "itl": 107.23094934451814,
    "ttft": 1975662.6276790171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 481,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4382141918479323,
    "arrivals": 1252442,
    "finished_requests": 113028,
    "scheduler_time": 293.78006780871215
}
#Debug simulation 
Total elapsed time: 108.84199552889913. Arrivals time: 0.587538072373718 Scheduler time: 108.03529994329438 Scheduler overhead time: 0.08372343750670552 Adapter cache time: 0.01901619555428624 Engine time: 0.08295983402058482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.05-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 5.000e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [540, 34560, 34560, 33, 34560, 34560, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 34560, 540, 34560, 34560, 33, 34560, 540, 540, 34560, 34560, 540, 33, 33, 540, 34560, 34560, 540, 540, 33, 33, 540, 34560, 34560, 33, 34560, 540, 33, 540, 34560, 33, 540, 34560, 34560, 540, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 540, 540, 540, 33, 540, 33, 34560, 33, 34560, 540, 34560, 34560, 33, 34560, 33, 34560, 540, 33, 33, 540, 540, 34560, 540, 34560, 34560, 34560, 33, 540, 540, 33, 34560, 540, 34560, 34560, 540, 33, 540, 540, 540, 33, 34560, 540, 34560, 33, 34560, 33, 33, 540, 34560, 34560, 540, 33, 540, 33, 540, 34560, 34560, 540, 33, 540, 33, 34560, 33, 33, 33, 33, 34560, 540, 540, 34560, 540, 540, 33, 540, 34560, 540, 33, 33, 540, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 540, 34560, 540, 540, 540, 33, 34560, 33, 34560, 540, 33, 540, 33, 33, 540, 33, 540, 34560, 34560, 34560, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 33, 33, 34560, 540, 34560, 540, 34560, 540, 33, 540, 33, 33, 33, 34560, 34560, 540, 540, 33, 33, 540, 33, 34560, 33, 33, 540, 33, 34560, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 33, 540, 34560, 540, 540, 34560, 540, 33, 540, 33, 34560, 540, 540, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 540, 33, 540, 33, 540, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 540, 540, 34560, 33, 34560, 33, 33, 33, 34560, 540, 34560, 34560, 33, 540, 540, 540, 33, 540, 33, 540, 540, 34560, 33, 33, 540, 33, 540, 540, 33, 34560, 34560, 34560, 33, 540, 540, 540, 540, 33, 540, 33, 34560, 33, 33, 34560, 540, 34560, 540, 540, 540, 540, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 540, 34560, 540, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3759198 . Total input tokens: 836988170 . Total output tokens: 751758956
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.70859621232376,
    "estimated_duration": 3600.0376476798106,
    "input_throughput": 7780.416690378791,
    "output_throughput": 6913.069094163398,
    "total_throughput": 14693.48578454219,
    "itl": 107.2325517057199,
    "ttft": 1973707.0028766624,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 477,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5994558994844548,
    "arrivals": 1252442,
    "finished_requests": 113333,
    "scheduler_time": 292.93459308252636
}
#Debug simulation 
Total elapsed time: 109.70875602122396. Arrivals time: 0.5920289307832718 Scheduler time: 108.89651288324967 Scheduler overhead time: 0.08514934312552214 Adapter cache time: 0.01877636183053255 Engine time: 0.08320895070210099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 110.05177322309464,
    "estimated_duration": 3600.0271674947735,
    "input_throughput": 7792.564804315669,
    "output_throughput": 6895.016855462671,
    "total_throughput": 14687.58165977834,
    "itl": 107.52147834434686,
    "ttft": 1985720.3861300754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 508,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5547277739178569,
    "arrivals": 1246365,
    "finished_requests": 113601,
    "scheduler_time": 292.5854965889442
}
#Debug simulation 
Total elapsed time: 110.05194386839867. Arrivals time: 0.5959264915436506 Scheduler time: 109.23867306532338 Scheduler overhead time: 0.08351194206625223 Adapter cache time: 0.019157785922288895 Engine time: 0.08220764389261603 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.57121990201995,
    "estimated_duration": 3600.02166216857,
    "input_throughput": 7821.1523824663,
    "output_throughput": 6950.832341638365,
    "total_throughput": 14771.984724104665,
    "itl": 108.4907904915495,
    "ttft": 1966111.2276371536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8400202060584034,
    "arrivals": 1246365,
    "finished_requests": 113978,
    "scheduler_time": 291.86366576933364
}
#Debug simulation 
Total elapsed time: 108.57138111582026. Arrivals time: 0.5967543567530811 Scheduler time: 107.75459369504824 Scheduler overhead time: 0.08478871639817953 Adapter cache time: 0.019546637777239084 Engine time: 0.08246476668864489 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.11171000218019,
    "estimated_duration": 3600.024916238598,
    "input_throughput": 7821.145312910354,
    "output_throughput": 6950.826058766518,
    "total_throughput": 14771.971371676873,
    "itl": 108.49080852273822,
    "ttft": 1966112.3359065698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.843349688649189,
    "arrivals": 1246365,
    "finished_requests": 113978,
    "scheduler_time": 291.8636903953271
}
#Debug simulation 
Total elapsed time: 109.11187648074701. Arrivals time: 0.6044145412743092 Scheduler time: 108.28786436002702 Scheduler overhead time: 0.08417587727308273 Adapter cache time: 0.019728164188563824 Engine time: 0.08303133444860578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 109.79971163766459,
    "estimated_duration": 3600.0071386185973,
    "input_throughput": 7821.184213208034,
    "output_throughput": 6950.860939015231,
    "total_throughput": 14772.045152223265,
    "itl": 108.48894780029975,
    "ttft": 1966139.4804259602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7623870955547225,
    "arrivals": 1246365,
    "finished_requests": 113979,
    "scheduler_time": 291.870062137607
}
#Debug simulation 
Total elapsed time: 109.79987002070993. Arrivals time: 0.6051787482574582 Scheduler time: 108.97274612961337 Scheduler overhead time: 0.08469289215281606 Adapter cache time: 0.019821714144200087 Engine time: 0.08384447079151869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 108.71776089910418,
    "estimated_duration": 3600.048673155179,
    "input_throughput": 7821.093700747953,
    "output_throughput": 6950.780189888112,
    "total_throughput": 14771.873890636065,
    "itl": 108.49114913948742,
    "ttft": 1966120.8935808442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8672429080680049,
    "arrivals": 1246365,
    "finished_requests": 113978,
    "scheduler_time": 291.86375416967024
}
#Debug simulation 
Total elapsed time: 108.71791745210066. Arrivals time: 0.5886800340376794 Scheduler time: 107.90801446838304 Scheduler overhead time: 0.08502661343663931 Adapter cache time: 0.019924717489629984 Engine time: 0.08299901336431503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 109.91096806805581,
    "estimated_duration": 3600.0723581321595,
    "input_throughput": 7731.3812699145265,
    "output_throughput": 6828.988296433981,
    "total_throughput": 14560.369566348507,
    "itl": 107.25814429467093,
    "ttft": 1985942.2924636903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 504,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.50698534863068,
    "arrivals": 1246365,
    "finished_requests": 112601,
    "scheduler_time": 296.2498581338002
}
#Debug simulation 
Total elapsed time: 109.91121084615588. Arrivals time: 0.9634209056384861 Scheduler time: 108.72827244503424 Scheduler overhead time: 0.08461495721712708 Adapter cache time: 0.019177861977368593 Engine time: 0.08226771699264646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.0125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  3.2   ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 135, 34560, 34560, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 34560, 270, 34560, 34560, 135, 34560, 270, 270, 34560, 34560, 270, 135, 135, 270, 34560, 34560, 270, 270, 135, 135, 270, 34560, 34560, 135, 34560, 270, 135, 270, 34560, 135, 270, 34560, 34560, 270, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 270, 270, 270, 135, 270, 135, 34560, 135, 34560, 270, 34560, 34560, 135, 34560, 135, 34560, 270, 135, 135, 270, 270, 34560, 270, 34560, 34560, 34560, 135, 270, 270, 135, 34560, 270, 34560, 34560, 270, 135, 270, 270, 270, 135, 34560, 270, 34560, 135, 34560, 135, 135, 270, 34560, 34560, 270, 135, 270, 135, 270, 34560, 34560, 270, 135, 270, 135, 34560, 135, 135, 135, 135, 34560, 270, 270, 34560, 270, 270, 135, 270, 34560, 270, 135, 135, 270, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 270, 34560, 270, 270, 270, 135, 34560, 135, 34560, 270, 135, 270, 135, 135, 270, 135, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 135, 135, 34560, 270, 34560, 270, 34560, 270, 135, 270, 135, 135, 135, 34560, 34560, 270, 270, 135, 135, 270, 135, 34560, 135, 135, 270, 135, 34560, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 135, 270, 34560, 270, 270, 34560, 270, 135, 270, 135, 34560, 270, 270, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 270, 135, 270, 135, 270, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 270, 270, 34560, 135, 34560, 135, 135, 135, 34560, 270, 34560, 34560, 135, 270, 270, 270, 135, 270, 135, 270, 270, 34560, 135, 135, 270, 135, 270, 270, 135, 34560, 34560, 34560, 135, 270, 270, 270, 270, 135, 270, 135, 34560, 135, 135, 34560, 270, 34560, 270, 270, 270, 270, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 270, 34560, 270, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 3741120 . Total input tokens: 832920866 . Total output tokens: 748146017
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 108.76231642719358,
    "estimated_duration": 3600.010967255715,
    "input_throughput": 7821.115339952247,
    "output_throughput": 6950.85243561775,
    "total_throughput": 14771.967775569998,
    "itl": 108.49217226307019,
    "ttft": 1966015.758996315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8906331123411613,
    "arrivals": 1246365,
    "finished_requests": 113977,
    "scheduler_time": 291.85737048658086
}
#Debug simulation 
Total elapsed time: 108.76247239904478. Arrivals time: 0.5841135205700994 Scheduler time: 107.96068699797615 Scheduler overhead time: 0.08310713618993759 Adapter cache time: 0.019319052807986736 Engine time: 0.08280645031481981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.76420072698966,
    "estimated_duration": 3600.032374908646,
    "input_throughput": 7783.254171627007,
    "output_throughput": 6901.248492419587,
    "total_throughput": 14684.502664046595,
    "itl": 107.03869647485443,
    "ttft": 1988112.3113345527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5180019209906626,
    "arrivals": 1243986,
    "finished_requests": 113214,
    "scheduler_time": 292.0169640588461
}
#Debug simulation 
Total elapsed time: 105.76446257391945. Arrivals time: 0.5824985671788454 Scheduler time: 104.9636793229729 Scheduler overhead time: 0.08411593968048692 Adapter cache time: 0.018847083672881126 Engine time: 0.08231806708499789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.68746861303225,
    "estimated_duration": 3600.057105716609,
    "input_throughput": 7802.268179412345,
    "output_throughput": 6911.134259645978,
    "total_throughput": 14713.402439058324,
    "itl": 106.98259855685214,
    "ttft": 1994002.2335911468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5991439089505064,
    "arrivals": 1243986,
    "finished_requests": 113420,
    "scheduler_time": 291.5774943896643
}
#Debug simulation 
Total elapsed time: 109.68763253977522. Arrivals time: 0.5896786744706333 Scheduler time: 108.87931944569573 Scheduler overhead time: 0.08414195524528623 Adapter cache time: 0.01893205475062132 Engine time: 0.08308628667145967 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 110.17040767800063,
    "estimated_duration": 3600.0602232203446,
    "input_throughput": 7802.261422969761,
    "output_throughput": 6911.128274888631,
    "total_throughput": 14713.389697858393,
    "itl": 106.9826089766272,
    "ttft": 1994003.6737711797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6019414141029216,
    "arrivals": 1243986,
    "finished_requests": 113420,
    "scheduler_time": 291.5776143110699
}
#Debug simulation 
Total elapsed time: 110.17058294406161. Arrivals time: 0.9789179898798466 Scheduler time: 108.9724804344587 Scheduler overhead time: 0.08415767038241029 Adapter cache time: 0.019179360009729862 Engine time: 0.0824540969915688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 110.23790952097625,
    "estimated_duration": 3600.118330498143,
    "input_throughput": 7802.6121425051,
    "output_throughput": 6911.251441159493,
    "total_throughput": 14713.863583664594,
    "itl": 106.98157038277832,
    "ttft": 1993995.4135476353,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5337686580000391,
    "arrivals": 1243986,
    "finished_requests": 113426,
    "scheduler_time": 291.5864577344642
}
#Debug simulation 
Total elapsed time: 110.23808166896924. Arrivals time: 0.6680075326003134 Scheduler time: 109.35294486721978 Scheduler overhead time: 0.08344857068732381 Adapter cache time: 0.018855313770473003 Engine time: 0.08224957343190908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 109.84752729488537,
    "estimated_duration": 3600.080485792844,
    "input_throughput": 7802.217508982736,
    "output_throughput": 6911.089376525588,
    "total_throughput": 14713.306885508324,
    "itl": 106.98292184576644,
    "ttft": 1994011.4545738045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6220620199292934,
    "arrivals": 1243986,
    "finished_requests": 113420,
    "scheduler_time": 291.5776562391773
}
#Debug simulation 
Total elapsed time: 109.84769855905324. Arrivals time: 0.5938624856062233 Scheduler time: 109.03482883656397 Scheduler overhead time: 0.0844364701770246 Adapter cache time: 0.019263469614088535 Engine time: 0.08244202891364694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 105.598024725914,
    "estimated_duration": 3600.124093956588,
    "input_throughput": 7783.181709496341,
    "output_throughput": 6901.44015916236,
    "total_throughput": 14684.6218686587,
    "itl": 107.03882091943207,
    "ttft": 1988145.363658003,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4830649462714633,
    "arrivals": 1243986,
    "finished_requests": 113218,
    "scheduler_time": 292.02588335517817
}
#Debug simulation 
Total elapsed time: 105.5981853287667. Arrivals time: 0.5871903342194855 Scheduler time: 104.79413567343727 Scheduler overhead time: 0.082887745462358 Adapter cache time: 0.018726833164691925 Engine time: 0.08245055098086596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   3.2    ]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 66, 34560, 34560, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 34560, 270, 34560, 34560, 66, 34560, 270, 270, 34560, 34560, 270, 66, 66, 270, 34560, 34560, 270, 270, 66, 66, 270, 34560, 34560, 66, 34560, 270, 66, 270, 34560, 66, 270, 34560, 34560, 270, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 270, 270, 270, 66, 270, 66, 34560, 66, 34560, 270, 34560, 34560, 66, 34560, 66, 34560, 270, 66, 66, 270, 270, 34560, 270, 34560, 34560, 34560, 66, 270, 270, 66, 34560, 270, 34560, 34560, 270, 66, 270, 270, 270, 66, 34560, 270, 34560, 66, 34560, 66, 66, 270, 34560, 34560, 270, 66, 270, 66, 270, 34560, 34560, 270, 66, 270, 66, 34560, 66, 66, 66, 66, 34560, 270, 270, 34560, 270, 270, 66, 270, 34560, 270, 66, 66, 270, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 270, 34560, 270, 270, 270, 66, 34560, 66, 34560, 270, 66, 270, 66, 66, 270, 66, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 66, 66, 34560, 270, 34560, 270, 34560, 270, 66, 270, 66, 66, 66, 34560, 34560, 270, 270, 66, 66, 270, 66, 34560, 66, 66, 270, 66, 34560, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 66, 270, 34560, 270, 270, 34560, 270, 66, 270, 66, 34560, 270, 270, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 270, 66, 270, 66, 270, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 270, 270, 34560, 66, 34560, 66, 66, 66, 34560, 270, 34560, 34560, 66, 270, 270, 270, 66, 270, 66, 270, 270, 34560, 66, 66, 270, 66, 270, 270, 66, 34560, 34560, 34560, 66, 270, 270, 270, 270, 66, 270, 66, 34560, 66, 66, 34560, 270, 34560, 270, 270, 270, 270, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 270, 34560, 270, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3733806 . Total input tokens: 831305829 . Total output tokens: 746662262
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.87438318133354,
    "estimated_duration": 3600.1011756364787,
    "input_throughput": 7802.172669503957,
    "output_throughput": 6911.049658375578,
    "total_throughput": 14713.222327879534,
    "itl": 106.98326495081578,
    "ttft": 1994019.62679476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 490,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6431886560469848,
    "arrivals": 1243986,
    "finished_requests": 113420,
    "scheduler_time": 291.5777196396096
}
#Debug simulation 
Total elapsed time: 109.87454615905881. Arrivals time: 0.5875048856250942 Scheduler time: 109.06862753164023 Scheduler overhead time: 0.0837815348058939 Adapter cache time: 0.018907825462520123 Engine time: 0.08286361116915941 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 112.18560635577887,
    "estimated_duration": 3600.1210024112606,
    "input_throughput": 7791.17479140658,
    "output_throughput": 6885.263018492388,
    "total_throughput": 14676.437809898967,
    "itl": 107.28562304924037,
    "ttft": 1983498.6922674724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 439,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3435541195864895,
    "arrivals": 1242821,
    "finished_requests": 113253,
    "scheduler_time": 293.18678078240305
}
#Debug simulation 
Total elapsed time: 112.1857690778561. Arrivals time: 0.5872908062301576 Scheduler time: 111.38039906928316 Scheduler overhead time: 0.08379152929410338 Adapter cache time: 0.01855583442375064 Engine time: 0.08279759855940938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.93119341135025,
    "estimated_duration": 3600.0369874205553,
    "input_throughput": 7885.076486488857,
    "output_throughput": 6982.0868751712205,
    "total_throughput": 14867.163361660077,
    "itl": 107.98656913851751,
    "ttft": 1979582.8449528562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5063035206217381,
    "arrivals": 1242821,
    "finished_requests": 114754,
    "scheduler_time": 287.6405044743777
}
#Debug simulation 
Total elapsed time: 109.93135499441996. Arrivals time: 0.5957565000280738 Scheduler time: 109.1188150998205 Scheduler overhead time: 0.08362848963588476 Adapter cache time: 0.018670748453587294 Engine time: 0.08203707123175263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 110.05753332516178,
    "estimated_duration": 3600.0393064794725,
    "input_throughput": 7885.071407111833,
    "output_throughput": 6982.082377478431,
    "total_throughput": 14867.153784590264,
    "itl": 107.98662039295724,
    "ttft": 1979583.7811207187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5086206550709993,
    "arrivals": 1242821,
    "finished_requests": 114754,
    "scheduler_time": 287.6405063988253
}
#Debug simulation 
Total elapsed time: 110.0577672701329. Arrivals time: 0.5886870985850692 Scheduler time: 109.2523975376971 Scheduler overhead time: 0.0833029206842184 Adapter cache time: 0.018889050465077162 Engine time: 0.08225147658959031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 110.21545365499333,
    "estimated_duration": 3600.075653708454,
    "input_throughput": 7884.991797535941,
    "output_throughput": 6982.011884696793,
    "total_throughput": 14867.003682232733,
    "itl": 107.98535146026532,
    "ttft": 1979558.6424080273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.444605627537236,
    "arrivals": 1242821,
    "finished_requests": 114754,
    "scheduler_time": 287.64764138128277
}
#Debug simulation 
Total elapsed time: 110.21561529114842. Arrivals time: 0.5875034346245229 Scheduler time: 109.41114036086947 Scheduler overhead time: 0.08401192585006356 Adapter cache time: 0.018373651895672083 Engine time: 0.0822802372276783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 110.38691537221894,
    "estimated_duration": 3600.058103471759,
    "input_throughput": 7885.030236768978,
    "output_throughput": 6982.045921914432,
    "total_throughput": 14867.07615868341,
    "itl": 107.98691965078272,
    "ttft": 1979590.9114972085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.527609476819639,
    "arrivals": 1242821,
    "finished_requests": 114754,
    "scheduler_time": 287.6406146851207
}
#Debug simulation 
Total elapsed time: 110.38708819635212. Arrivals time: 0.5925671304576099 Scheduler time: 109.57812110939994 Scheduler overhead time: 0.0832395451143384 Adapter cache time: 0.01886012265458703 Engine time: 0.08171976078301668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 108.80396486492828,
    "estimated_duration": 3600.0795781005168,
    "input_throughput": 7790.049745177319,
    "output_throughput": 6883.394231267213,
    "total_throughput": 14673.443976444532,
    "itl": 107.36674975400784,
    "ttft": 1979773.3265648468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 449,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.342532582411066,
    "arrivals": 1242821,
    "finished_requests": 113246,
    "scheduler_time": 293.1592613986184
}
#Debug simulation 
Total elapsed time: 108.80412045493722. Arrivals time: 0.5977133633568883 Scheduler time: 107.98999377852306 Scheduler overhead time: 0.08288867957890034 Adapter cache time: 0.01840386399999261 Engine time: 0.08213700959458947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.025-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 2.500e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [270, 34560, 34560, 33, 34560, 34560, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 34560, 270, 34560, 34560, 33, 34560, 270, 270, 34560, 34560, 270, 33, 33, 270, 34560, 34560, 270, 270, 33, 33, 270, 34560, 34560, 33, 34560, 270, 33, 270, 34560, 33, 270, 34560, 34560, 270, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 270, 270, 270, 33, 270, 33, 34560, 33, 34560, 270, 34560, 34560, 33, 34560, 33, 34560, 270, 33, 33, 270, 270, 34560, 270, 34560, 34560, 34560, 33, 270, 270, 33, 34560, 270, 34560, 34560, 270, 33, 270, 270, 270, 33, 34560, 270, 34560, 33, 34560, 33, 33, 270, 34560, 34560, 270, 33, 270, 33, 270, 34560, 34560, 270, 33, 270, 33, 34560, 33, 33, 33, 33, 34560, 270, 270, 34560, 270, 270, 33, 270, 34560, 270, 33, 33, 270, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 270, 34560, 270, 270, 270, 33, 34560, 33, 34560, 270, 33, 270, 33, 33, 270, 33, 270, 34560, 34560, 34560, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 33, 33, 34560, 270, 34560, 270, 34560, 270, 33, 270, 33, 33, 33, 34560, 34560, 270, 270, 33, 33, 270, 33, 34560, 33, 33, 270, 33, 34560, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 33, 270, 34560, 270, 270, 34560, 270, 33, 270, 33, 34560, 270, 270, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 270, 33, 270, 33, 270, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 270, 270, 34560, 33, 34560, 33, 33, 33, 34560, 270, 34560, 34560, 33, 270, 270, 270, 33, 270, 33, 270, 270, 34560, 33, 33, 270, 33, 270, 270, 33, 34560, 34560, 34560, 33, 270, 270, 270, 270, 33, 270, 33, 34560, 33, 33, 34560, 270, 34560, 270, 270, 270, 270, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 270, 34560, 270, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3730308 . Total input tokens: 830506775 . Total output tokens: 745982208
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 109.90129645587876,
    "estimated_duration": 3600.0788560462815,
    "input_throughput": 7884.9847836874915,
    "output_throughput": 6982.005674065952,
    "total_throughput": 14866.990457753443,
    "itl": 107.98730221875627,
    "ttft": 1979599.1146738357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 461,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5479815902188414,
    "arrivals": 1242821,
    "finished_requests": 114754,
    "scheduler_time": 287.6406950305216
}
#Debug simulation 
Total elapsed time: 109.90145877189934. Arrivals time: 0.5993829760700464 Scheduler time: 109.08465766115114 Scheduler overhead time: 0.08410024270415306 Adapter cache time: 0.018869025632739067 Engine time: 0.08203694364055991 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-8/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 113.1877960851416,
    "estimated_duration": 3600.017724301049,
    "input_throughput": 7822.57315287735,
    "output_throughput": 6975.085380968574,
    "total_throughput": 14797.658533845924,
    "itl": 107.8740624038506,
    "ttft": 1988949.3102609573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3925219234894153,
    "arrivals": 1239193,
    "finished_requests": 114496,
    "scheduler_time": 287.8408682320468
}
#Debug simulation 
Total elapsed time: 113.18796420097351. Arrivals time: 0.5878077587112784 Scheduler time: 112.38351707393304 Scheduler overhead time: 0.08282952476292849 Adapter cache time: 0.018508492968976498 Engine time: 0.0826277113519609 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-16/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 113.30126687092707,
    "estimated_duration": 3600.1081618673966,
    "input_throughput": 7822.37664364854,
    "output_throughput": 6974.910161303342,
    "total_throughput": 14797.286804951882,
    "itl": 107.87565422615687,
    "ttft": 1988985.2735021322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4830514797126,
    "arrivals": 1239193,
    "finished_requests": 114496,
    "scheduler_time": 287.84107635787626
}
#Debug simulation 
Total elapsed time: 113.30142997158691. Arrivals time: 0.5937718618661165 Scheduler time: 112.49120034696534 Scheduler overhead time: 0.08404402062296867 Adapter cache time: 0.018495789729058743 Engine time: 0.08182518510147929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-8-32/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 113.06583102140576,
    "estimated_duration": 3600.1112584521857,
    "input_throughput": 7822.3699153418875,
    "output_throughput": 6974.904161933,
    "total_throughput": 14797.274077274888,
    "itl": 107.87567605591991,
    "ttft": 1988986.6725681687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4859753245487897,
    "arrivals": 1239193,
    "finished_requests": 114496,
    "scheduler_time": 287.8411490592309
}
#Debug simulation 
Total elapsed time: 113.0659922491759. Arrivals time: 0.6123867412097752 Scheduler time: 112.23684083577245 Scheduler overhead time: 0.08352794032543898 Adapter cache time: 0.018335784785449505 Engine time: 0.08227453660219908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-16/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 113.33290897402912,
    "estimated_duration": 3600.0484685668284,
    "input_throughput": 7822.506348424524,
    "output_throughput": 6975.025814026445,
    "total_throughput": 14797.532162450969,
    "itl": 107.8745984332541,
    "ttft": 1988961.1972441496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4238051585387406,
    "arrivals": 1239193,
    "finished_requests": 114496,
    "scheduler_time": 287.8409294942039
}
#Debug simulation 
Total elapsed time: 113.33307823911309. Arrivals time: 0.585397120565176 Scheduler time: 112.53194118198007 Scheduler overhead time: 0.08313529752194881 Adapter cache time: 0.01833044458180666 Engine time: 0.08187281619757414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_8-16-32/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 113.61719109583646,
    "estimated_duration": 3600.0353227573314,
    "input_throughput": 7731.433862343849,
    "output_throughput": 6882.459692374012,
    "total_throughput": 14613.89355471786,
    "itl": 107.5620796677771,
    "ttft": 1986309.773046465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.445762287918483,
    "arrivals": 1239193,
    "finished_requests": 113032,
    "scheduler_time": 293.37358729925415
}
#Debug simulation 
Total elapsed time: 113.61735391896218. Arrivals time: 0.580871872138232 Scheduler time: 112.81940666865557 Scheduler overhead time: 0.0834683976136148 Adapter cache time: 0.018432583659887314 Engine time: 0.0822382727637887 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-16/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 112.9908292433247,
    "estimated_duration": 3600.1126007511375,
    "input_throughput": 7822.483106257354,
    "output_throughput": 6975.05655649792,
    "total_throughput": 14797.539662755275,
    "itl": 107.87401999082799,
    "ttft": 1988984.6877122107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3604728841804785,
    "arrivals": 1239193,
    "finished_requests": 114499,
    "scheduler_time": 287.8497568793856
}
#Debug simulation 
Total elapsed time: 112.99099985742941. Arrivals time: 0.5907909884117544 Scheduler time: 112.18435732927173 Scheduler overhead time: 0.08322909334674478 Adapter cache time: 0.01832720683887601 Engine time: 0.08170705428346992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.00625_size_16-16-32/adapters_320_slots_16_rate_3.2-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  3.2    ]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 66, 34560, 34560, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 34560, 135, 34560, 34560, 66, 34560, 135, 135, 34560, 34560, 135, 66, 66, 135, 34560, 34560, 135, 135, 66, 66, 135, 34560, 34560, 66, 34560, 135, 66, 135, 34560, 66, 135, 34560, 34560, 135, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 135, 135, 135, 66, 135, 66, 34560, 66, 34560, 135, 34560, 34560, 66, 34560, 66, 34560, 135, 66, 66, 135, 135, 34560, 135, 34560, 34560, 34560, 66, 135, 135, 66, 34560, 135, 34560, 34560, 135, 66, 135, 135, 135, 66, 34560, 135, 34560, 66, 34560, 66, 66, 135, 34560, 34560, 135, 66, 135, 66, 135, 34560, 34560, 135, 66, 135, 66, 34560, 66, 66, 66, 66, 34560, 135, 135, 34560, 135, 135, 66, 135, 34560, 135, 66, 66, 135, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 135, 34560, 135, 135, 135, 66, 34560, 66, 34560, 135, 66, 135, 66, 66, 135, 66, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 66, 66, 34560, 135, 34560, 135, 34560, 135, 66, 135, 66, 66, 66, 34560, 34560, 135, 135, 66, 66, 135, 66, 34560, 66, 66, 135, 66, 34560, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 66, 135, 34560, 135, 135, 34560, 135, 66, 135, 66, 34560, 135, 135, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 135, 66, 135, 66, 135, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 135, 135, 34560, 66, 34560, 66, 66, 66, 34560, 135, 34560, 34560, 66, 135, 135, 135, 66, 135, 66, 135, 135, 34560, 66, 66, 135, 66, 135, 135, 66, 34560, 34560, 34560, 66, 135, 135, 135, 135, 66, 135, 66, 34560, 66, 66, 34560, 135, 34560, 135, 135, 135, 135, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 135, 34560, 135, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 3719361 . Total input tokens: 828083487 . Total output tokens: 743797253
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 114.1510011269711,
    "estimated_duration": 3600.054372128081,
    "input_throughput": 7731.392952142267,
    "output_throughput": 6882.423274444504,
    "total_throughput": 14613.81622658677,
    "itl": 107.56240071176778,
    "ttft": 1986317.3159334948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4647511096671226,
    "arrivals": 1239193,
    "finished_requests": 113032,
    "scheduler_time": 293.3736478482699
}
#Debug simulation 
Total elapsed time: 114.15125086717308. Arrivals time: 0.5965504059568048 Scheduler time: 113.33548032585531 Scheduler overhead time: 0.08479490038007498 Adapter cache time: 0.018671633675694466 Engine time: 0.08279933547601104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 109.18859938532114,
    "estimated_duration": 3600.0116779792093,
    "input_throughput": 7938.688136712497,
    "output_throughput": 7050.968794148061,
    "total_throughput": 14989.656930860558,
    "itl": 108.15291793108308,
    "ttft": 1970217.7256655598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.398642898977281,
    "arrivals": 1238058,
    "finished_requests": 115389,
    "scheduler_time": 285.5235033929698
}
#Debug simulation 
Total elapsed time: 109.18875455623493. Arrivals time: 0.5920649389736354 Scheduler time: 108.3824482113123 Scheduler overhead time: 0.08245264319702983 Adapter cache time: 0.018619057722389698 Engine time: 0.08108687261119485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 113.65274732885882,
    "estimated_duration": 3600.1119332227636,
    "input_throughput": 7880.248871763223,
    "output_throughput": 6959.889154771341,
    "total_throughput": 14840.138026534565,
    "itl": 107.73660912353108,
    "ttft": 1983749.7206588853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4391477989917676,
    "arrivals": 1238058,
    "finished_requests": 114445,
    "scheduler_time": 288.50622606348253
}
#Debug simulation 
Total elapsed time: 113.65291559696198. Arrivals time: 0.6130396155640483 Scheduler time: 112.82259320514277 Scheduler overhead time: 0.08421619050204754 Adapter cache time: 0.01824175426736474 Engine time: 0.08239280944690108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 113.91913625504822,
    "estimated_duration": 3600.114463750192,
    "input_throughput": 7880.243332721031,
    "output_throughput": 6959.884262651776,
    "total_throughput": 14840.127595372807,
    "itl": 107.73664877002687,
    "ttft": 1983750.6578588649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 441,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4416798231937076,
    "arrivals": 1238058,
    "finished_requests": 114445,
    "scheduler_time": 288.50622456669
}
#Debug simulation 
Total elapsed time: 113.91931356023997. Arrivals time: 0.5895249610766768 Scheduler time: 113.11250970698893 Scheduler overhead time: 0.08426667517051101 Adapter cache time: 0.01828388124704361 Engine time: 0.0822143042460084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 110.8701586718671,
    "estimated_duration": 3600.025772577653,
    "input_throughput": 7931.675438966342,
    "output_throughput": 7012.041189339984,
    "total_throughput": 14943.716628306327,
    "itl": 108.35484023167918,
    "ttft": 1978924.140858245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.422170777264979,
    "arrivals": 1238058,
    "finished_requests": 115259,
    "scheduler_time": 285.4854811952086
}
#Debug simulation 
Total elapsed time: 110.87031938275322. Arrivals time: 0.591850358992815 Scheduler time: 110.06410417566076 Scheduler overhead time: 0.08266009530052543 Adapter cache time: 0.01839421922340989 Engine time: 0.08113042078912258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 112.23506755707785,
    "estimated_duration": 3600.0931822367224,
    "input_throughput": 7894.5570465323535,
    "output_throughput": 6981.317351453868,
    "total_throughput": 14875.874397986221,
    "itl": 108.20840287083145,
    "ttft": 1979976.0556625517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5714362647011926,
    "arrivals": 1238058,
    "finished_requests": 114766,
    "scheduler_time": 287.42360539715395
}
#Debug simulation 
Total elapsed time: 112.23522317502648. Arrivals time: 0.608148240018636 Scheduler time: 111.41122110420838 Scheduler overhead time: 0.08339869137853384 Adapter cache time: 0.018275194335728884 Engine time: 0.08208225946873426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 109.26983527094126,
    "estimated_duration": 3600.0145918702283,
    "input_throughput": 7938.681711051858,
    "output_throughput": 7050.963087017125,
    "total_throughput": 14989.644798068983,
    "itl": 108.15245900867384,
    "ttft": 1970204.391614274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 457,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3664529847702827,
    "arrivals": 1238058,
    "finished_requests": 115389,
    "scheduler_time": 285.52880438400047
}
#Debug simulation 
Total elapsed time: 109.26999355480075. Arrivals time: 0.5918077323585749 Scheduler time: 108.46296307910234 Scheduler overhead time: 0.0824672132730484 Adapter cache time: 0.018194546923041344 Engine time: 0.08182294107973576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.0125-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.250e-02 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [135, 34560, 34560, 33, 34560, 34560, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 34560, 135, 34560, 34560, 33, 34560, 135, 135, 34560, 34560, 135, 33, 33, 135, 34560, 34560, 135, 135, 33, 33, 135, 34560, 34560, 33, 34560, 135, 33, 135, 34560, 33, 135, 34560, 34560, 135, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 135, 135, 135, 33, 135, 33, 34560, 33, 34560, 135, 34560, 34560, 33, 34560, 33, 34560, 135, 33, 33, 135, 135, 34560, 135, 34560, 34560, 34560, 33, 135, 135, 33, 34560, 135, 34560, 34560, 135, 33, 135, 135, 135, 33, 34560, 135, 34560, 33, 34560, 33, 33, 135, 34560, 34560, 135, 33, 135, 33, 135, 34560, 34560, 135, 33, 135, 33, 34560, 33, 33, 33, 33, 34560, 135, 135, 34560, 135, 135, 33, 135, 34560, 135, 33, 33, 135, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 135, 34560, 135, 135, 135, 33, 34560, 33, 34560, 135, 33, 135, 33, 33, 135, 33, 135, 34560, 34560, 34560, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 33, 33, 34560, 135, 34560, 135, 34560, 135, 33, 135, 33, 33, 33, 34560, 34560, 135, 135, 33, 33, 135, 33, 34560, 33, 33, 135, 33, 34560, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 33, 135, 34560, 135, 135, 34560, 135, 33, 135, 33, 34560, 135, 135, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 135, 33, 135, 33, 135, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 135, 135, 34560, 33, 34560, 33, 33, 33, 34560, 135, 34560, 34560, 33, 135, 135, 135, 33, 135, 33, 135, 135, 34560, 33, 33, 135, 33, 135, 135, 33, 34560, 34560, 34560, 33, 135, 135, 135, 135, 33, 135, 33, 34560, 33, 33, 34560, 135, 34560, 135, 135, 135, 135, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 135, 34560, 135, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3715863 . Total input tokens: 827311191 . Total output tokens: 743093542
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 112.62388261174783,
    "estimated_duration": 3600.112967913727,
    "input_throughput": 7894.513659239452,
    "output_throughput": 6981.278983188367,
    "total_throughput": 14875.79264242782,
    "itl": 108.20872972342336,
    "ttft": 1979983.6284890724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 475,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5910538553819056,
    "arrivals": 1238058,
    "finished_requests": 114766,
    "scheduler_time": 287.42377348349424
}
#Debug simulation 
Total elapsed time: 112.6240447089076. Arrivals time: 0.59313875855878 Scheduler time: 111.8162201908417 Scheduler overhead time: 0.08295557601377368 Adapter cache time: 0.01814671140164137 Engine time: 0.08137619309127331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-8/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 107.33008125424385,
    "estimated_duration": 3600.017404141226,
    "input_throughput": 8072.724305879473,
    "output_throughput": 7126.293325829039,
    "total_throughput": 15199.017631708512,
    "itl": 108.80007725820971,
    "ttft": 1971909.8895662627,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3221307053789595,
    "arrivals": 1235689,
    "finished_requests": 117430,
    "scheduler_time": 278.8141401081225
}
#Debug simulation 
Total elapsed time: 107.33024431299418. Arrivals time: 0.5978767103515565 Scheduler time: 106.52243209816515 Scheduler overhead time: 0.08117931056767702 Adapter cache time: 0.017935481388121843 Engine time: 0.07949252473190427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-16/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.14322284283116,
    "estimated_duration": 3600.1035015306143,
    "input_throughput": 8072.531244627847,
    "output_throughput": 7126.122898714621,
    "total_throughput": 15198.654143342468,
    "itl": 108.80195613921833,
    "ttft": 1971943.3983884645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4077427978348043,
    "arrivals": 1235689,
    "finished_requests": 117430,
    "scheduler_time": 278.81472544360054
}
#Debug simulation 
Total elapsed time: 107.14338917518035. Arrivals time: 0.5956910965032876 Scheduler time: 106.33499564696103 Scheduler overhead time: 0.082422886043787 Adapter cache time: 0.017969724722206593 Engine time: 0.08027056697756052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-8-32/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.29602768272161,
    "estimated_duration": 3600.106569297285,
    "input_throughput": 8072.524365764173,
    "output_throughput": 7126.116826315958,
    "total_throughput": 15198.641192080131,
    "itl": 108.80201432096476,
    "ttft": 1971944.7707670005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4105784311145626,
    "arrivals": 1235689,
    "finished_requests": 117430,
    "scheduler_time": 278.81475749981286
}
#Debug simulation 
Total elapsed time: 107.29619217477739. Arrivals time: 0.5911479741334915 Scheduler time: 106.49273885181174 Scheduler overhead time: 0.08209908753633499 Adapter cache time: 0.018247900065034628 Engine time: 0.08011362561956048 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-16/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 106.92396857216954,
    "estimated_duration": 3600.046925060537,
    "input_throughput": 8072.658108341548,
    "output_throughput": 7126.234889165674,
    "total_throughput": 15198.89299750722,
    "itl": 108.80071788899214,
    "ttft": 1971921.479566576,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3513566438900282,
    "arrivals": 1235689,
    "finished_requests": 117430,
    "scheduler_time": 278.81423501170906
}
#Debug simulation 
Total elapsed time: 106.92423605313525. Arrivals time: 0.6062265583314002 Scheduler time: 106.10839038575068 Scheduler overhead time: 0.08019329886883497 Adapter cache time: 0.01786091271787882 Engine time: 0.07997852610424161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_8-16-32/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 107.42216782271862,
    "estimated_duration": 3600.123863633492,
    "input_throughput": 8072.4855868344175,
    "output_throughput": 7126.082593754826,
    "total_throughput": 15198.568180589244,
    "itl": 108.80242564094763,
    "ttft": 1971951.3610230638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.42793245363981,
    "arrivals": 1235689,
    "finished_requests": 117430,
    "scheduler_time": 278.8149979292513
}
#Debug simulation 
Total elapsed time: 107.42232252983376. Arrivals time: 0.5895943096838892 Scheduler time: 106.6223667836748 Scheduler overhead time: 0.08117057941854 Adapter cache time: 0.017861996311694384 Engine time: 0.07988069811835885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-16/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 107.24625481292605,
    "estimated_duration": 3600.115729086635,
    "input_throughput": 8073.021865709194,
    "output_throughput": 7126.4967380671105,
    "total_throughput": 15199.518603776303,
    "itl": 108.79952495864708,
    "ttft": 1971970.3578429695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.291701727397731,
    "arrivals": 1235689,
    "finished_requests": 117437,
    "scheduler_time": 278.82315653359177
}
#Debug simulation 
Total elapsed time: 107.24642337067053. Arrivals time: 0.6039859866723418 Scheduler time: 106.43123743776232 Scheduler overhead time: 0.08146005915477872 Adapter cache time: 0.017921519000083208 Engine time: 0.0801424803212285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.00625-0.003125_size_16-16-32/adapters_320_slots_16_rate_3.2-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 6.250e-03 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [66, 34560, 34560, 33, 34560, 34560, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 34560, 66, 34560, 34560, 33, 34560, 66, 66, 34560, 34560, 66, 33, 33, 66, 34560, 34560, 66, 66, 33, 33, 66, 34560, 34560, 33, 34560, 66, 33, 66, 34560, 33, 66, 34560, 34560, 66, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 66, 66, 66, 33, 66, 33, 34560, 33, 34560, 66, 34560, 34560, 33, 34560, 33, 34560, 66, 33, 33, 66, 66, 34560, 66, 34560, 34560, 34560, 33, 66, 66, 33, 34560, 66, 34560, 34560, 66, 33, 66, 66, 66, 33, 34560, 66, 34560, 33, 34560, 33, 33, 66, 34560, 34560, 66, 33, 66, 33, 66, 34560, 34560, 66, 33, 66, 33, 34560, 33, 33, 33, 33, 34560, 66, 66, 34560, 66, 66, 33, 66, 34560, 66, 33, 33, 66, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 66, 34560, 66, 66, 66, 33, 34560, 33, 34560, 66, 33, 66, 33, 33, 66, 33, 66, 34560, 34560, 34560, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 33, 33, 34560, 66, 34560, 66, 34560, 66, 33, 66, 33, 33, 33, 34560, 34560, 66, 66, 33, 33, 66, 33, 34560, 33, 33, 66, 33, 34560, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 33, 66, 34560, 66, 66, 34560, 66, 33, 66, 33, 34560, 66, 66, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 66, 33, 66, 33, 66, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 66, 66, 34560, 33, 34560, 33, 33, 33, 34560, 66, 34560, 34560, 33, 66, 66, 66, 33, 66, 33, 66, 66, 34560, 33, 33, 66, 33, 66, 66, 33, 34560, 34560, 34560, 33, 66, 66, 66, 66, 33, 66, 33, 34560, 33, 33, 34560, 66, 34560, 66, 66, 66, 66, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 66, 34560, 66, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 3708480 . Total input tokens: 825698762 . Total output tokens: 741622434
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 107.05542379617691,
    "estimated_duration": 3600.012825967554,
    "input_throughput": 8072.126240880762,
    "output_throughput": 7125.817945691731,
    "total_throughput": 15197.944186572493,
    "itl": 108.80237261363523,
    "ttft": 1971905.9165492875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 432,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4462925064563763,
    "arrivals": 1235689,
    "finished_requests": 117424,
    "scheduler_time": 278.80583790126667
}
#Debug simulation 
Total elapsed time: 107.05557598825544. Arrivals time: 0.598719681147486 Scheduler time: 106.24509900715202 Scheduler overhead time: 0.08160454919561744 Adapter cache time: 0.018005821388214827 Engine time: 0.08036070130765438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 89.69126158580184,
    "estimated_duration": 3600.023925090656,
    "input_throughput": 6942.733026245262,
    "output_throughput": 6162.220991195595,
    "total_throughput": 13104.954017440858,
    "itl": 76.80062969733454,
    "ttft": 2041254.729519948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9403492296533973,
    "arrivals": 1075699,
    "finished_requests": 100889,
    "scheduler_time": 335.0375357225116
}
#Debug simulation 
Total elapsed time: 89.69142056582496. Arrivals time: 0.5314082796685398 Scheduler time: 88.93638968421146 Scheduler overhead time: 0.08598053874447942 Adapter cache time: 0.01949545368552208 Engine time: 0.08291562227532268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 94.05534143932164,
    "estimated_duration": 3600.042965551694,
    "input_throughput": 7057.776321874055,
    "output_throughput": 6254.955625661311,
    "total_throughput": 13312.731947535367,
    "itl": 80.5001981660611,
    "ttft": 2033785.1062221138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1254874914581943,
    "arrivals": 1075699,
    "finished_requests": 102505,
    "scheduler_time": 328.770870148944
}
#Debug simulation 
Total elapsed time: 94.05549831641838. Arrivals time: 0.5577253494411707 Scheduler time: 93.27336446521804 Scheduler overhead time: 0.08642829162999988 Adapter cache time: 0.019543134607374668 Engine time: 0.08314809575676918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 94.36117259366438,
    "estimated_duration": 3600.046472342468,
    "input_throughput": 7057.769446922556,
    "output_throughput": 6254.949532734221,
    "total_throughput": 13312.718979656776,
    "itl": 80.50027589299569,
    "ttft": 2033786.1763380724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1290451731532882,
    "arrivals": 1075699,
    "finished_requests": 102505,
    "scheduler_time": 328.7708192579958
}
#Debug simulation 
Total elapsed time: 94.36132992198691. Arrivals time: 0.5385386822745204 Scheduler time: 93.59768110327423 Scheduler overhead time: 0.08722036983817816 Adapter cache time: 0.01968360785394907 Engine time: 0.08335742261260748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 92.99602467566729,
    "estimated_duration": 3600.029135767687,
    "input_throughput": 6950.971243921288,
    "output_throughput": 6162.98539908032,
    "total_throughput": 13113.95664300161,
    "itl": 78.09019411771342,
    "ttft": 2050514.4995238692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.985712740090662,
    "arrivals": 1075699,
    "finished_requests": 101021,
    "scheduler_time": 334.62428841477526
}
#Debug simulation 
Total elapsed time: 92.99618446780369. Arrivals time: 0.5432829945348203 Scheduler time: 92.2261476633139 Scheduler overhead time: 0.08725785836577415 Adapter cache time: 0.019884977489709854 Engine time: 0.08401598548516631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 94.18394162505865,
    "estimated_duration": 3600.0741092802377,
    "input_throughput": 7057.715266055975,
    "output_throughput": 6254.90151493077,
    "total_throughput": 13312.616780986744,
    "itl": 80.50080757058124,
    "ttft": 2033797.8197647291,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1564594985917234,
    "arrivals": 1075699,
    "finished_requests": 102505,
    "scheduler_time": 328.77104187035206
}
#Debug simulation 
Total elapsed time: 94.18411488085985. Arrivals time: 0.5287948199547827 Scheduler time: 93.43163320608437 Scheduler overhead time: 0.0859697419218719 Adapter cache time: 0.019562616012990475 Engine time: 0.08331857994198799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 91.36129293311387,
    "estimated_duration": 3600.0367075052595,
    "input_throughput": 6942.913095272511,
    "output_throughput": 6162.407720385054,
    "total_throughput": 13105.320815657564,
    "itl": 76.79965534878701,
    "ttft": 2041230.3854605597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8956918869679489,
    "arrivals": 1075699,
    "finished_requests": 100891,
    "scheduler_time": 335.043564332233
}
#Debug simulation 
Total elapsed time: 91.3614486111328. Arrivals time: 0.5386611400172114 Scheduler time: 90.59643156034872 Scheduler overhead time: 0.08810495492070913 Adapter cache time: 0.019677940756082535 Engine time: 0.08319534687325358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.4_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 4320, 17280, 17280, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 4320, 17280, 8640, 8640, 17280, 17280, 8640, 4320, 4320, 8640, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 17280, 17280, 4320, 17280, 8640, 4320, 8640, 17280, 4320, 8640, 17280, 17280, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 17280, 8640, 17280, 17280, 4320, 17280, 4320, 17280, 8640, 4320, 4320, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 4320, 8640, 8640, 4320, 17280, 8640, 17280, 17280, 8640, 4320, 8640, 8640, 8640, 4320, 17280, 8640, 17280, 4320, 17280, 4320, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 4320, 4320, 17280, 8640, 8640, 17280, 8640, 8640, 4320, 8640, 17280, 8640, 4320, 4320, 8640, 17280, 4320, 4320, 4320, 17280, 17280, 17280, 4320, 8640, 17280, 8640, 8640, 8640, 4320, 17280, 4320, 17280, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 17280, 8640, 4320, 8640, 4320, 4320, 4320, 17280, 17280, 8640, 8640, 4320, 4320, 8640, 4320, 17280, 4320, 4320, 8640, 4320, 17280, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 4320, 8640, 17280, 8640, 8640, 17280, 8640, 4320, 8640, 4320, 17280, 8640, 8640, 17280, 17280, 4320, 4320, 4320, 17280, 17280, 4320, 4320, 17280, 8640, 4320, 8640, 4320, 8640, 17280, 17280, 17280, 4320, 17280, 17280, 17280, 17280, 4320, 8640, 8640, 17280, 4320, 17280, 4320, 4320, 4320, 17280, 8640, 17280, 17280, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 17280, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 17280, 17280, 17280, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 17280, 4320, 4320, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 4320, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 17280, 8640, 17280, 8640, 4320, 17280, 4320, 17280, 17280, 4320, 4320, 4320]
Prompts retrieved: 3231360 . Total input tokens: 719366854 . Total output tokens: 646131383
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 94.55735792405903,
    "estimated_duration": 3600.0235010750953,
    "input_throughput": 7057.744482060257,
    "output_throughput": 6254.840556811768,
    "total_throughput": 13312.585038872025,
    "itl": 80.50128111356844,
    "ttft": 2033812.2811293334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.184125331602991,
    "arrivals": 1075699,
    "finished_requests": 102504,
    "scheduler_time": 328.76418669576765
}
#Debug simulation 
Total elapsed time: 94.55751729896292. Arrivals time: 0.5573528804816306 Scheduler time: 93.77542728604749 Scheduler overhead time: 0.0864885188639164 Adapter cache time: 0.019475208595395088 Engine time: 0.08347335644066334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.0679186610505,
    "estimated_duration": 3600.0326194703994,
    "input_throughput": 7259.088392328073,
    "output_throughput": 6385.350753677806,
    "total_throughput": 13644.439146005878,
    "itl": 89.33307877825175,
    "ttft": 2000494.1866932677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.004619472275987,
    "arrivals": 961706,
    "finished_requests": 105229,
    "scheduler_time": 319.3784302336198
}
#Debug simulation 
Total elapsed time: 103.06807561591268. Arrivals time: 0.56619155080989 Scheduler time: 102.2693071984686 Scheduler overhead time: 0.0913571659475565 Adapter cache time: 0.020360483787953854 Engine time: 0.08534387079998851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 102.37007084861398,
    "estimated_duration": 3600.0456290169823,
    "input_throughput": 7258.754941707637,
    "output_throughput": 6385.2460131947855,
    "total_throughput": 13644.000954902423,
    "itl": 89.33499666294284,
    "ttft": 2000552.4264238856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.137447692637803,
    "arrivals": 961706,
    "finished_requests": 105227,
    "scheduler_time": 319.37064608695624
}
#Debug simulation 
Total elapsed time: 102.37023335369304. Arrivals time: 0.5639412058517337 Scheduler time: 101.5795696224086 Scheduler overhead time: 0.08794402424246073 Adapter cache time: 0.01904952572658658 Engine time: 0.08556462172418833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 101.88844158407301,
    "estimated_duration": 3600.0494518915275,
    "input_throughput": 7258.747233671993,
    "output_throughput": 6385.239232733913,
    "total_throughput": 13643.986466405906,
    "itl": 89.33505537744117,
    "ttft": 2000554.0160612292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1412192485481576,
    "arrivals": 961706,
    "finished_requests": 105227,
    "scheduler_time": 319.3706974055595
}
#Debug simulation 
Total elapsed time: 101.88859344832599. Arrivals time: 0.5629063853994012 Scheduler time: 101.09760328382254 Scheduler overhead time: 0.0888798413798213 Adapter cache time: 0.019317620899528265 Engine time: 0.08547766460105777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 100.36331586213782,
    "estimated_duration": 3600.076016705079,
    "input_throughput": 7259.000887408437,
    "output_throughput": 6385.273781257256,
    "total_throughput": 13644.274668665694,
    "itl": 89.33378537367048,
    "ttft": 2000511.1549174073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.047148127262466,
    "arrivals": 961706,
    "finished_requests": 105229,
    "scheduler_time": 319.37879862033583
}
#Debug simulation 
Total elapsed time: 100.3634649082087. Arrivals time: 0.5036899205297232 Scheduler time: 99.64132176199928 Scheduler overhead time: 0.0849963785149157 Adapter cache time: 0.018653254956007004 Engine time: 0.08193537592887878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 99.785356474109,
    "estimated_duration": 3600.077406465474,
    "input_throughput": 7258.690869554394,
    "output_throughput": 6385.189651399362,
    "total_throughput": 13643.880520953757,
    "itl": 89.33565221814067,
    "ttft": 2000564.692700933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.169010835345837,
    "arrivals": 961706,
    "finished_requests": 105227,
    "scheduler_time": 319.37096043131584
}
#Debug simulation 
Total elapsed time: 99.78550385078415. Arrivals time: 0.45988274179399014 Scheduler time: 99.11373021267354 Scheduler overhead time: 0.08268101420253515 Adapter cache time: 0.018036356195807457 Engine time: 0.07866291515529156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 100.1806431566365,
    "estimated_duration": 3600.10685962912,
    "input_throughput": 7259.182857336708,
    "output_throughput": 6385.690452079615,
    "total_throughput": 13644.873309416324,
    "itl": 89.33332722598229,
    "ttft": 2000462.6631474649,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9584829431608923,
    "arrivals": 961706,
    "finished_requests": 105233,
    "scheduler_time": 319.3868724327705
}
#Debug simulation 
Total elapsed time: 100.18079688679427. Arrivals time: 0.5172005430795252 Scheduler time: 99.45490556955338 Scheduler overhead time: 0.08098527556285262 Adapter cache time: 0.017760359216481447 Engine time: 0.07796009723097086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.1_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 1.6]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 1080, 17280, 17280, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 1080, 17280, 8640, 8640, 17280, 17280, 8640, 1080, 1080, 8640, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 17280, 17280, 1080, 17280, 8640, 1080, 8640, 17280, 1080, 8640, 17280, 17280, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 17280, 8640, 17280, 17280, 1080, 17280, 1080, 17280, 8640, 1080, 1080, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 1080, 8640, 8640, 1080, 17280, 8640, 17280, 17280, 8640, 1080, 8640, 8640, 8640, 1080, 17280, 8640, 17280, 1080, 17280, 1080, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 1080, 1080, 17280, 8640, 8640, 17280, 8640, 8640, 1080, 8640, 17280, 8640, 1080, 1080, 8640, 17280, 1080, 1080, 1080, 17280, 17280, 17280, 1080, 8640, 17280, 8640, 8640, 8640, 1080, 17280, 1080, 17280, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 17280, 8640, 1080, 8640, 1080, 1080, 1080, 17280, 17280, 8640, 8640, 1080, 1080, 8640, 1080, 17280, 1080, 1080, 8640, 1080, 17280, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 1080, 8640, 17280, 8640, 8640, 17280, 8640, 1080, 8640, 1080, 17280, 8640, 8640, 17280, 17280, 1080, 1080, 1080, 17280, 17280, 1080, 1080, 17280, 8640, 1080, 8640, 1080, 8640, 17280, 17280, 17280, 1080, 17280, 17280, 17280, 17280, 1080, 8640, 8640, 17280, 1080, 17280, 1080, 1080, 1080, 17280, 8640, 17280, 17280, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 17280, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 17280, 17280, 17280, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 17280, 1080, 1080, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 1080, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 17280, 8640, 17280, 8640, 1080, 17280, 1080, 17280, 17280, 1080, 1080, 1080]
Prompts retrieved: 2887920 . Total input tokens: 643016451 . Total output tokens: 577573617
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.85211473191157,
    "estimated_duration": 3600.0779115976666,
    "input_throughput": 7258.6898510768715,
    "output_throughput": 6385.188755484071,
    "total_throughput": 13643.878606560942,
    "itl": 89.33658771635707,
    "ttft": 2000554.405807416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 655,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1962994069978605,
    "arrivals": 961706,
    "finished_requests": 105227,
    "scheduler_time": 319.36587668099526
}
#Debug simulation 
Total elapsed time: 99.85226622503251. Arrivals time: 0.4559525861404836 Scheduler time: 99.18512940686196 Scheduler overhead time: 0.08293449552729726 Adapter cache time: 0.017934226896613836 Engine time: 0.07795791095122695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 99.49906569905579,
    "estimated_duration": 3600.0443569167505,
    "input_throughput": 7198.631858579425,
    "output_throughput": 6422.285313118061,
    "total_throughput": 13620.917171697485,
    "itl": 93.01736316241579,
    "ttft": 1999962.4491478382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9281072786776658,
    "arrivals": 942321,
    "finished_requests": 105164,
    "scheduler_time": 319.3759957087634
}
#Debug simulation 
Total elapsed time: 99.49922551773489. Arrivals time: 0.4491869625635445 Scheduler time: 98.84001964516938 Scheduler overhead time: 0.0821250039152801 Adapter cache time: 0.017890874296426773 Engine time: 0.07800828292965889 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 98.990879453253,
    "estimated_duration": 3600.035903627616,
    "input_throughput": 7140.571563216008,
    "output_throughput": 6339.996491979685,
    "total_throughput": 13480.568055195694,
    "itl": 90.1875538544999,
    "ttft": 2000306.8882857608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9974348610406796,
    "arrivals": 942321,
    "finished_requests": 104309,
    "scheduler_time": 321.64640734569537
}
#Debug simulation 
Total elapsed time: 98.99103013426065. Arrivals time: 0.45647987676784396 Scheduler time: 98.3230862938799 Scheduler overhead time: 0.08244888624176383 Adapter cache time: 0.01790041569620371 Engine time: 0.07862884597852826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.82250594394282,
    "estimated_duration": 3600.039387459765,
    "input_throughput": 7140.564653138063,
    "output_throughput": 6339.990356634699,
    "total_throughput": 13480.555009772763,
    "itl": 90.18760569389961,
    "ttft": 2000308.0639594926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0009050082042936,
    "arrivals": 942321,
    "finished_requests": 104309,
    "scheduler_time": 321.6464210306562
}
#Debug simulation 
Total elapsed time: 99.82265976583585. Arrivals time: 0.44938601180911064 Scheduler time: 99.16341959126294 Scheduler overhead time: 0.08167623030021787 Adapter cache time: 0.017476357985287905 Engine time: 0.07825304614380002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 99.19668768392876,
    "estimated_duration": 3600.026738426434,
    "input_throughput": 7198.516256389624,
    "output_throughput": 6422.149244954129,
    "total_throughput": 13620.665501343754,
    "itl": 93.01993813336506,
    "ttft": 1999881.23137203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9707624886161526,
    "arrivals": 942321,
    "finished_requests": 105160,
    "scheduler_time": 319.36963412041763
}
#Debug simulation 
Total elapsed time: 99.19683848274872. Arrivals time: 0.4503669408150017 Scheduler time: 98.53507385822013 Scheduler overhead time: 0.08231825428083539 Adapter cache time: 0.018129336647689342 Engine time: 0.07823924999684095 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 99.07124253129587,
    "estimated_duration": 3600.065366843203,
    "input_throughput": 7140.5131242217285,
    "output_throughput": 6339.944604954193,
    "total_throughput": 13480.457729175921,
    "itl": 90.18807645488458,
    "ttft": 2000318.7944649553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.026810288205746,
    "arrivals": 942321,
    "finished_requests": 104309,
    "scheduler_time": 321.6466952112727
}
#Debug simulation 
Total elapsed time: 99.07138624833897. Arrivals time: 0.4558867490850389 Scheduler time: 98.4059140663594 Scheduler overhead time: 0.08148895017802715 Adapter cache time: 0.017732156440615654 Engine time: 0.07802011305466294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 99.1758031300269,
    "estimated_duration": 3600.060105722073,
    "input_throughput": 7198.662033116817,
    "output_throughput": 6422.257773766436,
    "total_throughput": 13620.919806883252,
    "itl": 93.01592165615264,
    "ttft": 2000051.8275784918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8837316857883406,
    "arrivals": 942321,
    "finished_requests": 105165,
    "scheduler_time": 319.3821079563137
}
#Debug simulation 
Total elapsed time: 99.1759393340908. Arrivals time: 0.4528556396253407 Scheduler time: 98.51191865745932 Scheduler overhead time: 0.08263658033683896 Adapter cache time: 0.01803758181631565 Engine time: 0.07824535574764013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.05_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  1.6 ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 540, 17280, 17280, 8640, 8640, 8640, 8640, 540, 8640, 540, 8640, 540, 8640, 8640, 17280, 8640, 17280, 17280, 540, 17280, 8640, 8640, 17280, 17280, 8640, 540, 540, 8640, 17280, 17280, 8640, 8640, 540, 540, 8640, 17280, 17280, 540, 17280, 8640, 540, 8640, 17280, 540, 8640, 17280, 17280, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 540, 540, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 17280, 8640, 17280, 17280, 540, 17280, 540, 17280, 8640, 540, 540, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 540, 8640, 8640, 540, 17280, 8640, 17280, 17280, 8640, 540, 8640, 8640, 8640, 540, 17280, 8640, 17280, 540, 17280, 540, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 8640, 540, 8640, 540, 17280, 540, 540, 540, 540, 17280, 8640, 8640, 17280, 8640, 8640, 540, 8640, 17280, 8640, 540, 540, 8640, 17280, 540, 540, 540, 17280, 17280, 17280, 540, 8640, 17280, 8640, 8640, 8640, 540, 17280, 540, 17280, 8640, 540, 8640, 540, 540, 8640, 540, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 540, 540, 17280, 8640, 17280, 8640, 17280, 8640, 540, 8640, 540, 540, 540, 17280, 17280, 8640, 8640, 540, 540, 8640, 540, 17280, 540, 540, 8640, 540, 17280, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 540, 8640, 17280, 8640, 8640, 17280, 8640, 540, 8640, 540, 17280, 8640, 8640, 17280, 17280, 540, 540, 540, 17280, 17280, 540, 540, 17280, 8640, 540, 8640, 540, 8640, 17280, 17280, 17280, 540, 17280, 17280, 17280, 17280, 540, 8640, 8640, 17280, 540, 17280, 540, 540, 540, 17280, 8640, 17280, 17280, 540, 8640, 8640, 8640, 540, 8640, 540, 8640, 8640, 17280, 540, 540, 8640, 540, 8640, 8640, 540, 17280, 17280, 17280, 540, 8640, 8640, 8640, 8640, 540, 8640, 540, 17280, 540, 540, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 540, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 17280, 17280, 8640, 17280, 8640, 540, 17280, 540, 17280, 17280, 540, 540, 540]
Prompts retrieved: 2830680 . Total input tokens: 630386708 . Total output tokens: 566081381
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.30919041205198,
    "estimated_duration": 3600.09117332428,
    "input_throughput": 7140.461938985591,
    "output_throughput": 6339.899158421702,
    "total_throughput": 13480.361097407293,
    "itl": 90.18860869610901,
    "ttft": 2000328.9605039821,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.052464060634371,
    "arrivals": 942321,
    "finished_requests": 104309,
    "scheduler_time": 321.6468479199467
}
#Debug simulation 
Total elapsed time: 99.30933786602691. Arrivals time: 0.45284230122342706 Scheduler time: 98.64609217876568 Scheduler overhead time: 0.08213442144915462 Adapter cache time: 0.01768807414919138 Engine time: 0.07798353908583522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 96.38495707511902,
    "estimated_duration": 3600.023429899297,
    "input_throughput": 7054.153256083218,
    "output_throughput": 6251.130149069477,
    "total_throughput": 13305.283405152695,
    "itl": 85.76747686584088,
    "ttft": 2033211.198571184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6924497223948356,
    "arrivals": 932854,
    "finished_requests": 102560,
    "scheduler_time": 328.32706028841255
}
#Debug simulation 
Total elapsed time: 96.38509745476767. Arrivals time: 0.5072027873247862 Scheduler time: 95.66664110077545 Scheduler overhead time: 0.0824157283641398 Adapter cache time: 0.017385682091116905 Engine time: 0.07881171442568302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.24773220065981,
    "estimated_duration": 3600.036908767534,
    "input_throughput": 7141.731779856096,
    "output_throughput": 6346.052715282103,
    "total_throughput": 13487.7844951382,
    "itl": 89.87129785951602,
    "ttft": 1999703.7235026902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.917910342912661,
    "arrivals": 932854,
    "finished_requests": 103883,
    "scheduler_time": 323.4252058263387
}
#Debug simulation 
Total elapsed time: 99.24786917306483. Arrivals time: 0.44561898708343506 Scheduler time: 98.59222196834162 Scheduler overhead time: 0.08211487112566829 Adapter cache time: 0.017579791601747274 Engine time: 0.07784405024722219 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 98.95198289398104,
    "estimated_duration": 3600.0404047322086,
    "input_throughput": 7141.72484458893,
    "output_throughput": 6346.046552691238,
    "total_throughput": 13487.771397280167,
    "itl": 89.87135073003395,
    "ttft": 1999705.0901764133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.921452853437525,
    "arrivals": 932854,
    "finished_requests": 103883,
    "scheduler_time": 323.42525931904646
}
#Debug simulation 
Total elapsed time: 98.95211945986375. Arrivals time: 0.4549551378004253 Scheduler time: 98.28608707757667 Scheduler overhead time: 0.08243673015385866 Adapter cache time: 0.01766599901020527 Engine time: 0.07835912052541971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 98.62228293716908,
    "estimated_duration": 3600.0078430434146,
    "input_throughput": 7141.911384910818,
    "output_throughput": 6346.105063117355,
    "total_throughput": 13488.016448028173,
    "itl": 89.86843419640553,
    "ttft": 1999827.0139996042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8386428511352169,
    "arrivals": 932854,
    "finished_requests": 103885,
    "scheduler_time": 323.43079906996206
}
#Debug simulation 
Total elapsed time: 98.62242155801505. Arrivals time: 0.448304386343807 Scheduler time: 97.96484694071114 Scheduler overhead time: 0.08155843894928694 Adapter cache time: 0.017422113101929426 Engine time: 0.07779016392305493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 98.70180451404303,
    "estimated_duration": 3600.014510932439,
    "input_throughput": 7141.653157764868,
    "output_throughput": 6346.091086750274,
    "total_throughput": 13487.744244515143,
    "itl": 89.87214036532522,
    "ttft": 1999595.4697346084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9458490880020003,
    "arrivals": 932854,
    "finished_requests": 103881,
    "scheduler_time": 323.41927769299963
}
#Debug simulation 
Total elapsed time: 98.70194570207968. Arrivals time: 0.44783122977241874 Scheduler time: 98.04350097849965 Scheduler overhead time: 0.08214383339509368 Adapter cache time: 0.017715169582515955 Engine time: 0.07862651394680142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 96.08948145993054,
    "estimated_duration": 3600.102353486984,
    "input_throughput": 7054.147773160476,
    "output_throughput": 6251.002830017555,
    "total_throughput": 13305.150603178032,
    "itl": 85.76652582922159,
    "ttft": 2033244.1219992707,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6534978130808813,
    "arrivals": 932854,
    "finished_requests": 102563,
    "scheduler_time": 328.33540222267226
}
#Debug simulation 
Total elapsed time: 96.0896230279468. Arrivals time: 0.4529203255660832 Scheduler time: 95.42665535444394 Scheduler overhead time: 0.08173849992454052 Adapter cache time: 0.01740413112565875 Engine time: 0.07837883429601789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.025_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   1.6  ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 270, 17280, 17280, 8640, 8640, 8640, 8640, 270, 8640, 270, 8640, 270, 8640, 8640, 17280, 8640, 17280, 17280, 270, 17280, 8640, 8640, 17280, 17280, 8640, 270, 270, 8640, 17280, 17280, 8640, 8640, 270, 270, 8640, 17280, 17280, 270, 17280, 8640, 270, 8640, 17280, 270, 8640, 17280, 17280, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 270, 270, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 17280, 8640, 17280, 17280, 270, 17280, 270, 17280, 8640, 270, 270, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 270, 8640, 8640, 270, 17280, 8640, 17280, 17280, 8640, 270, 8640, 8640, 8640, 270, 17280, 8640, 17280, 270, 17280, 270, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 8640, 270, 8640, 270, 17280, 270, 270, 270, 270, 17280, 8640, 8640, 17280, 8640, 8640, 270, 8640, 17280, 8640, 270, 270, 8640, 17280, 270, 270, 270, 17280, 17280, 17280, 270, 8640, 17280, 8640, 8640, 8640, 270, 17280, 270, 17280, 8640, 270, 8640, 270, 270, 8640, 270, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 270, 270, 17280, 8640, 17280, 8640, 17280, 8640, 270, 8640, 270, 270, 270, 17280, 17280, 8640, 8640, 270, 270, 8640, 270, 17280, 270, 270, 8640, 270, 17280, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 270, 8640, 17280, 8640, 8640, 17280, 8640, 270, 8640, 270, 17280, 8640, 8640, 17280, 17280, 270, 270, 270, 17280, 17280, 270, 270, 17280, 8640, 270, 8640, 270, 8640, 17280, 17280, 17280, 270, 17280, 17280, 17280, 17280, 270, 8640, 8640, 17280, 270, 17280, 270, 270, 270, 17280, 8640, 17280, 17280, 270, 8640, 8640, 8640, 270, 8640, 270, 8640, 8640, 17280, 270, 270, 8640, 270, 8640, 8640, 270, 17280, 17280, 17280, 270, 8640, 8640, 8640, 8640, 270, 8640, 270, 17280, 270, 270, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 270, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 17280, 17280, 8640, 17280, 8640, 270, 17280, 270, 17280, 17280, 270, 270, 270]
Prompts retrieved: 2802060 . Total input tokens: 624030052 . Total output tokens: 560316778
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 99.04773702472448,
    "estimated_duration": 3600.0396306330003,
    "input_throughput": 7141.603326038764,
    "output_throughput": 6346.046806152229,
    "total_throughput": 13487.650132190993,
    "itl": 89.87260823231394,
    "ttft": 1999605.6764861944,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9706225839257192,
    "arrivals": 932854,
    "finished_requests": 103881,
    "scheduler_time": 323.41962389765865
}
#Debug simulation 
Total elapsed time: 99.04786877287552. Arrivals time: 0.46125383488833904 Scheduler time: 98.37503304565325 Scheduler overhead time: 0.08277990808710456 Adapter cache time: 0.017839180771261454 Engine time: 0.07863082131370902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 102.39065653085709,
    "estimated_duration": 3600.0897297882093,
    "input_throughput": 7366.541389389248,
    "output_throughput": 6520.948299080611,
    "total_throughput": 13887.48968846986,
    "itl": 93.9641427059138,
    "ttft": 2003621.5805505575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7842643547128214,
    "arrivals": 928080,
    "finished_requests": 107146,
    "scheduler_time": 311.1841458672113
}
#Debug simulation 
Total elapsed time: 102.39080198621377. Arrivals time: 0.46895612170919776 Scheduler time: 101.71223856275901 Scheduler overhead time: 0.08220660639926791 Adapter cache time: 0.017517211847007275 Engine time: 0.0784367211163044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 98.12752626696602,
    "estimated_duration": 3600.0785561817784,
    "input_throughput": 7182.625488990678,
    "output_throughput": 6385.928984944954,
    "total_throughput": 13568.554473935632,
    "itl": 88.42177505602164,
    "ttft": 2001573.8756137213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8352658914239208,
    "arrivals": 928080,
    "finished_requests": 104601,
    "scheduler_time": 320.5419067211202
}
#Debug simulation 
Total elapsed time: 98.12766830297187. Arrivals time: 0.46054180432111025 Scheduler time: 97.4535863273777 Scheduler overhead time: 0.08272495307028294 Adapter cache time: 0.0177105194889009 Engine time: 0.08058701874688268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 98.21127705369145,
    "estimated_duration": 3600.081577085809,
    "input_throughput": 7182.61946189884,
    "output_throughput": 6385.9236263778785,
    "total_throughput": 13568.543088276718,
    "itl": 88.42182663252402,
    "ttft": 2001575.1531638934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.838274393435579,
    "arrivals": 928080,
    "finished_requests": 104601,
    "scheduler_time": 320.54191912311603
}
#Debug simulation 
Total elapsed time: 98.21141582680866. Arrivals time: 0.45899463118985295 Scheduler time: 97.54302948247641 Scheduler overhead time: 0.08213515020906925 Adapter cache time: 0.017694898881018162 Engine time: 0.07737018261104822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 102.6889190771617,
    "estimated_duration": 3600.005054812592,
    "input_throughput": 7366.387712302954,
    "output_throughput": 6521.023621513246,
    "total_throughput": 13887.4113338162,
    "itl": 93.96499397983726,
    "ttft": 2003593.4295263551,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8241011949791468,
    "arrivals": 928080,
    "finished_requests": 107142,
    "scheduler_time": 311.17557008305613
}
#Debug simulation 
Total elapsed time: 102.68906644312665. Arrivals time: 0.48286805022507906 Scheduler time: 101.99521036027 Scheduler overhead time: 0.08307321323081851 Adapter cache time: 0.018244759179651737 Engine time: 0.0777268554084003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 98.45815378893167,
    "estimated_duration": 3600.022124176211,
    "input_throughput": 7182.521692395677,
    "output_throughput": 6385.9679765886685,
    "total_throughput": 13568.489668984346,
    "itl": 88.42327943775531,
    "ttft": 2001483.746357656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8619161052815658,
    "arrivals": 928080,
    "finished_requests": 104598,
    "scheduler_time": 320.5346450627687
}
#Debug simulation 
Total elapsed time: 98.45829378906637. Arrivals time: 0.47200630279257894 Scheduler time: 97.77585155470297 Scheduler overhead time: 0.08198303822427988 Adapter cache time: 0.017783362418413162 Engine time: 0.07818097481504083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 102.52831543190405,
    "estimated_duration": 3600.048221737605,
    "input_throughput": 7366.626324577317,
    "output_throughput": 6521.023484699056,
    "total_throughput": 13887.649809276374,
    "itl": 93.9633750745264,
    "ttft": 2003604.679013525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7431993219279434,
    "arrivals": 928080,
    "finished_requests": 107146,
    "scheduler_time": 311.18380288787966
}
#Debug simulation 
Total elapsed time: 102.52845958899707. Arrivals time: 0.47763169230893254 Scheduler time: 101.84132447652519 Scheduler overhead time: 0.08174395933747292 Adapter cache time: 0.01794741628691554 Engine time: 0.07765580713748932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.0125_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    1.6   ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 135, 17280, 17280, 8640, 8640, 8640, 8640, 135, 8640, 135, 8640, 135, 8640, 8640, 17280, 8640, 17280, 17280, 135, 17280, 8640, 8640, 17280, 17280, 8640, 135, 135, 8640, 17280, 17280, 8640, 8640, 135, 135, 8640, 17280, 17280, 135, 17280, 8640, 135, 8640, 17280, 135, 8640, 17280, 17280, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 135, 135, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 17280, 8640, 17280, 17280, 135, 17280, 135, 17280, 8640, 135, 135, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 135, 8640, 8640, 135, 17280, 8640, 17280, 17280, 8640, 135, 8640, 8640, 8640, 135, 17280, 8640, 17280, 135, 17280, 135, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 8640, 135, 8640, 135, 17280, 135, 135, 135, 135, 17280, 8640, 8640, 17280, 8640, 8640, 135, 8640, 17280, 8640, 135, 135, 8640, 17280, 135, 135, 135, 17280, 17280, 17280, 135, 8640, 17280, 8640, 8640, 8640, 135, 17280, 135, 17280, 8640, 135, 8640, 135, 135, 8640, 135, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 135, 135, 17280, 8640, 17280, 8640, 17280, 8640, 135, 8640, 135, 135, 135, 17280, 17280, 8640, 8640, 135, 135, 8640, 135, 17280, 135, 135, 8640, 135, 17280, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 135, 8640, 17280, 8640, 8640, 17280, 8640, 135, 8640, 135, 17280, 8640, 8640, 17280, 17280, 135, 135, 135, 17280, 17280, 135, 135, 17280, 8640, 135, 8640, 135, 8640, 17280, 17280, 17280, 135, 17280, 17280, 17280, 17280, 135, 8640, 8640, 17280, 135, 17280, 135, 135, 135, 17280, 8640, 17280, 17280, 135, 8640, 8640, 8640, 135, 8640, 135, 8640, 8640, 17280, 135, 135, 8640, 135, 8640, 8640, 135, 17280, 17280, 17280, 135, 8640, 8640, 8640, 8640, 135, 8640, 135, 17280, 135, 135, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 135, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 17280, 17280, 8640, 17280, 8640, 135, 17280, 135, 17280, 17280, 135, 135, 135]
Prompts retrieved: 2787750 . Total input tokens: 620823562 . Total output tokens: 557458365
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 98.47003367170691,
    "estimated_duration": 3600.0463901201733,
    "input_throughput": 7182.473278944846,
    "output_throughput": 6385.9249322708265,
    "total_throughput": 13568.398211215674,
    "itl": 88.42374406187758,
    "ttft": 2001493.715535021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 562,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8859350784867963,
    "arrivals": 928080,
    "finished_requests": 104598,
    "scheduler_time": 320.5348920335468
}
#Debug simulation 
Total elapsed time: 98.47017096774653. Arrivals time: 0.47894228994846344 Scheduler time: 97.78110156022012 Scheduler overhead time: 0.08222534833475947 Adapter cache time: 0.017688044346868992 Engine time: 0.07800135482102633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 103.18493998982012,
    "estimated_duration": 3600.076999256623,
    "input_throughput": 7450.332869418739,
    "output_throughput": 6594.951164906344,
    "total_throughput": 14045.284034325083,
    "itl": 95.68268281350434,
    "ttft": 1995040.925518466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.726115087578097,
    "arrivals": 925677,
    "finished_requests": 108453,
    "scheduler_time": 306.46804380309237
}
#Debug simulation 
Total elapsed time: 103.18508040392771. Arrivals time: 0.5450306218117476 Scheduler time: 102.43279610248283 Scheduler overhead time: 0.08065994316712022 Adapter cache time: 0.017394188791513443 Engine time: 0.0775049664080143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 101.58145262300968,
    "estimated_duration": 3600.094846851465,
    "input_throughput": 7358.478630963968,
    "output_throughput": 6535.1325453483805,
    "total_throughput": 13893.611176312348,
    "itl": 93.60559866760207,
    "ttft": 2002775.630329021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7978807896771525,
    "arrivals": 925677,
    "finished_requests": 107151,
    "scheduler_time": 311.7480578848741
}
#Debug simulation 
Total elapsed time: 101.58159460732713. Arrivals time: 0.49242657562717795 Scheduler time: 100.87823180202395 Scheduler overhead time: 0.08230785140767694 Adapter cache time: 0.017775059211999178 Engine time: 0.0784456068649888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-8-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 101.8762045269832,
    "estimated_duration": 3600.0981358458557,
    "input_throughput": 7358.471908370851,
    "output_throughput": 6535.126574951609,
    "total_throughput": 13893.598483322461,
    "itl": 93.60567312838195,
    "ttft": 2002776.985653511,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8010859636589995,
    "arrivals": 925677,
    "finished_requests": 107151,
    "scheduler_time": 311.7481417052594
}
#Debug simulation 
Total elapsed time: 101.87634384864941. Arrivals time: 0.49785062624141574 Scheduler time: 101.16818100679666 Scheduler overhead time: 0.08240898000076413 Adapter cache time: 0.017681578639894724 Engine time: 0.07796731544658542 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 103.04494944168255,
    "estimated_duration": 3600.1144925893004,
    "input_throughput": 7450.255278050629,
    "output_throughput": 6594.88248189681,
    "total_throughput": 14045.13775994744,
    "itl": 95.68342557953903,
    "ttft": 1995057.3366264822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7632042861916026,
    "arrivals": 925677,
    "finished_requests": 108453,
    "scheduler_time": 306.4684479370929
}
#Debug simulation 
Total elapsed time: 103.04509164672345. Arrivals time: 0.49135974841192365 Scheduler time: 102.34561047470197 Scheduler overhead time: 0.08104608487337828 Adapter cache time: 0.017359967343509197 Engine time: 0.07745756348595023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_8-16-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 101.80941969109699,
    "estimated_duration": 3600.019094334424,
    "input_throughput": 7358.509859486633,
    "output_throughput": 6535.246448282992,
    "total_throughput": 13893.756307769625,
    "itl": 93.60745633753297,
    "ttft": 2002628.4387078853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8242246603593266,
    "arrivals": 925677,
    "finished_requests": 107147,
    "scheduler_time": 311.7400891184317
}
#Debug simulation 
Total elapsed time: 101.80955469468608. Arrivals time: 0.47792124282568693 Scheduler time: 101.12128316704184 Scheduler overhead time: 0.08233120571821928 Adapter cache time: 0.017766581382602453 Engine time: 0.07863284973427653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-16/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 102.98296661721542,
    "estimated_duration": 3600.0634664052172,
    "input_throughput": 7450.360875660458,
    "output_throughput": 6594.975955717666,
    "total_throughput": 14045.336831378125,
    "itl": 95.6812505069018,
    "ttft": 1995045.3036270416,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.686388366324804,
    "arrivals": 925677,
    "finished_requests": 108453,
    "scheduler_time": 306.4729381380654
}
#Debug simulation 
Total elapsed time: 102.98310297401622. Arrivals time: 0.4908589404076338 Scheduler time: 102.28322574635968 Scheduler overhead time: 0.08223012369126081 Adapter cache time: 0.017425543628633022 Engine time: 0.07760297041386366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.00625_size_16-16-32/adapters_320_slots_16_rate_1.6-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     1.6    ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 66, 17280, 17280, 8640, 8640, 8640, 8640, 66, 8640, 66, 8640, 66, 8640, 8640, 17280, 8640, 17280, 17280, 66, 17280, 8640, 8640, 17280, 17280, 8640, 66, 66, 8640, 17280, 17280, 8640, 8640, 66, 66, 8640, 17280, 17280, 66, 17280, 8640, 66, 8640, 17280, 66, 8640, 17280, 17280, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 66, 66, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 17280, 8640, 17280, 17280, 66, 17280, 66, 17280, 8640, 66, 66, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 66, 8640, 8640, 66, 17280, 8640, 17280, 17280, 8640, 66, 8640, 8640, 8640, 66, 17280, 8640, 17280, 66, 17280, 66, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 8640, 66, 8640, 66, 17280, 66, 66, 66, 66, 17280, 8640, 8640, 17280, 8640, 8640, 66, 8640, 17280, 8640, 66, 66, 8640, 17280, 66, 66, 66, 17280, 17280, 17280, 66, 8640, 17280, 8640, 8640, 8640, 66, 17280, 66, 17280, 8640, 66, 8640, 66, 66, 8640, 66, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 66, 66, 17280, 8640, 17280, 8640, 17280, 8640, 66, 8640, 66, 66, 66, 17280, 17280, 8640, 8640, 66, 66, 8640, 66, 17280, 66, 66, 8640, 66, 17280, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 66, 8640, 17280, 8640, 8640, 17280, 8640, 66, 8640, 66, 17280, 8640, 8640, 17280, 17280, 66, 66, 66, 17280, 17280, 66, 66, 17280, 8640, 66, 8640, 66, 8640, 17280, 17280, 17280, 66, 17280, 17280, 17280, 17280, 66, 8640, 8640, 17280, 66, 17280, 66, 66, 66, 17280, 8640, 17280, 17280, 66, 8640, 8640, 8640, 66, 8640, 66, 8640, 8640, 17280, 66, 66, 8640, 66, 8640, 8640, 66, 17280, 17280, 17280, 66, 8640, 8640, 8640, 8640, 66, 8640, 66, 17280, 66, 66, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 66, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 17280, 17280, 8640, 17280, 8640, 66, 17280, 66, 17280, 17280, 66, 66, 66]
Prompts retrieved: 2780436 . Total input tokens: 619158227 . Total output tokens: 555999522
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 101.53927549300715,
    "estimated_duration": 3600.0424892143815,
    "input_throughput": 7358.46204020246,
    "output_throughput": 6535.203978976975,
    "total_throughput": 13893.666019179434,
    "itl": 93.6079531173114,
    "ttft": 2002638.444953806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 551,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.847363357059654,
    "arrivals": 925677,
    "finished_requests": 107147,
    "scheduler_time": 311.74034530170763
}
#Debug simulation 
Total elapsed time: 101.53940525185317. Arrivals time: 0.4818524541333318 Scheduler time: 100.84572768257931 Scheduler overhead time: 0.08277732646092772 Adapter cache time: 0.01758435508236289 Engine time: 0.07885223161429167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-8/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 99.29968557925895,
    "estimated_duration": 3600.0240204098304,
    "input_throughput": 7260.463222416066,
    "output_throughput": 6431.6240304874755,
    "total_throughput": 13692.087252903542,
    "itl": 90.62102723618152,
    "ttft": 2010950.7921730909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 514,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.573090700381454,
    "arrivals": 924451,
    "finished_requests": 105635,
    "scheduler_time": 316.7506630365291
}
#Debug simulation 
Total elapsed time: 99.2998141841963. Arrivals time: 0.45289137540385127 Scheduler time: 98.6390902926214 Scheduler overhead time: 0.08194877114146948 Adapter cache time: 0.017068864312022924 Engine time: 0.0769853126257658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 320,
    "served_adapters_rates": [
        1.6,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.8-0.003125_size_8-8-16/adapters_320_slots_16_rate_1.6-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.8      1.6     ]. Counts: [106 107 107]
Adapter prompts. [8640, 17280, 17280, 33, 17280, 17280, 8640, 8640, 8640, 8640, 33, 8640, 33, 8640, 33, 8640, 8640, 17280, 8640, 17280, 17280, 33, 17280, 8640, 8640, 17280, 17280, 8640, 33, 33, 8640, 17280, 17280, 8640, 8640, 33, 33, 8640, 17280, 17280, 33, 17280, 8640, 33, 8640, 17280, 33, 8640, 17280, 17280, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 33, 33, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 17280, 8640, 17280, 17280, 33, 17280, 33, 17280, 8640, 33, 33, 8640, 8640, 17280, 8640, 17280, 17280, 17280, 33, 8640, 8640, 33, 17280, 8640, 17280, 17280, 8640, 33, 8640, 8640, 8640, 33, 17280, 8640, 17280, 33, 17280, 33, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 8640, 33, 8640, 33, 17280, 33, 33, 33, 33, 17280, 8640, 8640, 17280, 8640, 8640, 33, 8640, 17280, 8640, 33, 33, 8640, 17280, 33, 33, 33, 17280, 17280, 17280, 33, 8640, 17280, 8640, 8640, 8640, 33, 17280, 33, 17280, 8640, 33, 8640, 33, 33, 8640, 33, 8640, 17280, 17280, 17280, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 33, 33, 17280, 8640, 17280, 8640, 17280, 8640, 33, 8640, 33, 33, 33, 17280, 17280, 8640, 8640, 33, 33, 8640, 33, 17280, 33, 33, 8640, 33, 17280, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 33, 8640, 17280, 8640, 8640, 17280, 8640, 33, 8640, 33, 17280, 8640, 8640, 17280, 17280, 33, 33, 33, 17280, 17280, 33, 33, 17280, 8640, 33, 8640, 33, 8640, 17280, 17280, 17280, 33, 17280, 17280, 17280, 17280, 33, 8640, 8640, 17280, 33, 17280, 33, 33, 33, 17280, 8640, 17280, 17280, 33, 8640, 8640, 8640, 33, 8640, 33, 8640, 8640, 17280, 33, 33, 8640, 33, 8640, 8640, 33, 17280, 17280, 17280, 33, 8640, 8640, 8640, 8640, 33, 8640, 33, 17280, 33, 33, 17280, 8640, 17280, 8640, 8640, 8640, 8640, 33, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 17280, 17280, 8640, 17280, 8640, 33, 17280, 33, 17280, 17280, 33, 33, 33]
Prompts retrieved: 2776938 . Total input tokens: 618377608 . Total output tokens: 555301754
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 96.76497759576887,
    "estimated_duration": 3600.020660910805,
    "input_throughput": 7096.123441007368,
    "output_throughput": 6304.334374086059,
    "total_throughput": 13400.457815093427,
    "itl": 86.56879260383151,
    "ttft": 2014464.5191803803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6029511498822886,
    "arrivals": 924451,
    "finished_requests": 103252,
    "scheduler_time": 324.95213513426665
}
#Debug simulation 
Total elapsed time: 96.76510757999495. Arrivals time: 0.44440976344048977 Scheduler time: 96.109289675951 Scheduler overhead time: 0.08299099048599601 Adapter cache time: 0.01697294693440199 Engine time: 0.07879208540543914 
