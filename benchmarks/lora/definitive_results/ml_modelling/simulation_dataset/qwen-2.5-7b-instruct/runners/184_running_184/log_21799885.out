INFO 06-01 00:47:14 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:15 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.795826956164092,
    "estimated_duration": 3600.0233020174383,
    "input_throughput": 4621.831750554431,
    "output_throughput": 4085.786609146996,
    "total_throughput": 8707.618359701426,
    "itl": 209.64652587372737,
    "ttft": 1826127.519074167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5891726313671635,
    "arrivals": 194481,
    "finished_requests": 67332,
    "scheduler_time": 99.4307128484796
}
#Debug simulation 
Total elapsed time: 14.795998721383512. Arrivals time: 0.28238021582365036 Scheduler time: 14.412469067145139 Scheduler overhead time: 0.033970729913562536 Adapter cache time: 0.020781761966645718 Engine time: 0.03279433213174343 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 15.217961663845927,
    "estimated_duration": 3600.0765324131453,
    "input_throughput": 4614.9966119923965,
    "output_throughput": 4082.975422232812,
    "total_throughput": 8697.972034225208,
    "itl": 209.89210494762867,
    "ttft": 1826087.797256396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6697713757352957,
    "arrivals": 194481,
    "finished_requests": 67226,
    "scheduler_time": 99.3578201364248
}
#Debug simulation 
Total elapsed time: 15.218147228006274. Arrivals time: 0.28689892403781414 Scheduler time: 14.830532213672996 Scheduler overhead time: 0.033273094333708286 Adapter cache time: 0.020359601825475693 Engine time: 0.03359576500952244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.388425591867417,
    "estimated_duration": 3600.0066168420803,
    "input_throughput": 4421.263262555332,
    "output_throughput": 3919.171407628253,
    "total_throughput": 8340.434670183586,
    "itl": 177.99365161480773,
    "ttft": 1871263.543023937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.297310552447971,
    "arrivals": 194481,
    "finished_requests": 64412,
    "scheduler_time": 104.07033306924568
}
#Debug simulation 
Total elapsed time: 9.388503569178283. Arrivals time: 0.4792291708290577 Scheduler time: 8.79921975871548 Scheduler overhead time: 0.03281376650556922 Adapter cache time: 0.030118371825665236 Engine time: 0.03256125235930085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 14.79641159530729,
    "estimated_duration": 3600.1608547518154,
    "input_throughput": 4619.171940067775,
    "output_throughput": 4084.678877775797,
    "total_throughput": 8703.850817843571,
    "itl": 209.79703504027523,
    "ttft": 1826184.5509317454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6865372503502045,
    "arrivals": 194481,
    "finished_requests": 67285,
    "scheduler_time": 99.39125863721523
}
#Debug simulation 
Total elapsed time: 14.79656720906496. Arrivals time: 0.28185422345995903 Scheduler time: 14.411942570935935 Scheduler overhead time: 0.0331176957115531 Adapter cache time: 0.02108483389019966 Engine time: 0.03507163422182202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.468704971950501,
    "estimated_duration": 3600.0458718503605,
    "input_throughput": 4421.099221110583,
    "output_throughput": 3915.606495523546,
    "total_throughput": 8336.70571663413,
    "itl": 178.08584173177104,
    "ttft": 1869648.607525851,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1189,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9390034768357918,
    "arrivals": 194481,
    "finished_requests": 64368,
    "scheduler_time": 104.06064567966749
}
#Debug simulation 
Total elapsed time: 9.468815078027546. Arrivals time: 0.24711234727874398 Scheduler time: 9.112039432860911 Scheduler overhead time: 0.03329358668997884 Adapter cache time: 0.02867694478482008 Engine time: 0.03303142357617617 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 15.330593977123499,
    "estimated_duration": 3600.101140062718,
    "input_throughput": 4615.352278605855,
    "output_throughput": 4083.312225984824,
    "total_throughput": 8698.664504590679,
    "itl": 209.87733174631802,
    "ttft": 1826003.9689387544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 818,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.44586114122993,
    "arrivals": 194481,
    "finished_requests": 67233,
    "scheduler_time": 99.36369134287852
}
#Debug simulation 
Total elapsed time: 15.330711328890175. Arrivals time: 0.2812369866296649 Scheduler time: 14.949936518911272 Scheduler overhead time: 0.032957812771201134 Adapter cache time: 0.020074542611837387 Engine time: 0.033027224242687225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 66, 4320, 4320, 1080, 1080, 1080, 1080, 66, 1080, 66, 1080, 66, 1080, 1080, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 4320, 1080, 66, 66, 1080, 4320, 4320, 1080, 1080, 66, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 1080, 4320, 4320, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 66, 4320, 1080, 66, 66, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 66, 1080, 1080, 66, 4320, 1080, 4320, 4320, 1080, 66, 1080, 1080, 1080, 66, 4320, 1080, 4320, 66, 4320, 66, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 1080, 66, 1080, 66, 4320, 66, 66, 66, 66, 4320, 1080, 1080, 4320, 1080, 1080, 66, 1080, 4320, 1080, 66, 66, 1080, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 1080, 4320, 1080, 1080, 1080, 66, 4320, 66, 4320, 1080, 66, 1080, 66, 66, 1080, 66, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 1080, 66, 1080, 66, 66, 66, 4320, 4320, 1080, 1080, 66, 66, 1080, 66, 4320, 66, 66, 1080, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 66, 1080, 66, 4320, 1080, 1080, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 1080, 66, 1080, 66, 1080, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 1080, 1080, 4320, 66, 4320, 66, 66, 66, 4320, 1080, 4320, 4320, 66, 1080, 1080, 1080, 66, 1080, 66, 1080, 1080, 4320, 66, 66, 1080, 66, 1080, 1080, 66, 4320, 4320, 4320, 66, 1080, 1080, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 584796 . Total input tokens: 130396952 . Total output tokens: 116962797
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.496394664049149,
    "estimated_duration": 3600.0587657941533,
    "input_throughput": 4414.829599731255,
    "output_throughput": 3915.189700213335,
    "total_throughput": 8330.01929994459,
    "itl": 177.5439395576089,
    "ttft": 1870792.2014348316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.817059938423391,
    "arrivals": 194481,
    "finished_requests": 64323,
    "scheduler_time": 104.17037593012672
}
#Debug simulation 
Total elapsed time: 9.496589579153806. Arrivals time: 0.24941557180136442 Scheduler time: 9.13840799452737 Scheduler overhead time: 0.033213147427886724 Adapter cache time: 0.027639554347842932 Engine time: 0.033052604645490646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.77681248402223,
    "estimated_duration": 3600.0892971365847,
    "input_throughput": 4646.486689456515,
    "output_throughput": 4079.6632493760003,
    "total_throughput": 8726.149938832516,
    "itl": 209.05648685386856,
    "ttft": 1826043.5902583678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.711592141124478,
    "arrivals": 193337,
    "finished_requests": 67342,
    "scheduler_time": 99.35121321618739
}
#Debug simulation 
Total elapsed time: 14.77695015212521. Arrivals time: 0.2794764395803213 Scheduler time: 14.394480931572616 Scheduler overhead time: 0.03390858834609389 Adapter cache time: 0.02205635281279683 Engine time: 0.03357341839000583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.833671366795897,
    "estimated_duration": 3600.091483949782,
    "input_throughput": 4644.982516292428,
    "output_throughput": 4080.346309389761,
    "total_throughput": 8725.328825682189,
    "itl": 209.10365534137725,
    "ttft": 1825642.44918718,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 883,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8804684576415513,
    "arrivals": 193337,
    "finished_requests": 67345,
    "scheduler_time": 99.3394599801522
}
#Debug simulation 
Total elapsed time: 14.833828816190362. Arrivals time: 0.29160031070932746 Scheduler time: 14.440012228209525 Scheduler overhead time: 0.03356023831292987 Adapter cache time: 0.021311808843165636 Engine time: 0.03372591268271208 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.015726572368294,
    "estimated_duration": 3600.091103478977,
    "input_throughput": 4448.590199432302,
    "output_throughput": 3916.082842008092,
    "total_throughput": 8364.673041440394,
    "itl": 177.84826237082657,
    "ttft": 1866066.7787932646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.865896576289029,
    "arrivals": 193337,
    "finished_requests": 64539,
    "scheduler_time": 103.99362930756331
}
#Debug simulation 
Total elapsed time: 9.015869948081672. Arrivals time: 0.2509387694299221 Scheduler time: 8.655510398093611 Scheduler overhead time: 0.03298051655292511 Adapter cache time: 0.0286127720028162 Engine time: 0.033078120555728674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 14.973318544216454,
    "estimated_duration": 3600.1409628502415,
    "input_throughput": 4647.456078151347,
    "output_throughput": 4081.396854074023,
    "total_throughput": 8728.85293222537,
    "itl": 209.04769537666007,
    "ttft": 1825629.1282135365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.748919711224708,
    "arrivals": 193337,
    "finished_requests": 67380,
    "scheduler_time": 99.350333311677
}
#Debug simulation 
Total elapsed time: 14.973443062976003. Arrivals time: 0.2873576697893441 Scheduler time: 14.58032445795834 Scheduler overhead time: 0.03483246685937047 Adapter cache time: 0.02202238282188773 Engine time: 0.03507540002465248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 8.96060165669769,
    "estimated_duration": 3600.1665269840005,
    "input_throughput": 4449.699723590367,
    "output_throughput": 3914.5311458151423,
    "total_throughput": 8364.23086940551,
    "itl": 177.77970574426573,
    "ttft": 1866303.2352633676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1204,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9841589566133924,
    "arrivals": 193337,
    "finished_requests": 64530,
    "scheduler_time": 103.99135860446022
}
#Debug simulation 
Total elapsed time: 8.960731084924191. Arrivals time: 0.24891321966424584 Scheduler time: 8.601384492125362 Scheduler overhead time: 0.03315564524382353 Adapter cache time: 0.029592161532491446 Engine time: 0.032912388909608126 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.83742525614798,
    "estimated_duration": 3600.112540165105,
    "input_throughput": 4645.275616643095,
    "output_throughput": 4080.5666034335354,
    "total_throughput": 8725.84222007663,
    "itl": 209.0909037345454,
    "ttft": 1825588.0847201976,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 883,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6402144103985643,
    "arrivals": 193337,
    "finished_requests": 67349,
    "scheduler_time": 99.34568278190369
}
#Debug simulation 
Total elapsed time: 14.83754162909463. Arrivals time: 0.28931196965277195 Scheduler time: 14.446673549711704 Scheduler overhead time: 0.03346724854782224 Adapter cache time: 0.021298828534781933 Engine time: 0.033464756328612566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [106 107 107]
Adapter prompts. [1080, 4320, 4320, 33, 4320, 4320, 1080, 1080, 1080, 1080, 33, 1080, 33, 1080, 33, 1080, 1080, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 4320, 1080, 33, 33, 1080, 4320, 4320, 1080, 1080, 33, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 1080, 4320, 4320, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 33, 4320, 1080, 33, 33, 1080, 1080, 4320, 1080, 4320, 4320, 4320, 33, 1080, 1080, 33, 4320, 1080, 4320, 4320, 1080, 33, 1080, 1080, 1080, 33, 4320, 1080, 4320, 33, 4320, 33, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 1080, 33, 1080, 33, 4320, 33, 33, 33, 33, 4320, 1080, 1080, 4320, 1080, 1080, 33, 1080, 4320, 1080, 33, 33, 1080, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 1080, 4320, 1080, 1080, 1080, 33, 4320, 33, 4320, 1080, 33, 1080, 33, 33, 1080, 33, 1080, 4320, 4320, 4320, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 1080, 33, 1080, 33, 33, 33, 4320, 4320, 1080, 1080, 33, 33, 1080, 33, 4320, 33, 33, 1080, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 33, 1080, 33, 4320, 1080, 1080, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 1080, 33, 1080, 33, 1080, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 1080, 1080, 4320, 33, 4320, 33, 33, 33, 4320, 1080, 4320, 4320, 33, 1080, 1080, 1080, 33, 1080, 33, 1080, 1080, 4320, 33, 33, 1080, 33, 1080, 1080, 33, 4320, 4320, 4320, 33, 1080, 1080, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 1080, 1080, 1080, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 581298 . Total input tokens: 129613956 . Total output tokens: 116260811
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.02232177508995,
    "estimated_duration": 3600.126398664641,
    "input_throughput": 4445.968343205106,
    "output_throughput": 3913.2420476196567,
    "total_throughput": 8359.210390824763,
    "itl": 177.52606125089744,
    "ttft": 1866754.1249908342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1213,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.065430397279615,
    "arrivals": 193337,
    "finished_requests": 64487,
    "scheduler_time": 104.05141988069975
}
#Debug simulation 
Total elapsed time: 9.022445629350841. Arrivals time: 0.2536686393432319 Scheduler time: 8.657804851420224 Scheduler overhead time: 0.03334922203794122 Adapter cache time: 0.029393516946583986 Engine time: 0.033304068725556135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.46937998291105,
    "estimated_duration": 3600.0191607801653,
    "input_throughput": 4586.355311626143,
    "output_throughput": 4084.0379851794387,
    "total_throughput": 8670.393296805581,
    "itl": 210.699028685242,
    "ttft": 1798673.6412959802,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1053,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2226935943612656,
    "arrivals": 182454,
    "finished_requests": 67137,
    "scheduler_time": 98.72113576320037
}
#Debug simulation 
Total elapsed time: 14.469518514350057. Arrivals time: 0.2788335708901286 Scheduler time: 14.08543572993949 Scheduler overhead time: 0.032874167431145906 Adapter cache time: 0.025533480569720268 Engine time: 0.033279981929808855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.775447384919971,
    "estimated_duration": 3600.2162336150504,
    "input_throughput": 4586.431738690267,
    "output_throughput": 4087.265609939303,
    "total_throughput": 8673.69734862957,
    "itl": 210.79253229945272,
    "ttft": 1797746.0147064675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3141015348862912,
    "arrivals": 182454,
    "finished_requests": 67139,
    "scheduler_time": 98.71992207980604
}
#Debug simulation 
Total elapsed time: 14.775622508022934. Arrivals time: 0.28420643182471395 Scheduler time: 14.385500599164516 Scheduler overhead time: 0.03343317564576864 Adapter cache time: 0.025208093225955963 Engine time: 0.03350787376984954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.994960662908852,
    "estimated_duration": 3600.0712698312327,
    "input_throughput": 4393.447744366869,
    "output_throughput": 3918.3015953629388,
    "total_throughput": 8311.749339729808,
    "itl": 178.60550087383223,
    "ttft": 1841770.9200748252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.759052751883809,
    "arrivals": 182454,
    "finished_requests": 64317,
    "scheduler_time": 103.40284977280622
}
#Debug simulation 
Total elapsed time: 9.99513061530888. Arrivals time: 0.2542819664813578 Scheduler time: 9.629187565296888 Scheduler overhead time: 0.033677034080028534 Adapter cache time: 0.029463935643434525 Engine time: 0.0336526264436543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 14.810121371410787,
    "estimated_duration": 3600.211361263049,
    "input_throughput": 4588.22367423585,
    "output_throughput": 4087.2861405663575,
    "total_throughput": 8675.509814802208,
    "itl": 210.71194880265645,
    "ttft": 1798446.0238439345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1015,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.17137188568475,
    "arrivals": 182454,
    "finished_requests": 67183,
    "scheduler_time": 98.72979305285632
}
#Debug simulation 
Total elapsed time: 14.810239739250392. Arrivals time: 0.2832805900834501 Scheduler time: 14.420981311239302 Scheduler overhead time: 0.03336659399792552 Adapter cache time: 0.02497004671022296 Engine time: 0.03411582065746188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_320_slots_128_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 10.035345288924873,
    "estimated_duration": 3600.010177271536,
    "input_throughput": 4393.62563468858,
    "output_throughput": 3920.3700281471392,
    "total_throughput": 8313.99566283572,
    "itl": 178.66470266697914,
    "ttft": 1842039.4863248896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7957968994043796,
    "arrivals": 182454,
    "finished_requests": 64360,
    "scheduler_time": 103.38442038603827
}
#Debug simulation 
Total elapsed time: 10.035475597716868. Arrivals time: 0.2609044606797397 Scheduler time: 9.664863359183073 Scheduler overhead time: 0.03351270267739892 Adapter cache time: 0.027972713112831116 Engine time: 0.03343211626634002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.51356519991532,
    "estimated_duration": 3600.03010154121,
    "input_throughput": 4585.073328396182,
    "output_throughput": 4084.976398865163,
    "total_throughput": 8670.049727261345,
    "itl": 210.77733980719776,
    "ttft": 1798299.5873713081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.100682155813483,
    "arrivals": 182454,
    "finished_requests": 67130,
    "scheduler_time": 98.717144199702
}
#Debug simulation 
Total elapsed time: 14.513706122059375. Arrivals time: 0.27694388339295983 Scheduler time: 14.132792583666742 Scheduler overhead time: 0.03269408596679568 Adapter cache time: 0.024792084004729986 Engine time: 0.03300699358806014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_320_slots_128_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_320_slots_128_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 270, 4320, 4320, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 4320, 540, 270, 270, 540, 4320, 4320, 540, 540, 270, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 540, 4320, 4320, 540, 270, 270, 4320, 270, 270, 4320, 4320, 270, 270, 540, 540, 540, 270, 540, 270, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 270, 4320, 540, 270, 270, 540, 540, 4320, 540, 4320, 4320, 4320, 270, 540, 540, 270, 4320, 540, 4320, 4320, 540, 270, 540, 540, 540, 270, 4320, 540, 4320, 270, 4320, 270, 270, 540, 4320, 4320, 540, 270, 540, 270, 540, 4320, 4320, 540, 270, 540, 270, 4320, 270, 270, 270, 270, 4320, 540, 540, 4320, 540, 540, 270, 540, 4320, 540, 270, 270, 540, 4320, 270, 270, 270, 4320, 4320, 4320, 270, 540, 4320, 540, 540, 540, 270, 4320, 270, 4320, 540, 270, 540, 270, 270, 540, 270, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 540, 270, 540, 270, 270, 270, 4320, 4320, 540, 540, 270, 270, 540, 270, 4320, 270, 270, 540, 270, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 270, 540, 270, 4320, 540, 540, 4320, 4320, 270, 270, 270, 4320, 4320, 270, 270, 4320, 540, 270, 540, 270, 540, 4320, 4320, 4320, 270, 4320, 4320, 4320, 4320, 270, 540, 540, 4320, 270, 4320, 270, 270, 270, 4320, 540, 4320, 4320, 270, 540, 540, 540, 270, 540, 270, 540, 540, 4320, 270, 270, 540, 270, 540, 540, 270, 4320, 4320, 4320, 270, 540, 540, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 540, 540, 540, 270, 270, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 4320, 270, 270, 270]
Prompts retrieved: 548640 . Total input tokens: 122301393 . Total output tokens: 109771629
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.846183610148728,
    "estimated_duration": 3600.094763240223,
    "input_throughput": 4391.213298444258,
    "output_throughput": 3918.060197755631,
    "total_throughput": 8309.273496199889,
    "itl": 178.37097939774225,
    "ttft": 1842040.2419276906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1343,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.499516953937721,
    "arrivals": 182454,
    "finished_requests": 64297,
    "scheduler_time": 103.43613487888143
}
#Debug simulation 
Total elapsed time: 9.84629772324115. Arrivals time: 0.2526961639523506 Scheduler time: 9.480577917769551 Scheduler overhead time: 0.03334982320666313 Adapter cache time: 0.0316698644310236 Engine time: 0.03326188027858734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.792263363022357,
    "estimated_duration": 3600.079645881168,
    "input_throughput": 4663.218220521041,
    "output_throughput": 4078.904481127334,
    "total_throughput": 8742.122701648375,
    "itl": 208.52610916735682,
    "ttft": 1784635.6629212892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 722,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.209672151119489,
    "arrivals": 177727,
    "finished_requests": 67441,
    "scheduler_time": 98.75440702267619
}
#Debug simulation 
Total elapsed time: 12.792403100989759. Arrivals time: 0.26762710930779576 Scheduler time: 12.428208607714623 Scheduler overhead time: 0.03207578510046005 Adapter cache time: 0.018957729917019606 Engine time: 0.03233037982136011 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.894292783923447,
    "estimated_duration": 3600.1796488721475,
    "input_throughput": 4662.946196381927,
    "output_throughput": 4078.533693339438,
    "total_throughput": 8741.479889721364,
    "itl": 208.53434582835615,
    "ttft": 1784711.0392322508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.359157902020967,
    "arrivals": 177727,
    "finished_requests": 67439,
    "scheduler_time": 98.75411661791064
}
#Debug simulation 
Total elapsed time: 12.894405169878155. Arrivals time: 0.2835725103504956 Scheduler time: 12.513249681331217 Scheduler overhead time: 0.03246746864169836 Adapter cache time: 0.019129408057779074 Engine time: 0.032514247577637434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.565657060127705,
    "estimated_duration": 3600.021092941802,
    "input_throughput": 4469.282424912753,
    "output_throughput": 3915.115116306862,
    "total_throughput": 8384.397541219616,
    "itl": 177.35287939822928,
    "ttft": 1830360.5777050974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1266,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.140092480387469,
    "arrivals": 177727,
    "finished_requests": 64629,
    "scheduler_time": 103.36864629933038
}
#Debug simulation 
Total elapsed time: 8.56578062986955. Arrivals time: 0.237063052598387 Scheduler time: 8.218174726236612 Scheduler overhead time: 0.03316950285807252 Adapter cache time: 0.02985416352748871 Engine time: 0.03273445274680853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 12.923951025120914,
    "estimated_duration": 3600.2127226488415,
    "input_throughput": 4662.9394686569,
    "output_throughput": 4078.6364949003178,
    "total_throughput": 8741.575963557218,
    "itl": 208.52972231818654,
    "ttft": 1784678.998629059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.259052049003057,
    "arrivals": 177727,
    "finished_requests": 67440,
    "scheduler_time": 98.75725195886339
}
#Debug simulation 
Total elapsed time: 12.924137485213578. Arrivals time: 0.2843693899922073 Scheduler time: 12.5424210508354 Scheduler overhead time: 0.031987175811082125 Adapter cache time: 0.0191746330820024 Engine time: 0.03246502438560128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 8.592125706374645,
    "estimated_duration": 3600.1839963879947,
    "input_throughput": 4468.767434148147,
    "output_throughput": 3910.1109871393633,
    "total_throughput": 8378.87842128751,
    "itl": 176.57843197278189,
    "ttft": 1831113.6876251132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.560263127665936,
    "arrivals": 177727,
    "finished_requests": 64575,
    "scheduler_time": 103.51345854699726
}
#Debug simulation 
Total elapsed time: 8.592269450426102. Arrivals time: 0.2517691473476589 Scheduler time: 8.228952046018094 Scheduler overhead time: 0.03247732436284423 Adapter cache time: 0.03157668700441718 Engine time: 0.03273050952702761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 12.77280556410551,
    "estimated_duration": 3600.005323334772,
    "input_throughput": 4663.171993437328,
    "output_throughput": 4078.7311909856735,
    "total_throughput": 8741.903184423001,
    "itl": 208.52427759305317,
    "ttft": 1784646.312151319,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1618063632142333,
    "arrivals": 177727,
    "finished_requests": 67439,
    "scheduler_time": 98.75324925662775
}
#Debug simulation 
Total elapsed time: 12.77292045392096. Arrivals time: 0.273502882104367 Scheduler time: 12.403116401284933 Scheduler overhead time: 0.03159564966335893 Adapter cache time: 0.019061057828366756 Engine time: 0.03212734591215849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.560132431332022,
    "estimated_duration": 3600.102824848854,
    "input_throughput": 4468.549589462185,
    "output_throughput": 3914.1026480518926,
    "total_throughput": 8382.652237514078,
    "itl": 177.32766810547812,
    "ttft": 1830679.2978361961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1274,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.275161113664544,
    "arrivals": 177727,
    "finished_requests": 64601,
    "scheduler_time": 103.37219339581861
}
#Debug simulation 
Total elapsed time: 8.560278118122369. Arrivals time: 0.24024601047858596 Scheduler time: 8.210309747140855 Scheduler overhead time: 0.03270478080958128 Adapter cache time: 0.0298525458201766 Engine time: 0.032531220000237226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.052976957056671,
    "estimated_duration": 3600.134127073,
    "input_throughput": 4618.461538686682,
    "output_throughput": 4083.5972997352433,
    "total_throughput": 8702.058838421925,
    "itl": 209.5824181582959,
    "ttft": 1778229.4151120612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 785,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.402482878987259,
    "arrivals": 175481,
    "finished_requests": 67333,
    "scheduler_time": 98.42065445915776
}
#Debug simulation 
Total elapsed time: 11.053057560231537. Arrivals time: 0.2629336710087955 Scheduler time: 10.696062638889998 Scheduler overhead time: 0.030240905936807394 Adapter cache time: 0.01976117631420493 Engine time: 0.030940943397581577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.687428872101009,
    "estimated_duration": 3600.13735499762,
    "input_throughput": 4614.535047374875,
    "output_throughput": 4083.6333590415798,
    "total_throughput": 8698.168406416455,
    "itl": 209.6678843544753,
    "ttft": 1778063.2695541042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.572715151156305,
    "arrivals": 175481,
    "finished_requests": 67313,
    "scheduler_time": 98.40815176200036
}
#Debug simulation 
Total elapsed time: 10.687558336183429. Arrivals time: 0.25951989041641355 Scheduler time: 10.332255566958338 Scheduler overhead time: 0.030973047483712435 Adapter cache time: 0.019957268610596657 Engine time: 0.03152712667360902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.828866303898394,
    "estimated_duration": 3600.0832687360157,
    "input_throughput": 4428.0867441149585,
    "output_throughput": 3919.9059984395026,
    "total_throughput": 8347.992742554461,
    "itl": 177.86435810679117,
    "ttft": 1821529.79873831,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1154,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.77088957978407,
    "arrivals": 175481,
    "finished_requests": 64534,
    "scheduler_time": 103.03635518178616
}
#Debug simulation 
Total elapsed time: 7.829008635133505. Arrivals time: 0.23630220675840974 Scheduler time: 7.485953441355377 Scheduler overhead time: 0.03231928404420614 Adapter cache time: 0.02726221177726984 Engine time: 0.03248811513185501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 10.723089547362179,
    "estimated_duration": 3600.0108985450042,
    "input_throughput": 4617.586854172739,
    "output_throughput": 4083.3934713756894,
    "total_throughput": 8700.980325548428,
    "itl": 209.58809621829317,
    "ttft": 1778084.2964930926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 779,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4326237952941816,
    "arrivals": 175481,
    "finished_requests": 67326,
    "scheduler_time": 98.41606423814537
}
#Debug simulation 
Total elapsed time: 10.723204573150724. Arrivals time: 0.266755991615355 Scheduler time: 10.36315536685288 Scheduler overhead time: 0.03023189678788185 Adapter cache time: 0.019652688410133123 Engine time: 0.03036508010700345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.882328975945711,
    "estimated_duration": 3600.0118008951645,
    "input_throughput": 4428.210484208975,
    "output_throughput": 3919.459929684519,
    "total_throughput": 8347.670413893495,
    "itl": 177.85579883882787,
    "ttft": 1821939.2204319595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1143,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.784848639406268,
    "arrivals": 175481,
    "finished_requests": 64529,
    "scheduler_time": 103.0313734516945
}
#Debug simulation 
Total elapsed time: 7.882464285008609. Arrivals time: 0.24488059571012855 Scheduler time: 7.530973439570516 Scheduler overhead time: 0.03243276523426175 Adapter cache time: 0.027346517890691757 Engine time: 0.032166617922484875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 10.713635256048292,
    "estimated_duration": 3600.02694352728,
    "input_throughput": 4616.232117340004,
    "output_throughput": 4084.4619306079303,
    "total_throughput": 8700.694047947934,
    "itl": 209.59673323185896,
    "ttft": 1778374.8822097378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3412093809083574,
    "arrivals": 175481,
    "finished_requests": 67329,
    "scheduler_time": 98.41835897361395
}
#Debug simulation 
Total elapsed time: 10.713829542975873. Arrivals time: 0.26706108171492815 Scheduler time: 10.352670688182116 Scheduler overhead time: 0.030338493641465902 Adapter cache time: 0.01951787481084466 Engine time: 0.03092520171776414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.886265798006207,
    "estimated_duration": 3600.1193443743305,
    "input_throughput": 4429.183722733283,
    "output_throughput": 3919.3209030830612,
    "total_throughput": 8348.504625816344,
    "itl": 177.8628391328798,
    "ttft": 1821562.6784081468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.777759704552646,
    "arrivals": 175481,
    "finished_requests": 64542,
    "scheduler_time": 103.0351608435995
}
#Debug simulation 
Total elapsed time: 7.88637791806832. Arrivals time: 0.23719635838642716 Scheduler time: 7.543213261291385 Scheduler overhead time: 0.03244819398969412 Adapter cache time: 0.026807062327861786 Engine time: 0.03218661993741989 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.193876486737281,
    "estimated_duration": 3600.0978393968835,
    "input_throughput": 4608.888074769572,
    "output_throughput": 4082.6815424722827,
    "total_throughput": 8691.569617241856,
    "itl": 209.97171033630067,
    "ttft": 1780325.0688061723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 765,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3412731241086018,
    "arrivals": 174302,
    "finished_requests": 67328,
    "scheduler_time": 98.45246154971498
}
#Debug simulation 
Total elapsed time: 9.19400041969493. Arrivals time: 0.2581430450081825 Scheduler time: 8.844964080955833 Scheduler overhead time: 0.029408756643533707 Adapter cache time: 0.019028407521545887 Engine time: 0.029422845225781202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.16345567535609,
    "estimated_duration": 3600.1289006420516,
    "input_throughput": 4608.555265074278,
    "output_throughput": 4084.1701521792047,
    "total_throughput": 8692.725417253483,
    "itl": 210.02206193256032,
    "ttft": 1780306.3379425367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5058381417789573,
    "arrivals": 174302,
    "finished_requests": 67334,
    "scheduler_time": 98.44874938839764
}
#Debug simulation 
Total elapsed time: 9.163569733966142. Arrivals time: 0.26170266745612025 Scheduler time: 8.810491593088955 Scheduler overhead time: 0.029443392530083656 Adapter cache time: 0.019140270072966814 Engine time: 0.029947548173367977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.3188201622106135,
    "estimated_duration": 3600.129400077559,
    "input_throughput": 4414.195500766623,
    "output_throughput": 3915.755916911292,
    "total_throughput": 8329.951417677914,
    "itl": 177.71200342877606,
    "ttft": 1825681.2389626338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.7617424404434288,
    "arrivals": 174302,
    "finished_requests": 64487,
    "scheduler_time": 103.12511729812643
}
#Debug simulation 
Total elapsed time: 7.3189276941120625. Arrivals time: 0.45994384912773967 Scheduler time: 6.752532390411943 Scheduler overhead time: 0.03236851375550032 Adapter cache time: 0.027560033835470676 Engine time: 0.031998306047171354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.175237291958183,
    "estimated_duration": 3600.0888311978283,
    "input_throughput": 4608.141570351262,
    "output_throughput": 4082.5614836592217,
    "total_throughput": 8690.703054010484,
    "itl": 209.98454445951882,
    "ttft": 1780213.5610228933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 762,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.3834273215546076,
    "arrivals": 174302,
    "finished_requests": 67321,
    "scheduler_time": 98.45042558473153
}
#Debug simulation 
Total elapsed time: 9.17537136375904. Arrivals time: 0.24978744238615036 Scheduler time: 8.834640604443848 Scheduler overhead time: 0.029404937755316496 Adapter cache time: 0.019065691623836756 Engine time: 0.02945889299735427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.286129142157733,
    "estimated_duration": 3600.0045739565253,
    "input_throughput": 4413.616614530412,
    "output_throughput": 3915.7800248312233,
    "total_throughput": 8329.396639361636,
    "itl": 177.72912956416596,
    "ttft": 1826145.3965829606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1151,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.818382500279698,
    "arrivals": 174302,
    "finished_requests": 64485,
    "scheduler_time": 103.1136551658998
}
#Debug simulation 
Total elapsed time: 7.286203735042363. Arrivals time: 0.23797630006447434 Scheduler time: 6.942875404842198 Scheduler overhead time: 0.03210521396249533 Adapter cache time: 0.02685083309188485 Engine time: 0.031851198989897966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.17679324792698,
    "estimated_duration": 3600.1610609051463,
    "input_throughput": 4608.884358031551,
    "output_throughput": 4084.2961609898402,
    "total_throughput": 8693.18051902139,
    "itl": 210.00947266308947,
    "ttft": 1780228.9216463089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2933685761899243,
    "arrivals": 174302,
    "finished_requests": 67338,
    "scheduler_time": 98.45424273742583
}
#Debug simulation 
Total elapsed time: 9.176915304735303. Arrivals time: 0.2632593405432999 Scheduler time: 8.822098610457033 Scheduler overhead time: 0.029687971342355013 Adapter cache time: 0.019156317692250013 Engine time: 0.029757563956081867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.307650055270642,
    "estimated_duration": 3600.0499319457354,
    "input_throughput": 4413.642949505486,
    "output_throughput": 3915.44624837511,
    "total_throughput": 8329.089197880596,
    "itl": 177.72755386439547,
    "ttft": 1825812.9888998952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1145,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.845507079698203,
    "arrivals": 174302,
    "finished_requests": 64484,
    "scheduler_time": 103.11690303967858
}
#Debug simulation 
Total elapsed time: 7.307726663071662. Arrivals time: 0.2344976607710123 Scheduler time: 6.968362760730088 Scheduler overhead time: 0.03198001720011234 Adapter cache time: 0.026253985706716776 Engine time: 0.03209957340732217 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.19320124015212,
    "estimated_duration": 3600.145378982196,
    "input_throughput": 4670.258900698452,
    "output_throughput": 4081.0710272354977,
    "total_throughput": 8751.32992793395,
    "itl": 208.3515403351475,
    "ttft": 1757465.6432031216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5708097049035663,
    "arrivals": 168141,
    "finished_requests": 67322,
    "scheduler_time": 98.1569014028486
}
#Debug simulation 
Total elapsed time: 9.193379723932594. Arrivals time: 0.25388109078630805 Scheduler time: 8.846814170479774 Scheduler overhead time: 0.0294057740829885 Adapter cache time: 0.02036151336506009 Engine time: 0.029808831866830587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.426885521039367,
    "estimated_duration": 3600.0390618112883,
    "input_throughput": 4669.797663679141,
    "output_throughput": 4080.7643327649225,
    "total_throughput": 8750.561996444063,
    "itl": 208.3613163113398,
    "ttft": 1757457.5649371806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.740455626044428,
    "arrivals": 168141,
    "finished_requests": 67317,
    "scheduler_time": 98.15021682566633
}
#Debug simulation 
Total elapsed time: 9.427001741714776. Arrivals time: 0.4859255254268646 Scheduler time: 8.847751867491752 Scheduler overhead time: 0.029973268508911133 Adapter cache time: 0.020561765879392624 Engine time: 0.029875685926526785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.283955347724259,
    "estimated_duration": 3600.1506403161948,
    "input_throughput": 4473.995287759777,
    "output_throughput": 3913.269862164058,
    "total_throughput": 8387.265149923835,
    "itl": 177.0583430422211,
    "ttft": 1804010.2487677918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.278045988269089,
    "arrivals": 168141,
    "finished_requests": 64438,
    "scheduler_time": 102.68659082303793
}
#Debug simulation 
Total elapsed time: 7.284099582117051. Arrivals time: 0.23691272921860218 Scheduler time: 6.937957432121038 Scheduler overhead time: 0.032430869061499834 Adapter cache time: 0.0298015046864748 Engine time: 0.03225046303123236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.233956508804113,
    "estimated_duration": 3600.1150849448304,
    "input_throughput": 4670.298199719262,
    "output_throughput": 4081.1053683927307,
    "total_throughput": 8751.403568111993,
    "itl": 208.35707166358532,
    "ttft": 1757432.822598899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.625770224628479,
    "arrivals": 168141,
    "finished_requests": 67322,
    "scheduler_time": 98.1551071007594
}
#Debug simulation 
Total elapsed time: 9.234067361801863. Arrivals time: 0.2536726277321577 Scheduler time: 8.887113979551941 Scheduler overhead time: 0.029592336621135473 Adapter cache time: 0.02045666566118598 Engine time: 0.03006649948656559 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.356195458211005,
    "estimated_duration": 3600.130421197937,
    "input_throughput": 4474.030692099314,
    "output_throughput": 3914.017646980482,
    "total_throughput": 8388.048339079796,
    "itl": 177.08082289034508,
    "ttft": 1804182.8583110734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1252,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.144772380907084,
    "arrivals": 168141,
    "finished_requests": 64469,
    "scheduler_time": 102.6837558460353
}
#Debug simulation 
Total elapsed time: 7.356329775881022. Arrivals time: 0.24507287982851267 Scheduler time: 7.003466236405075 Scheduler overhead time: 0.03240628866478801 Adapter cache time: 0.028661493211984634 Engine time: 0.03208084590733051 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.183424467220902,
    "estimated_duration": 3600.072408164095,
    "input_throughput": 4670.35356340911,
    "output_throughput": 4081.1537475415976,
    "total_throughput": 8751.507310950708,
    "itl": 208.3494867516829,
    "ttft": 1757440.316916241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5116422477177753,
    "arrivals": 168141,
    "finished_requests": 67322,
    "scheduler_time": 98.15603377387423
}
#Debug simulation 
Total elapsed time: 9.183566662017256. Arrivals time: 0.24858088698238134 Scheduler time: 8.841870624106377 Scheduler overhead time: 0.029722665902227163 Adapter cache time: 0.02024018345400691 Engine time: 0.030257402453571558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.367275892756879,
    "estimated_duration": 3600.1511197038703,
    "input_throughput": 4473.874697050174,
    "output_throughput": 3914.0293091805156,
    "total_throughput": 8387.90400623069,
    "itl": 177.11953207744702,
    "ttft": 1804196.4433286719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1254,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.202252703383606,
    "arrivals": 168141,
    "finished_requests": 64470,
    "scheduler_time": 102.67800759991297
}
#Debug simulation 
Total elapsed time: 7.367386571131647. Arrivals time: 0.234966772608459 Scheduler time: 7.02490507857874 Scheduler overhead time: 0.03222653502598405 Adapter cache time: 0.028366512153297663 Engine time: 0.0323874824680388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.802155736833811,
    "estimated_duration": 3600.1004234156817,
    "input_throughput": 4685.041808916371,
    "output_throughput": 4079.686751089318,
    "total_throughput": 8764.72856000569,
    "itl": 208.06665476546337,
    "ttft": 1746124.6388502785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.625898484294358,
    "arrivals": 165887,
    "finished_requests": 67681,
    "scheduler_time": 98.01778984715038
}
#Debug simulation 
Total elapsed time: 7.802282266784459. Arrivals time: 0.24592746887356043 Scheduler time: 7.465662561357021 Scheduler overhead time: 0.028411847073584795 Adapter cache time: 0.020471721421927214 Engine time: 0.02898550173267722 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.818094005808234,
    "estimated_duration": 3600.2057891031013,
    "input_throughput": 4683.582269390411,
    "output_throughput": 4079.7159552535168,
    "total_throughput": 8763.298224643928,
    "itl": 208.11069254271578,
    "ttft": 1746162.4253145081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.801352534831973,
    "arrivals": 165887,
    "finished_requests": 67674,
    "scheduler_time": 98.01280794342814
}
#Debug simulation 
Total elapsed time: 7.818238647654653. Arrivals time: 0.24473088514059782 Scheduler time: 7.482467351015657 Scheduler overhead time: 0.028667624108493328 Adapter cache time: 0.020627984777092934 Engine time: 0.028831086587160826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.390913089737296,
    "estimated_duration": 3600.000323875946,
    "input_throughput": 4488.664040619357,
    "output_throughput": 3917.776314201803,
    "total_throughput": 8406.440354821161,
    "itl": 177.51774975585127,
    "ttft": 1791461.9045213445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.177626449055912,
    "arrivals": 165887,
    "finished_requests": 64869,
    "scheduler_time": 102.40951813157824
}
#Debug simulation 
Total elapsed time: 6.391094035003334. Arrivals time: 0.21930283028632402 Scheduler time: 6.064564395695925 Scheduler overhead time: 0.031819865107536316 Adapter cache time: 0.028908317908644676 Engine time: 0.03185743372887373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.067147542722523,
    "estimated_duration": 3600.023220251751,
    "input_throughput": 4683.805066907554,
    "output_throughput": 4079.8456291548296,
    "total_throughput": 8763.650696062383,
    "itl": 208.105099781459,
    "ttft": 1746133.4037826085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6808169158920374,
    "arrivals": 165887,
    "finished_requests": 67673,
    "scheduler_time": 98.01013640103892
}
#Debug simulation 
Total elapsed time: 8.067255760077387. Arrivals time: 0.25330006051808596 Scheduler time: 7.72337214788422 Scheduler overhead time: 0.028700968250632286 Adapter cache time: 0.020225160755217075 Engine time: 0.028874732553958893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.388665205799043,
    "estimated_duration": 3600.1750877654536,
    "input_throughput": 4487.920061140267,
    "output_throughput": 3917.140043528558,
    "total_throughput": 8405.060104668824,
    "itl": 177.51058235297154,
    "ttft": 1791537.380646498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.2411886793374975,
    "arrivals": 165887,
    "finished_requests": 64863,
    "scheduler_time": 102.41421198385876
}
#Debug simulation 
Total elapsed time: 6.388806678820401. Arrivals time: 0.22769607370719314 Scheduler time: 6.054029401391745 Scheduler overhead time: 0.0318996487185359 Adapter cache time: 0.028750690631568432 Engine time: 0.03184500755742192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.819686288945377,
    "estimated_duration": 3600.2254951159725,
    "input_throughput": 4684.048824963053,
    "output_throughput": 4080.134985968932,
    "total_throughput": 8764.183810931985,
    "itl": 208.09786233407186,
    "ttft": 1746123.9825838972,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 859,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5684532033209146,
    "arrivals": 165887,
    "finished_requests": 67680,
    "scheduler_time": 98.01836638934257
}
#Debug simulation 
Total elapsed time: 7.819795049726963. Arrivals time: 0.25728692347183824 Scheduler time: 7.472024106420577 Scheduler overhead time: 0.028604830149561167 Adapter cache time: 0.02037234790623188 Engine time: 0.02876748377457261 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.618190246168524,
    "estimated_duration": 3600.1947244490357,
    "input_throughput": 4487.081182108065,
    "output_throughput": 3917.136454933893,
    "total_throughput": 8404.217637041958,
    "itl": 177.50914244993658,
    "ttft": 1791871.0892723938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.281050661243534,
    "arrivals": 165887,
    "finished_requests": 64858,
    "scheduler_time": 102.4123247932513
}
#Debug simulation 
Total elapsed time: 6.6182940332219005. Arrivals time: 0.22568318527191877 Scheduler time: 6.285603012423962 Scheduler overhead time: 0.031926891300827265 Adapter cache time: 0.02861455548554659 Engine time: 0.03200555918738246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.9476161119528115,
    "estimated_duration": 3600.1286137532734,
    "input_throughput": 4617.646974192044,
    "output_throughput": 4083.551610861289,
    "total_throughput": 8701.198585053333,
    "itl": 209.7892759453539,
    "ttft": 1736740.1695822817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 895,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7391365308198736,
    "arrivals": 164660,
    "finished_requests": 67562,
    "scheduler_time": 97.62990209346702
}
#Debug simulation 
Total elapsed time: 6.947757212910801. Arrivals time: 0.24092795187607408 Scheduler time: 6.6168832131661475 Scheduler overhead time: 0.028087459038943052 Adapter cache time: 0.020640868227928877 Engine time: 0.02844133786857128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.94095304235816,
    "estimated_duration": 3600.154658174188,
    "input_throughput": 4617.40163363718,
    "output_throughput": 4083.3345774804575,
    "total_throughput": 8700.736211117637,
    "itl": 209.7970415132817,
    "ttft": 1736812.126101367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9178535593883193,
    "arrivals": 164660,
    "finished_requests": 67560,
    "scheduler_time": 97.62678321446097
}
#Debug simulation 
Total elapsed time: 6.941067470237613. Arrivals time: 0.23935620533302426 Scheduler time: 6.612293668091297 Scheduler overhead time: 0.027980653569102287 Adapter cache time: 0.020573561545461416 Engine time: 0.028085795231163502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.092913922388107,
    "estimated_duration": 3600.152193505431,
    "input_throughput": 4425.784006782702,
    "output_throughput": 3924.1185485117708,
    "total_throughput": 8349.902555294473,
    "itl": 178.90524833493154,
    "ttft": 1780478.1643467913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.994036741238024,
    "arrivals": 164660,
    "finished_requests": 64812,
    "scheduler_time": 102.08861518652951
}
#Debug simulation 
Total elapsed time: 6.093020939268172. Arrivals time: 0.459580535069108 Scheduler time: 5.52936293836683 Scheduler overhead time: 0.03145346511155367 Adapter cache time: 0.027134012430906296 Engine time: 0.031104546505957842 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.968368512112647,
    "estimated_duration": 3600.2035564189055,
    "input_throughput": 4617.593905311299,
    "output_throughput": 4083.4252201625877,
    "total_throughput": 8701.019125473886,
    "itl": 209.79164211709954,
    "ttft": 1736760.778408705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.7907804153533364,
    "arrivals": 164660,
    "finished_requests": 67562,
    "scheduler_time": 97.63092228223022
}
#Debug simulation 
Total elapsed time: 6.9685058682225645. Arrivals time: 0.24100420158356428 Scheduler time: 6.637195270508528 Scheduler overhead time: 0.028112794738262892 Adapter cache time: 0.020810105372220278 Engine time: 0.02857318241149187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.87100728508085,
    "estimated_duration": 3600.092647537179,
    "input_throughput": 4426.135258185864,
    "output_throughput": 3924.5506666794995,
    "total_throughput": 8350.685924865364,
    "itl": 178.90864984018373,
    "ttft": 1780398.7848199382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.9909407873824296,
    "arrivals": 164660,
    "finished_requests": 64820,
    "scheduler_time": 102.08884366547102
}
#Debug simulation 
Total elapsed time: 5.87118056230247. Arrivals time: 0.22976878192275763 Scheduler time: 5.5366595215164125 Scheduler overhead time: 0.0316307065077126 Adapter cache time: 0.026615433860570192 Engine time: 0.03212576545774937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.187382988166064,
    "estimated_duration": 3600.0060738494867,
    "input_throughput": 4617.70526465368,
    "output_throughput": 4083.6078324390733,
    "total_throughput": 8701.313097092754,
    "itl": 209.78525703367163,
    "ttft": 1736714.5974693643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 894,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.673104963642487,
    "arrivals": 164660,
    "finished_requests": 67561,
    "scheduler_time": 97.62783380867334
}
#Debug simulation 
Total elapsed time: 7.187458408996463. Arrivals time: 0.4695162121206522 Scheduler time: 6.627967154607177 Scheduler overhead time: 0.028244032058864832 Adapter cache time: 0.020482129883021116 Engine time: 0.028514078352600336 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.851168174762279,
    "estimated_duration": 3600.0197351737634,
    "input_throughput": 4424.914631539127,
    "output_throughput": 3923.4940469897842,
    "total_throughput": 8348.408678528911,
    "itl": 178.92361834219741,
    "ttft": 1780169.58377619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1214,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.067547913566286,
    "arrivals": 164660,
    "finished_requests": 64802,
    "scheduler_time": 102.07993542555737
}
#Debug simulation 
Total elapsed time: 5.851302416995168. Arrivals time: 0.2244424642995 Scheduler time: 5.523119593504816 Scheduler overhead time: 0.03139845374971628 Adapter cache time: 0.026619324926286936 Engine time: 0.031447991263121367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.1500289691612124,
    "estimated_duration": 3600.1392075574536,
    "input_throughput": 4647.126412467484,
    "output_throughput": 4083.601814379391,
    "total_throughput": 8730.728226846875,
    "itl": 208.9455598777482,
    "ttft": 1730546.1718601529,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1076,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2930848124717214,
    "arrivals": 161177,
    "finished_requests": 67338,
    "scheduler_time": 97.55785025360844
}
#Debug simulation 
Total elapsed time: 6.150137927383184. Arrivals time: 0.22428127471357584 Scheduler time: 5.833648761268705 Scheduler overhead time: 0.028051697183400393 Adapter cache time: 0.02321348339319229 Engine time: 0.02825588919222355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.146170815918595,
    "estimated_duration": 3600.2212872825153,
    "input_throughput": 4647.574041936103,
    "output_throughput": 4083.0467982415653,
    "total_throughput": 8730.620840177668,
    "itl": 208.93322748400527,
    "ttft": 1730553.5553268723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5530836845887888,
    "arrivals": 161177,
    "finished_requests": 67348,
    "scheduler_time": 97.55650549789766
}
#Debug simulation 
Total elapsed time: 6.146285302005708. Arrivals time: 0.2377873589284718 Scheduler time: 5.816422468982637 Scheduler overhead time: 0.027942609041929245 Adapter cache time: 0.023520929738879204 Engine time: 0.028012041002511978 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.297592915594578,
    "estimated_duration": 3600.0916362162575,
    "input_throughput": 4445.497397621972,
    "output_throughput": 3913.5109390736834,
    "total_throughput": 8359.008336695655,
    "itl": 176.91303735332357,
    "ttft": 1776069.6319129816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1519,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.970132803153195,
    "arrivals": 161177,
    "finished_requests": 64425,
    "scheduler_time": 102.17064328461676
}
#Debug simulation 
Total elapsed time: 5.297730923630297. Arrivals time: 0.21423721220344305 Scheduler time: 4.973075921647251 Scheduler overhead time: 0.0321518168784678 Adapter cache time: 0.031857792753726244 Engine time: 0.031780241057276726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.15402374509722,
    "estimated_duration": 3600.045276347822,
    "input_throughput": 4647.159331554923,
    "output_throughput": 4083.0836480234907,
    "total_throughput": 8730.242979578414,
    "itl": 208.9466850866264,
    "ttft": 1730573.6965880306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.367229653061328,
    "arrivals": 161177,
    "finished_requests": 67335,
    "scheduler_time": 97.55344343451418
}
#Debug simulation 
Total elapsed time: 6.154132902156562. Arrivals time: 0.2339670923538506 Scheduler time: 5.828212697524577 Scheduler overhead time: 0.027784676756709814 Adapter cache time: 0.023576315492391586 Engine time: 0.027960458770394325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.300500913988799,
    "estimated_duration": 3600.0052310788224,
    "input_throughput": 4445.6165957303265,
    "output_throughput": 3913.6493131644334,
    "total_throughput": 8359.265908894758,
    "itl": 176.9141172412067,
    "ttft": 1776090.3001262858,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1516,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.028446289990055,
    "arrivals": 161177,
    "finished_requests": 64427,
    "scheduler_time": 102.16614276909918
}
#Debug simulation 
Total elapsed time: 5.300614791922271. Arrivals time: 0.21865198435261846 Scheduler time: 4.972035146318376 Scheduler overhead time: 0.03168505383655429 Adapter cache time: 0.032111361157149076 Engine time: 0.031578133814036846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.385729622095823,
    "estimated_duration": 3600.189459529431,
    "input_throughput": 4647.859560754099,
    "output_throughput": 4083.3639910499332,
    "total_throughput": 8731.223551804032,
    "itl": 208.91721096323894,
    "ttft": 1730461.6447851704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2531747208534885,
    "arrivals": 161177,
    "finished_requests": 67352,
    "scheduler_time": 97.5621499121426
}
#Debug simulation 
Total elapsed time: 6.385810488834977. Arrivals time: 0.4686167864128947 Scheduler time: 5.825268802698702 Scheduler overhead time: 0.027857196982949972 Adapter cache time: 0.023513583932071924 Engine time: 0.027922095730900764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.3007927420549095,
    "estimated_duration": 3600.0725328015847,
    "input_throughput": 4444.444619994507,
    "output_throughput": 3913.538927793738,
    "total_throughput": 8357.983547788244,
    "itl": 176.9300176941322,
    "ttft": 1775978.5856932749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.115214044898701,
    "arrivals": 161177,
    "finished_requests": 64417,
    "scheduler_time": 102.16468488063468
}
#Debug simulation 
Total elapsed time: 5.300988967996091. Arrivals time: 0.22005308652296662 Scheduler time: 4.970601459033787 Scheduler overhead time: 0.03168288106098771 Adapter cache time: 0.032313734758645296 Engine time: 0.03171591833233833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.376259697135538,
    "estimated_duration": 3600.1635751584236,
    "input_throughput": 4629.629363234296,
    "output_throughput": 4082.3150651851324,
    "total_throughput": 8711.944428419429,
    "itl": 209.4822453855001,
    "ttft": 1732087.2360186146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.605254562352873,
    "arrivals": 159905,
    "finished_requests": 67247,
    "scheduler_time": 97.51012856012015
}
#Debug simulation 
Total elapsed time: 5.376375684980303. Arrivals time: 0.22776838205754757 Scheduler time: 5.0563726727850735 Scheduler overhead time: 0.027652660850435495 Adapter cache time: 0.02445516362786293 Engine time: 0.02755198162049055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.579969868995249,
    "estimated_duration": 3600.0443750423224,
    "input_throughput": 4629.652655268746,
    "output_throughput": 4081.894962705076,
    "total_throughput": 8711.547617973822,
    "itl": 209.49251097735888,
    "ttft": 1732220.8976642434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.843435167688882,
    "arrivals": 159905,
    "finished_requests": 67242,
    "scheduler_time": 97.50130073794233
}
#Debug simulation 
Total elapsed time: 5.580042890738696. Arrivals time: 0.22532299300655723 Scheduler time: 5.2626983262598515 Scheduler overhead time: 0.027506706304848194 Adapter cache time: 0.024481303989887238 Engine time: 0.027443220373243093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.8024763790890574,
    "estimated_duration": 3600.161836550983,
    "input_throughput": 4431.404954640592,
    "output_throughput": 3914.875397241162,
    "total_throughput": 8346.280351881755,
    "itl": 177.82925472609122,
    "ttft": 1778420.1230169598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.346796605624208,
    "arrivals": 159905,
    "finished_requests": 64422,
    "scheduler_time": 102.03264713257288
}
#Debug simulation 
Total elapsed time: 4.802589457016438. Arrivals time: 0.21616628160700202 Scheduler time: 4.476076302118599 Scheduler overhead time: 0.03136733919382095 Adapter cache time: 0.03339037857949734 Engine time: 0.031162076629698277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.370012250263244,
    "estimated_duration": 3600.0800796615226,
    "input_throughput": 4629.650071997018,
    "output_throughput": 4082.1453064404373,
    "total_throughput": 8711.795378437455,
    "itl": 209.4851723393734,
    "ttft": 1732136.1981462813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.673050919899206,
    "arrivals": 159905,
    "finished_requests": 67244,
    "scheduler_time": 97.50626268210374
}
#Debug simulation 
Total elapsed time: 5.370160228107125. Arrivals time: 0.23258258355781436 Scheduler time: 5.045189145021141 Scheduler overhead time: 0.027693628799170256 Adapter cache time: 0.02476906171068549 Engine time: 0.0273908618837595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.797089252620935,
    "estimated_duration": 3600.1320576091,
    "input_throughput": 4431.628824914712,
    "output_throughput": 3914.986387849434,
    "total_throughput": 8346.615212764147,
    "itl": 177.87414926270256,
    "ttft": 1778306.2965539247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.414064039271261,
    "arrivals": 159905,
    "finished_requests": 64425,
    "scheduler_time": 102.02070886545215
}
#Debug simulation 
Total elapsed time: 4.797205725684762. Arrivals time: 0.21506776940077543 Scheduler time: 4.471749853808433 Scheduler overhead time: 0.031194028444588184 Adapter cache time: 0.03345172246918082 Engine time: 0.03130389517173171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.388319415971637,
    "estimated_duration": 3600.0305156724,
    "input_throughput": 4629.755477749597,
    "output_throughput": 4082.2340077456556,
    "total_throughput": 8711.989485495253,
    "itl": 209.476691216615,
    "ttft": 1732070.521178025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.5222792473946747,
    "arrivals": 159905,
    "finished_requests": 67245,
    "scheduler_time": 97.50817549800222
}
#Debug simulation 
Total elapsed time: 5.388431689236313. Arrivals time: 0.23240979155525565 Scheduler time: 5.06333885807544 Scheduler overhead time: 0.02764027612283826 Adapter cache time: 0.024720565415918827 Engine time: 0.027835677843540907 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.797348765190691,
    "estimated_duration": 3600.1872099566913,
    "input_throughput": 4431.528714917001,
    "output_throughput": 3914.907247328827,
    "total_throughput": 8346.435962245829,
    "itl": 177.87495458847036,
    "ttft": 1778423.030029056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.476855192556894,
    "arrivals": 159905,
    "finished_requests": 64426,
    "scheduler_time": 102.02171862436019
}
#Debug simulation 
Total elapsed time: 4.797494057100266. Arrivals time: 0.21843671007081866 Scheduler time: 4.4687791066244245 Scheduler overhead time: 0.031164587009698153 Adapter cache time: 0.03347359597682953 Engine time: 0.031183702871203423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.770428730174899,
    "estimated_duration": 3600.05267496278,
    "input_throughput": 4646.34979269378,
    "output_throughput": 4103.842175073937,
    "total_throughput": 8750.191967767716,
    "itl": 208.60930275198922,
    "ttft": 1714385.6578500727,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.397920888031484,
    "arrivals": 157567,
    "finished_requests": 67608,
    "scheduler_time": 97.58548192438263
}
#Debug simulation 
Total elapsed time: 4.770550401881337. Arrivals time: 0.22686424665153027 Scheduler time: 4.448289538733661 Scheduler overhead time: 0.026749647222459316 Adapter cache time: 0.028662398923188448 Engine time: 0.027601105626672506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.753930682782084,
    "estimated_duration": 3600.0694402237973,
    "input_throughput": 4645.891774509844,
    "output_throughput": 4103.3464063075635,
    "total_throughput": 8749.238180817409,
    "itl": 208.62217944373631,
    "ttft": 1714571.4764899297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.69467411393527,
    "arrivals": 157567,
    "finished_requests": 67601,
    "scheduler_time": 97.57922412476927
}
#Debug simulation 
Total elapsed time: 4.754092772025615. Arrivals time: 0.22334417514503002 Scheduler time: 4.43625155184418 Scheduler overhead time: 0.02656165510416031 Adapter cache time: 0.02848715241998434 Engine time: 0.027097356040030718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.6604558899998665,
    "estimated_duration": 3600.0885990548627,
    "input_throughput": 4514.600836286895,
    "output_throughput": 3994.20197707775,
    "total_throughput": 8508.802813364646,
    "itl": 174.4167974913534,
    "ttft": 1745117.0033588582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.761865988448203,
    "arrivals": 157567,
    "finished_requests": 65659,
    "scheduler_time": 103.58341762751161
}
#Debug simulation 
Total elapsed time: 4.660566294100136. Arrivals time: 0.2232872056774795 Scheduler time: 4.329199990723282 Scheduler overhead time: 0.03058137372136116 Adapter cache time: 0.031812695786356926 Engine time: 0.03139519318938255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.778204512782395,
    "estimated_duration": 3600.19880556422,
    "input_throughput": 4646.32619013895,
    "output_throughput": 4103.709211048584,
    "total_throughput": 8750.035401187533,
    "itl": 208.61399709082096,
    "ttft": 1714428.5647750811,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.48629050153067,
    "arrivals": 157567,
    "finished_requests": 67610,
    "scheduler_time": 97.58721524818158
}
#Debug simulation 
Total elapsed time: 4.778317215852439. Arrivals time: 0.22997029079124331 Scheduler time: 4.453194589819759 Scheduler overhead time: 0.026761095505207777 Adapter cache time: 0.028637826442718506 Engine time: 0.027325688861310482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.664770043920726,
    "estimated_duration": 3600.1357091718987,
    "input_throughput": 4514.495372658732,
    "output_throughput": 3993.9449958422238,
    "total_throughput": 8508.440368500957,
    "itl": 174.42528400292056,
    "ttft": 1745215.9710684232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.826251927092636,
    "arrivals": 157567,
    "finished_requests": 65657,
    "scheduler_time": 103.58138851853501
}
#Debug simulation 
Total elapsed time: 4.664879254065454. Arrivals time: 0.21806224342435598 Scheduler time: 4.338458142243326 Scheduler overhead time: 0.030881785787642002 Adapter cache time: 0.031839458271861076 Engine time: 0.03128793276846409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.767700842116028,
    "estimated_duration": 3600.1599411410275,
    "input_throughput": 4646.376348129233,
    "output_throughput": 4103.753511383582,
    "total_throughput": 8750.129859512814,
    "itl": 208.60371279510557,
    "ttft": 1714399.0949403914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1437,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.296702273774311,
    "arrivals": 157567,
    "finished_requests": 67610,
    "scheduler_time": 97.59101610645646
}
#Debug simulation 
Total elapsed time: 4.767813529353589. Arrivals time: 0.22385135618969798 Scheduler time: 4.449742935132235 Scheduler overhead time: 0.02652339357882738 Adapter cache time: 0.028267938643693924 Engine time: 0.02715750178322196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.667241157963872,
    "estimated_duration": 3600.182623157466,
    "input_throughput": 4513.962957175577,
    "output_throughput": 3993.5474127116668,
    "total_throughput": 8507.510369887243,
    "itl": 174.30865801496046,
    "ttft": 1745218.9415219675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1455,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.88159817900506,
    "arrivals": 157567,
    "finished_requests": 65651,
    "scheduler_time": 103.61095896657025
}
#Debug simulation 
Total elapsed time: 4.667366406880319. Arrivals time: 0.22563156485557556 Scheduler time: 4.333476192783564 Scheduler overhead time: 0.030729546677321196 Adapter cache time: 0.03173676086589694 Engine time: 0.031493297312408686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 15.012457494158298,
    "estimated_duration": 3600.143016219681,
    "input_throughput": 4411.122816080638,
    "output_throughput": 3867.013598426027,
    "total_throughput": 8278.136414506664,
    "itl": 168.5175423904893,
    "ttft": 333482.00019525795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.931225247741847,
    "arrivals": 67679,
    "finished_requests": 63459,
    "scheduler_time": 58.21023221912856
}
#Debug simulation 
Total elapsed time: 15.012591688893735. Arrivals time: 0.1868054778315127 Scheduler time: 14.69383911602199 Scheduler overhead time: 0.03729846375063062 Adapter cache time: 0.04134258255362511 Engine time: 0.03724744729697704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 15.011415919754654,
    "estimated_duration": 3600.0315999076793,
    "input_throughput": 4412.6154338221295,
    "output_throughput": 3872.5748963863316,
    "total_throughput": 8285.190330208461,
    "itl": 168.97924437972358,
    "ttft": 333351.50722224714,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1928,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.29394790595144,
    "arrivals": 67679,
    "finished_requests": 63522,
    "scheduler_time": 58.2369839068909
}
#Debug simulation 
Total elapsed time: 15.011599415913224. Arrivals time: 0.19045709865167737 Scheduler time: 14.688845599535853 Scheduler overhead time: 0.0376257449388504 Adapter cache time: 0.04110689228400588 Engine time: 0.03748995577916503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.079560999758542,
    "estimated_duration": 3600.0118889460796,
    "input_throughput": 4359.147270648096,
    "output_throughput": 3829.0920767029907,
    "total_throughput": 8188.2393473510865,
    "itl": 161.34976146661592,
    "ttft": 384691.9984704473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.439319552592897,
    "arrivals": 67679,
    "finished_requests": 62774,
    "scheduler_time": 58.18204440457462
}
#Debug simulation 
Total elapsed time: 12.07970170257613. Arrivals time: 0.18152843974530697 Scheduler time: 11.76057073334232 Scheduler overhead time: 0.036845698952674866 Adapter cache time: 0.04720988217741251 Engine time: 0.03714895900338888 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 14.98145508300513,
    "estimated_duration": 3600.062552529159,
    "input_throughput": 4412.524162626015,
    "output_throughput": 3873.2035337008388,
    "total_throughput": 8285.727696326854,
    "itl": 168.77204644358224,
    "ttft": 336993.18080612185,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.059895833188021,
    "arrivals": 67679,
    "finished_requests": 63494,
    "scheduler_time": 58.240369928501686
}
#Debug simulation 
Total elapsed time: 14.981572099030018. Arrivals time: 0.1865217532031238 Scheduler time: 14.662925980985165 Scheduler overhead time: 0.037106340285390615 Adapter cache time: 0.04104385990649462 Engine time: 0.037673849146813154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_320_slots_128_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 12.47254652902484,
    "estimated_duration": 3600.136381669944,
    "input_throughput": 4361.938364322689,
    "output_throughput": 3827.2952852993394,
    "total_throughput": 8189.233649622029,
    "itl": 161.40697622208066,
    "ttft": 387331.2909108317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2186,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.241520834900285,
    "arrivals": 67679,
    "finished_requests": 62760,
    "scheduler_time": 58.256443234207566
}
#Debug simulation 
Total elapsed time: 12.472671939060092. Arrivals time: 0.18446995224803686 Scheduler time: 12.152138335630298 Scheduler overhead time: 0.03712870692834258 Adapter cache time: 0.045462222304195166 Engine time: 0.03685590671375394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 15.546595061197877,
    "estimated_duration": 3600.1946501663106,
    "input_throughput": 4407.692233881564,
    "output_throughput": 3866.908973756986,
    "total_throughput": 8274.60120763855,
    "itl": 168.00263336258482,
    "ttft": 338008.3511095171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1858,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.555513447928082,
    "arrivals": 67679,
    "finished_requests": 63456,
    "scheduler_time": 58.270177367169254
}
#Debug simulation 
Total elapsed time: 15.546710547059774. Arrivals time: 0.1895564291626215 Scheduler time: 15.225387930404395 Scheduler overhead time: 0.0375359277240932 Adapter cache time: 0.040344000328332186 Engine time: 0.037577652372419834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_320_slots_128_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_320_slots_128_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 13.450093895662576,
    "estimated_duration": 3600.1937757152123,
    "input_throughput": 4371.328872950337,
    "output_throughput": 3831.387380602797,
    "total_throughput": 8202.716253553135,
    "itl": 161.0319927408496,
    "ttft": 377194.2978748187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2034,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.823440089449069,
    "arrivals": 67679,
    "finished_requests": 62865,
    "scheduler_time": 58.20732235594479
}
#Debug simulation 
Total elapsed time: 13.450236172880977. Arrivals time: 0.18545411666855216 Scheduler time: 13.129268967080861 Scheduler overhead time: 0.037954929284751415 Adapter cache time: 0.043576973024755716 Engine time: 0.03750575007870793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.15145377162844,
    "estimated_duration": 3600.1419826009046,
    "input_throughput": 4209.756191074116,
    "output_throughput": 3691.2844171771585,
    "total_throughput": 7901.0406082512745,
    "itl": 143.00215939664264,
    "ttft": 180517.37623037017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.865453501907415,
    "arrivals": 62899,
    "finished_requests": 60869,
    "scheduler_time": 52.799154021016015
}
#Debug simulation 
Total elapsed time: 11.151562706567347. Arrivals time: 0.1645310572348535 Scheduler time: 10.838853219989687 Scheduler overhead time: 0.04021792113780975 Adapter cache time: 0.05055961525067687 Engine time: 0.03947447659447789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.142003260087222,
    "estimated_duration": 3600.0234142103277,
    "input_throughput": 4207.964298288574,
    "output_throughput": 3690.0707221966627,
    "total_throughput": 7898.0350204852375,
    "itl": 143.0874564071718,
    "ttft": 181388.8273645984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.414532253588266,
    "arrivals": 62899,
    "finished_requests": 60850,
    "scheduler_time": 52.81308134736539
}
#Debug simulation 
Total elapsed time: 11.142123455181718. Arrivals time: 0.16725315852090716 Scheduler time: 10.824645755812526 Scheduler overhead time: 0.04028610186651349 Adapter cache time: 0.051925255451351404 Engine time: 0.04012011829763651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.210795572958887,
    "estimated_duration": 3600.1595735169226,
    "input_throughput": 4207.745709782993,
    "output_throughput": 3690.583355731786,
    "total_throughput": 7898.329065514778,
    "itl": 143.04534214209318,
    "ttft": 181398.27213802698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2564,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.379938296396185,
    "arrivals": 62899,
    "finished_requests": 60859,
    "scheduler_time": 52.80523690829963
}
#Debug simulation 
Total elapsed time: 11.21093134302646. Arrivals time: 0.16495185485109687 Scheduler time: 10.896027500741184 Scheduler overhead time: 0.040300578344613314 Adapter cache time: 0.051508438773453236 Engine time: 0.040053138975054026 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 11.159801847301424,
    "estimated_duration": 3600.128557039967,
    "input_throughput": 4211.39766532834,
    "output_throughput": 3693.5258809015863,
    "total_throughput": 7904.923546229926,
    "itl": 143.07867631639454,
    "ttft": 179382.95371544256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.037715379162398,
    "arrivals": 62899,
    "finished_requests": 60887,
    "scheduler_time": 52.78660998880526
}
#Debug simulation 
Total elapsed time: 11.159973570145667. Arrivals time: 0.16570282028988004 Scheduler time: 10.845314889680594 Scheduler overhead time: 0.03940998716279864 Adapter cache time: 0.052096734289079905 Engine time: 0.03950650431215763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.160051357001066,
    "estimated_duration": 3600.066819844395,
    "input_throughput": 4210.828786965467,
    "output_throughput": 3691.463149168551,
    "total_throughput": 7902.291936134017,
    "itl": 143.0281924817609,
    "ttft": 179824.6143108172,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.520445482656102,
    "arrivals": 62899,
    "finished_requests": 60877,
    "scheduler_time": 52.78149092747382
}
#Debug simulation 
Total elapsed time: 11.160171058960259. Arrivals time: 0.16786520881578326 Scheduler time: 10.842425087001175 Scheduler overhead time: 0.04052461078390479 Adapter cache time: 0.051756156608462334 Engine time: 0.03959793318063021 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.145510328002274,
    "estimated_duration": 3600.127293052589,
    "input_throughput": 4209.986971640839,
    "output_throughput": 3691.6452997779766,
    "total_throughput": 7901.632271418815,
    "itl": 143.00582961942098,
    "ttft": 179717.07848422072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.693399408783061,
    "arrivals": 62899,
    "finished_requests": 60878,
    "scheduler_time": 52.78584461234235
}
#Debug simulation 
Total elapsed time: 11.145664405077696. Arrivals time: 0.16312814876437187 Scheduler time: 10.833549424540251 Scheduler overhead time: 0.039727212861180305 Adapter cache time: 0.05162622919306159 Engine time: 0.03974456246942282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.155149254016578,
    "estimated_duration": 3600.0461392403527,
    "input_throughput": 4207.5971846283865,
    "output_throughput": 3688.661891095119,
    "total_throughput": 7896.259075723505,
    "itl": 143.00226285404003,
    "ttft": 182605.14409832165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2557,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.572157881594805,
    "arrivals": 62899,
    "finished_requests": 60836,
    "scheduler_time": 52.809091828940126
}
#Debug simulation 
Total elapsed time: 11.15525851584971. Arrivals time: 0.1636948105879128 Scheduler time: 10.843942635226995 Scheduler overhead time: 0.03968838835135102 Adapter cache time: 0.050725231412798166 Engine time: 0.03936467273160815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.415136077906936,
    "estimated_duration": 3600.0890529353155,
    "input_throughput": 4053.2722345027455,
    "output_throughput": 3617.4582929779526,
    "total_throughput": 7670.730527480699,
    "itl": 135.44428882954878,
    "ttft": 148407.65131498934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2864,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.765236898623453,
    "arrivals": 60544,
    "finished_requests": 58848,
    "scheduler_time": 50.60513461611686
}
#Debug simulation 
Total elapsed time: 9.415258652996272. Arrivals time: 0.1583164669573307 Scheduler time: 9.099844694137573 Scheduler overhead time: 0.04149537021294236 Adapter cache time: 0.056184695567935705 Engine time: 0.04077961528673768 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.413333829957992,
    "estimated_duration": 3600.128333576715,
    "input_throughput": 4051.974720997582,
    "output_throughput": 3614.3086563452166,
    "total_throughput": 7666.283377342799,
    "itl": 135.33303147445235,
    "ttft": 149231.23758466993,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2871,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.370980384661706,
    "arrivals": 60544,
    "finished_requests": 58835,
    "scheduler_time": 50.59747903331304
}
#Debug simulation 
Total elapsed time: 9.413470029365271. Arrivals time: 0.15509013691917062 Scheduler time: 9.101408335845917 Scheduler overhead time: 0.041286987252533436 Adapter cache time: 0.05592769384384155 Engine time: 0.04113284032791853 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.410616509150714,
    "estimated_duration": 3600.01499210183,
    "input_throughput": 4051.290906287275,
    "output_throughput": 3617.464657389303,
    "total_throughput": 7668.755563676577,
    "itl": 135.5047066942371,
    "ttft": 148376.6679505872,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2881,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.419602715242378,
    "arrivals": 60544,
    "finished_requests": 58841,
    "scheduler_time": 50.59330724531204
}
#Debug simulation 
Total elapsed time: 9.410735225304961. Arrivals time: 0.15621440531685948 Scheduler time: 9.096653647255152 Scheduler overhead time: 0.04154832847416401 Adapter cache time: 0.056635725777596235 Engine time: 0.04105550516396761 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.454722905065864,
    "estimated_duration": 3600.0021076104904,
    "input_throughput": 4053.4267935986577,
    "output_throughput": 3616.7651047966456,
    "total_throughput": 7670.191898395303,
    "itl": 135.3430389027128,
    "ttft": 148518.6747185574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.905314344486584,
    "arrivals": 60544,
    "finished_requests": 58849,
    "scheduler_time": 50.60077339212965
}
#Debug simulation 
Total elapsed time: 9.454853267874569. Arrivals time: 0.15706752939149737 Scheduler time: 9.140283224638551 Scheduler overhead time: 0.04158316692337394 Adapter cache time: 0.05625822115689516 Engine time: 0.04093047557398677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.408422660082579,
    "estimated_duration": 3600.024618206009,
    "input_throughput": 4051.330350976336,
    "output_throughput": 3616.093327297089,
    "total_throughput": 7667.423678273425,
    "itl": 135.3547561297982,
    "ttft": 148700.698854236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2880,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.5370599132586,
    "arrivals": 60544,
    "finished_requests": 58841,
    "scheduler_time": 50.58948120682817
}
#Debug simulation 
Total elapsed time: 9.408557842019945. Arrivals time: 0.1523248334415257 Scheduler time: 9.099997824057937 Scheduler overhead time: 0.04103773599490523 Adapter cache time: 0.055730815045535564 Engine time: 0.040914332028478384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.37773084687069,
    "estimated_duration": 3600.0818780932623,
    "input_throughput": 4052.1203389202724,
    "output_throughput": 3616.391360214149,
    "total_throughput": 7668.511699134421,
    "itl": 135.40517106645302,
    "ttft": 148852.99776772602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2867,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.572474195484439,
    "arrivals": 60544,
    "finished_requests": 58840,
    "scheduler_time": 50.60156677140084
}
#Debug simulation 
Total elapsed time: 9.377898370847106. Arrivals time: 0.15340918116271496 Scheduler time: 9.067969170864671 Scheduler overhead time: 0.04099814733490348 Adapter cache time: 0.0559548637829721 Engine time: 0.04095252975821495 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.394577393773943,
    "estimated_duration": 3600.0531339840254,
    "input_throughput": 4054.566545757202,
    "output_throughput": 3617.0960581321747,
    "total_throughput": 7671.662603889376,
    "itl": 135.59911194436924,
    "ttft": 147184.22716097784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.635307118333383,
    "arrivals": 60544,
    "finished_requests": 58863,
    "scheduler_time": 50.60863219879422
}
#Debug simulation 
Total elapsed time: 9.394691781140864. Arrivals time: 0.15367598412558436 Scheduler time: 9.084336422849447 Scheduler overhead time: 0.041184555273503065 Adapter cache time: 0.05620661936700344 Engine time: 0.040784306824207306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.771015060134232,
    "estimated_duration": 3600.034293305367,
    "input_throughput": 4042.9375984184326,
    "output_throughput": 3513.8656938696504,
    "total_throughput": 7556.803292288083,
    "itl": 124.5761951733845,
    "ttft": 100672.34720203665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.775197854121004,
    "arrivals": 59315,
    "finished_requests": 58167,
    "scheduler_time": 47.95595121800079
}
#Debug simulation 
Total elapsed time: 7.771123521029949. Arrivals time: 0.15079933125525713 Scheduler time: 7.452010439243168 Scheduler overhead time: 0.04389771306887269 Adapter cache time: 0.06103178858757019 Engine time: 0.043557883240282536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.777842823881656,
    "estimated_duration": 3600.043510584046,
    "input_throughput": 4041.411432174504,
    "output_throughput": 3513.7294765495267,
    "total_throughput": 7555.140908724031,
    "itl": 124.55295424737798,
    "ttft": 102009.97886035035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.369010507611163,
    "arrivals": 59315,
    "finished_requests": 58151,
    "scheduler_time": 47.96185264425907
}
#Debug simulation 
Total elapsed time: 7.7779547879472375. Arrivals time: 0.1511020460166037 Scheduler time: 7.45949885295704 Scheduler overhead time: 0.04342647409066558 Adapter cache time: 0.06100939027965069 Engine time: 0.043193158227950335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.816369755193591,
    "estimated_duration": 3600.1060481037825,
    "input_throughput": 4042.6111913191194,
    "output_throughput": 3514.0406507367707,
    "total_throughput": 7556.6518420558905,
    "itl": 124.52504239844725,
    "ttft": 101153.31620553216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3176,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.379831562116289,
    "arrivals": 59315,
    "finished_requests": 58167,
    "scheduler_time": 47.96582741701734
}
#Debug simulation 
Total elapsed time: 7.816514333244413. Arrivals time: 0.15150837926194072 Scheduler time: 7.4970580618828535 Scheduler overhead time: 0.04368576733395457 Adapter cache time: 0.06080649048089981 Engine time: 0.043618998024612665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 7.754155343398452,
    "estimated_duration": 3600.050528021958,
    "input_throughput": 4042.2432648454314,
    "output_throughput": 3513.937346582387,
    "total_throughput": 7556.180611427819,
    "itl": 124.57059266004292,
    "ttft": 100696.35735338602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.979524438532664,
    "arrivals": 59315,
    "finished_requests": 58168,
    "scheduler_time": 47.95471727151572
}
#Debug simulation 
Total elapsed time: 7.754287709016353. Arrivals time: 0.14946159487590194 Scheduler time: 7.436766700353473 Scheduler overhead time: 0.04356103157624602 Adapter cache time: 0.061261883936822414 Engine time: 0.04341259738430381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.777943445369601,
    "estimated_duration": 3600.0015286055877,
    "input_throughput": 4043.378005352719,
    "output_throughput": 3514.4871188153757,
    "total_throughput": 7557.865124168095,
    "itl": 124.57342705128072,
    "ttft": 100447.31730749166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.517185837048501,
    "arrivals": 59315,
    "finished_requests": 58172,
    "scheduler_time": 47.96511306107734
}
#Debug simulation 
Total elapsed time: 7.778054072055966. Arrivals time: 0.15126986941322684 Scheduler time: 7.459170188289136 Scheduler overhead time: 0.04377185832709074 Adapter cache time: 0.06049609975889325 Engine time: 0.04346186527982354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.744467128068209,
    "estimated_duration": 3600.0156591199075,
    "input_throughput": 4043.38407893441,
    "output_throughput": 3513.786660331488,
    "total_throughput": 7557.170739265898,
    "itl": 124.58591461092372,
    "ttft": 100400.5832481337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3192,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.5442405413279,
    "arrivals": 59315,
    "finished_requests": 58169,
    "scheduler_time": 47.95983572102684
}
#Debug simulation 
Total elapsed time: 7.74460473889485. Arrivals time: 0.14952469849959016 Scheduler time: 7.427110634744167 Scheduler overhead time: 0.04376880684867501 Adapter cache time: 0.061030018143355846 Engine time: 0.043362954165786505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.798385242931545,
    "estimated_duration": 3600.0415443809425,
    "input_throughput": 4041.636136869083,
    "output_throughput": 3513.5452866489313,
    "total_throughput": 7555.1814235180145,
    "itl": 124.60824830116664,
    "ttft": 101859.52067536635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.632826496213081,
    "arrivals": 59315,
    "finished_requests": 58154,
    "scheduler_time": 47.96708256552146
}
#Debug simulation 
Total elapsed time: 7.7984956367872655. Arrivals time: 0.15253036143258214 Scheduler time: 7.47828336013481 Scheduler overhead time: 0.04384460533037782 Adapter cache time: 0.06045139441266656 Engine time: 0.043554505333304405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.150740460027009,
    "estimated_duration": 3600.022057800969,
    "input_throughput": 3630.924141610542,
    "output_throughput": 3181.426340203053,
    "total_throughput": 6812.350481813595,
    "itl": 102.25053640806131,
    "ttft": 68440.02645199605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5857,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.925276716212963,
    "arrivals": 53129,
    "finished_requests": 52410,
    "scheduler_time": 41.35021429251223
}
#Debug simulation 
Total elapsed time: 6.150903524830937. Arrivals time: 0.13807512866333127 Scheduler time: 5.786274277605116 Scheduler overhead time: 0.050698860082775354 Adapter cache time: 0.10273331450298429 Engine time: 0.05010303435847163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.132635981310159,
    "estimated_duration": 3600.109061286393,
    "input_throughput": 3631.519983821945,
    "output_throughput": 3181.5475045378985,
    "total_throughput": 6813.067488359843,
    "itl": 102.33939334972015,
    "ttft": 68188.54438535015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.062770179877973,
    "arrivals": 53129,
    "finished_requests": 52418,
    "scheduler_time": 41.36309703638469
}
#Debug simulation 
Total elapsed time: 6.132759013213217. Arrivals time: 0.13937145052477717 Scheduler time: 5.767421689815819 Scheduler overhead time: 0.05049055255949497 Adapter cache time: 0.10259961150586605 Engine time: 0.04994853958487511 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.133509568870068,
    "estimated_duration": 3600.0776476493907,
    "input_throughput": 3631.3966751622693,
    "output_throughput": 3181.5419335409506,
    "total_throughput": 6812.93860870322,
    "itl": 102.32229776412879,
    "ttft": 68206.66252210336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.09514851288787,
    "arrivals": 53129,
    "finished_requests": 52417,
    "scheduler_time": 41.356282925585425
}
#Debug simulation 
Total elapsed time: 6.133621810935438. Arrivals time: 0.13752541365101933 Scheduler time: 5.7700813370756805 Scheduler overhead time: 0.050739260856062174 Adapter cache time: 0.10218054102733731 Engine time: 0.05019534006714821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.147937367204577,
    "estimated_duration": 3600.0543300942404,
    "input_throughput": 3631.184365947554,
    "output_throughput": 3180.880884011612,
    "total_throughput": 6812.065249959166,
    "itl": 102.2646604924704,
    "ttft": 68884.23023406156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5842,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.258914359319693,
    "arrivals": 53129,
    "finished_requests": 52409,
    "scheduler_time": 41.35935833998922
}
#Debug simulation 
Total elapsed time: 6.148044776171446. Arrivals time: 0.13713150704279542 Scheduler time: 5.78508109645918 Scheduler overhead time: 0.05064711347222328 Adapter cache time: 0.1019981475546956 Engine time: 0.05029850313439965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.143053557258099,
    "estimated_duration": 3600.048768335726,
    "input_throughput": 3630.840536097158,
    "output_throughput": 3180.917742204342,
    "total_throughput": 6811.7582783015,
    "itl": 102.34454419261341,
    "ttft": 68686.03285127108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5840,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.34145445441713,
    "arrivals": 53129,
    "finished_requests": 52410,
    "scheduler_time": 41.35622684559441
}
#Debug simulation 
Total elapsed time: 6.143156103324145. Arrivals time: 0.13794793607667089 Scheduler time: 5.779775854665786 Scheduler overhead time: 0.05057939840480685 Adapter cache time: 0.10177740547806025 Engine time: 0.05011012917384505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.129476258996874,
    "estimated_duration": 3600.049230343766,
    "input_throughput": 3631.447006282087,
    "output_throughput": 3181.7328783879516,
    "total_throughput": 6813.1798846700385,
    "itl": 102.22669600845802,
    "ttft": 67911.6783483726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5892,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.617376337564924,
    "arrivals": 53129,
    "finished_requests": 52418,
    "scheduler_time": 41.34416778490305
}
#Debug simulation 
Total elapsed time: 6.129612772259861. Arrivals time: 0.13765475759282708 Scheduler time: 5.764420069288462 Scheduler overhead time: 0.05078680533915758 Adapter cache time: 0.10310148820281029 Engine time: 0.050562534481287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.140593387186527,
    "estimated_duration": 3600.0232089154324,
    "input_throughput": 3631.9440851435756,
    "output_throughput": 3181.55559987365,
    "total_throughput": 6813.499685017226,
    "itl": 102.38455754847527,
    "ttft": 67921.52644978675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.597782653382435,
    "arrivals": 53129,
    "finished_requests": 52419,
    "scheduler_time": 41.36152699199534
}
#Debug simulation 
Total elapsed time: 6.140709174331278. Arrivals time: 0.13815300213173032 Scheduler time: 5.776914166752249 Scheduler overhead time: 0.050481819082051516 Adapter cache time: 0.10250163869932294 Engine time: 0.0497171962633729 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.029612429905683,
    "estimated_duration": 3600.016780443604,
    "input_throughput": 3471.4552076226846,
    "output_throughput": 3057.948523963125,
    "total_throughput": 6529.4037315858095,
    "itl": 95.84984550753119,
    "ttft": 49753.856253601516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6739,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.62462690636253,
    "arrivals": 50759,
    "finished_requests": 50206,
    "scheduler_time": 38.642283317714934
}
#Debug simulation 
Total elapsed time: 5.029721235856414. Arrivals time: 0.1290145912207663 Scheduler time: 4.656594487838447 Scheduler overhead time: 0.052432145457714796 Adapter cache time: 0.11516202613711357 Engine time: 0.052560496143996716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.0270259929820895,
    "estimated_duration": 3600.02677678487,
    "input_throughput": 3471.2369587318676,
    "output_throughput": 3057.8775332975365,
    "total_throughput": 6529.114492029405,
    "itl": 95.93781659316375,
    "ttft": 50353.28971917104,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.904349037563772,
    "arrivals": 50759,
    "finished_requests": 50200,
    "scheduler_time": 38.648692677262055
}
#Debug simulation 
Total elapsed time: 5.027138873934746. Arrivals time: 0.12950243055820465 Scheduler time: 4.6548559363000095 Scheduler overhead time: 0.05212320387363434 Adapter cache time: 0.11441994644701481 Engine time: 0.0522995637729764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.028184553142637,
    "estimated_duration": 3600.082594687032,
    "input_throughput": 3471.4103555411457,
    "output_throughput": 3058.0770608561775,
    "total_throughput": 6529.487416397324,
    "itl": 95.9368417018246,
    "ttft": 49865.28593666716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6705,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.916988161503966,
    "arrivals": 50759,
    "finished_requests": 50207,
    "scheduler_time": 38.65072788369784
}
#Debug simulation 
Total elapsed time: 5.028374832123518. Arrivals time: 0.12815927620977163 Scheduler time: 4.65793820656836 Scheduler overhead time: 0.05220078211277723 Adapter cache time: 0.11438365187495947 Engine time: 0.05181624926626682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.025760148186237,
    "estimated_duration": 3600.0311813722515,
    "input_throughput": 3471.4413210266443,
    "output_throughput": 3057.9362914861595,
    "total_throughput": 6529.377612512804,
    "itl": 95.87342754921937,
    "ttft": 49888.33825621934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6731,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.046185192113896,
    "arrivals": 50759,
    "finished_requests": 50206,
    "scheduler_time": 38.64380685121069
}
#Debug simulation 
Total elapsed time: 5.025894005782902. Arrivals time: 0.12978361081331968 Scheduler time: 4.653255278244615 Scheduler overhead time: 0.05243017338216305 Adapter cache time: 0.11468375800177455 Engine time: 0.051928692031651735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.036789428908378,
    "estimated_duration": 3600.0432726014,
    "input_throughput": 3471.2210531208325,
    "output_throughput": 3057.8635217474134,
    "total_throughput": 6529.084574868246,
    "itl": 95.95755821436303,
    "ttft": 50365.448369743564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.20155439427025,
    "arrivals": 50759,
    "finished_requests": 50200,
    "scheduler_time": 38.65065747245057
}
#Debug simulation 
Total elapsed time: 5.03689670516178. Arrivals time: 0.1300009205006063 Scheduler time: 4.663612339645624 Scheduler overhead time: 0.05239294236525893 Adapter cache time: 0.11489569675177336 Engine time: 0.051968392450362444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.012651854194701,
    "estimated_duration": 3600.0911742098515,
    "input_throughput": 3471.341806431576,
    "output_throughput": 3057.883111089869,
    "total_throughput": 6529.224917521445,
    "itl": 95.8199990484511,
    "ttft": 49874.073899991075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6746,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.170879289410532,
    "arrivals": 50759,
    "finished_requests": 50206,
    "scheduler_time": 38.641044722334854
}
#Debug simulation 
Total elapsed time: 5.012761299032718. Arrivals time: 0.12828253768384457 Scheduler time: 4.6409271182492375 Scheduler overhead time: 0.05235707713291049 Adapter cache time: 0.11504540964961052 Engine time: 0.05231319786980748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.035998458974063,
    "estimated_duration": 3600.0149137969674,
    "input_throughput": 3471.0672870020057,
    "output_throughput": 3057.779832470113,
    "total_throughput": 6528.847119472119,
    "itl": 95.96620655193902,
    "ttft": 50162.04486590065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6703,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.474026579370825,
    "arrivals": 50759,
    "finished_requests": 50201,
    "scheduler_time": 38.650914311374635
}
#Debug simulation 
Total elapsed time: 5.036138157825917. Arrivals time: 0.12883332278579473 Scheduler time: 4.664093325845897 Scheduler overhead time: 0.052538384683430195 Adapter cache time: 0.11482188664376736 Engine time: 0.05190705135464668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.5046028406359255,
    "estimated_duration": 3600.0923337709155,
    "input_throughput": 3383.174616313892,
    "output_throughput": 3007.3137009404627,
    "total_throughput": 6390.488317254354,
    "itl": 93.38880746796235,
    "ttft": 36985.39538285621,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.680495178019672,
    "arrivals": 49552,
    "finished_requests": 49133,
    "scheduler_time": 37.459254762430824
}
#Debug simulation 
Total elapsed time: 4.504734497051686. Arrivals time: 0.12473204219713807 Scheduler time: 4.130487765185535 Scheduler overhead time: 0.05332813737913966 Adapter cache time: 0.1191896665841341 Engine time: 0.05276501039043069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.515366244129837,
    "estimated_duration": 3600.066866965599,
    "input_throughput": 3383.0610513814054,
    "output_throughput": 3007.108589937046,
    "total_throughput": 6390.169641318451,
    "itl": 93.47688608382548,
    "ttft": 37019.80402931715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7067,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.062932694976602,
    "arrivals": 49552,
    "finished_requests": 49132,
    "scheduler_time": 37.46676361742789
}
#Debug simulation 
Total elapsed time: 4.515475294087082. Arrivals time: 0.12461930839344859 Scheduler time: 4.141029328107834 Scheduler overhead time: 0.05300274258479476 Adapter cache time: 0.11970614595338702 Engine time: 0.05285906884819269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.507185074966401,
    "estimated_duration": 3600.0091278671057,
    "input_throughput": 3383.0283667129593,
    "output_throughput": 3007.260430590677,
    "total_throughput": 6390.288797303637,
    "itl": 93.47871557466298,
    "ttft": 37092.64698332626,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7069,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.109815391078516,
    "arrivals": 49552,
    "finished_requests": 49131,
    "scheduler_time": 37.466661189113566
}
#Debug simulation 
Total elapsed time: 4.50730200484395. Arrivals time: 0.1265902523882687 Scheduler time: 4.129928876645863 Scheduler overhead time: 0.05310344183817506 Adapter cache time: 0.12030983762815595 Engine time: 0.053077463526278734 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.515042653307319,
    "estimated_duration": 3600.1069762926754,
    "input_throughput": 3383.160856109469,
    "output_throughput": 3007.3014694549556,
    "total_throughput": 6390.462325564425,
    "itl": 93.41425407820905,
    "ttft": 37008.84617484362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7087,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.141696341300165,
    "arrivals": 49552,
    "finished_requests": 49133,
    "scheduler_time": 37.462620326521396
}
#Debug simulation 
Total elapsed time: 4.515154328197241. Arrivals time: 0.12304529454559088 Scheduler time: 4.14151160325855 Scheduler overhead time: 0.05303936172276735 Adapter cache time: 0.12011539749801159 Engine time: 0.05316373938694596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.5154710579663515,
    "estimated_duration": 3600.0391597879216,
    "input_throughput": 3383.079866474974,
    "output_throughput": 3007.357564587657,
    "total_throughput": 6390.437431062632,
    "itl": 93.49424671478376,
    "ttft": 37030.102784173476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7059,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.38000606765872,
    "arrivals": 49552,
    "finished_requests": 49132,
    "scheduler_time": 37.468440651457286
}
#Debug simulation 
Total elapsed time: 4.5156588619574904. Arrivals time: 0.12435863446444273 Scheduler time: 4.1407094253227115 Scheduler overhead time: 0.05326300533488393 Adapter cache time: 0.12028032494708896 Engine time: 0.05261199548840523 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.505104528740048,
    "estimated_duration": 3600.082589998102,
    "input_throughput": 3383.18377301628,
    "output_throughput": 3007.321840359698,
    "total_throughput": 6390.505613375978,
    "itl": 93.3541213684595,
    "ttft": 36983.85550260785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.196466540561637,
    "arrivals": 49552,
    "finished_requests": 49133,
    "scheduler_time": 37.456863660905114
}
#Debug simulation 
Total elapsed time: 4.505211414769292. Arrivals time: 0.1284090830013156 Scheduler time: 4.125759901013225 Scheduler overhead time: 0.053606335539370775 Adapter cache time: 0.12006445042788982 Engine time: 0.05299888597801328 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.511612304951996,
    "estimated_duration": 3600.0785986712654,
    "input_throughput": 3383.1875238766615,
    "output_throughput": 3007.325174510339,
    "total_throughput": 6390.5126983870005,
    "itl": 93.5107729496516,
    "ttft": 36958.03111770881,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7063,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.684517682602614,
    "arrivals": 49552,
    "finished_requests": 49133,
    "scheduler_time": 37.47004837046056
}
#Debug simulation 
Total elapsed time: 4.511724671814591. Arrivals time: 0.1269538626074791 Scheduler time: 4.133675056044012 Scheduler overhead time: 0.05342545406892896 Adapter cache time: 0.11963491328060627 Engine time: 0.0536861470900476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.6859470861963928,
    "estimated_duration": 3600.0452714154085,
    "input_throughput": 3148.255687224714,
    "output_throughput": 2796.004005816991,
    "total_throughput": 5944.259693041706,
    "itl": 84.26958283340059,
    "ttft": 25287.763655864754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9870,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.207014032619096,
    "arrivals": 45990,
    "finished_requests": 45682,
    "scheduler_time": 33.307179456146116
}
#Debug simulation 
Total elapsed time: 3.6860874821431935. Arrivals time: 0.11605198634788394 Scheduler time: 3.276095553766936 Scheduler overhead time: 0.05543990386649966 Adapter cache time: 0.1583522497676313 Engine time: 0.05464490223675966 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.675227683968842,
    "estimated_duration": 3600.0026430437692,
    "input_throughput": 3148.292966367748,
    "output_throughput": 2796.0371138754244,
    "total_throughput": 5944.330080243172,
    "itl": 84.39406429682468,
    "ttft": 25226.598150063055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.169173218531114,
    "arrivals": 45990,
    "finished_requests": 45682,
    "scheduler_time": 33.31898954764848
}
#Debug simulation 
Total elapsed time: 3.6753574940375984. Arrivals time: 0.11731492727994919 Scheduler time: 3.266082525718957 Scheduler overhead time: 0.05528664169833064 Adapter cache time: 0.15670838905498385 Engine time: 0.05427067680284381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6890712683089077,
    "estimated_duration": 3600.0476126620247,
    "input_throughput": 3148.2536397954113,
    "output_throughput": 2796.0021874702297,
    "total_throughput": 5944.2558272656415,
    "itl": 84.39739782498985,
    "ttft": 25304.74325484472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9854,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.24229900926531,
    "arrivals": 45990,
    "finished_requests": 45682,
    "scheduler_time": 33.31962173815271
}
#Debug simulation 
Total elapsed time: 3.6891784970648587. Arrivals time: 0.11549411015585065 Scheduler time: 3.2801008061505854 Scheduler overhead time: 0.055066192988306284 Adapter cache time: 0.1575932721607387 Engine time: 0.055553143844008446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.678638253826648,
    "estimated_duration": 3600.034647577699,
    "input_throughput": 3148.2649778457117,
    "output_throughput": 2796.0122569300224,
    "total_throughput": 5944.2772347757345,
    "itl": 84.31147773056405,
    "ttft": 25292.970553963154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9863,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.85026268306747,
    "arrivals": 45990,
    "finished_requests": 45682,
    "scheduler_time": 33.311195095314005
}
#Debug simulation 
Total elapsed time: 3.6787458858452737. Arrivals time: 0.1158321495167911 Scheduler time: 3.267685051076114 Scheduler overhead time: 0.05503848986700177 Adapter cache time: 0.1596197672188282 Engine time: 0.05514075141400099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6886596558615565,
    "estimated_duration": 3600.0774024975317,
    "input_throughput": 3148.2275887005103,
    "output_throughput": 2795.9790511773313,
    "total_throughput": 5944.206639877842,
    "itl": 84.42283557863274,
    "ttft": 25308.151140683483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9846,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.63800280677122,
    "arrivals": 45990,
    "finished_requests": 45682,
    "scheduler_time": 33.32272493813628
}
#Debug simulation 
Total elapsed time: 3.688767144922167. Arrivals time: 0.1161727630533278 Scheduler time: 3.2794355573132634 Scheduler overhead time: 0.05506120575591922 Adapter cache time: 0.15784803126007318 Engine time: 0.054825738072395325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.676051467191428,
    "estimated_duration": 3600.009886524468,
    "input_throughput": 3148.2866317742173,
    "output_throughput": 2796.0314880461888,
    "total_throughput": 5944.3181198204065,
    "itl": 84.22161696156456,
    "ttft": 25203.018659821442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9875,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.526746662156327,
    "arrivals": 45990,
    "finished_requests": 45682,
    "scheduler_time": 33.3022130404559
}
#Debug simulation 
Total elapsed time: 3.6761953961104155. Arrivals time: 0.11572089605033398 Scheduler time: 3.267276938073337 Scheduler overhead time: 0.055175920482724905 Adapter cache time: 0.1580718271434307 Engine time: 0.05452852789312601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.687232180032879,
    "estimated_duration": 3600.092151100782,
    "input_throughput": 3148.214691264084,
    "output_throughput": 2795.9675968078345,
    "total_throughput": 5944.182288071918,
    "itl": 84.45338696022131,
    "ttft": 25312.456947734936,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9844,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.047229087350296,
    "arrivals": 45990,
    "finished_requests": 45682,
    "scheduler_time": 33.325503843409045
}
#Debug simulation 
Total elapsed time: 3.6873985049314797. Arrivals time: 0.11589636886492372 Scheduler time: 3.278428030665964 Scheduler overhead time: 0.05504234181717038 Adapter cache time: 0.15785062266513705 Engine time: 0.05478463787585497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.4064085902646184,
    "estimated_duration": 3600.0048343947283,
    "input_throughput": 3089.513351131373,
    "output_throughput": 2705.7538664771587,
    "total_throughput": 5795.267217608532,
    "itl": 73.92346551487738,
    "ttft": 18262.55521338566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8976,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.470937989542325,
    "arrivals": 44803,
    "finished_requests": 44577,
    "scheduler_time": 30.7190473424978
}
#Debug simulation 
Total elapsed time: 3.406518556177616. Arrivals time: 0.11384115694090724 Scheduler time: 2.982592158485204 Scheduler overhead time: 0.0565231847576797 Adapter cache time: 0.16937102936208248 Engine time: 0.0576564921066165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4339026152156293,
    "estimated_duration": 3600.0616281374023,
    "input_throughput": 3088.929065293094,
    "output_throughput": 2704.8225852283526,
    "total_throughput": 5793.751650521446,
    "itl": 75.01265043586811,
    "ttft": 18932.28390226201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9050,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.550343634754775,
    "arrivals": 44803,
    "finished_requests": 44570,
    "scheduler_time": 30.853325502603766
}
#Debug simulation 
Total elapsed time: 3.4340123338624835. Arrivals time: 0.11304993042722344 Scheduler time: 3.0147914099507034 Scheduler overhead time: 0.05632599722594023 Adapter cache time: 0.16760031832382083 Engine time: 0.05591642903164029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.442330975085497,
    "estimated_duration": 3600.055092736038,
    "input_throughput": 3088.9343950424263,
    "output_throughput": 2704.7638853214503,
    "total_throughput": 5793.698280363877,
    "itl": 75.01482732653574,
    "ttft": 19012.92681624089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9044,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.57975895745794,
    "arrivals": 44803,
    "finished_requests": 44569,
    "scheduler_time": 30.85345738048031
}
#Debug simulation 
Total elapsed time: 3.4424388580955565. Arrivals time: 0.11151740886271 Scheduler time: 3.0251193116419017 Scheduler overhead time: 0.05649007437750697 Adapter cache time: 0.16680934140458703 Engine time: 0.05606581177562475 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.437972621060908,
    "estimated_duration": 3600.000590741571,
    "input_throughput": 3089.516715248345,
    "output_throughput": 2705.647333794901,
    "total_throughput": 5795.1640490432455,
    "itl": 73.96800631404899,
    "ttft": 18343.36130102932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8973,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.040389224693236,
    "arrivals": 44803,
    "finished_requests": 44576,
    "scheduler_time": 30.72442239333265
}
#Debug simulation 
Total elapsed time: 3.438080369029194. Arrivals time: 0.11190969217568636 Scheduler time: 3.0162048642523587 Scheduler overhead time: 0.05752886366099119 Adapter cache time: 0.16890121856704354 Engine time: 0.05688864039257169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4414327847771347,
    "estimated_duration": 3600.0781614469674,
    "input_throughput": 3088.9148794287403,
    "output_throughput": 2704.8101633677384,
    "total_throughput": 5793.725042796479,
    "itl": 75.04350397575413,
    "ttft": 18932.955824824894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9038,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.95430694706661,
    "arrivals": 44803,
    "finished_requests": 44570,
    "scheduler_time": 30.8571609091254
}
#Debug simulation 
Total elapsed time: 3.441535736899823. Arrivals time: 0.11023022048175335 Scheduler time: 3.02425885386765 Scheduler overhead time: 0.05680015357211232 Adapter cache time: 0.16703792242333293 Engine time: 0.056634942069649696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.428526456002146,
    "estimated_duration": 3600.0091469012586,
    "input_throughput": 3089.509650155637,
    "output_throughput": 2705.7506252128337,
    "total_throughput": 5795.2602753684705,
    "itl": 73.87357332657436,
    "ttft": 18261.592011778175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8972,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.82673124586056,
    "arrivals": 44803,
    "finished_requests": 44577,
    "scheduler_time": 30.713140393463355
}
#Debug simulation 
Total elapsed time: 3.42863204004243. Arrivals time: 0.11121872067451477 Scheduler time: 3.008829354774207 Scheduler overhead time: 0.056889479979872704 Adapter cache time: 0.1689506401307881 Engine time: 0.056289944332093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.442433064803481,
    "estimated_duration": 3600.061061941041,
    "input_throughput": 3088.9292733285647,
    "output_throughput": 2704.7594005947085,
    "total_throughput": 5793.688673923273,
    "itl": 75.07177029440916,
    "ttft": 19013.742977885264,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9041,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.336131712680015,
    "arrivals": 44803,
    "finished_requests": 44569,
    "scheduler_time": 30.86031874854359
}
#Debug simulation 
Total elapsed time: 3.4425406926311553. Arrivals time: 0.1113267713226378 Scheduler time: 3.025483733974397 Scheduler overhead time: 0.056501420214772224 Adapter cache time: 0.16629174537956715 Engine time: 0.056611830834299326 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.308604624122381,
    "estimated_duration": 3600.0444742402087,
    "input_throughput": 2934.891520258206,
    "output_throughput": 2581.0139476015866,
    "total_throughput": 5515.905467859793,
    "itl": 57.46819081465708,
    "ttft": 11148.500530042387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.749269930276213,
    "arrivals": 42341,
    "finished_requests": 42211,
    "scheduler_time": 26.334275305483853
}
#Debug simulation 
Total elapsed time: 3.3087376160547137. Arrivals time: 0.10888456413522363 Scheduler time: 2.8636143086478114 Scheduler overhead time: 0.0679326867684722 Adapter cache time: 0.16859188629314303 Engine time: 0.06771446485072374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.322367929853499,
    "estimated_duration": 3600.052611019118,
    "input_throughput": 2934.8848868653076,
    "output_throughput": 2581.00811403688,
    "total_throughput": 5515.893000902188,
    "itl": 57.518035864733136,
    "ttft": 11148.437005776164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.773979923672393,
    "arrivals": 42341,
    "finished_requests": 42211,
    "scheduler_time": 26.344041905824547
}
#Debug simulation 
Total elapsed time: 3.322523796930909. Arrivals time: 0.10808358620852232 Scheduler time: 2.8761497186496854 Scheduler overhead time: 0.06814951077103615 Adapter cache time: 0.16958116739988327 Engine time: 0.06883178697898984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.310370267368853,
    "estimated_duration": 3600.000958290461,
    "input_throughput": 2934.785885450745,
    "output_throughput": 2581.00431295783,
    "total_throughput": 5515.790198408575,
    "itl": 57.52216507232869,
    "ttft": 11233.829801406797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5148,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.812990277389677,
    "arrivals": 42341,
    "finished_requests": 42209,
    "scheduler_time": 26.34415718311149
}
#Debug simulation 
Total elapsed time: 3.3104774300009012. Arrivals time: 0.10766530688852072 Scheduler time: 2.8660884662531316 Scheduler overhead time: 0.06771959969773889 Adapter cache time: 0.1696445536799729 Engine time: 0.06763478368520737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.311653167940676,
    "estimated_duration": 3600.012981894352,
    "input_throughput": 2934.813027935369,
    "output_throughput": 2580.783193484788,
    "total_throughput": 5515.596221420157,
    "itl": 57.6663395715869,
    "ttft": 11234.015522155194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5138,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.053404503373002,
    "arrivals": 42341,
    "finished_requests": 42209,
    "scheduler_time": 26.373959140095476
}
#Debug simulation 
Total elapsed time: 3.3117637489922345. Arrivals time: 0.10770594608038664 Scheduler time: 2.8676911732181907 Scheduler overhead time: 0.06746909394860268 Adapter cache time: 0.16938171442598104 Engine time: 0.06781899416819215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.310371393803507,
    "estimated_duration": 3600.004184458135,
    "input_throughput": 2934.78325542287,
    "output_throughput": 2581.0019999736624,
    "total_throughput": 5515.785255396532,
    "itl": 57.53261128371699,
    "ttft": 11233.834789055598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.031158510929604,
    "arrivals": 42341,
    "finished_requests": 42209,
    "scheduler_time": 26.34632875487965
}
#Debug simulation 
Total elapsed time: 3.310485070105642. Arrivals time: 0.10898816399276257 Scheduler time: 2.8655237848870456 Scheduler overhead time: 0.06772228516638279 Adapter cache time: 0.16951474966481328 Engine time: 0.06692623579874635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.340078050736338,
    "estimated_duration": 3600.0335053020885,
    "input_throughput": 2934.900462575945,
    "output_throughput": 2581.0218116901397,
    "total_throughput": 5515.922274266084,
    "itl": 57.45228409760547,
    "ttft": 11063.447563794767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.39875901874789,
    "arrivals": 42341,
    "finished_requests": 42211,
    "scheduler_time": 26.330879110302384
}
#Debug simulation 
Total elapsed time: 3.3401891491375864. Arrivals time: 0.10854542069137096 Scheduler time: 2.894151131156832 Scheduler overhead time: 0.06747257895767689 Adapter cache time: 0.17027310002595186 Engine time: 0.06798956543207169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.3328977143391967,
    "estimated_duration": 3600.0073135118237,
    "input_throughput": 2934.780704568505,
    "output_throughput": 2580.999756618823,
    "total_throughput": 5515.780461187328,
    "itl": 57.542764923154664,
    "ttft": 11233.89152263367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5147,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.236417862138392,
    "arrivals": 42341,
    "finished_requests": 42209,
    "scheduler_time": 26.348258592104536
}
#Debug simulation 
Total elapsed time: 3.3330081962049007. Arrivals time: 0.11045870557427406 Scheduler time: 2.8835238656029105 Scheduler overhead time: 0.06832145992666483 Adapter cache time: 0.17065018508583307 Engine time: 0.06828663172200322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.9073425410315394,
    "estimated_duration": 3600.036984888672,
    "input_throughput": 2318.354793307241,
    "output_throughput": 2071.4878850697737,
    "total_throughput": 4389.842678377015,
    "itl": 50.96408097771157,
    "ttft": 10442.765161124857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17165,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.53327212459195,
    "arrivals": 33871,
    "finished_requests": 33773,
    "scheduler_time": 17.259050249081387
}
#Debug simulation 
Total elapsed time: 2.907453204970807. Arrivals time: 0.09161492995917797 Scheduler time: 2.359483886975795 Scheduler overhead time: 0.07476676627993584 Adapter cache time: 0.27334096003323793 Engine time: 0.0730547378771007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.9057197482325137,
    "estimated_duration": 3600.043825915548,
    "input_throughput": 2318.35038782547,
    "output_throughput": 2071.483948699835,
    "total_throughput": 4389.834336525305,
    "itl": 51.138985973742486,
    "ttft": 10550.826505969331,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.02961594528857,
    "arrivals": 33871,
    "finished_requests": 33773,
    "scheduler_time": 17.3032350747197
}
#Debug simulation 
Total elapsed time: 2.9058773959986866. Arrivals time: 0.09751306986436248 Scheduler time: 2.350963902659714 Scheduler overhead time: 0.07530154194682837 Adapter cache time: 0.2726088557392359 Engine time: 0.07411383325234056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.918938220012933,
    "estimated_duration": 3600.000800737653,
    "input_throughput": 2318.3780954409344,
    "output_throughput": 2071.5087059069388,
    "total_throughput": 4389.886801347873,
    "itl": 51.14786980550645,
    "ttft": 10444.700246266579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.15277273410548,
    "arrivals": 33871,
    "finished_requests": 33773,
    "scheduler_time": 17.304880249585104
}
#Debug simulation 
Total elapsed time: 2.9190508788451552. Arrivals time: 0.09385891119018197 Scheduler time: 2.365181209985167 Scheduler overhead time: 0.07503973972052336 Adapter cache time: 0.27445119014009833 Engine time: 0.07508139172568917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.8982782689854503,
    "estimated_duration": 3600.039216850536,
    "input_throughput": 2318.353355967486,
    "output_throughput": 2071.4866007832193,
    "total_throughput": 4389.839956750706,
    "itl": 51.02239625700257,
    "ttft": 10443.474911766512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17167,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.69596030636821,
    "arrivals": 33871,
    "finished_requests": 33773,
    "scheduler_time": 17.273777672718296
}
#Debug simulation 
Total elapsed time: 2.898385134059936. Arrivals time: 0.0919378506951034 Scheduler time: 2.350666848476976 Scheduler overhead time: 0.07445055386051536 Adapter cache time: 0.27330998377874494 Engine time: 0.07288628723472357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.8814162369817495,
    "estimated_duration": 3600.0294160216404,
    "input_throughput": 2318.359667522736,
    "output_throughput": 2071.4922402609536,
    "total_throughput": 4389.85190778369,
    "itl": 51.18158912074074,
    "ttft": 10445.165604874946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.88603931887998,
    "arrivals": 33871,
    "finished_requests": 33773,
    "scheduler_time": 17.313970426942493
}
#Debug simulation 
Total elapsed time: 2.881520335096866. Arrivals time: 0.09087013639509678 Scheduler time: 2.336184149608016 Scheduler overhead time: 0.07389690261334181 Adapter cache time: 0.2734583015553653 Engine time: 0.07216764194890857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.9266645810566843,
    "estimated_duration": 3600.0150507193634,
    "input_throughput": 2318.368918577785,
    "output_throughput": 2071.5005062297832,
    "total_throughput": 4389.869424807568,
    "itl": 50.90314893007104,
    "ttft": 10441.877965101075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17169,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.33617351318851,
    "arrivals": 33871,
    "finished_requests": 33773,
    "scheduler_time": 17.24374375399134
}
#Debug simulation 
Total elapsed time: 2.926774642895907. Arrivals time: 0.09189531533047557 Scheduler time: 2.3749626288190484 Scheduler overhead time: 0.07534933974966407 Adapter cache time: 0.2742398236878216 Engine time: 0.07489613490179181 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_320_slots_128_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.9129626899957657,
    "estimated_duration": 3600.0236791836724,
    "input_throughput": 2318.3633619578145,
    "output_throughput": 2071.4955412990557,
    "total_throughput": 4389.858903256871,
    "itl": 51.21928833846157,
    "ttft": 10445.53603985697,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17172,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.607266455743314,
    "arrivals": 33871,
    "finished_requests": 33773,
    "scheduler_time": 17.32313454106626
}
#Debug simulation 
Total elapsed time: 2.9130710759200156. Arrivals time: 0.09298579767346382 Scheduler time: 2.36398958042264 Scheduler overhead time: 0.07440774142742157 Adapter cache time: 0.27349371649324894 Engine time: 0.07304977206513286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.754215905908495,
    "estimated_duration": 3599.960166113722,
    "input_throughput": 2154.225780884659,
    "output_throughput": 1928.0996676952486,
    "total_throughput": 4082.325448579908,
    "itl": 42.04756527330659,
    "ttft": 9224.727529047143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.32198350762724,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.478635679940812
}
#Debug simulation 
Total elapsed time: 2.7543258322402835. Arrivals time: 0.0881897839717567 Scheduler time: 2.1994485026225448 Scheduler overhead time: 0.08670572331175208 Adapter cache time: 0.25570985674858093 Engine time: 0.08359689451754093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7546706330031157,
    "estimated_duration": 3599.9700612589204,
    "input_throughput": 2154.2198596196126,
    "output_throughput": 1928.0943679772388,
    "total_throughput": 4082.3142275968517,
    "itl": 42.14492337215795,
    "ttft": 9224.958177488996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.278079297588526,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.513479698782103
}
#Debug simulation 
Total elapsed time: 2.7547780978493392. Arrivals time: 0.0880912751890719 Scheduler time: 2.195034042466432 Scheduler overhead time: 0.08657788392156363 Adapter cache time: 0.2578080175444484 Engine time: 0.08638412645086646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.722708651330322,
    "estimated_duration": 3599.9903503647984,
    "input_throughput": 2154.2077186996207,
    "output_throughput": 1928.0835014728966,
    "total_throughput": 4082.291220172517,
    "itl": 42.14620092628048,
    "ttft": 9224.829774792839,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14481,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.353265580843065,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.514411547481568
}
#Debug simulation 
Total elapsed time: 2.722815695218742. Arrivals time: 0.08712781872600317 Scheduler time: 2.1695360629819334 Scheduler overhead time: 0.08646737271919847 Adapter cache time: 0.2552171014249325 Engine time: 0.08362734504044056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.7662752280011773,
    "estimated_duration": 3599.9720380994263,
    "input_throughput": 2154.2186766801256,
    "output_throughput": 1928.0933092092803,
    "total_throughput": 4082.3119858894056,
    "itl": 42.07890322485962,
    "ttft": 9224.795796532868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14480,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.25882017997727,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.489514837229645
}
#Debug simulation 
Total elapsed time: 2.7664381661452353. Arrivals time: 0.08794445032253861 Scheduler time: 2.2074929969385266 Scheduler overhead time: 0.08665113244205713 Adapter cache time: 0.25736196525394917 Engine time: 0.08600945258513093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7544749630615115,
    "estimated_duration": 3599.988311109796,
    "input_throughput": 2154.20893897549,
    "output_throughput": 1928.0845936580886,
    "total_throughput": 4082.2935326335787,
    "itl": 42.16843667646602,
    "ttft": 9225.005831333458,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14481,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 47.97129971501066,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.521862750889547
}
#Debug simulation 
Total elapsed time: 2.7545819520018995. Arrivals time: 0.08741290448233485 Scheduler time: 2.195567929185927 Scheduler overhead time: 0.08874895283952355 Adapter cache time: 0.2571326391771436 Engine time: 0.08495458401739597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.764410328119993,
    "estimated_duration": 3599.987317129601,
    "input_throughput": 2154.2095337667583,
    "output_throughput": 1928.0851260149366,
    "total_throughput": 4082.294659781695,
    "itl": 42.0139405666397,
    "ttft": 9224.603791267016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14482,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.30190837077949,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.466881301264923
}
#Debug simulation 
Total elapsed time: 2.764518218114972. Arrivals time: 0.08872814988717437 Scheduler time: 2.201660533901304 Scheduler overhead time: 0.08686632802709937 Adapter cache time: 0.2586572300642729 Engine time: 0.08778125233948231 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7243365407921374,
    "estimated_duration": 3599.969140278574,
    "input_throughput": 2154.220410733824,
    "output_throughput": 1928.0948612417503,
    "total_throughput": 4082.315271975574,
    "itl": 42.18608947033068,
    "ttft": 9225.108806408067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 14483,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.58197094392184,
    "arrivals": 31462,
    "finished_requests": 31382,
    "scheduler_time": 12.528789797224196
}
#Debug simulation 
Total elapsed time: 2.724450347945094. Arrivals time: 0.09237858327105641 Scheduler time: 2.1639993293210864 Scheduler overhead time: 0.08580268546938896 Adapter cache time: 0.2560269399546087 Engine time: 0.08546441420912743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.645277470815927,
    "estimated_duration": 3600.0289887978315,
    "input_throughput": 2061.63812099703,
    "output_throughput": 1828.9699945440523,
    "total_throughput": 3890.6081155410825,
    "itl": 38.107464931884785,
    "ttft": 13511.113673006494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.55296411031882,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.576945544956503
}
#Debug simulation 
Total elapsed time: 2.6453805058263242. Arrivals time: 0.08421230595558882 Scheduler time: 2.087317625526339 Scheduler overhead time: 0.09340037498623133 Adapter cache time: 0.24411397660151124 Engine time: 0.0922053474932909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.610589124262333,
    "estimated_duration": 3600.018441811256,
    "input_throughput": 2061.6441609854187,
    "output_throughput": 1828.9753528838196,
    "total_throughput": 3890.6195138692383,
    "itl": 38.17658172150911,
    "ttft": 13392.891065034013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.111385777534004,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.605197194168449
}
#Debug simulation 
Total elapsed time: 2.6106974869035184. Arrivals time: 0.08348776213824749 Scheduler time: 2.0569427642039955 Scheduler overhead time: 0.0934543157927692 Adapter cache time: 0.24317864049226046 Engine time: 0.08957746019586921 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.626815860159695,
    "estimated_duration": 3600.0282793129372,
    "input_throughput": 2061.638527299701,
    "output_throughput": 1828.9703549930496,
    "total_throughput": 3890.6088822927504,
    "itl": 38.17584512170062,
    "ttft": 13511.311067731873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12595,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.19331590137176,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.606017451045767
}
#Debug simulation 
Total elapsed time: 2.6269222032278776. Arrivals time: 0.08344382187351584 Scheduler time: 2.0707541592419147 Scheduler overhead time: 0.09387496905401349 Adapter cache time: 0.2449537911452353 Engine time: 0.08974962960928679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.6441724859178066,
    "estimated_duration": 3600.028908318682,
    "input_throughput": 2061.6381670852384,
    "output_throughput": 1828.970035430932,
    "total_throughput": 3890.6082025161704,
    "itl": 38.130909192665406,
    "ttft": 13511.196899876926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.407524353516585,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.586330870303161
}
#Debug simulation 
Total elapsed time: 2.644353928975761. Arrivals time: 0.08847770653665066 Scheduler time: 2.078050632029772 Scheduler overhead time: 0.09334366209805012 Adapter cache time: 0.2466377131640911 Engine time: 0.09367123572155833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6285479818470776,
    "estimated_duration": 3600.0484516223833,
    "input_throughput": 2061.6269752300836,
    "output_throughput": 1828.9601066432108,
    "total_throughput": 3890.587081873294,
    "itl": 38.1916254019663,
    "ttft": 13511.18310310754,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.734038853257445,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.61208879633877
}
#Debug simulation 
Total elapsed time: 2.6286719110794365. Arrivals time: 0.08344016456976533 Scheduler time: 2.075213690754026 Scheduler overhead time: 0.09311745362356305 Adapter cache time: 0.24345683865249157 Engine time: 0.08969606505706906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.656842216849327,
    "estimated_duration": 3600.020797969761,
    "input_throughput": 2061.6428116708735,
    "output_throughput": 1828.974155847448,
    "total_throughput": 3890.6169675183214,
    "itl": 38.086931678477065,
    "ttft": 13511.049150698542,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.65370336370445,
    "arrivals": 30252,
    "finished_requests": 30139,
    "scheduler_time": 9.567011663397246
}
#Debug simulation 
Total elapsed time: 2.656954617705196. Arrivals time: 0.08551202900707722 Scheduler time: 2.09295949107036 Scheduler overhead time: 0.09388719545677304 Adapter cache time: 0.24658011179417372 Engine time: 0.09378501353785396 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_320_slots_128_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6485146363265812,
    "estimated_duration": 3600.0140228965874,
    "input_throughput": 2061.47085894648,
    "output_throughput": 1828.85009839561,
    "total_throughput": 3890.32095734209,
    "itl": 38.205934140187445,
    "ttft": 13511.804699993756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.269427321776554,
    "arrivals": 30252,
    "finished_requests": 30138,
    "scheduler_time": 9.617894013117901
}
#Debug simulation 
Total elapsed time: 2.648622216191143. Arrivals time: 0.08877925854176283 Scheduler time: 2.0851847426965833 Scheduler overhead time: 0.09362090844660997 Adapter cache time: 0.2458514398895204 Engine time: 0.0910539417527616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.360314509831369,
    "estimated_duration": 3600.0163297804543,
    "input_throughput": 1837.839996798984,
    "output_throughput": 1596.6616463516266,
    "total_throughput": 3434.5016431506106,
    "itl": 32.114492446734594,
    "ttft": 9399.652296738384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.832133024647916,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.5712092287891553
}
#Debug simulation 
Total elapsed time: 2.3604173422791064. Arrivals time: 0.07718579098582268 Scheduler time: 1.8061393415555358 Scheduler overhead time: 0.10599989024922252 Adapter cache time: 0.2180916997604072 Engine time: 0.1027166647836566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.356863357126713,
    "estimated_duration": 3600.00547493443,
    "input_throughput": 1837.8455383100516,
    "output_throughput": 1596.6664606543948,
    "total_throughput": 3434.5119989644463,
    "itl": 32.15023828749211,
    "ttft": 9400.154780108081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.92673295474979,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.587795444198361
}
#Debug simulation 
Total elapsed time: 2.356971079017967. Arrivals time: 0.07676681224256754 Scheduler time: 1.8018615595065057 Scheduler overhead time: 0.10600632941350341 Adapter cache time: 0.21806344529613853 Engine time: 0.10389535687863827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3925002296455204,
    "estimated_duration": 3600.008244785076,
    "input_throughput": 1837.8441242694978,
    "output_throughput": 1596.6652321773117,
    "total_throughput": 3434.5093564468098,
    "itl": 32.15101550640025,
    "ttft": 9400.067801004117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10400,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.99107015427469,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.5881579340720666
}
#Debug simulation 
Total elapsed time: 2.3926085038110614. Arrivals time: 0.07633022218942642 Scheduler time: 1.838308253325522 Scheduler overhead time: 0.10654350742697716 Adapter cache time: 0.21844419743865728 Engine time: 0.10246480535715818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.386993578169495,
    "estimated_duration": 3600.02440619271,
    "input_throughput": 1837.835873728749,
    "output_throughput": 1596.6580643487748,
    "total_throughput": 3434.4939380775236,
    "itl": 32.126928720885985,
    "ttft": 9399.923332853303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.53015415632028,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.5766726388368983
}
#Debug simulation 
Total elapsed time: 2.387146348133683. Arrivals time: 0.07780326809734106 Scheduler time: 1.8314847056753933 Scheduler overhead time: 0.10650351084768772 Adapter cache time: 0.21764724096283317 Engine time: 0.10332277277484536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.34056355105713,
    "estimated_duration": 3600.029049374313,
    "input_throughput": 1837.8335033573987,
    "output_throughput": 1596.6560050394612,
    "total_throughput": 3434.48950839686,
    "itl": 32.15923138232707,
    "ttft": 9399.99897465138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10399,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.418190324884314,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.591829243913512
}
#Debug simulation 
Total elapsed time: 2.340671226847917. Arrivals time: 0.07602606294676661 Scheduler time: 1.7927937130443752 Scheduler overhead time: 0.10516303591430187 Adapter cache time: 0.21656582737341523 Engine time: 0.10000273771584034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.381869092117995,
    "estimated_duration": 3600.027606430838,
    "input_throughput": 1837.8342399878227,
    "output_throughput": 1596.6566450024327,
    "total_throughput": 3434.4908849902554,
    "itl": 32.10165584670285,
    "ttft": 9399.716789895288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.10250316756925,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.565198393795859
}
#Debug simulation 
Total elapsed time: 2.3819780494086444. Arrivals time: 0.07684234529733658 Scheduler time: 1.8260469841770828 Scheduler overhead time: 0.1055627316236496 Adapter cache time: 0.21812927164137363 Engine time: 0.10480886744335294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_320_slots_128_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.37104931473732,
    "estimated_duration": 3600.0065614468954,
    "input_throughput": 1837.844983632705,
    "output_throughput": 1596.6659787669364,
    "total_throughput": 3434.5109623996414,
    "itl": 32.165203248501115,
    "ttft": 9399.867287520598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.85649687029221,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.5954496806084375
}
#Debug simulation 
Total elapsed time: 2.371182720642537. Arrivals time: 0.07627320662140846 Scheduler time: 1.8192151016555727 Scheduler overhead time: 0.10660073487088084 Adapter cache time: 0.21713091200217605 Engine time: 0.10167769808322191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.330098871141672,
    "estimated_duration": 3599.928401188163,
    "input_throughput": 1731.4580473163703,
    "output_throughput": 1563.190811834667,
    "total_throughput": 3294.6488591510374,
    "itl": 31.183268392052184,
    "ttft": 5722.295261899287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8687,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.58645703154547,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.7502870032716347
}
#Debug simulation 
Total elapsed time: 2.3302041543647647. Arrivals time: 0.07405114686116576 Scheduler time: 1.7812881893478334 Scheduler overhead time: 0.10875628143548965 Adapter cache time: 0.207242788746953 Engine time: 0.10693506617099047 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_128_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3014227831736207,
    "estimated_duration": 3599.9272341422243,
    "input_throughput": 1731.4586086307945,
    "output_throughput": 1563.1913185992125,
    "total_throughput": 3294.649927230007,
    "itl": 31.213327841107,
    "ttft": 5722.133955630213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8689,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.356937384450674,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.762369971470916
}
#Debug simulation 
Total elapsed time: 2.3015382010489702. Arrivals time: 0.07401700830087066 Scheduler time: 1.757397309411317 Scheduler overhead time: 0.1073859129101038 Adapter cache time: 0.20498328749090433 Engine time: 0.1064721499569714 
