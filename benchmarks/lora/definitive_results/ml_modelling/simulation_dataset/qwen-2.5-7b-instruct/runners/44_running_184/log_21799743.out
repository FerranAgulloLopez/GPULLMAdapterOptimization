INFO 06-01 00:47:02 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:02 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.6821038271300495,
    "estimated_duration": 3600.082636463247,
    "input_throughput": 6291.161144637025,
    "output_throughput": 5485.089925435547,
    "total_throughput": 11776.251070072572,
    "itl": 151.99395338676345,
    "ttft": 440050.60845060507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 99385,
    "finished_requests": 90660,
    "scheduler_time": 73.0931313303292
}
#Debug simulation 
Total elapsed time: 6.682363539002836. Arrivals time: 0.2570667709223926 Scheduler time: 6.303838958963752 Scheduler overhead time: 0.03714859206229448 Adapter cache time: 0.026554475538432598 Engine time: 0.039899816270917654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.721286095213145,
    "estimated_duration": 3600.1055263683693,
    "input_throughput": 6296.770145753906,
    "output_throughput": 5490.1571232380575,
    "total_throughput": 11786.927268991964,
    "itl": 153.6203130169539,
    "ttft": 435182.4393153038,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 99385,
    "finished_requests": 90753,
    "scheduler_time": 73.28704539415097
}
#Debug simulation 
Total elapsed time: 6.721435469109565. Arrivals time: 0.2907609133981168 Scheduler time: 6.310186050832272 Scheduler overhead time: 0.03689915034919977 Adapter cache time: 0.02735271956771612 Engine time: 0.03881612000986934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 135, 8640, 135, 135, 8640, 540, 8640, 540, 8640, 8640, 540, 135, 8640, 540, 135, 135, 540, 8640, 135, 540, 135, 135, 540, 540, 540, 135, 135, 8640, 540, 540, 135, 8640, 8640, 540, 8640, 8640, 540, 8640, 135, 8640, 540, 540, 540, 8640, 8640, 135, 135, 540, 135, 8640, 135, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 540, 8640, 8640, 135, 135, 8640, 540, 8640, 135, 540, 8640, 135, 8640, 540, 135, 8640, 135, 135, 8640, 135, 135, 540]
Prompts retrieved: 298080 . Total input tokens: 66485273 . Total output tokens: 59678888
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.670483168680221,
    "estimated_duration": 3600.1535447528413,
    "input_throughput": 6291.514158614866,
    "output_throughput": 5485.250491269179,
    "total_throughput": 11776.764649884046,
    "itl": 151.99658621530187,
    "ttft": 439866.360709567,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 99385,
    "finished_requests": 90666,
    "scheduler_time": 73.09520043414389
}
#Debug simulation 
Total elapsed time: 6.670595240779221. Arrivals time: 0.2700155368074775 Scheduler time: 6.279271612409502 Scheduler overhead time: 0.037171863950788975 Adapter cache time: 0.027444851584732533 Engine time: 0.03918751468881965 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.8582433350384235,
    "estimated_duration": 3600.164299179724,
    "input_throughput": 6343.4457714064265,
    "output_throughput": 5645.09208777792,
    "total_throughput": 11988.537859184346,
    "itl": 151.14630790516244,
    "ttft": 313970.9856721086,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 98626,
    "finished_requests": 92448,
    "scheduler_time": 76.4365039322644
}
#Debug simulation 
Total elapsed time: 6.858393686357886. Arrivals time: 0.27977245347574353 Scheduler time: 6.457487927749753 Scheduler overhead time: 0.03745068050920963 Adapter cache time: 0.026501673739403486 Engine time: 0.039481217972934246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.825183109845966,
    "estimated_duration": 3600.0838193025857,
    "input_throughput": 6343.321196455899,
    "output_throughput": 5645.099953238581,
    "total_throughput": 11988.42114969448,
    "itl": 151.14710617369838,
    "ttft": 314107.06215008866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 98626,
    "finished_requests": 92445,
    "scheduler_time": 76.4331625810263
}
#Debug simulation 
Total elapsed time: 6.825275930110365. Arrivals time: 0.22185093397274613 Scheduler time: 6.484556032344699 Scheduler overhead time: 0.03877651318907738 Adapter cache time: 0.02276361919939518 Engine time: 0.039450077805668116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.874029809143394,
    "estimated_duration": 3600.064556094058,
    "input_throughput": 6334.616683858205,
    "output_throughput": 5638.281948483392,
    "total_throughput": 11972.898632341596,
    "itl": 149.06322787085364,
    "ttft": 320904.6356034131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 98626,
    "finished_requests": 92322,
    "scheduler_time": 76.17393158110161
}
#Debug simulation 
Total elapsed time: 6.8741458910517395. Arrivals time: 0.28857789328321815 Scheduler time: 6.464385772123933 Scheduler overhead time: 0.03787181433290243 Adapter cache time: 0.025623895227909088 Engine time: 0.039825056213885546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.862827157136053,
    "estimated_duration": 3600.0538987130763,
    "input_throughput": 6343.37391675259,
    "output_throughput": 5645.146870513487,
    "total_throughput": 11988.520787266078,
    "itl": 151.14815364775941,
    "ttft": 314068.08254864713,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 98626,
    "finished_requests": 92445,
    "scheduler_time": 76.43268014570033
}
#Debug simulation 
Total elapsed time: 6.863017835188657. Arrivals time: 0.25777452578768134 Scheduler time: 6.488207077141851 Scheduler overhead time: 0.037172175478190184 Adapter cache time: 0.023210518062114716 Engine time: 0.03896991349756718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8765813782811165,
    "estimated_duration": 3600.04611014731,
    "input_throughput": 6334.649141220817,
    "output_throughput": 5638.310837960189,
    "total_throughput": 11972.959979181005,
    "itl": 149.06908021798355,
    "ttft": 320889.8659566951,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 98626,
    "finished_requests": 92322,
    "scheduler_time": 76.1745340207479
}
#Debug simulation 
Total elapsed time: 6.876685407944024. Arrivals time: 0.2936650509946048 Scheduler time: 6.461050869431347 Scheduler overhead time: 0.03798955539241433 Adapter cache time: 0.02619627770036459 Engine time: 0.039924224838614464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.807478063274175,
    "estimated_duration": 3600.0891586192524,
    "input_throughput": 6343.577893153868,
    "output_throughput": 5645.13824646346,
    "total_throughput": 11988.716139617329,
    "itl": 151.1437017881578,
    "ttft": 314014.12946239434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 98626,
    "finished_requests": 92447,
    "scheduler_time": 76.43457159687767
}
#Debug simulation 
Total elapsed time: 6.807600972242653. Arrivals time: 0.2605240852572024 Scheduler time: 6.429429262876511 Scheduler overhead time: 0.03732459852471948 Adapter cache time: 0.02365191373974085 Engine time: 0.03902849508449435 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 66, 8640, 66, 66, 8640, 540, 8640, 540, 8640, 8640, 540, 66, 8640, 540, 66, 66, 540, 8640, 66, 540, 66, 66, 540, 540, 540, 66, 66, 8640, 540, 540, 66, 8640, 8640, 540, 8640, 8640, 540, 8640, 66, 8640, 540, 540, 540, 8640, 8640, 66, 66, 540, 66, 8640, 66, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 540, 8640, 8640, 66, 66, 8640, 540, 8640, 66, 540, 8640, 66, 8640, 540, 66, 8640, 66, 66, 8640, 66, 66, 540]
Prompts retrieved: 295872 . Total input tokens: 65996354 . Total output tokens: 59243662
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.893933780025691,
    "estimated_duration": 3600.0551244396947,
    "input_throughput": 6334.633279691607,
    "output_throughput": 5638.296720014577,
    "total_throughput": 11972.929999706184,
    "itl": 149.06873658173336,
    "ttft": 320897.23247253464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 98626,
    "finished_requests": 92322,
    "scheduler_time": 76.1744496299383
}
#Debug simulation 
Total elapsed time: 6.894064539112151. Arrivals time: 0.2994233383797109 Scheduler time: 6.471761271823198 Scheduler overhead time: 0.037993174046278 Adapter cache time: 0.026787903159856796 Engine time: 0.0400487519800663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.905089744832367,
    "estimated_duration": 3600.1022050280308,
    "input_throughput": 6567.358273045449,
    "output_throughput": 5721.1739631263135,
    "total_throughput": 12288.532236171763,
    "itl": 146.18206043665413,
    "ttft": 187156.241432037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 98351,
    "finished_requests": 94552,
    "scheduler_time": 78.37021009992483
}
#Debug simulation 
Total elapsed time: 6.905197479762137. Arrivals time: 0.25987662887200713 Scheduler time: 6.5263292053714395 Scheduler overhead time: 0.03850566130131483 Adapter cache time: 0.021522297523915768 Engine time: 0.040837660897523165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.926409585867077,
    "estimated_duration": 3600.0227660604032,
    "input_throughput": 6567.295413487758,
    "output_throughput": 5721.114653543951,
    "total_throughput": 12288.41006703171,
    "itl": 146.18209626326188,
    "ttft": 187112.46482506496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 98351,
    "finished_requests": 94550,
    "scheduler_time": 78.36930091106856
}
#Debug simulation 
Total elapsed time: 6.926527900621295. Arrivals time: 0.2872108155861497 Scheduler time: 6.518813277129084 Scheduler overhead time: 0.03858376806601882 Adapter cache time: 0.022968847304582596 Engine time: 0.040749667678028345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.9191247508861125,
    "estimated_duration": 3600.0585869369556,
    "input_throughput": 6559.4118622641,
    "output_throughput": 5714.3378373470505,
    "total_throughput": 12273.74969961115,
    "itl": 144.84663206865113,
    "ttft": 193377.31819042904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 98351,
    "finished_requests": 94430,
    "scheduler_time": 78.1759587738471
}
#Debug simulation 
Total elapsed time: 6.919232090935111. Arrivals time: 0.25958326598629355 Scheduler time: 6.540174982510507 Scheduler overhead time: 0.03877829294651747 Adapter cache time: 0.021458338014781475 Engine time: 0.04086043452844024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.951678185258061,
    "estimated_duration": 3600.1119434482603,
    "input_throughput": 6567.340508127117,
    "output_throughput": 5721.15848716414,
    "total_throughput": 12288.498995291257,
    "itl": 146.1814899487999,
    "ttft": 187188.2581266668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 98351,
    "finished_requests": 94552,
    "scheduler_time": 78.37051245959724
}
#Debug simulation 
Total elapsed time: 6.951812721323222. Arrivals time: 0.29442891385406256 Scheduler time: 6.535789621528238 Scheduler overhead time: 0.038677799981087446 Adapter cache time: 0.024132519494742155 Engine time: 0.04054664680734277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.87501333700493,
    "estimated_duration": 3600.062725842964,
    "input_throughput": 6559.404321065172,
    "output_throughput": 5714.3312677095155,
    "total_throughput": 12273.735588774687,
    "itl": 144.84617801629335,
    "ttft": 193381.003887119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 98351,
    "finished_requests": 94430,
    "scheduler_time": 78.17580283504189
}
#Debug simulation 
Total elapsed time: 6.875137116294354. Arrivals time: 0.25977973779663444 Scheduler time: 6.494998218957335 Scheduler overhead time: 0.03863004827871919 Adapter cache time: 0.022798628080636263 Engine time: 0.04067820915952325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.960626696702093,
    "estimated_duration": 3600.022953025995,
    "input_throughput": 6567.295072418191,
    "output_throughput": 5721.114356420405,
    "total_throughput": 12288.409428838595,
    "itl": 146.17939069621195,
    "ttft": 187114.64436973943,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 98351,
    "finished_requests": 94550,
    "scheduler_time": 78.36907750695859
}
#Debug simulation 
Total elapsed time: 6.960759251844138. Arrivals time: 0.2935978686437011 Scheduler time: 6.546100119128823 Scheduler overhead time: 0.03877976071089506 Adapter cache time: 0.02325032837688923 Engine time: 0.04072201671078801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 8640, 540, 540, 540, 540, 8640, 540, 8640, 540, 33, 8640, 33, 33, 8640, 540, 8640, 540, 8640, 8640, 540, 33, 8640, 540, 33, 33, 540, 8640, 33, 540, 33, 33, 540, 540, 540, 33, 33, 8640, 540, 540, 33, 8640, 8640, 540, 8640, 8640, 540, 8640, 33, 8640, 540, 540, 540, 8640, 8640, 33, 33, 540, 33, 8640, 33, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 540, 8640, 8640, 33, 33, 8640, 540, 8640, 33, 540, 8640, 33, 8640, 540, 33, 8640, 33, 33, 8640, 33, 33, 540]
Prompts retrieved: 294816 . Total input tokens: 65753074 . Total output tokens: 59033708
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8713298961520195,
    "estimated_duration": 3600.0667968527805,
    "input_throughput": 6559.396903591862,
    "output_throughput": 5714.324805857556,
    "total_throughput": 12273.721709449417,
    "itl": 144.84544969226803,
    "ttft": 193382.3303840037,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 98351,
    "finished_requests": 94430,
    "scheduler_time": 78.17584601086031
}
#Debug simulation 
Total elapsed time: 6.871454842854291. Arrivals time: 0.2616099277511239 Scheduler time: 6.490788883063942 Scheduler overhead time: 0.0386359840631485 Adapter cache time: 0.02186405658721924 Engine time: 0.04024593019858003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.942804295103997,
    "estimated_duration": 3600.0958938127565,
    "input_throughput": 6472.5664780339175,
    "output_throughput": 5694.239988226883,
    "total_throughput": 12166.8064662608,
    "itl": 147.20768575186548,
    "ttft": 152322.8040310557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 96609,
    "finished_requests": 93552,
    "scheduler_time": 78.31582151281161
}
#Debug simulation 
Total elapsed time: 6.942908313125372. Arrivals time: 0.2831010930240154 Scheduler time: 6.532787647563964 Scheduler overhead time: 0.038470578379929066 Adapter cache time: 0.02971570799127221 Engine time: 0.04068662133067846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.892714196816087,
    "estimated_duration": 3600.00782955382,
    "input_throughput": 6472.724811514646,
    "output_throughput": 5694.379282097483,
    "total_throughput": 12167.10409361213,
    "itl": 147.20734514461864,
    "ttft": 152249.71217429053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 96609,
    "finished_requests": 93552,
    "scheduler_time": 78.31424560953718
}
#Debug simulation 
Total elapsed time: 6.892841211985797. Arrivals time: 0.25629836739972234 Scheduler time: 6.511086426209658 Scheduler overhead time: 0.03816285403445363 Adapter cache time: 0.028845604974776506 Engine time: 0.04035643208771944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.92238659132272,
    "estimated_duration": 3600.154884184994,
    "input_throughput": 6467.992836166951,
    "output_throughput": 5690.335460286081,
    "total_throughput": 12158.328296453032,
    "itl": 145.33907994681343,
    "ttft": 156792.67508404853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 96609,
    "finished_requests": 93482,
    "scheduler_time": 78.13943341989153
}
#Debug simulation 
Total elapsed time: 6.9225294310599566. Arrivals time: 0.28331930097192526 Scheduler time: 6.511068599764258 Scheduler overhead time: 0.03883275110274553 Adapter cache time: 0.029764815233647823 Engine time: 0.04114078311249614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.9133849600329995,
    "estimated_duration": 3600.1494491099243,
    "input_throughput": 6472.470193080731,
    "output_throughput": 5694.155281544834,
    "total_throughput": 12166.625474625565,
    "itl": 147.20906401435911,
    "ttft": 152507.14231241183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 96609,
    "finished_requests": 93552,
    "scheduler_time": 78.31643109048174
}
#Debug simulation 
Total elapsed time: 6.913500348106027. Arrivals time: 0.2632222040556371 Scheduler time: 6.524565897881985 Scheduler overhead time: 0.038055689074099064 Adapter cache time: 0.029462847393006086 Engine time: 0.040163511876016855 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.91382073611021,
    "estimated_duration": 3600.011995554958,
    "input_throughput": 6467.956225909896,
    "output_throughput": 5690.132706583444,
    "total_throughput": 12158.08893249334,
    "itl": 145.33876223711022,
    "ttft": 156787.15400575512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970506,
    "arrivals": 96609,
    "finished_requests": 93477,
    "scheduler_time": 78.13535760840013
}
#Debug simulation 
Total elapsed time: 6.913981594145298. Arrivals time: 0.2838491452857852 Scheduler time: 6.501984836533666 Scheduler overhead time: 0.03887373302131891 Adapter cache time: 0.029870915692299604 Engine time: 0.0409374781884253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.938670612405986,
    "estimated_duration": 3600.162190236449,
    "input_throughput": 6472.471452312428,
    "output_throughput": 5694.204015473428,
    "total_throughput": 12166.675467785855,
    "itl": 147.20574262788412,
    "ttft": 152461.83975367213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 96609,
    "finished_requests": 93553,
    "scheduler_time": 78.31701497397626
}
#Debug simulation 
Total elapsed time: 6.93878922611475. Arrivals time: 0.25629446981474757 Scheduler time: 6.556529304012656 Scheduler overhead time: 0.03835403360426426 Adapter cache time: 0.02929824497550726 Engine time: 0.04019703669473529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.8   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 135, 8640, 135, 135, 8640, 270, 8640, 270, 8640, 8640, 270, 135, 8640, 270, 135, 135, 270, 8640, 135, 270, 135, 135, 270, 270, 270, 135, 135, 8640, 270, 270, 135, 8640, 8640, 270, 8640, 8640, 270, 8640, 135, 8640, 270, 270, 270, 8640, 8640, 135, 135, 270, 135, 8640, 135, 135, 8640, 135, 270, 270, 135, 270, 8640, 8640, 8640, 270, 8640, 8640, 135, 135, 8640, 270, 8640, 135, 270, 8640, 135, 8640, 270, 135, 8640, 135, 135, 8640, 135, 135, 270]
Prompts retrieved: 289440 . Total input tokens: 64589415 . Total output tokens: 57941137
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.934001223184168,
    "estimated_duration": 3600.002802773872,
    "input_throughput": 6467.972742148609,
    "output_throughput": 5690.147236612222,
    "total_throughput": 12158.11997876083,
    "itl": 145.33746438816473,
    "ttft": 156779.46489167845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 96609,
    "finished_requests": 93477,
    "scheduler_time": 78.13538348120227
}
#Debug simulation 
Total elapsed time: 6.934113116003573. Arrivals time: 0.28544980846345425 Scheduler time: 6.519649753347039 Scheduler overhead time: 0.03927009040489793 Adapter cache time: 0.030117780901491642 Engine time: 0.04119851067662239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.896887212060392,
    "estimated_duration": 3600.0644697137977,
    "input_throughput": 6554.143182295791,
    "output_throughput": 5801.274720410865,
    "total_throughput": 12355.417902706657,
    "itl": 131.86360620342265,
    "ttft": 34071.24991062548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 95912,
    "finished_requests": 95028,
    "scheduler_time": 80.1793616717165
}
#Debug simulation 
Total elapsed time: 6.897023571189493. Arrivals time: 0.2426600093021989 Scheduler time: 6.523012093268335 Scheduler overhead time: 0.04193701362237334 Adapter cache time: 0.025888363365083933 Engine time: 0.0437909634783864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.964923493098468,
    "estimated_duration": 3600.0756257465932,
    "input_throughput": 6554.122872101259,
    "output_throughput": 5801.256743229893,
    "total_throughput": 12355.379615331152,
    "itl": 131.86655127667197,
    "ttft": 34146.12797109582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 95912,
    "finished_requests": 95028,
    "scheduler_time": 80.17984920000414
}
#Debug simulation 
Total elapsed time: 6.965040317270905. Arrivals time: 0.2668538331054151 Scheduler time: 6.56629914464429 Scheduler overhead time: 0.04181772843003273 Adapter cache time: 0.026552131865173578 Engine time: 0.043738562148064375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.98093410115689,
    "estimated_duration": 3600.041609517038,
    "input_throughput": 6553.975081183942,
    "output_throughput": 5801.188782037926,
    "total_throughput": 12355.163863221867,
    "itl": 131.76327007413954,
    "ttft": 34385.11178772204,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 95912,
    "finished_requests": 95027,
    "scheduler_time": 80.17285692914753
}
#Debug simulation 
Total elapsed time: 6.981039019301534. Arrivals time: 0.24769851984456182 Scheduler time: 6.601784870959818 Scheduler overhead time: 0.041720557026565075 Adapter cache time: 0.026382983662188053 Engine time: 0.04372183978557587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.9526511817239225,
    "estimated_duration": 3600.0673835141356,
    "input_throughput": 6554.137877543801,
    "output_throughput": 5801.270025010907,
    "total_throughput": 12355.407902554707,
    "itl": 131.8684697213959,
    "ttft": 34070.0130447509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 95912,
    "finished_requests": 95028,
    "scheduler_time": 80.1797491100484
}
#Debug simulation 
Total elapsed time: 6.952753794845194. Arrivals time: 0.2611926682293415 Scheduler time: 6.559282911941409 Scheduler overhead time: 0.041744329035282135 Adapter cache time: 0.026670082472264767 Engine time: 0.04409696813672781 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.911764476913959,
    "estimated_duration": 3600.0763547407496,
    "input_throughput": 6554.121544930165,
    "output_throughput": 5801.255568509734,
    "total_throughput": 12355.3771134399,
    "itl": 131.7713908432245,
    "ttft": 34424.19242482333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 95912,
    "finished_requests": 95028,
    "scheduler_time": 80.17376770472804
}
#Debug simulation 
Total elapsed time: 6.911861372180283. Arrivals time: 0.24638877110555768 Scheduler time: 6.535390826873481 Scheduler overhead time: 0.04146519396454096 Adapter cache time: 0.02583571569994092 Engine time: 0.04318082705140114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.942634853068739,
    "estimated_duration": 3600.134800910867,
    "input_throughput": 6554.195969003716,
    "output_throughput": 5801.428878361908,
    "total_throughput": 12355.624847365623,
    "itl": 131.8682806660461,
    "ttft": 34218.20809156023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 95912,
    "finished_requests": 95030,
    "scheduler_time": 80.18114212788493
}
#Debug simulation 
Total elapsed time: 6.942768297158182. Arrivals time: 0.26230685878545046 Scheduler time: 6.548779886215925 Scheduler overhead time: 0.041900924406945705 Adapter cache time: 0.026612455490976572 Engine time: 0.043380461167544127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.98115852707997,
    "estimated_duration": 3600.027259963029,
    "input_throughput": 6554.001205047072,
    "output_throughput": 5801.211905327205,
    "total_throughput": 12355.213110374278,
    "itl": 131.77248649010218,
    "ttft": 34385.06393441533,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 95912,
    "finished_requests": 95027,
    "scheduler_time": 80.17278286438041
}
#Debug simulation 
Total elapsed time: 6.981309885159135. Arrivals time: 0.24415625352412462 Scheduler time: 6.605952977668494 Scheduler overhead time: 0.04160477081313729 Adapter cache time: 0.02618468226864934 Engine time: 0.04338797368109226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.906198471784592,
    "estimated_duration": 3600.07506488691,
    "input_throughput": 6541.752762241308,
    "output_throughput": 5770.828559279673,
    "total_throughput": 12312.581321520982,
    "itl": 110.31662045908982,
    "ttft": 25397.243566893507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 95515,
    "finished_requests": 94845,
    "scheduler_time": 78.58844518022026
}
#Debug simulation 
Total elapsed time: 6.906320984940976. Arrivals time: 0.2680166936479509 Scheduler time: 6.490883546881378 Scheduler overhead time: 0.04806316923350096 Adapter cache time: 0.026543679181486368 Engine time: 0.050099510699510574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.889895617030561,
    "estimated_duration": 3600.064600616077,
    "input_throughput": 6541.771777086935,
    "output_throughput": 5770.845333287829,
    "total_throughput": 12312.617110374764,
    "itl": 110.31863625352977,
    "ttft": 25359.973344293183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 95515,
    "finished_requests": 94845,
    "scheduler_time": 78.58849172492427
}
#Debug simulation 
Total elapsed time: 6.890006952919066. Arrivals time: 0.241533774882555 Scheduler time: 6.501859583891928 Scheduler overhead time: 0.047895846888422966 Adapter cache time: 0.02576633682474494 Engine time: 0.050199505407363176 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.9207493220455945,
    "estimated_duration": 3600.057972023653,
    "input_throughput": 6541.783822098204,
    "output_throughput": 5770.855958833849,
    "total_throughput": 12312.639780932053,
    "itl": 110.31143824252307,
    "ttft": 25361.826118913265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 95515,
    "finished_requests": 94845,
    "scheduler_time": 78.58809747304718
}
#Debug simulation 
Total elapsed time: 6.920886725187302. Arrivals time: 0.26442201202735305 Scheduler time: 6.508264224976301 Scheduler overhead time: 0.0480416608043015 Adapter cache time: 0.02658524364233017 Engine time: 0.05074511747807264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.8704254371114075,
    "estimated_duration": 3600.0262069849223,
    "input_throughput": 6541.581268021761,
    "output_throughput": 5770.879934065717,
    "total_throughput": 12312.461202087477,
    "itl": 110.31904024650626,
    "ttft": 25360.78558099453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007002,
    "arrivals": 95515,
    "finished_requests": 94843,
    "scheduler_time": 78.58746549097907
}
#Debug simulation 
Total elapsed time: 6.870564355049282. Arrivals time: 0.25545397074893117 Scheduler time: 6.468084461987019 Scheduler overhead time: 0.047807535622268915 Adapter cache time: 0.02589418087154627 Engine time: 0.05058280844241381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.929619482252747,
    "estimated_duration": 3600.0514726803717,
    "input_throughput": 6541.658689803655,
    "output_throughput": 5770.8399887216065,
    "total_throughput": 12312.498678525262,
    "itl": 110.31498107908945,
    "ttft": 25399.2533080679,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705035,
    "arrivals": 95515,
    "finished_requests": 94844,
    "scheduler_time": 78.58792597275155
}
#Debug simulation 
Total elapsed time: 6.9297494874335825. Arrivals time: 0.2662027468904853 Scheduler time: 6.515028323512524 Scheduler overhead time: 0.048058535903692245 Adapter cache time: 0.0266571631655097 Engine time: 0.05079863267019391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.900322520174086,
    "estimated_duration": 3600.0640965399352,
    "input_throughput": 6541.772693057037,
    "output_throughput": 5770.846141313846,
    "total_throughput": 12312.618834370882,
    "itl": 110.31316342083689,
    "ttft": 25359.769833784252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 95515,
    "finished_requests": 94845,
    "scheduler_time": 78.58797091330672
}
#Debug simulation 
Total elapsed time: 6.900437182281166. Arrivals time: 0.24303485406562686 Scheduler time: 6.5118264788761735 Scheduler overhead time: 0.04750288464128971 Adapter cache time: 0.025700323283672333 Engine time: 0.04972724476829171 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.92737930919975,
    "estimated_duration": 3600.0641837166977,
    "input_throughput": 6541.7725346458155,
    "output_throughput": 5770.846001570869,
    "total_throughput": 12312.618536216685,
    "itl": 110.31521127791132,
    "ttft": 25361.865106892434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 95515,
    "finished_requests": 94845,
    "scheduler_time": 78.58829036838851
}
#Debug simulation 
Total elapsed time: 6.9274850292131305. Arrivals time: 0.2630536356009543 Scheduler time: 6.518454416655004 Scheduler overhead time: 0.047738483641296625 Adapter cache time: 0.025931889656931162 Engine time: 0.04961487511172891 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.828600801993161,
    "estimated_duration": 3600.079296800353,
    "input_throughput": 6482.093608532571,
    "output_throughput": 5713.06665891493,
    "total_throughput": 12195.1602674475,
    "itl": 88.4867609348228,
    "ttft": 20845.722372263546,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 94463,
    "finished_requests": 93919,
    "scheduler_time": 76.24085577935787
}
#Debug simulation 
Total elapsed time: 6.8286999319680035. Arrivals time: 0.24273024266585708 Scheduler time: 6.418095136061311 Scheduler overhead time: 0.05669098813086748 Adapter cache time: 0.024715717881917953 Engine time: 0.05945498123764992 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.822586274705827,
    "estimated_duration": 3600.068766045716,
    "input_throughput": 6482.1122918805,
    "output_throughput": 5713.082814968324,
    "total_throughput": 12195.195106848823,
    "itl": 88.48856536427895,
    "ttft": 20884.0489646326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 94463,
    "finished_requests": 93918,
    "scheduler_time": 76.24076694299288
}
#Debug simulation 
Total elapsed time: 6.822701882105321. Arrivals time: 0.2279612347483635 Scheduler time: 6.4263294585980475 Scheduler overhead time: 0.05657772719860077 Adapter cache time: 0.02473376877605915 Engine time: 0.060093739069998264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.8374488623812795,
    "estimated_duration": 3600.067771355448,
    "input_throughput": 6482.114082872899,
    "output_throughput": 5713.084393479685,
    "total_throughput": 12195.198476352583,
    "itl": 88.48866570845193,
    "ttft": 20884.20419021279,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 94463,
    "finished_requests": 93918,
    "scheduler_time": 76.24088839844973
}
#Debug simulation 
Total elapsed time: 6.8375578061677516. Arrivals time: 0.2500040903687477 Scheduler time: 6.418163613881916 Scheduler overhead time: 0.057230561040341854 Adapter cache time: 0.025029474403709173 Engine time: 0.059928343165665865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.834030403289944,
    "estimated_duration": 3600.0677363646555,
    "input_throughput": 6482.114145875687,
    "output_throughput": 5713.084449007904,
    "total_throughput": 12195.198594883592,
    "itl": 88.48684985240087,
    "ttft": 20884.20762448343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 94463,
    "finished_requests": 93918,
    "scheduler_time": 76.24060418176082
}
#Debug simulation 
Total elapsed time: 6.834148199297488. Arrivals time: 0.25659446278586984 Scheduler time: 6.408297865185887 Scheduler overhead time: 0.056845189537853 Adapter cache time: 0.025476180482655764 Engine time: 0.059856589417904615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.862404068000615,
    "estimated_duration": 3600.067765500005,
    "input_throughput": 6482.114093415937,
    "output_throughput": 5713.0844027719095,
    "total_throughput": 12195.198496187846,
    "itl": 88.48844648907415,
    "ttft": 20884.201738941258,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 94463,
    "finished_requests": 93918,
    "scheduler_time": 76.24085653168443
}
#Debug simulation 
Total elapsed time: 6.862514874897897. Arrivals time: 0.25007527647539973 Scheduler time: 6.442712577059865 Scheduler overhead time: 0.056889128405600786 Adapter cache time: 0.025431609246879816 Engine time: 0.060144735500216484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.840693445876241,
    "estimated_duration": 3600.07930284006,
    "input_throughput": 6482.093597657826,
    "output_throughput": 5713.066649330349,
    "total_throughput": 12195.160246988175,
    "itl": 88.4872622939117,
    "ttft": 20845.797196304287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 94463,
    "finished_requests": 93919,
    "scheduler_time": 76.24100258072
}
#Debug simulation 
Total elapsed time: 6.840843725949526. Arrivals time: 0.25568528193980455 Scheduler time: 6.416351854801178 Scheduler overhead time: 0.05682326294481754 Adapter cache time: 0.025099552236497402 Engine time: 0.059789085760712624 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.865505944937468,
    "estimated_duration": 3600.0700097571,
    "input_throughput": 6482.110052513814,
    "output_throughput": 5713.080841277225,
    "total_throughput": 12195.19089379104,
    "itl": 88.48818734741941,
    "ttft": 20884.30299440638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232575,
    "arrivals": 94463,
    "finished_requests": 93918,
    "scheduler_time": 76.24095213198049
}
#Debug simulation 
Total elapsed time: 6.865612340159714. Arrivals time: 0.2503026220947504 Scheduler time: 6.44550401205197 Scheduler overhead time: 0.057259713765233755 Adapter cache time: 0.02513304678723216 Engine time: 0.06026218784973025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.860849158838391,
    "estimated_duration": 3600.0287203749363,
    "input_throughput": 6454.5235065735715,
    "output_throughput": 5706.398086140953,
    "total_throughput": 12160.921592714523,
    "itl": 83.99870667710044,
    "ttft": 21955.501389190948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 94079,
    "finished_requests": 93504,
    "scheduler_time": 75.78573147188405
}
#Debug simulation 
Total elapsed time: 6.860990887042135. Arrivals time: 0.25380935287103057 Scheduler time: 6.433514994569123 Scheduler overhead time: 0.05948683712631464 Adapter cache time: 0.02318592742085457 Engine time: 0.06268592784181237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.881117626093328,
    "estimated_duration": 3600.048400678141,
    "input_throughput": 6454.587109335219,
    "output_throughput": 5706.396890700207,
    "total_throughput": 12160.984000035425,
    "itl": 84.00102972737348,
    "ttft": 21993.46732802213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 94079,
    "finished_requests": 93505,
    "scheduler_time": 75.7863755945386
}
#Debug simulation 
Total elapsed time: 6.881212891079485. Arrivals time: 0.25747770443558693 Scheduler time: 6.450160580221564 Scheduler overhead time: 0.05923051247373223 Adapter cache time: 0.023279390297830105 Engine time: 0.06264853477478027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.827455413993448,
    "estimated_duration": 3600.036017389099,
    "input_throughput": 6454.609311618039,
    "output_throughput": 5706.416519382184,
    "total_throughput": 12161.025831000223,
    "itl": 84.00065721780614,
    "ttft": 21955.29706083842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 94079,
    "finished_requests": 93505,
    "scheduler_time": 75.78593376803882
}
#Debug simulation 
Total elapsed time: 6.827575140167028. Arrivals time: 0.24450757494196296 Scheduler time: 6.40998842054978 Scheduler overhead time: 0.05928158201277256 Adapter cache time: 0.02315649064257741 Engine time: 0.06244142074137926 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.87071981234476,
    "estimated_duration": 3600.048741929022,
    "input_throughput": 6454.5864975008535,
    "output_throughput": 5706.396349787263,
    "total_throughput": 12160.982847288116,
    "itl": 83.99938278918818,
    "ttft": 21993.34673835139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 94079,
    "finished_requests": 93505,
    "scheduler_time": 75.78606857238951
}
#Debug simulation 
Total elapsed time: 6.8708304963074625. Arrivals time: 0.26348243840038776 Scheduler time: 6.433258017059416 Scheduler overhead time: 0.05929336417466402 Adapter cache time: 0.023697301745414734 Engine time: 0.06283335573971272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.830980141181499,
    "estimated_duration": 3600.0327730078848,
    "input_throughput": 6454.516240580098,
    "output_throughput": 5706.391662328071,
    "total_throughput": 12160.90790290817,
    "itl": 84.00012836974493,
    "ttft": 21993.63186292572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 94079,
    "finished_requests": 93504,
    "scheduler_time": 75.78598320718406
}
#Debug simulation 
Total elapsed time: 6.831118191126734. Arrivals time: 0.2414111141115427 Scheduler time: 6.417237070389092 Scheduler overhead time: 0.058957640547305346 Adapter cache time: 0.023322010412812233 Engine time: 0.06200796086341143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.864159697666764,
    "estimated_duration": 3600.04541031149,
    "input_throughput": 6454.592470818156,
    "output_throughput": 5706.40163070124,
    "total_throughput": 12160.994101519396,
    "itl": 83.99765940841567,
    "ttft": 21993.36585556639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 94079,
    "finished_requests": 93505,
    "scheduler_time": 75.78579252726591
}
#Debug simulation 
Total elapsed time: 6.864283735863864. Arrivals time: 0.261403891723603 Scheduler time: 6.428651950787753 Scheduler overhead time: 0.059551252983510494 Adapter cache time: 0.023392944131046534 Engine time: 0.06291089812293649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.830716069322079,
    "estimated_duration": 3600.050999571754,
    "input_throughput": 6454.58244973867,
    "output_throughput": 5706.392771225669,
    "total_throughput": 12160.97522096434,
    "itl": 84.00069398365365,
    "ttft": 21993.336661884063,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 94079,
    "finished_requests": 93505,
    "scheduler_time": 75.78630315676816
}
#Debug simulation 
Total elapsed time: 6.830813885200769. Arrivals time: 0.24576892238110304 Scheduler time: 6.411823659669608 Scheduler overhead time: 0.05944412015378475 Adapter cache time: 0.023141751997172832 Engine time: 0.0623968867585063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.822174098342657,
    "estimated_duration": 3600.0541637654414,
    "input_throughput": 6443.008061784057,
    "output_throughput": 5679.233442036655,
    "total_throughput": 12122.241503820711,
    "itl": 74.52307229866142,
    "ttft": 15852.408286117841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.30100663409165
}
#Debug simulation 
Total elapsed time: 6.822276349179447. Arrivals time: 0.2595363981090486 Scheduler time: 6.376849707216024 Scheduler overhead time: 0.0652043386362493 Adapter cache time: 0.020704508293420076 Engine time: 0.06901059113442898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.7956686918623745,
    "estimated_duration": 3600.046605026994,
    "input_throughput": 6443.021589668026,
    "output_throughput": 5679.245366282334,
    "total_throughput": 12122.26695595036,
    "itl": 74.5239529019766,
    "ttft": 15852.528493027405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.30095601867413
}
#Debug simulation 
Total elapsed time: 6.7957650208845735. Arrivals time: 0.24549544882029295 Scheduler time: 6.365275033283979 Scheduler overhead time: 0.06527514383196831 Adapter cache time: 0.020652854349464178 Engine time: 0.06792617589235306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.863446985371411,
    "estimated_duration": 3600.048322726779,
    "input_throughput": 6443.018515493512,
    "output_throughput": 5679.242656530221,
    "total_throughput": 12122.261172023733,
    "itl": 74.52400421548768,
    "ttft": 15852.49149370792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.30094797003288
}
#Debug simulation 
Total elapsed time: 6.863576934207231. Arrivals time: 0.25568540254607797 Scheduler time: 6.421142915729433 Scheduler overhead time: 0.0655984515324235 Adapter cache time: 0.020722717978060246 Engine time: 0.06922881584614515 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.835950049106032,
    "estimated_duration": 3600.0715515363922,
    "input_throughput": 6443.015831199522,
    "output_throughput": 5679.368786788213,
    "total_throughput": 12122.384617987735,
    "itl": 74.52341032121875,
    "ttft": 15813.880219560013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 93393,
    "finished_requests": 92986,
    "scheduler_time": 74.30126871262894
}
#Debug simulation 
Total elapsed time: 6.836066918913275. Arrivals time: 0.28183937864378095 Scheduler time: 6.368021782953292 Scheduler overhead time: 0.06560010416433215 Adapter cache time: 0.02057718764990568 Engine time: 0.06874019559472799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.805000416003168,
    "estimated_duration": 3600.054971914405,
    "input_throughput": 6443.006615442174,
    "output_throughput": 5679.232167148728,
    "total_throughput": 12122.2387825909,
    "itl": 74.52398239495356,
    "ttft": 15852.414266227981,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.30106841282577
}
#Debug simulation 
Total elapsed time: 6.805129710119218. Arrivals time: 0.2474863464012742 Scheduler time: 6.37253289623186 Scheduler overhead time: 0.06539720669388771 Adapter cache time: 0.020634880289435387 Engine time: 0.0679683517664671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.832245529163629,
    "estimated_duration": 3600.0307999636852,
    "input_throughput": 6443.049876193831,
    "output_throughput": 5679.270299633615,
    "total_throughput": 12122.320175827446,
    "itl": 74.52279503206302,
    "ttft": 15852.580032448574,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 93393,
    "finished_requests": 92985,
    "scheduler_time": 74.30034757623056
}
#Debug simulation 
Total elapsed time: 6.832341433968395. Arrivals time: 0.25709253177046776 Scheduler time: 6.3887026542797685 Scheduler overhead time: 0.06552334362640977 Adapter cache time: 0.020807448774576187 Engine time: 0.06894522905349731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.819807095918804,
    "estimated_duration": 3600.0711129811652,
    "input_throughput": 6443.016616077982,
    "output_throughput": 5679.369478640343,
    "total_throughput": 12122.386094718324,
    "itl": 74.52440237609942,
    "ttft": 15813.874620980454,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232575,
    "arrivals": 93393,
    "finished_requests": 92986,
    "scheduler_time": 74.3014300542265
}
#Debug simulation 
Total elapsed time: 6.819914581719786. Arrivals time: 0.24117020377889276 Scheduler time: 6.393581984564662 Scheduler overhead time: 0.06530447863042355 Adapter cache time: 0.020277902018278837 Engine time: 0.06846587127074599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.816514305770397,
    "estimated_duration": 3600.0688441364146,
    "input_throughput": 4404.05216856437,
    "output_throughput": 3856.273755045432,
    "total_throughput": 8260.325923609802,
    "itl": 73.13681779869205,
    "ttft": 16620.090009760246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 63713,
    "finished_requests": 63421,
    "scheduler_time": 47.51990984112232
}
#Debug simulation 
Total elapsed time: 4.816626694984734. Arrivals time: 0.1930525484494865 Scheduler time: 4.407035328447819 Scheduler overhead time: 0.06312129413709044 Adapter cache time: 0.056730191223323345 Engine time: 0.06648588413372636 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.784279483836144,
    "estimated_duration": 3600.061444114009,
    "input_throughput": 4404.061221211173,
    "output_throughput": 3856.2816817190824,
    "total_throughput": 8260.342902930255,
    "itl": 73.13593733824231,
    "ttft": 16620.18524473016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 63713,
    "finished_requests": 63421,
    "scheduler_time": 47.51966735751445
}
#Debug simulation 
Total elapsed time: 4.784404833801091. Arrivals time: 0.1946812686510384 Scheduler time: 4.374893578700721 Scheduler overhead time: 0.06287047080695629 Adapter cache time: 0.05634978041052818 Engine time: 0.06556045869365335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.778945272788405,
    "estimated_duration": 3600.061438667712,
    "input_throughput": 4404.061227873788,
    "output_throughput": 3856.2816875529984,
    "total_throughput": 8260.342915426787,
    "itl": 73.13586395211425,
    "ttft": 16620.200305104612,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 63713,
    "finished_requests": 63421,
    "scheduler_time": 47.519683454796784
}
#Debug simulation 
Total elapsed time: 4.779051347635686. Arrivals time: 0.17702516773715615 Scheduler time: 4.385168917942792 Scheduler overhead time: 0.06342729879543185 Adapter cache time: 0.0566381081007421 Engine time: 0.06661242293193936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.749289239756763,
    "estimated_duration": 3600.013963669832,
    "input_throughput": 4403.906251474204,
    "output_throughput": 3856.245597961022,
    "total_throughput": 8260.151849435226,
    "itl": 73.13744147579276,
    "ttft": 16733.55480708502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 63713,
    "finished_requests": 63418,
    "scheduler_time": 47.519156426991415
}
#Debug simulation 
Total elapsed time: 4.749450160656124. Arrivals time: 0.18076544627547264 Scheduler time: 4.3529031770303845 Scheduler overhead time: 0.06296276673674583 Adapter cache time: 0.05655602319166064 Engine time: 0.06601623073220253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.779267673846334,
    "estimated_duration": 3600.0603964860147,
    "input_throughput": 4404.062502805734,
    "output_throughput": 3856.2828039082124,
    "total_throughput": 8260.345306713945,
    "itl": 73.13740117499445,
    "ttft": 16620.074200440285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 63713,
    "finished_requests": 63421,
    "scheduler_time": 47.51991301096948
}
#Debug simulation 
Total elapsed time: 4.779374103993177. Arrivals time: 0.18936380604282022 Scheduler time: 4.374331769533455 Scheduler overhead time: 0.06325184414163232 Adapter cache time: 0.05640736687928438 Engine time: 0.06577662331983447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.785154344979674,
    "estimated_duration": 3600.0606029876403,
    "input_throughput": 4404.062250186079,
    "output_throughput": 3856.2825827095285,
    "total_throughput": 8260.344832895607,
    "itl": 73.13551574332601,
    "ttft": 16620.257615027655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 63713,
    "finished_requests": 63421,
    "scheduler_time": 47.51951369578373
}
#Debug simulation 
Total elapsed time: 4.785260810982436. Arrivals time: 0.19201760832220316 Scheduler time: 4.378420082386583 Scheduler overhead time: 0.06277023768052459 Adapter cache time: 0.05640439223498106 Engine time: 0.06562466733157635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.788052836898714,
    "estimated_duration": 3600.0139758693217,
    "input_throughput": 4403.906236550537,
    "output_throughput": 3856.2455848932314,
    "total_throughput": 8260.15182144377,
    "itl": 73.13815303228571,
    "ttft": 16733.564467244007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 63713,
    "finished_requests": 63418,
    "scheduler_time": 47.51929319842861
}
#Debug simulation 
Total elapsed time: 4.7881968300789595. Arrivals time: 0.17689411342144012 Scheduler time: 4.396034436766058 Scheduler overhead time: 0.06293462449684739 Adapter cache time: 0.05636856937780976 Engine time: 0.06565459072589874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.524196900893003,
    "estimated_duration": 3600.0603099703785,
    "input_throughput": 4202.4187645135535,
    "output_throughput": 3707.921770929953,
    "total_throughput": 7910.340535443506,
    "itl": 60.180444599876836,
    "ttft": 14063.862976430093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 60841,
    "finished_requests": 60605,
    "scheduler_time": 43.350709721513425
}
#Debug simulation 
Total elapsed time: 4.524326365906745. Arrivals time: 0.16674635279923677 Scheduler time: 4.123372528236359 Scheduler overhead time: 0.07000272441655397 Adapter cache time: 0.05785500118508935 Engine time: 0.07259026449173689 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.555972300935537,
    "estimated_duration": 3600.061748792291,
    "input_throughput": 4202.417084950083,
    "output_throughput": 3707.9202890000674,
    "total_throughput": 7910.337373950151,
    "itl": 60.18130518744558,
    "ttft": 14063.891330378685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 60841,
    "finished_requests": 60605,
    "scheduler_time": 43.350858668349765
}
#Debug simulation 
Total elapsed time: 4.556089460849762. Arrivals time: 0.18331276392564178 Scheduler time: 4.138062619138509 Scheduler overhead time: 0.07049839850515127 Adapter cache time: 0.05753081385046244 Engine time: 0.07300991378724575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.577216465957463,
    "estimated_duration": 3600.059918994254,
    "input_throughput": 4202.419220907458,
    "output_throughput": 3707.922173620162,
    "total_throughput": 7910.341394527621,
    "itl": 60.1811999690622,
    "ttft": 14063.913116759297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 60841,
    "finished_requests": 60605,
    "scheduler_time": 43.3507776902392
}
#Debug simulation 
Total elapsed time: 4.577332695946097. Arrivals time: 0.18381626624614 Scheduler time: 4.158898586872965 Scheduler overhead time: 0.07085577305406332 Adapter cache time: 0.05734696378931403 Engine time: 0.07258527167141438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.557285068091005,
    "estimated_duration": 3600.0610284616478,
    "input_throughput": 4202.417925805219,
    "output_throughput": 3707.9210309121036,
    "total_throughput": 7910.338956717322,
    "itl": 60.18024698796983,
    "ttft": 14063.936730641415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 60841,
    "finished_requests": 60605,
    "scheduler_time": 43.35066510570011
}
#Debug simulation 
Total elapsed time: 4.557394224219024. Arrivals time: 0.1702734879218042 Scheduler time: 4.155102237593383 Scheduler overhead time: 0.06969624292105436 Adapter cache time: 0.05728221172466874 Engine time: 0.07146060187369585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.533955168910325,
    "estimated_duration": 3600.0626734509765,
    "input_throughput": 4202.416005579581,
    "output_throughput": 3707.9193366386753,
    "total_throughput": 7910.335342218256,
    "itl": 60.181132626075204,
    "ttft": 14063.853184739874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 60841,
    "finished_requests": 60605,
    "scheduler_time": 43.350907287995945
}
#Debug simulation 
Total elapsed time: 4.534080738201737. Arrivals time: 0.1715378174558282 Scheduler time: 4.13039963459596 Scheduler overhead time: 0.06977347936481237 Adapter cache time: 0.05732541251927614 Engine time: 0.07147705601528287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.520400719251484,
    "estimated_duration": 3600.062158844951,
    "input_throughput": 4202.416606288264,
    "output_throughput": 3707.919866662199,
    "total_throughput": 7910.336472950463,
    "itl": 60.179690499735564,
    "ttft": 14063.908174198341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 60841,
    "finished_requests": 60605,
    "scheduler_time": 43.35053242004571
}
#Debug simulation 
Total elapsed time: 4.5205134390853345. Arrivals time: 0.17727871797978878 Scheduler time: 4.1109260157682 Scheduler overhead time: 0.07041849009692669 Adapter cache time: 0.057209608145058155 Engine time: 0.07128331158310175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.508986829780042,
    "estimated_duration": 3600.062178910505,
    "input_throughput": 4202.416582865386,
    "output_throughput": 3707.9198459954823,
    "total_throughput": 7910.336428860868,
    "itl": 60.180903226231266,
    "ttft": 14063.893844340293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 60841,
    "finished_requests": 60605,
    "scheduler_time": 43.35085433671709
}
#Debug simulation 
Total elapsed time: 4.509092262946069. Arrivals time: 0.1764795510098338 Scheduler time: 4.101418792735785 Scheduler overhead time: 0.06965399300679564 Adapter cache time: 0.056735364720225334 Engine time: 0.07141125993803144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.373209539800882,
    "estimated_duration": 3600.0560721283377,
    "input_throughput": 4114.5450801945035,
    "output_throughput": 3590.3188008842844,
    "total_throughput": 7704.863881078788,
    "itl": 53.58705029852455,
    "ttft": 13968.216789689937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 59397,
    "finished_requests": 59168,
    "scheduler_time": 40.35646811552879
}
#Debug simulation 
Total elapsed time: 4.373315506149083. Arrivals time: 0.16281140828505158 Scheduler time: 3.9746826509945095 Scheduler overhead time: 0.073088763281703 Adapter cache time: 0.054064763244241476 Engine time: 0.07391296792775393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.371022054925561,
    "estimated_duration": 3600.056065356215,
    "input_throughput": 4114.545087934439,
    "output_throughput": 3590.3188076380898,
    "total_throughput": 7704.863895572529,
    "itl": 53.58747959843068,
    "ttft": 13968.221710404161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 59397,
    "finished_requests": 59168,
    "scheduler_time": 40.35662511100627
}
#Debug simulation 
Total elapsed time: 4.371115610934794. Arrivals time: 0.1638198597356677 Scheduler time: 3.969880595803261 Scheduler overhead time: 0.07340614451095462 Adapter cache time: 0.05446633789688349 Engine time: 0.07435946818441153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.360244838986546,
    "estimated_duration": 3600.0568857754843,
    "input_throughput": 4114.544150268124,
    "output_throughput": 3590.317989438038,
    "total_throughput": 7704.862139706162,
    "itl": 53.5875073837346,
    "ttft": 13968.212114308062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 59397,
    "finished_requests": 59168,
    "scheduler_time": 40.356649338879535
}
#Debug simulation 
Total elapsed time: 4.360422936268151. Arrivals time: 0.1633514128625393 Scheduler time: 3.959867595694959 Scheduler overhead time: 0.07314443169161677 Adapter cache time: 0.05433043232187629 Engine time: 0.07464533671736717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.394987739622593,
    "estimated_duration": 3600.014738406515,
    "input_throughput": 4114.561488311154,
    "output_throughput": 3590.2544681583768,
    "total_throughput": 7704.815956469531,
    "itl": 53.58690168618003,
    "ttft": 13968.226524492024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 59397,
    "finished_requests": 59167,
    "scheduler_time": 40.35605875593062
}
#Debug simulation 
Total elapsed time: 4.395092403981835. Arrivals time: 0.1725826459005475 Scheduler time: 3.9856926035135984 Scheduler overhead time: 0.07319808844476938 Adapter cache time: 0.05450966628268361 Engine time: 0.073800896294415 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.333328357897699,
    "estimated_duration": 3600.0130976932387,
    "input_throughput": 4114.563363530904,
    "output_throughput": 3590.256104424138,
    "total_throughput": 7704.819467955042,
    "itl": 53.58732443737309,
    "ttft": 13968.307802098298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 59397,
    "finished_requests": 59167,
    "scheduler_time": 40.35621575140796
}
#Debug simulation 
Total elapsed time: 4.3335156929679215. Arrivals time: 0.16960069397464395 Scheduler time: 3.930254900828004 Scheduler overhead time: 0.07226023357361555 Adapter cache time: 0.05375796556472778 Engine time: 0.07296584779396653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.358514710795134,
    "estimated_duration": 3600.0551067553965,
    "input_throughput": 4114.546183530527,
    "output_throughput": 3590.319763646386,
    "total_throughput": 7704.865947176912,
    "itl": 53.58702896161513,
    "ttft": 13967.999857502224,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 59397,
    "finished_requests": 59168,
    "scheduler_time": 40.35650819483478
}
#Debug simulation 
Total elapsed time: 4.358705746941268. Arrivals time: 0.16203636582940817 Scheduler time: 3.961122313980013 Scheduler overhead time: 0.0725513156503439 Adapter cache time: 0.05405300622805953 Engine time: 0.07382612070068717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.346589487046003,
    "estimated_duration": 3600.01275790492,
    "input_throughput": 4114.563751885241,
    "output_throughput": 3590.256443291572,
    "total_throughput": 7704.820195176812,
    "itl": 53.58728569953328,
    "ttft": 13968.257496672775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 59397,
    "finished_requests": 59167,
    "scheduler_time": 40.356215669458145
}
#Debug simulation 
Total elapsed time: 4.346682585775852. Arrivals time: 0.15820737089961767 Scheduler time: 3.9543293709866703 Scheduler overhead time: 0.07221932709217072 Adapter cache time: 0.05387953529134393 Engine time: 0.07341594668105245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.351570668164641,
    "estimated_duration": 3600.023097967625,
    "input_throughput": 4085.8907289522845,
    "output_throughput": 3562.971306278922,
    "total_throughput": 7648.862035231206,
    "itl": 51.77757741189821,
    "ttft": 13028.271540911397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.545350847968784
}
#Debug simulation 
Total elapsed time: 4.351678301114589. Arrivals time: 0.15752337407320738 Scheduler time: 3.9594809729605913 Scheduler overhead time: 0.07369017461314797 Adapter cache time: 0.05093148583546281 Engine time: 0.0745656038634479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.3189427559264,
    "estimated_duration": 3599.9954896812305,
    "input_throughput": 4085.922063558604,
    "output_throughput": 3562.9986306276664,
    "total_throughput": 7648.92069418627,
    "itl": 51.951960444631794,
    "ttft": 13028.776447859265,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.58847545854383
}
#Debug simulation 
Total elapsed time: 4.319078698754311. Arrivals time: 0.1601157197728753 Scheduler time: 3.925205480773002 Scheduler overhead time: 0.07362265652045608 Adapter cache time: 0.049858667422086 Engine time: 0.07476101722568274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.371330049820244,
    "estimated_duration": 3600.012601575267,
    "input_throughput": 4085.902641997312,
    "output_throughput": 3562.9816946716664,
    "total_throughput": 7648.884336668978,
    "itl": 51.95216781554474,
    "ttft": 13028.740297286347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.58875843120732
}
#Debug simulation 
Total elapsed time: 4.371426757890731. Arrivals time: 0.17140324506908655 Scheduler time: 3.9654964306391776 Scheduler overhead time: 0.07414176687598228 Adapter cache time: 0.04993652272969484 Engine time: 0.07477154117077589 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.324552763719112,
    "estimated_duration": 3600.0221969712297,
    "input_throughput": 4085.8917515495395,
    "output_throughput": 3562.972198002397,
    "total_throughput": 7648.8639495519365,
    "itl": 51.94760327238008,
    "ttft": 13028.579572009745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.587687352284824
}
#Debug simulation 
Total elapsed time: 4.324697783682495. Arrivals time: 0.16399865923449397 Scheduler time: 3.9281526478007436 Scheduler overhead time: 0.07364226086065173 Adapter cache time: 0.04962111497297883 Engine time: 0.07390849152579904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.3626866191625595,
    "estimated_duration": 3600.02424035912,
    "input_throughput": 4085.889432381343,
    "output_throughput": 3562.970175645391,
    "total_throughput": 7648.859608026734,
    "itl": 51.78196649411413,
    "ttft": 13028.332029669342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.54652768003695
}
#Debug simulation 
Total elapsed time: 4.362806854303926. Arrivals time: 0.15861108247190714 Scheduler time: 3.9703386346809566 Scheduler overhead time: 0.07345285871997476 Adapter cache time: 0.05050773732364178 Engine time: 0.07428381871432066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.331792638171464,
    "estimated_duration": 3600.0241327816157,
    "input_throughput": 4085.889554477688,
    "output_throughput": 3562.970282115633,
    "total_throughput": 7648.85983659332,
    "itl": 51.77790819390912,
    "ttft": 13028.36958971201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.54539121409958
}
#Debug simulation 
Total elapsed time: 4.331883045844734. Arrivals time: 0.1565634231083095 Scheduler time: 3.9413767410442233 Scheduler overhead time: 0.07358144177123904 Adapter cache time: 0.05056223599240184 Engine time: 0.07418637350201607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.338842544239014,
    "estimated_duration": 3600.026682876323,
    "input_throughput": 4085.8866602198823,
    "output_throughput": 3562.96775826999,
    "total_throughput": 7648.854418489872,
    "itl": 51.781753637065194,
    "ttft": 13028.36584811293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 58689,
    "finished_requests": 58478,
    "scheduler_time": 39.54656012045121
}
#Debug simulation 
Total elapsed time: 4.338982142042369. Arrivals time: 0.15870557958260179 Scheduler time: 3.9464896861463785 Scheduler overhead time: 0.07378259347751737 Adapter cache time: 0.050385667476803064 Engine time: 0.07417149003595114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.382911735214293,
    "estimated_duration": 3599.276020304583,
    "input_throughput": 4038.2404455799474,
    "output_throughput": 3563.1165622342946,
    "total_throughput": 7601.357007814242,
    "itl": 50.85759250814448,
    "ttft": 11991.907892205494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 58348,
    "finished_requests": 58155,
    "scheduler_time": 39.294589938904544
}
#Debug simulation 
Total elapsed time: 4.383003228344023. Arrivals time: 0.16850926168262959 Scheduler time: 3.980125244706869 Scheduler overhead time: 0.07480567693710327 Adapter cache time: 0.04904418531805277 Engine time: 0.07406781567260623 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.354014864191413,
    "estimated_duration": 3599.2760203894763,
    "input_throughput": 4038.240445484701,
    "output_throughput": 3563.1165621502546,
    "total_throughput": 7601.357007634955,
    "itl": 50.85826968648296,
    "ttft": 11991.816917410375,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 58348,
    "finished_requests": 58155,
    "scheduler_time": 39.294743723560046
}
#Debug simulation 
Total elapsed time: 4.35411716485396. Arrivals time: 0.17256102664396167 Scheduler time: 3.9464047169312835 Scheduler overhead time: 0.07488772924989462 Adapter cache time: 0.0483706402592361 Engine time: 0.07545177405700088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.29195449501276,
    "estimated_duration": 3599.2762425032797,
    "input_throughput": 4038.2401962821154,
    "output_throughput": 3563.1163422678896,
    "total_throughput": 7601.356538550005,
    "itl": 50.85822118909804,
    "ttft": 11991.83929727956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 58348,
    "finished_requests": 58155,
    "scheduler_time": 39.29475177220118
}
#Debug simulation 
Total elapsed time: 4.292074759956449. Arrivals time: 0.15951422648504376 Scheduler time: 3.899860175792128 Scheduler overhead time: 0.0742104584351182 Adapter cache time: 0.048012157902121544 Engine time: 0.0744863236322999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.290959605947137,
    "estimated_duration": 3599.289362080478,
    "input_throughput": 4038.38773095982,
    "output_throughput": 3563.2333802100234,
    "total_throughput": 7601.621111169843,
    "itl": 50.857587878816275,
    "ttft": 11930.241668983066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 58348,
    "finished_requests": 58156,
    "scheduler_time": 39.2947560628589
}
#Debug simulation 
Total elapsed time: 4.29105086484924. Arrivals time: 0.1548830745741725 Scheduler time: 3.9038265608251095 Scheduler overhead time: 0.07432102179154754 Adapter cache time: 0.04809732409194112 Engine time: 0.07425493327900767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.3443912379443645,
    "estimated_duration": 3599.29013542545,
    "input_throughput": 4038.3868632701565,
    "output_throughput": 3563.2326146122205,
    "total_throughput": 7601.619477882377,
    "itl": 50.85820296560922,
    "ttft": 11930.288602287608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 58348,
    "finished_requests": 58156,
    "scheduler_time": 39.29492189998856
}
#Debug simulation 
Total elapsed time: 4.344478217884898. Arrivals time: 0.1570677114650607 Scheduler time: 3.9540733662433922 Scheduler overhead time: 0.07480880245566368 Adapter cache time: 0.04838340915739536 Engine time: 0.07426289841532707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.3058255398646,
    "estimated_duration": 3599.2757533443887,
    "input_throughput": 4038.2407450983865,
    "output_throughput": 3563.116826512543,
    "total_throughput": 7601.357571610929,
    "itl": 50.85755870256414,
    "ttft": 11991.850169389147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 58348,
    "finished_requests": 58155,
    "scheduler_time": 39.29461012196978
}
#Debug simulation 
Total elapsed time: 4.305927954148501. Arrivals time: 0.15683096880093217 Scheduler time: 3.9159218962304294 Scheduler overhead time: 0.07420527841895819 Adapter cache time: 0.04843246191740036 Engine time: 0.07451810827478766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.366833847947419,
    "estimated_duration": 3599.2893819858105,
    "input_throughput": 4038.38770862612,
    "output_throughput": 3563.233360504093,
    "total_throughput": 7601.621069130213,
    "itl": 50.858070368348564,
    "ttft": 11930.230093472193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 58348,
    "finished_requests": 58156,
    "scheduler_time": 39.29490171692327
}
#Debug simulation 
Total elapsed time: 4.366927712690085. Arrivals time: 0.1676453733816743 Scheduler time: 3.965355104301125 Scheduler overhead time: 0.07443747110664845 Adapter cache time: 0.04847268294543028 Engine time: 0.07482254272326827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.104523758869618,
    "estimated_duration": 3600.0242920690907,
    "input_throughput": 3799.8246373326047,
    "output_throughput": 3335.067495641659,
    "total_throughput": 7134.892132974264,
    "itl": 46.567193102340084,
    "ttft": 11000.648614520103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 55037,
    "finished_requests": 54870,
    "scheduler_time": 34.804857869355914
}
#Debug simulation 
Total elapsed time: 4.104618423152715. Arrivals time: 0.1602025581523776 Scheduler time: 3.678793968167156 Scheduler overhead time: 0.07980567496269941 Adapter cache time: 0.06590784015133977 Engine time: 0.08133310126140714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.056929850950837,
    "estimated_duration": 3600.012352821206,
    "input_throughput": 3799.8372392472143,
    "output_throughput": 3335.078556214135,
    "total_throughput": 7134.915795461349,
    "itl": 46.92010003787179,
    "ttft": 11001.10355053394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 55037,
    "finished_requests": 54870,
    "scheduler_time": 34.90898953085899
}
#Debug simulation 
Total elapsed time: 4.057049400638789. Arrivals time: 0.15031227050349116 Scheduler time: 3.6484033055603504 Scheduler overhead time: 0.07823405554518104 Adapter cache time: 0.06429591216146946 Engine time: 0.07776473136618733 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.080369983799756,
    "estimated_duration": 3600.012102234591,
    "input_throughput": 3799.837503743089,
    "output_throughput": 3335.078788359479,
    "total_throughput": 7134.916292102568,
    "itl": 46.92010587446333,
    "ttft": 11001.086799386678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 55037,
    "finished_requests": 54870,
    "scheduler_time": 34.90899757949991
}
#Debug simulation 
Total elapsed time: 4.080470024142414. Arrivals time: 0.14971921127289534 Scheduler time: 3.6701183491386473 Scheduler overhead time: 0.07864666590467095 Adapter cache time: 0.0641428492963314 Engine time: 0.07956997398287058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.096816839184612,
    "estimated_duration": 3599.9995115561737,
    "input_throughput": 3799.850793337128,
    "output_throughput": 3335.090452501206,
    "total_throughput": 7134.941245838334,
    "itl": 46.571307242368974,
    "ttft": 11000.472811778238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 55037,
    "finished_requests": 54870,
    "scheduler_time": 34.80591977882698
}
#Debug simulation 
Total elapsed time: 4.096905957907438. Arrivals time: 0.15862343972548842 Scheduler time: 3.6741257831454277 Scheduler overhead time: 0.07955963723361492 Adapter cache time: 0.06569381710141897 Engine time: 0.08028792217373848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_96_slots_96_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.132355129811913,
    "estimated_duration": 3600.01275134779,
    "input_throughput": 3799.8368185997724,
    "output_throughput": 3335.0781870161472,
    "total_throughput": 7134.91500561592,
    "itl": 46.920040190668495,
    "ttft": 11001.078836787507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970503,
    "arrivals": 55037,
    "finished_requests": 54870,
    "scheduler_time": 34.909001583333264
}
#Debug simulation 
Total elapsed time: 4.132480308879167. Arrivals time: 0.1656920681707561 Scheduler time: 3.7033673031255603 Scheduler overhead time: 0.07942899968475103 Adapter cache time: 0.06519123446196318 Engine time: 0.08028972428292036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_96_slots_96_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_96_slots_96_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.109741213265806,
    "estimated_duration": 3600.023853722562,
    "input_throughput": 3799.8251000073,
    "output_throughput": 3335.067901726541,
    "total_throughput": 7134.893001733841,
    "itl": 46.56705062186318,
    "ttft": 11000.573023926054,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 55037,
    "finished_requests": 54870,
    "scheduler_time": 34.80486203708876
}
#Debug simulation 
Total elapsed time: 4.109841584227979. Arrivals time: 0.15439839474856853 Scheduler time: 3.692309582605958 Scheduler overhead time: 0.07910683378577232 Adapter cache time: 0.06593411229550838 Engine time: 0.07960571022704244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_96_slots_96_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_96_slots_96_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.0737451440654695,
    "estimated_duration": 3599.9937692686226,
    "input_throughput": 3799.856854413148,
    "output_throughput": 3335.095772246076,
    "total_throughput": 7134.952626659224,
    "itl": 46.57142228411207,
    "ttft": 11000.518523224107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 55037,
    "finished_requests": 54870,
    "scheduler_time": 34.80599988197684
}
#Debug simulation 
Total elapsed time: 4.0738424570299685. Arrivals time: 0.14769390365108848 Scheduler time: 3.6621757596731186 Scheduler overhead time: 0.07918876269832253 Adapter cache time: 0.06695078639313579 Engine time: 0.07928905123844743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.994928406085819,
    "estimated_duration": 3600.0298946220546,
    "input_throughput": 3698.934006046079,
    "output_throughput": 3239.032269542911,
    "total_throughput": 6937.96627558899,
    "itl": 42.89895825527508,
    "ttft": 8216.236832627335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.17230696628101
}
#Debug simulation 
Total elapsed time: 3.9950428688898683. Arrivals time: 0.14550400152802467 Scheduler time: 3.580104451160878 Scheduler overhead time: 0.0846030623652041 Adapter cache time: 0.0597318671643734 Engine time: 0.08392501855269074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9971899511292577,
    "estimated_duration": 3600.009921609935,
    "input_throughput": 3698.954527893335,
    "output_throughput": 3239.0502398352664,
    "total_throughput": 6938.004767728602,
    "itl": 42.899329084482325,
    "ttft": 8216.317072001786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.172197797438685
}
#Debug simulation 
Total elapsed time: 3.9972899639979005. Arrivals time: 0.15603400906547904 Scheduler time: 3.5734224221669137 Scheduler overhead time: 0.08359139086678624 Adapter cache time: 0.05974432127550244 Engine time: 0.08376555284485221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.005756570957601,
    "estimated_duration": 3600.0099282156343,
    "input_throughput": 3698.9545211060813,
    "output_throughput": 3239.0502338918964,
    "total_throughput": 6938.004754997978,
    "itl": 42.89928200196891,
    "ttft": 8216.327768229963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.17219375263065
}
#Debug simulation 
Total elapsed time: 4.005851989146322. Arrivals time: 0.16038600681349635 Scheduler time: 3.5758049124851823 Scheduler overhead time: 0.08399725193157792 Adapter cache time: 0.05970908375456929 Engine time: 0.08485262980684638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.063939713872969,
    "estimated_duration": 3600.0314328000245,
    "input_throughput": 3698.9324256102113,
    "output_throughput": 3239.030885608305,
    "total_throughput": 6937.9633112185165,
    "itl": 42.898945676066916,
    "ttft": 8216.260101289094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.17229879471509
}
#Debug simulation 
Total elapsed time: 4.0640400210395455. Arrivals time: 0.14817247772589326 Scheduler time: 3.6467000218108296 Scheduler overhead time: 0.0841463073156774 Adapter cache time: 0.059814094100147486 Engine time: 0.0840070410631597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.070582950022072,
    "estimated_duration": 3600.029960729506,
    "input_throughput": 3698.93393812245,
    "output_throughput": 3239.0322100644703,
    "total_throughput": 6937.96614818692,
    "itl": 42.89926419383259,
    "ttft": 8216.262236991593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.17244444877949
}
#Debug simulation 
Total elapsed time: 4.070670013781637. Arrivals time: 0.1469106450676918 Scheduler time: 3.6535756373777986 Scheduler overhead time: 0.0844439584761858 Adapter cache time: 0.060046407394111156 Engine time: 0.08471764763817191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.9821700151078403,
    "estimated_duration": 3600.03669799115,
    "input_throughput": 3698.9270157803085,
    "output_throughput": 3239.0261484019643,
    "total_throughput": 6937.953164182272,
    "itl": 42.898586829932384,
    "ttft": 8216.20598300022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.17223495274731
}
#Debug simulation 
Total elapsed time: 3.9822672163136303. Arrivals time: 0.14695190824568272 Scheduler time: 3.56512844376266 Scheduler overhead time: 0.08436304237693548 Adapter cache time: 0.059630705043673515 Engine time: 0.08552400721237063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.007198364008218,
    "estimated_duration": 3600.0299589026613,
    "input_throughput": 3698.9339399994838,
    "output_throughput": 3239.032211708126,
    "total_throughput": 6937.966151707609,
    "itl": 42.899165090476934,
    "ttft": 8216.247137881795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 53479,
    "finished_requests": 53358,
    "scheduler_time": 32.17243231435537
}
#Debug simulation 
Total elapsed time: 4.0072983666323125. Arrivals time: 0.15834851143881679 Scheduler time: 3.5783539302647114 Scheduler overhead time: 0.08467204077169299 Adapter cache time: 0.059998106211423874 Engine time: 0.08475152775645256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.9720808188430965,
    "estimated_duration": 3600.0213947439183,
    "input_throughput": 3669.610136008572,
    "output_throughput": 3211.572858116979,
    "total_throughput": 6881.182994125552,
    "itl": 42.23944013541977,
    "ttft": 12542.23563039865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 52821,
    "finished_requests": 52637,
    "scheduler_time": 31.578989341593847
}
#Debug simulation 
Total elapsed time: 3.972264150157571. Arrivals time: 0.15676731895655394 Scheduler time: 3.5488192555494606 Scheduler overhead time: 0.08542844234034419 Adapter cache time: 0.054933950770646334 Engine time: 0.08463487774133682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.956790725234896,
    "estimated_duration": 3600.022081004224,
    "input_throughput": 3669.6094364829255,
    "output_throughput": 3211.5722459054646,
    "total_throughput": 6881.18168238839,
    "itl": 42.23102452600777,
    "ttft": 12542.285295225138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 52821,
    "finished_requests": 52637,
    "scheduler_time": 31.57579094388559
}
#Debug simulation 
Total elapsed time: 3.9568948103114963. Arrivals time: 0.1504074577242136 Scheduler time: 3.5405054022558033 Scheduler overhead time: 0.0847783936187625 Adapter cache time: 0.05498039163649082 Engine time: 0.08486554678529501 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9711212338879704,
    "estimated_duration": 3600.023880548633,
    "input_throughput": 3669.607602154776,
    "output_throughput": 3211.5706405364253,
    "total_throughput": 6881.178242691201,
    "itl": 42.23107633181686,
    "ttft": 12542.254574207525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 52821,
    "finished_requests": 52637,
    "scheduler_time": 31.575799074476524
}
#Debug simulation 
Total elapsed time: 3.9712371258065104. Arrivals time: 0.1479058642871678 Scheduler time: 3.5553676802664995 Scheduler overhead time: 0.08553479192778468 Adapter cache time: 0.055055176839232445 Engine time: 0.0859637726098299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.9718607109971344,
    "estimated_duration": 3600.034974618641,
    "input_throughput": 3669.6937927386302,
    "output_throughput": 3211.62268742258,
    "total_throughput": 6881.31648016121,
    "itl": 41.91268668977896,
    "ttft": 12541.565064336923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 52821,
    "finished_requests": 52638,
    "scheduler_time": 31.459837346927987
}
#Debug simulation 
Total elapsed time: 3.971962532028556. Arrivals time: 0.14228561148047447 Scheduler time: 3.5615616575814784 Scheduler overhead time: 0.08504019444808364 Adapter cache time: 0.05587921338155866 Engine time: 0.08554512821137905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9626875650137663,
    "estimated_duration": 3600.045105246835,
    "input_throughput": 3669.585967338656,
    "output_throughput": 3211.5517061576584,
    "total_throughput": 6881.137673496314,
    "itl": 42.23117850665741,
    "ttft": 12610.203815986097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 52821,
    "finished_requests": 52637,
    "scheduler_time": 31.57607912314204
}
#Debug simulation 
Total elapsed time: 3.962828549090773. Arrivals time: 0.14631800772622228 Scheduler time: 3.548425124026835 Scheduler overhead time: 0.08619893481954932 Adapter cache time: 0.05507519096136093 Engine time: 0.08518802467733622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.9561004410497844,
    "estimated_duration": 3600.040747800986,
    "input_throughput": 3669.5904089611986,
    "output_throughput": 3211.5555933810624,
    "total_throughput": 6881.146002342261,
    "itl": 42.238985298940435,
    "ttft": 12610.192433065826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 52821,
    "finished_requests": 52637,
    "scheduler_time": 31.57906706790751
}
#Debug simulation 
Total elapsed time: 3.956196832936257. Arrivals time: 0.14503889437764883 Scheduler time: 3.545618610922247 Scheduler overhead time: 0.08486168785020709 Adapter cache time: 0.05467800237238407 Engine time: 0.0848631882108748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9456495041958988,
    "estimated_duration": 3600.0132206768108,
    "input_throughput": 3669.6184681000595,
    "output_throughput": 3211.5801502046615,
    "total_throughput": 6881.198618304721,
    "itl": 42.231609238586096,
    "ttft": 12474.364672303429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623256,
    "arrivals": 52821,
    "finished_requests": 52637,
    "scheduler_time": 31.575835641648652
}
#Debug simulation 
Total elapsed time: 3.945750941056758. Arrivals time: 0.15575460763648152 Scheduler time: 3.5240060538053513 Scheduler overhead time: 0.08475110214203596 Adapter cache time: 0.054928913712501526 Engine time: 0.08506173128262162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.949770983774215,
    "estimated_duration": 3600.032232435748,
    "input_throughput": 3635.276340608035,
    "output_throughput": 3209.8457052373737,
    "total_throughput": 6845.122045845408,
    "itl": 41.28969459347787,
    "ttft": 9330.530063543747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 52471,
    "finished_requests": 52336,
    "scheduler_time": 31.158409793872284
}
#Debug simulation 
Total elapsed time: 3.9498640657402575. Arrivals time: 0.15638013510033488 Scheduler time: 3.5243353927507997 Scheduler overhead time: 0.08651802921667695 Adapter cache time: 0.05344904540106654 Engine time: 0.08717904193326831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.947996878065169,
    "estimated_duration": 3600.041043678811,
    "input_throughput": 3635.2674431251867,
    "output_throughput": 3209.837849012858,
    "total_throughput": 6845.105292138045,
    "itl": 41.294095161966254,
    "ttft": 9330.557112425642,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 52471,
    "finished_requests": 52336,
    "scheduler_time": 31.16003730638266
}
#Debug simulation 
Total elapsed time: 3.9481658576987684. Arrivals time: 0.1468768040649593 Scheduler time: 3.5342879686504602 Scheduler overhead time: 0.0865214872173965 Adapter cache time: 0.05284125776961446 Engine time: 0.08569194236770272 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.017698104958981,
    "estimated_duration": 3600.0121870064695,
    "input_throughput": 3635.29658239362,
    "output_throughput": 3209.863578158835,
    "total_throughput": 6845.160160552455,
    "itl": 41.29421749500173,
    "ttft": 9330.560448787575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3137616491317753,
    "arrivals": 52471,
    "finished_requests": 52336,
    "scheduler_time": 31.159882769691073
}
#Debug simulation 
Total elapsed time: 4.01780782872811. Arrivals time: 0.14484287286177278 Scheduler time: 3.6032456159591675 Scheduler overhead time: 0.08629534160718322 Adapter cache time: 0.05334213329479098 Engine time: 0.08783451467752457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.9294495987705886,
    "estimated_duration": 3600.0322271365026,
    "input_throughput": 3635.2763459591597,
    "output_throughput": 3209.8457099622647,
    "total_throughput": 6845.122055921424,
    "itl": 41.2896655665653,
    "ttft": 9330.529917636168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 52471,
    "finished_requests": 52336,
    "scheduler_time": 31.158389610806967
}
#Debug simulation 
Total elapsed time: 3.929546756669879. Arrivals time: 0.1423026784323156 Scheduler time: 3.5196184585802257 Scheduler overhead time: 0.08621916733682156 Adapter cache time: 0.053074867464601994 Engine time: 0.08618113771080971 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9504405548796058,
    "estimated_duration": 3600.017734846021,
    "input_throughput": 3635.2909801872847,
    "output_throughput": 3209.858631569839,
    "total_throughput": 6845.149611757123,
    "itl": 41.2940469805536,
    "ttft": 9330.577498766426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970505,
    "arrivals": 52471,
    "finished_requests": 52336,
    "scheduler_time": 31.15993606325687
}
#Debug simulation 
Total elapsed time: 3.950642484240234. Arrivals time: 0.1438845586962998 Scheduler time: 3.539834749419242 Scheduler overhead time: 0.0864199916832149 Adapter cache time: 0.05296132480725646 Engine time: 0.08543059648945928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.000407355837524,
    "estimated_duration": 3600.041024659524,
    "input_throughput": 3635.267462330578,
    "output_throughput": 3209.8378659706727,
    "total_throughput": 6845.105328301251,
    "itl": 41.29370396172819,
    "ttft": 9330.548257603896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 52471,
    "finished_requests": 52336,
    "scheduler_time": 31.159872303239005
}
#Debug simulation 
Total elapsed time: 4.000501809641719. Arrivals time: 0.15458926558494568 Scheduler time: 3.5768521963618696 Scheduler overhead time: 0.08684697048738599 Adapter cache time: 0.05336951231583953 Engine time: 0.08670087158679962 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9511542920954525,
    "estimated_duration": 3600.033560387439,
    "input_throughput": 3635.2749996562675,
    "output_throughput": 3209.844521215069,
    "total_throughput": 6845.119520871337,
    "itl": 41.28995341288658,
    "ttft": 9330.54906301036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 52471,
    "finished_requests": 52336,
    "scheduler_time": 31.158539268704413
}
#Debug simulation 
Total elapsed time: 3.9512453419156373. Arrivals time: 0.15593034820631146 Scheduler time: 3.5254348036833107 Scheduler overhead time: 0.0868840804323554 Adapter cache time: 0.053382548969238997 Engine time: 0.08703221520408988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.8486696230247617,
    "estimated_duration": 3599.9176880158752,
    "input_throughput": 3494.148502860027,
    "output_throughput": 3100.9781243505954,
    "total_throughput": 6595.126627210622,
    "itl": 38.845705085397896,
    "ttft": 10087.380122411874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 50642,
    "finished_requests": 50501,
    "scheduler_time": 28.60742411119106
}
#Debug simulation 
Total elapsed time: 3.8487746310420334. Arrivals time: 0.14386172499507666 Scheduler time: 3.427715036086738 Scheduler overhead time: 0.09022551169618964 Adapter cache time: 0.05275260750204325 Engine time: 0.09011262422427535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.84698250470683,
    "estimated_duration": 3599.90673347254,
    "input_throughput": 3494.159135580269,
    "output_throughput": 3100.9875606504106,
    "total_throughput": 6595.1466962306795,
    "itl": 38.84603301805231,
    "ttft": 10087.40375964779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 50642,
    "finished_requests": 50501,
    "scheduler_time": 28.607431366821015
}
#Debug simulation 
Total elapsed time: 3.847075656056404. Arrivals time: 0.13899494288489223 Scheduler time: 3.4322938346304 Scheduler overhead time: 0.08971415366977453 Adapter cache time: 0.052698574028909206 Engine time: 0.08975422009825706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.859206236898899,
    "estimated_duration": 3599.901657380658,
    "input_throughput": 3494.164062568423,
    "output_throughput": 3100.9919332414647,
    "total_throughput": 6595.155995809888,
    "itl": 38.84590893455029,
    "ttft": 10087.410066590324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 50642,
    "finished_requests": 50501,
    "scheduler_time": 28.607350470660183
}
#Debug simulation 
Total elapsed time: 3.859304590616375. Arrivals time: 0.13915794203057885 Scheduler time: 3.442251688335091 Scheduler overhead time: 0.09042083099484444 Adapter cache time: 0.05339925270527601 Engine time: 0.08996891556307673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.851208481937647,
    "estimated_duration": 3599.9181514183197,
    "input_throughput": 3494.148053072868,
    "output_throughput": 3100.9777251746186,
    "total_throughput": 6595.125778247487,
    "itl": 38.845781871699955,
    "ttft": 10087.480071169026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 50642,
    "finished_requests": 50501,
    "scheduler_time": 28.607411976766976
}
#Debug simulation 
Total elapsed time: 3.8513200599700212. Arrivals time: 0.13865791307762265 Scheduler time: 3.433767448645085 Scheduler overhead time: 0.08997435355558991 Adapter cache time: 0.05364384688436985 Engine time: 0.091279411688447 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.8626596950925887,
    "estimated_duration": 3599.9302773194986,
    "input_throughput": 3494.136283485478,
    "output_throughput": 3100.967279930807,
    "total_throughput": 6595.1035634162845,
    "itl": 38.86188001803122,
    "ttft": 10087.55618361548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 50642,
    "finished_requests": 50501,
    "scheduler_time": 28.614593846008148
}
#Debug simulation 
Total elapsed time: 3.8627534680999815. Arrivals time: 0.14944664109498262 Scheduler time: 3.4364500883966684 Scheduler overhead time: 0.09018240496516228 Adapter cache time: 0.052580833435058594 Engine time: 0.09019641578197479 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.8557844487950206,
    "estimated_duration": 3599.9022762447858,
    "input_throughput": 3494.1634618818966,
    "output_throughput": 3100.991400145697,
    "total_throughput": 6595.1548620275935,
    "itl": 38.84559462163839,
    "ttft": 10087.398630251131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 50642,
    "finished_requests": 50501,
    "scheduler_time": 28.60722904446916
}
#Debug simulation 
Total elapsed time: 3.8558865496888757. Arrivals time: 0.1519147576764226 Scheduler time: 3.4268916356377304 Scheduler overhead time: 0.09038476087152958 Adapter cache time: 0.05253061605617404 Engine time: 0.09003357589244843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.81287810113281,
    "estimated_duration": 3599.918026380687,
    "input_throughput": 3494.148174436743,
    "output_throughput": 3100.9778328823254,
    "total_throughput": 6595.126007319068,
    "itl": 38.845960537909704,
    "ttft": 10087.479632085766,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 50642,
    "finished_requests": 50501,
    "scheduler_time": 28.607568890294615
}
#Debug simulation 
Total elapsed time: 3.812967814039439. Arrivals time: 0.12836837954819202 Scheduler time: 3.4098833706229925 Scheduler overhead time: 0.08971169916912913 Adapter cache time: 0.052301288582384586 Engine time: 0.08905546041205525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.807628730777651,
    "estimated_duration": 3599.941303211864,
    "input_throughput": 3449.946250212258,
    "output_throughput": 3051.8442037368472,
    "total_throughput": 6501.7904539491055,
    "itl": 37.596958034519254,
    "ttft": 7777.2387295108865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 49929,
    "finished_requests": 49822,
    "scheduler_time": 27.339219849665273
}
#Debug simulation 
Total elapsed time: 3.807737975846976. Arrivals time: 0.15163599094375968 Scheduler time: 3.3766302429139614 Scheduler overhead time: 0.091694091912359 Adapter cache time: 0.04993030382320285 Engine time: 0.09284085547551513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.798310191836208,
    "estimated_duration": 3599.9391512137377,
    "input_throughput": 3449.948312546524,
    "output_throughput": 3051.846028090741,
    "total_throughput": 6501.794340637265,
    "itl": 37.59744384758753,
    "ttft": 7777.163089761295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 49929,
    "finished_requests": 49822,
    "scheduler_time": 27.339381723936487
}
#Debug simulation 
Total elapsed time: 3.7983993352390826. Arrivals time: 0.14354857569560409 Scheduler time: 3.3763244138099253 Scheduler overhead time: 0.09171228250488639 Adapter cache time: 0.04999923566356301 Engine time: 0.0918243583291769 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.8123052809387445,
    "estimated_duration": 3599.933894775808,
    "input_throughput": 3449.953349983237,
    "output_throughput": 3051.850484239017,
    "total_throughput": 6501.803834222254,
    "itl": 37.597383958565054,
    "ttft": 7777.160648720781,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 49929,
    "finished_requests": 49822,
    "scheduler_time": 27.339312962199777
}
#Debug simulation 
Total elapsed time: 3.812417047098279. Arrivals time: 0.1500103371217847 Scheduler time: 3.3828081861138344 Scheduler overhead time: 0.09230142273008823 Adapter cache time: 0.049857429694384336 Engine time: 0.09245613683015108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.786341480910778,
    "estimated_duration": 3599.9495709362914,
    "input_throughput": 3449.938326988801,
    "output_throughput": 3051.8371948034237,
    "total_throughput": 6501.775521792224,
    "itl": 37.5971165976074,
    "ttft": 7777.122484844022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 49929,
    "finished_requests": 49822,
    "scheduler_time": 27.339296782967857
}
#Debug simulation 
Total elapsed time: 3.786455255933106. Arrivals time: 0.14189084945246577 Scheduler time: 3.365866346284747 Scheduler overhead time: 0.09243008261546493 Adapter cache time: 0.05017588008195162 Engine time: 0.0911839259788394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.7799662249162793,
    "estimated_duration": 3599.938780188587,
    "input_throughput": 3449.948668113013,
    "output_throughput": 3051.846342627099,
    "total_throughput": 6501.795010740112,
    "itl": 37.597293846908755,
    "ttft": 7777.201179926435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705035,
    "arrivals": 49929,
    "finished_requests": 49822,
    "scheduler_time": 27.339365503729535
}
#Debug simulation 
Total elapsed time: 3.7801405820064247. Arrivals time: 0.13648421317338943 Scheduler time: 3.3642167933285236 Scheduler overhead time: 0.09186674887314439 Adapter cache time: 0.049871401861310005 Engine time: 0.09266796195879579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.806481961160898,
    "estimated_duration": 3599.9161999705843,
    "input_throughput": 3449.9703076703518,
    "output_throughput": 3051.8654851159513,
    "total_throughput": 6501.8357927863035,
    "itl": 37.5967648936035,
    "ttft": 7777.1156130859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 49929,
    "finished_requests": 49822,
    "scheduler_time": 27.338928746410843
}
#Debug simulation 
Total elapsed time: 3.806578889954835. Arrivals time: 0.13626592746004462 Scheduler time: 3.3902781871147454 Scheduler overhead time: 0.09226315189152956 Adapter cache time: 0.050495097413659096 Engine time: 0.09230000991374254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.8032377008348703,
    "estimated_duration": 3599.949489025063,
    "input_throughput": 3449.938405486759,
    "output_throughput": 3051.8372642432128,
    "total_throughput": 6501.775669729972,
    "itl": 37.59741587054639,
    "ttft": 7777.075134319891,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 49929,
    "finished_requests": 49822,
    "scheduler_time": 27.339474672571797
}
#Debug simulation 
Total elapsed time: 3.803344921208918. Arrivals time: 0.13801628863438964 Scheduler time: 3.3830935158766806 Scheduler overhead time: 0.09226456983014941 Adapter cache time: 0.0501366606913507 Engine time: 0.09468423621729016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.8064909391105175,
    "estimated_duration": 3600.0103071936783,
    "input_throughput": 3413.681337368139,
    "output_throughput": 3022.666067998726,
    "total_throughput": 6436.347405366864,
    "itl": 36.955751131885464,
    "ttft": 10148.510380853817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 49606,
    "finished_requests": 49467,
    "scheduler_time": 26.586424284883265
}
#Debug simulation 
Total elapsed time: 3.8066488169133663. Arrivals time: 0.14630500180646777 Scheduler time: 3.3807449438609183 Scheduler overhead time: 0.093685831874609 Adapter cache time: 0.047214449383318424 Engine time: 0.09285223251208663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.7594393333420157,
    "estimated_duration": 3600.0103100672372,
    "input_throughput": 3413.681334643309,
    "output_throughput": 3022.666065586008,
    "total_throughput": 6436.347400229317,
    "itl": 36.95598066653077,
    "ttft": 10148.49514519997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 49606,
    "finished_requests": 49467,
    "scheduler_time": 26.586604633273087
}
#Debug simulation 
Total elapsed time: 3.7595438212156296. Arrivals time: 0.14857407240197062 Scheduler time: 3.3314385637640953 Scheduler overhead time: 0.09330560266971588 Adapter cache time: 0.04693039786070585 Engine time: 0.0938037927262485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.778764102142304,
    "estimated_duration": 3600.0103076812,
    "input_throughput": 3413.68133690585,
    "output_throughput": 3022.666067589389,
    "total_throughput": 6436.347404495239,
    "itl": 36.955919285785676,
    "ttft": 10148.514386198918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 49606,
    "finished_requests": 49467,
    "scheduler_time": 26.586604592298183
}
#Debug simulation 
Total elapsed time: 3.7788871210068464. Arrivals time: 0.13871800806373358 Scheduler time: 3.3551798020489514 Scheduler overhead time: 0.0934720179066062 Adapter cache time: 0.04739892249926925 Engine time: 0.09840267105028033 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.7658493989147246,
    "estimated_duration": 3599.9984127791276,
    "input_throughput": 3413.692616190048,
    "output_throughput": 3022.6760549040346,
    "total_throughput": 6436.368671094083,
    "itl": 36.9558978923801,
    "ttft": 10148.465970436791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 49606,
    "finished_requests": 49467,
    "scheduler_time": 26.586475199415993
}
#Debug simulation 
Total elapsed time: 3.7659345348365605. Arrivals time: 0.13439299957826734 Scheduler time: 3.35199006088078 Scheduler overhead time: 0.09340289840474725 Adapter cache time: 0.04701084969565272 Engine time: 0.09355060383677483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.7484808512963355,
    "estimated_duration": 3600.0082028563475,
    "input_throughput": 3413.683332790557,
    "output_throughput": 3022.6678348583237,
    "total_throughput": 6436.351167648881,
    "itl": 36.95593439559602,
    "ttft": 10148.519308956798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 49606,
    "finished_requests": 49467,
    "scheduler_time": 26.586560058434817
}
#Debug simulation 
Total elapsed time: 3.748612250201404. Arrivals time: 0.13415602361783385 Scheduler time: 3.336802409030497 Scheduler overhead time: 0.09331406466662884 Adapter cache time: 0.046803107019513845 Engine time: 0.09185077669098973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.775888972915709,
    "estimated_duration": 3600.008838771223,
    "input_throughput": 3413.6827297887007,
    "output_throughput": 3022.6673009264564,
    "total_throughput": 6436.350030715157,
    "itl": 36.955754313684054,
    "ttft": 10148.51003343155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 49606,
    "finished_requests": 49467,
    "scheduler_time": 26.5864274957053
}
#Debug simulation 
Total elapsed time: 3.775978366844356. Arrivals time: 0.14131347415968776 Scheduler time: 3.356256491970271 Scheduler overhead time: 0.0931217884644866 Adapter cache time: 0.046946879010647535 Engine time: 0.09281059307977557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.797517893835902,
    "estimated_duration": 3599.998402741917,
    "input_throughput": 3413.6926257078167,
    "output_throughput": 3022.676063331604,
    "total_throughput": 6436.368689039421,
    "itl": 36.9562335785604,
    "ttft": 10148.445983444157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 49606,
    "finished_requests": 49467,
    "scheduler_time": 26.586648292175777
}
#Debug simulation 
Total elapsed time: 3.7976391669362783. Arrivals time: 0.14888414554297924 Scheduler time: 3.3675718172453344 Scheduler overhead time: 0.09385059820488095 Adapter cache time: 0.047238240484148264 Engine time: 0.09439171198755503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.7000580350868404,
    "estimated_duration": 3599.9656189303682,
    "input_throughput": 3339.087722613194,
    "output_throughput": 2967.7705653129046,
    "total_throughput": 6306.8582879260985,
    "itl": 35.52407616220246,
    "ttft": 9701.7260979723,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 48532,
    "finished_requests": 48402,
    "scheduler_time": 25.096300843288123
}
#Debug simulation 
Total elapsed time: 3.7001889520324767. Arrivals time: 0.1367192529141903 Scheduler time: 3.2808820442296565 Scheduler overhead time: 0.0958569529466331 Adapter cache time: 0.04350145813077688 Engine time: 0.09635020419955254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.7068767519667745,
    "estimated_duration": 3599.9659460058465,
    "input_throughput": 3339.087419239848,
    "output_throughput": 2967.7702956756384,
    "total_throughput": 6306.857714915486,
    "itl": 35.52427875839253,
    "ttft": 9701.723063212192,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3131949286907911,
    "arrivals": 48532,
    "finished_requests": 48402,
    "scheduler_time": 25.096473977022807
}
#Debug simulation 
Total elapsed time: 3.706993391737342. Arrivals time: 0.13678390020504594 Scheduler time: 3.287751409690827 Scheduler overhead time: 0.09637877671048045 Adapter cache time: 0.043697440065443516 Engine time: 0.09546665288507938 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.7361826333217323,
    "estimated_duration": 3599.9652231848013,
    "input_throughput": 3339.0880896803965,
    "output_throughput": 2967.7708915610688,
    "total_throughput": 6306.858981241466,
    "itl": 35.524258934173304,
    "ttft": 9701.73728211504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 48532,
    "finished_requests": 48402,
    "scheduler_time": 25.096461801623796
}
#Debug simulation 
Total elapsed time: 3.736270957160741. Arrivals time: 0.1334068956784904 Scheduler time: 3.318561766296625 Scheduler overhead time: 0.09613976767286658 Adapter cache time: 0.043787043541669846 Engine time: 0.09730217233300209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.7072758129797876,
    "estimated_duration": 3599.9372014571627,
    "input_throughput": 3339.114080971848,
    "output_throughput": 2967.793992538381,
    "total_throughput": 6306.908073510229,
    "itl": 35.52408798325156,
    "ttft": 9701.805237073942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3001198785007001,
    "arrivals": 48532,
    "finished_requests": 48402,
    "scheduler_time": 25.096134295097027
}
#Debug simulation 
Total elapsed time: 3.707367171999067. Arrivals time: 0.13176134740933776 Scheduler time: 3.293949298094958 Scheduler overhead time: 0.09591710055246949 Adapter cache time: 0.043593496549874544 Engine time: 0.09529289277270436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.715105509851128,
    "estimated_duration": 3599.937242140132,
    "input_throughput": 3339.114043236447,
    "output_throughput": 2967.7939589992766,
    "total_throughput": 6306.908002235723,
    "itl": 35.52441104962819,
    "ttft": 9701.806033793513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 48532,
    "finished_requests": 48402,
    "scheduler_time": 25.096279074200485
}
#Debug simulation 
Total elapsed time: 3.7152067269198596. Arrivals time: 0.13738721376284957 Scheduler time: 3.295434646308422 Scheduler overhead time: 0.09604768827557564 Adapter cache time: 0.043755860067903996 Engine time: 0.09563914034515619 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.7162543423473835,
    "estimated_duration": 3599.965638602135,
    "input_throughput": 3339.0877043669766,
    "output_throughput": 2967.7705490957246,
    "total_throughput": 6306.858253462701,
    "itl": 35.524119003132796,
    "ttft": 9701.73005229411,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 48532,
    "finished_requests": 48402,
    "scheduler_time": 25.096329197919566
}
#Debug simulation 
Total elapsed time: 3.7163510131649673. Arrivals time: 0.14344729064032435 Scheduler time: 3.290744659025222 Scheduler overhead time: 0.09600520972162485 Adapter cache time: 0.04359034728258848 Engine time: 0.09552995068952441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_96_slots_96_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.696484967134893,
    "estimated_duration": 3599.958489278329,
    "input_throughput": 3339.094335615444,
    "output_throughput": 2967.7764429283066,
    "total_throughput": 6306.870778543751,
    "itl": 35.5247299485154,
    "ttft": 9701.702419087493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 48532,
    "finished_requests": 48402,
    "scheduler_time": 25.09652576651647
}
#Debug simulation 
Total elapsed time: 3.6966228587552905. Arrivals time: 0.13729938585311174 Scheduler time: 3.276990761049092 Scheduler overhead time: 0.09548337198793888 Adapter cache time: 0.04381169145926833 Engine time: 0.09600678272545338 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.6560462238267064,
    "estimated_duration": 3600.038413354516,
    "input_throughput": 3317.7184875843204,
    "output_throughput": 2945.1249632974145,
    "total_throughput": 6262.8434508817345,
    "itl": 35.01028198228199,
    "ttft": 9106.7410269296,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 48139,
    "finished_requests": 48018,
    "scheduler_time": 24.49292845279503
}
#Debug simulation 
Total elapsed time: 3.656142021995038. Arrivals time: 0.13222364615648985 Scheduler time: 3.2420083922334015 Scheduler overhead time: 0.09657834097743034 Adapter cache time: 0.04172716895118356 Engine time: 0.09647304052487016 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.645336418878287,
    "estimated_duration": 3600.0005472889184,
    "input_throughput": 3317.7533845084276,
    "output_throughput": 2945.1559411524418,
    "total_throughput": 6262.909325660869,
    "itl": 35.01058643775535,
    "ttft": 9032.114362745871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 48139,
    "finished_requests": 48018,
    "scheduler_time": 24.492875036304497
}
#Debug simulation 
Total elapsed time: 3.645462111569941. Arrivals time: 0.1320582926273346 Scheduler time: 3.230368354357779 Scheduler overhead time: 0.09633077960461378 Adapter cache time: 0.04150712350383401 Engine time: 0.09798096073791385 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.662180142942816,
    "estimated_duration": 3600.0011234378817,
    "input_throughput": 3317.7528535307674,
    "output_throughput": 2945.1554698057716,
    "total_throughput": 6262.908323336539,
    "itl": 35.01065081948517,
    "ttft": 9032.09579140397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 48139,
    "finished_requests": 48018,
    "scheduler_time": 24.49287099149658
}
#Debug simulation 
Total elapsed time: 3.6622745343483984. Arrivals time: 0.13369262171909213 Scheduler time: 3.245382193941623 Scheduler overhead time: 0.09691567020490766 Adapter cache time: 0.04165681637823582 Engine time: 0.09722061920911074 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.6572309038601816,
    "estimated_duration": 3600.0005609454,
    "input_throughput": 3317.753371922641,
    "output_throughput": 2945.155929980091,
    "total_throughput": 6262.909301902732,
    "itl": 35.01034631193887,
    "ttft": 9032.079141585898,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 48139,
    "finished_requests": 48018,
    "scheduler_time": 24.492668833044206
}
#Debug simulation 
Total elapsed time: 3.6573300659656525. Arrivals time: 0.14245971059426665 Scheduler time: 3.2332502263598144 Scheduler overhead time: 0.09673090884461999 Adapter cache time: 0.04146662447601557 Engine time: 0.0960564287379384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.633417241740972,
    "estimated_duration": 3600.000534811799,
    "input_throughput": 3317.753396007316,
    "output_throughput": 2945.1559513599577,
    "total_throughput": 6262.909347367274,
    "itl": 35.0106298654601,
    "ttft": 9032.10768303076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 48139,
    "finished_requests": 48018,
    "scheduler_time": 24.49285084940609
}
#Debug simulation 
Total elapsed time: 3.6335135521367192. Arrivals time: 0.13605202082544565 Scheduler time: 3.2185425418429077 Scheduler overhead time: 0.09653006959706545 Adapter cache time: 0.0413815276697278 Engine time: 0.09372569806873798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.6902831019833684,
    "estimated_duration": 3600.031880642194,
    "input_throughput": 3317.7245080033504,
    "output_throughput": 2945.130307598458,
    "total_throughput": 6262.854815601808,
    "itl": 35.010289912018244,
    "ttft": 9106.65713385138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 48139,
    "finished_requests": 48018,
    "scheduler_time": 24.492835422210195
}
#Debug simulation 
Total elapsed time: 3.690398607868701. Arrivals time: 0.13958701211959124 Scheduler time: 3.266945964191109 Scheduler overhead time: 0.09698056941851974 Adapter cache time: 0.04184635262936354 Engine time: 0.09757096460089087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.6484230016358197,
    "estimated_duration": 3600.038407811073,
    "input_throughput": 3317.718492693039,
    "output_throughput": 2945.1249678324025,
    "total_throughput": 6262.8434605254415,
    "itl": 35.010491380160694,
    "ttft": 9106.646647037669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 48139,
    "finished_requests": 48018,
    "scheduler_time": 24.493082237450437
}
#Debug simulation 
Total elapsed time: 3.6485481499694288. Arrivals time: 0.13233472174033523 Scheduler time: 3.2337382202968 Scheduler overhead time: 0.09665374225005507 Adapter cache time: 0.041988739743828773 Engine time: 0.0965142548084259 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.6140497997403145,
    "estimated_duration": 3600.0107890004915,
    "input_throughput": 3266.0913228164204,
    "output_throughput": 2916.250982379644,
    "total_throughput": 6182.342305196064,
    "itl": 34.133838733434025,
    "ttft": 7338.13493216105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.59396291148105
}
#Debug simulation 
Total elapsed time: 3.6141571640037. Arrivals time: 0.12950667645782232 Scheduler time: 3.205548746045679 Scheduler overhead time: 0.09830973111093044 Adapter cache time: 0.036939175333827734 Engine time: 0.09566700225695968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.656443224288523,
    "estimated_duration": 3600.0072192980815,
    "input_throughput": 3266.094561413833,
    "output_throughput": 2916.253874081667,
    "total_throughput": 6182.3484354955,
    "itl": 34.134262058693054,
    "ttft": 7338.176619463116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.59412791462475
}
#Debug simulation 
Total elapsed time: 3.6565356492064893. Arrivals time: 0.13148030545562506 Scheduler time: 3.2428824133239686 Scheduler overhead time: 0.09836859256029129 Adapter cache time: 0.037131276447325945 Engine time: 0.09831453440710902 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.641256732866168,
    "estimated_duration": 3600.0067801942346,
    "input_throughput": 3266.0949597893846,
    "output_throughput": 2916.254229786079,
    "total_throughput": 6182.349189575463,
    "itl": 34.13421477942875,
    "ttft": 7338.166961556619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.59411982500873
}
#Debug simulation 
Total elapsed time: 3.641430104151368. Arrivals time: 0.14129550801590085 Scheduler time: 3.2169217602349818 Scheduler overhead time: 0.09847270464524627 Adapter cache time: 0.037338932510465384 Engine time: 0.09928169241175056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.6232614014297724,
    "estimated_duration": 3600.016339549355,
    "input_throughput": 3266.0862871171985,
    "output_throughput": 2916.2464860685027,
    "total_throughput": 6182.332773185701,
    "itl": 34.13385399855374,
    "ttft": 7338.075871179102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.59402358360171
}
#Debug simulation 
Total elapsed time: 3.623364260420203. Arrivals time: 0.1373056247830391 Scheduler time: 3.201890500728041 Scheduler overhead time: 0.09887434355914593 Adapter cache time: 0.03741915710270405 Engine time: 0.09927238430827856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.623190062586218,
    "estimated_duration": 3600.0071243218886,
    "input_throughput": 3266.09464758067,
    "output_throughput": 2916.253951018929,
    "total_throughput": 6182.3485985995985,
    "itl": 34.13417628555902,
    "ttft": 7338.138839878989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.59411173539261
}
#Debug simulation 
Total elapsed time: 3.6232836809940636. Arrivals time: 0.1214210968464613 Scheduler time: 3.22088500065729 Scheduler overhead time: 0.09796557249501348 Adapter cache time: 0.03698744950816035 Engine time: 0.09787923889234662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.6105373040772974,
    "estimated_duration": 3600.0089954434325,
    "input_throughput": 3266.092950012673,
    "output_throughput": 2916.2524352822734,
    "total_throughput": 6182.345385294946,
    "itl": 34.140880245261116,
    "ttft": 7338.1479083961685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.598292732433215
}
#Debug simulation 
Total elapsed time: 3.610662477090955. Arrivals time: 0.14184314431622624 Scheduler time: 3.186774923466146 Scheduler overhead time: 0.0984181142412126 Adapter cache time: 0.036648793146014214 Engine time: 0.09881675848737359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_96_slots_96_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.636355692986399,
    "estimated_duration": 3600.016311306442,
    "input_throughput": 3266.0863127403577,
    "output_throughput": 2916.2465089470925,
    "total_throughput": 6182.33282168745,
    "itl": 34.13428277855042,
    "ttft": 7338.103344867196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232575,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.59419263155344
}
#Debug simulation 
Total elapsed time: 3.636442470829934. Arrivals time: 0.12972235679626465 Scheduler time: 3.2224993826821446 Scheduler overhead time: 0.09864048101007938 Adapter cache time: 0.03713331837207079 Engine time: 0.10032659955322742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.9245016323402524,
    "estimated_duration": 3599.9738248113613,
    "input_throughput": 1378.7491913944916,
    "output_throughput": 1256.8777497256096,
    "total_throughput": 2635.6269411201015,
    "itl": 25.346618244503457,
    "ttft": 5182.224051792219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 20310,
    "finished_requests": 20281,
    "scheduler_time": 0.03687461501396591
}
#Debug simulation 
Total elapsed time: 1.9245972163043916. Arrivals time: 0.067020068410784 Scheduler time: 1.446783134713769 Scheduler overhead time: 0.11959140468388796 Adapter cache time: 0.11080515570938587 Engine time: 0.12066318513825536 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9157182141207159,
    "estimated_duration": 3599.9738255557577,
    "input_throughput": 1378.7491911093964,
    "output_throughput": 1256.8777494657147,
    "total_throughput": 2635.626940575111,
    "itl": 25.346741905000695,
    "ttft": 5182.158245043195,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 20310,
    "finished_requests": 20281,
    "scheduler_time": 0.03683821174159467
}
#Debug simulation 
Total elapsed time: 1.9158491441048682. Arrivals time: 0.06253843707963824 Scheduler time: 1.4448962002061307 Scheduler overhead time: 0.11940953088924289 Adapter cache time: 0.11009617382660508 Engine time: 0.11950502451509237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9041267409920692,
    "estimated_duration": 3599.971829640225,
    "input_throughput": 1378.7499555228574,
    "output_throughput": 1256.8784463105626,
    "total_throughput": 2635.62840183342,
    "itl": 25.34672841576749,
    "ttft": 5182.178441479677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 20310,
    "finished_requests": 20281,
    "scheduler_time": 0.03683500091956245
}
#Debug simulation 
Total elapsed time: 1.9042128738947213. Arrivals time: 0.06524161854758859 Scheduler time: 1.4313369011506438 Scheduler overhead time: 0.11974950507283211 Adapter cache time: 0.11036482686176896 Engine time: 0.1179823549464345 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.9333753366954625,
    "estimated_duration": 3599.973843032086,
    "input_throughput": 1378.7491844161607,
    "output_throughput": 1256.8777433641126,
    "total_throughput": 2635.626927780273,
    "itl": 25.346621899494178,
    "ttft": 5182.053601395573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 20310,
    "finished_requests": 20281,
    "scheduler_time": 0.03684546737166815
}
#Debug simulation 
Total elapsed time: 1.933473230805248. Arrivals time: 0.06843017414212227 Scheduler time: 1.4544996009208262 Scheduler overhead time: 0.11927703209221363 Adapter cache time: 0.11084033316001296 Engine time: 0.12060623615980148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_96_slots_96_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.946912626735866,
    "estimated_duration": 3599.9738911961667,
    "input_throughput": 1378.7491659698637,
    "output_throughput": 1256.8777265483347,
    "total_throughput": 2635.6268925181985,
    "itl": 25.34678659803036,
    "ttft": 5182.035733718122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 20310,
    "finished_requests": 20281,
    "scheduler_time": 0.03683570978356759
}
#Debug simulation 
Total elapsed time: 1.9470050437375903. Arrivals time: 0.0697923325933516 Scheduler time: 1.4669521762989461 Scheduler overhead time: 0.12113562971353531 Adapter cache time: 0.10983121022582054 Engine time: 0.11969790514558554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_96_slots_96_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_96_slots_96_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.893210798036307,
    "estimated_duration": 3599.9816265057675,
    "input_throughput": 1378.7462034403936,
    "output_throughput": 1256.875025885011,
    "total_throughput": 2635.6212293254043,
    "itl": 25.346429295681983,
    "ttft": 5182.041932721808,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 20310,
    "finished_requests": 20281,
    "scheduler_time": 0.03692411181847376
}
#Debug simulation 
Total elapsed time: 1.8933366830460727. Arrivals time: 0.06530749564990401 Scheduler time: 1.4245673124678433 Scheduler overhead time: 0.11787796718999743 Adapter cache time: 0.11036908812820911 Engine time: 0.11597100924700499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_96_slots_96_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_96_slots_96_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9310337719507515,
    "estimated_duration": 3599.977664985738,
    "input_throughput": 1378.747720652779,
    "output_throughput": 1256.8764089868112,
    "total_throughput": 2635.62412963959,
    "itl": 25.34659933217733,
    "ttft": 5182.100192652932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.32180989146232564,
    "arrivals": 20310,
    "finished_requests": 20281,
    "scheduler_time": 0.03689400506816311
}
#Debug simulation 
Total elapsed time: 1.9311233130283654. Arrivals time: 0.0643431250937283 Scheduler time: 1.4589432920329273 Scheduler overhead time: 0.11881713708862662 Adapter cache time: 0.11109626153483987 Engine time: 0.1185380071401596 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.8260422479361296,
    "estimated_duration": 3599.7007118769116,
    "input_throughput": 1299.9252922780224,
    "output_throughput": 1137.4481735358245,
    "total_throughput": 2437.373465813847,
    "itl": 24.224189287107347,
    "ttft": 5183.609578423289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 18897,
    "finished_requests": 18870,
    "scheduler_time": 0.011350363722473
}
#Debug simulation 
Total elapsed time: 1.8261442459188402. Arrivals time: 0.0650027496740222 Scheduler time: 1.3475038018077612 Scheduler overhead time: 0.12500948645174503 Adapter cache time: 0.10349153215065598 Engine time: 0.12293875217437744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7761266590096056,
    "estimated_duration": 3599.7007000638414,
    "input_throughput": 1299.925296543963,
    "output_throughput": 1137.4481772685667,
    "total_throughput": 2437.3734738125295,
    "itl": 24.224345128933237,
    "ttft": 5183.629090005316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 18897,
    "finished_requests": 18870,
    "scheduler_time": 0.011346318914431752
}
#Debug simulation 
Total elapsed time: 1.7762134429067373. Arrivals time: 0.059711008332669735 Scheduler time: 1.3085705190896988 Scheduler overhead time: 0.12327825417742133 Adapter cache time: 0.10335044004023075 Engine time: 0.11975360382348299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7809540168382227,
    "estimated_duration": 3599.7004382145865,
    "input_throughput": 1299.925391103073,
    "output_throughput": 1137.4482600087733,
    "total_throughput": 2437.3736511118464,
    "itl": 24.224360551795044,
    "ttft": 5183.613291981299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 18897,
    "finished_requests": 18870,
    "scheduler_time": 0.011351197708482027
}
#Debug simulation 
Total elapsed time: 1.7810421008616686. Arrivals time: 0.060946798883378506 Scheduler time: 1.3100402634590864 Scheduler overhead time: 0.12302511371672153 Adapter cache time: 0.10300525184720755 Engine time: 0.12220857106149197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.8167313123121858,
    "estimated_duration": 3599.6857734269347,
    "input_throughput": 1299.9306868791557,
    "output_throughput": 1137.4528938680176,
    "total_throughput": 2437.3835807471733,
    "itl": 24.224271066960583,
    "ttft": 5183.681345593452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 18897,
    "finished_requests": 18870,
    "scheduler_time": 0.011361914404595495
}
#Debug simulation 
Total elapsed time: 1.816869247239083. Arrivals time: 0.06621447764337063 Scheduler time: 1.3354668016545475 Scheduler overhead time: 0.12434938922524452 Adapter cache time: 0.10347910737618804 Engine time: 0.1253028456121683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.8090760940685868,
    "estimated_duration": 3599.70688419048,
    "input_throughput": 1299.9230633336174,
    "output_throughput": 1137.4462231862485,
    "total_throughput": 2437.369286519866,
    "itl": 24.22434670180773,
    "ttft": 5183.613251309759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31778577029705046,
    "arrivals": 18897,
    "finished_requests": 18870,
    "scheduler_time": 0.011369878898674106
}
#Debug simulation 
Total elapsed time: 1.809183687902987. Arrivals time: 0.06318759452551603 Scheduler time: 1.3306779125705361 Scheduler overhead time: 0.12439756700769067 Adapter cache time: 0.10283862054347992 Engine time: 0.12610031431540847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.7940544891171157,
    "estimated_duration": 3599.693158978029,
    "input_throughput": 1299.928019789467,
    "output_throughput": 1137.450560136754,
    "total_throughput": 2437.378579926221,
    "itl": 24.22415090018825,
    "ttft": 5183.717621343274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 18897,
    "finished_requests": 18870,
    "scheduler_time": 0.011386308374846874
}
#Debug simulation 
Total elapsed time: 1.7941411579959095. Arrivals time: 0.06296387175098062 Scheduler time: 1.3157622339203954 Scheduler overhead time: 0.12463629199191928 Adapter cache time: 0.10439053736627102 Engine time: 0.12425517337396741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_96_slots_96_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7981522381305695,
    "estimated_duration": 3599.709088518437,
    "input_throughput": 1299.9222673090833,
    "output_throughput": 1137.445526656488,
    "total_throughput": 2437.3677939655713,
    "itl": 24.224412586684014,
    "ttft": 5183.644057269167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3218098914623257,
    "arrivals": 18897,
    "finished_requests": 18870,
    "scheduler_time": 0.011352281938498828
}
#Debug simulation 
Total elapsed time: 1.7982468120753765. Arrivals time: 0.06523150578141212 Scheduler time: 1.3176134005188942 Scheduler overhead time: 0.1270542903803289 Adapter cache time: 0.10317458398640156 Engine time: 0.12287617567926645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.775761772878468,
    "estimated_duration": 3599.657360594282,
    "input_throughput": 1253.643485460789,
    "output_throughput": 1098.1014591198252,
    "total_throughput": 2351.744944580614,
    "itl": 23.791918563067824,
    "ttft": 3991.288008923632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.29380682341754405,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.0017347659579008679
}
#Debug simulation 
Total elapsed time: 1.7758890120312572. Arrivals time: 0.06390550639480352 Scheduler time: 1.2959242286160588 Scheduler overhead time: 0.1266660839319229 Adapter cache time: 0.09959133761003613 Engine time: 0.1267368644475937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.761152592021972,
    "estimated_duration": 3599.657322300722,
    "input_throughput": 1253.6434987971895,
    "output_throughput": 1098.1014708015523,
    "total_throughput": 2351.7449695987416,
    "itl": 23.79192038755686,
    "ttft": 3991.333234630414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31319492869079113,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.0017443984239975368
}
#Debug simulation 
Total elapsed time: 1.7612563432194293. Arrivals time: 0.06260324409231544 Scheduler time: 1.2860966054722667 Scheduler overhead time: 0.12646859185770154 Adapter cache time: 0.09950974211096764 Engine time: 0.1235942579805851 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7411321043036878,
    "estimated_duration": 3599.661384028458,
    "input_throughput": 1253.6420842311993,
    "output_throughput": 1098.1002317435618,
    "total_throughput": 2351.742315974761,
    "itl": 23.79199559038265,
    "ttft": 3991.2763113815645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.31376164913177523,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.0017469003820246157
}
#Debug simulation 
Total elapsed time: 1.7412369041703641. Arrivals time: 0.06257410952821374 Scheduler time: 1.2681262185797095 Scheduler overhead time: 0.12611265666782856 Adapter cache time: 0.09830287098884583 Engine time: 0.12326940009370446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.7343041799031198,
    "estimated_duration": 3599.6697401446236,
    "input_throughput": 1253.6391740812016,
    "output_throughput": 1098.0976826616293,
    "total_throughput": 2351.7368567428307,
    "itl": 23.791993562851435,
    "ttft": 3991.1337674926745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.30011987850070015,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.0017153759037036476
}
#Debug simulation 
Total elapsed time: 1.7343972390517592. Arrivals time: 0.06215487327426672 Scheduler time: 1.264580504503101 Scheduler overhead time: 0.1247794316150248 Adapter cache time: 0.09910602495074272 Engine time: 0.12146793911233544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7809690400026739,
    "estimated_duration": 3599.6692068742454,
    "input_throughput": 1253.639359800666,
    "output_throughput": 1098.0978453385121,
    "total_throughput": 2351.737205139178,
    "itl": 23.792108242321373,
    "ttft": 3991.0938367265326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.3177857702970504,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.0017234655197861462
}
#Debug simulation 
Total elapsed time: 1.7810964626260102. Arrivals time: 0.06260874075815082 Scheduler time: 1.305785009637475 Scheduler overhead time: 0.12461236072704196 Adapter cache time: 0.09900237061083317 Engine time: 0.12626220751553774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_96_slots_96_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.7959915231913328,
    "estimated_duration": 3599.6540407537263,
    "input_throughput": 1253.644641654256,
    "output_throughput": 1098.1024718620824,
    "total_throughput": 2351.7471135163382,
    "itl": 23.792002145881682,
    "ttft": 3991.272924940857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 96,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2870448283106092,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.001746900382024616
}
#Debug simulation 
Total elapsed time: 1.7960887742228806. Arrivals time: 0.06306523364037275 Scheduler time: 1.317831619642675 Scheduler overhead time: 0.12637927010655403 Adapter cache time: 0.09881357103586197 Engine time: 0.12689304957166314 
