INFO 06-01 00:47:14 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:15 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.800938553642482,
    "estimated_duration": 3600.0315854628734,
    "input_throughput": 4079.143377324528,
    "output_throughput": 3648.2232692164935,
    "total_throughput": 7727.3666465410215,
    "itl": 87.98103475620302,
    "ttft": 120041.27274631902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.914537648855624,
    "arrivals": 60544,
    "finished_requests": 59259,
    "scheduler_time": 50.060050115061124
}
#Debug simulation 
Total elapsed time: 9.801079019904137. Arrivals time: 0.14960950799286366 Scheduler time: 9.432665841653943 Scheduler overhead time: 0.06103115389123559 Adapter cache time: 0.06827078759670258 Engine time: 0.06123196752741933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.248774063307792,
    "estimated_duration": 3600.0102002282933,
    "input_throughput": 4058.9673882238903,
    "output_throughput": 3537.16720002418,
    "total_throughput": 7596.13458824807,
    "itl": 82.95436604824975,
    "ttft": 84615.47951672555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.772974339961914,
    "arrivals": 59315,
    "finished_requests": 58438,
    "scheduler_time": 46.94242508310255
}
#Debug simulation 
Total elapsed time: 8.248870650306344. Arrivals time: 0.14843525039032102 Scheduler time: 7.872676780447364 Scheduler overhead time: 0.0638413648121059 Adapter cache time: 0.0732026076875627 Engine time: 0.06160311168059707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.21107626426965,
    "estimated_duration": 3600.0791419967954,
    "input_throughput": 4058.0346775090434,
    "output_throughput": 3537.230571252629,
    "total_throughput": 7595.265248761672,
    "itl": 83.00589656965957,
    "ttft": 85187.82931572905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.606334124550777,
    "arrivals": 59315,
    "finished_requests": 58435,
    "scheduler_time": 46.979369353175976
}
#Debug simulation 
Total elapsed time: 8.211192271206528. Arrivals time: 0.14859872171655297 Scheduler time: 7.836908067110926 Scheduler overhead time: 0.06261295545846224 Adapter cache time: 0.07259843125939369 Engine time: 0.06147616636008024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.230060920119286,
    "estimated_duration": 3600.019112570802,
    "input_throughput": 4058.5220642249155,
    "output_throughput": 3535.4992854221073,
    "total_throughput": 7594.021349647023,
    "itl": 82.98576190309936,
    "ttft": 85463.97025200464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.581567588279528,
    "arrivals": 59315,
    "finished_requests": 58434,
    "scheduler_time": 46.9918011464335
}
#Debug simulation 
Total elapsed time: 8.23014565370977. Arrivals time: 0.14722888357937336 Scheduler time: 7.856713585555553 Scheduler overhead time: 0.06325682625174522 Adapter cache time: 0.07268469966948032 Engine time: 0.06111084623262286 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.304793291259557,
    "estimated_duration": 3600.067974694122,
    "input_throughput": 4059.001691833766,
    "output_throughput": 3536.879606025176,
    "total_throughput": 7595.881297858942,
    "itl": 82.94315059978729,
    "ttft": 84875.90046295099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4816,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.057512087620642,
    "arrivals": 59315,
    "finished_requests": 58436,
    "scheduler_time": 46.95105442890888
}
#Debug simulation 
Total elapsed time: 8.304879642091691. Arrivals time: 0.14883279195055366 Scheduler time: 7.927371995057911 Scheduler overhead time: 0.06291981413960457 Adapter cache time: 0.07421387359499931 Engine time: 0.06231921585276723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 8.323084119241685,
    "estimated_duration": 3600.0821396334427,
    "input_throughput": 4058.9385000776215,
    "output_throughput": 3536.2520926525967,
    "total_throughput": 7595.190592730219,
    "itl": 82.98867718790028,
    "ttft": 84852.28642796777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.857653521242227,
    "arrivals": 59315,
    "finished_requests": 58441,
    "scheduler_time": 46.98103751327848
}
#Debug simulation 
Total elapsed time: 8.323197558056563. Arrivals time: 0.14663926977664232 Scheduler time: 7.949889454524964 Scheduler overhead time: 0.0623755119740963 Adapter cache time: 0.07373348344117403 Engine time: 0.06140740728005767 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.29922105697915,
    "estimated_duration": 3600.04084882761,
    "input_throughput": 4059.3478278889916,
    "output_throughput": 3536.865700884085,
    "total_throughput": 7596.213528773076,
    "itl": 82.93553435989551,
    "ttft": 84349.99537613055,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4829,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.438952874084041,
    "arrivals": 59315,
    "finished_requests": 58443,
    "scheduler_time": 46.94786391640369
}
#Debug simulation 
Total elapsed time: 8.299353132024407. Arrivals time: 0.14964766753837466 Scheduler time: 7.920787469018251 Scheduler overhead time: 0.06262759491801262 Adapter cache time: 0.07451731525361538 Engine time: 0.06247810833156109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.381962233223021,
    "estimated_duration": 3600.0804142872767,
    "input_throughput": 4059.134329890528,
    "output_throughput": 3535.8932399070072,
    "total_throughput": 7595.027569797536,
    "itl": 82.96614128165487,
    "ttft": 84872.5814685957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.989397959708047,
    "arrivals": 59315,
    "finished_requests": 58444,
    "scheduler_time": 46.98979029835098
}
#Debug simulation 
Total elapsed time: 8.382050059270114. Arrivals time: 0.15091295121237636 Scheduler time: 8.0016980166547 Scheduler overhead time: 0.06341621186584234 Adapter cache time: 0.07456371560692787 Engine time: 0.06198041560128331 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.8237870638258755,
    "estimated_duration": 3600.0410799588285,
    "input_throughput": 3634.461860126784,
    "output_throughput": 3187.7247356664175,
    "total_throughput": 6822.186595793201,
    "itl": 72.2130180651349,
    "ttft": 69986.14180385982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.613943939919466,
    "arrivals": 53129,
    "finished_requests": 52454,
    "scheduler_time": 40.045690436285994
}
#Debug simulation 
Total elapsed time: 6.823864229023457. Arrivals time: 0.13937332155182958 Scheduler time: 6.412381405942142 Scheduler overhead time: 0.06873672129586339 Adapter cache time: 0.10622222861275077 Engine time: 0.06594249978661537 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.829063323326409,
    "estimated_duration": 3600.0012157422557,
    "input_throughput": 3634.343494881956,
    "output_throughput": 3187.244201425707,
    "total_throughput": 6821.587696307663,
    "itl": 72.28796679854082,
    "ttft": 70499.02739009622,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7295,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.81289958039357,
    "arrivals": 53129,
    "finished_requests": 52450,
    "scheduler_time": 40.074532268697304
}
#Debug simulation 
Total elapsed time: 6.8291685320436954. Arrivals time: 0.13745366502553225 Scheduler time: 6.422123841010034 Scheduler overhead time: 0.06793694058433175 Adapter cache time: 0.1054488425143063 Engine time: 0.06496041174978018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.841364942956716,
    "estimated_duration": 3600.07421517367,
    "input_throughput": 3634.343965703169,
    "output_throughput": 3186.9229116562888,
    "total_throughput": 6821.266877359458,
    "itl": 72.27987821220057,
    "ttft": 70589.18084672122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.886092408448544,
    "arrivals": 53129,
    "finished_requests": 52450,
    "scheduler_time": 40.07892619516105
}
#Debug simulation 
Total elapsed time: 6.841441547963768. Arrivals time: 0.13807431794703007 Scheduler time: 6.433110728859901 Scheduler overhead time: 0.06828483240678906 Adapter cache time: 0.10543431248515844 Engine time: 0.06546853855252266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.8256322094239295,
    "estimated_duration": 3600.000674459461,
    "input_throughput": 3634.060152492708,
    "output_throughput": 3187.4927361570462,
    "total_throughput": 6821.552888649754,
    "itl": 72.22515881706026,
    "ttft": 70208.08394908597,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7389,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.100260493668173,
    "arrivals": 53129,
    "finished_requests": 52450,
    "scheduler_time": 40.047632925215034
}
#Debug simulation 
Total elapsed time: 6.825714901089668. Arrivals time: 0.13891356205567718 Scheduler time: 6.415945870336145 Scheduler overhead time: 0.06793923722580075 Adapter cache time: 0.1067250482738018 Engine time: 0.06483026873320341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.800137099809945,
    "estimated_duration": 3600.079320372054,
    "input_throughput": 3633.8582669472985,
    "output_throughput": 3187.4078260070423,
    "total_throughput": 6821.266092954341,
    "itl": 72.2925231492492,
    "ttft": 70424.8586112884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.2224611313073,
    "arrivals": 53129,
    "finished_requests": 52452,
    "scheduler_time": 40.07940305086018
}
#Debug simulation 
Total elapsed time: 6.8002353250049055. Arrivals time: 0.14023833023384213 Scheduler time: 6.390717132482678 Scheduler overhead time: 0.06787941558286548 Adapter cache time: 0.10497525427490473 Engine time: 0.06510291062295437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.7946928748860955,
    "estimated_duration": 3600.031777399246,
    "input_throughput": 3634.599583854979,
    "output_throughput": 3188.1746355838163,
    "total_throughput": 6822.774219438796,
    "itl": 72.1889608612374,
    "ttft": 69597.72671955549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7376,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.054610975198276,
    "arrivals": 53129,
    "finished_requests": 52460,
    "scheduler_time": 40.047169199566
}
#Debug simulation 
Total elapsed time: 6.79478116473183. Arrivals time: 0.13935648137703538 Scheduler time: 6.384517962578684 Scheduler overhead time: 0.06791829178109765 Adapter cache time: 0.10618965327739716 Engine time: 0.06541146757081151 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.788583716843277,
    "estimated_duration": 3600.0421270951247,
    "input_throughput": 3634.4746917052594,
    "output_throughput": 3186.8657629452373,
    "total_throughput": 6821.340454650497,
    "itl": 72.30025363430943,
    "ttft": 70564.20580147927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.43869159467323,
    "arrivals": 53129,
    "finished_requests": 52451,
    "scheduler_time": 40.0850802705165
}
#Debug simulation 
Total elapsed time: 6.788670651149005. Arrivals time: 0.13787279883399606 Scheduler time: 6.382241159211844 Scheduler overhead time: 0.06827149214223027 Adapter cache time: 0.10456576896831393 Engine time: 0.06446843361482024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.705166016239673,
    "estimated_duration": 3600.01213894956,
    "input_throughput": 3473.6613426111594,
    "output_throughput": 3063.0452271801355,
    "total_throughput": 6536.706569791295,
    "itl": 68.89085943367249,
    "ttft": 53657.78998457234,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.841979017503235,
    "arrivals": 50759,
    "finished_requests": 50223,
    "scheduler_time": 36.95693612194786
}
#Debug simulation 
Total elapsed time: 5.705294824205339. Arrivals time: 0.13280903222039342 Scheduler time: 5.295798695180565 Scheduler overhead time: 0.06718281889334321 Adapter cache time: 0.11326493183150887 Engine time: 0.06486727809533477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.700713842641562,
    "estimated_duration": 3600.0466000614797,
    "input_throughput": 3473.012543722762,
    "output_throughput": 3063.1367382332437,
    "total_throughput": 6536.149281956005,
    "itl": 68.9644343495658,
    "ttft": 53934.52978339119,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8097,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.431969984180384,
    "arrivals": 50759,
    "finished_requests": 50220,
    "scheduler_time": 36.97332669630317
}
#Debug simulation 
Total elapsed time: 5.700786971021444. Arrivals time: 0.1308759986422956 Scheduler time: 5.293598104733974 Scheduler overhead time: 0.06693829549476504 Adapter cache time: 0.11334098130464554 Engine time: 0.06459609651938081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.703805889934301,
    "estimated_duration": 3600.002744012645,
    "input_throughput": 3472.8762417732437,
    "output_throughput": 3062.9718319907115,
    "total_throughput": 6535.848073763956,
    "itl": 68.96548892722008,
    "ttft": 54021.677838338124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.511814443562777,
    "arrivals": 50759,
    "finished_requests": 50218,
    "scheduler_time": 36.971085456218596
}
#Debug simulation 
Total elapsed time: 5.703905378933996. Arrivals time: 0.1303438739851117 Scheduler time: 5.296118888538331 Scheduler overhead time: 0.06702167261391878 Adapter cache time: 0.11400019377470016 Engine time: 0.06532487832009792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.712549909949303,
    "estimated_duration": 3600.057636506893,
    "input_throughput": 3472.8580101653774,
    "output_throughput": 3062.9912388567636,
    "total_throughput": 6535.8492490221415,
    "itl": 68.9195299099294,
    "ttft": 53802.60417750011,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.367633278226055,
    "arrivals": 50759,
    "finished_requests": 50221,
    "scheduler_time": 36.96653202426963
}
#Debug simulation 
Total elapsed time: 5.712623263243586. Arrivals time: 0.13209809130057693 Scheduler time: 5.302951203659177 Scheduler overhead time: 0.0670413482002914 Adapter cache time: 0.11403160961344838 Engine time: 0.0651368242688477 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.700486645102501,
    "estimated_duration": 3600.031649505274,
    "input_throughput": 3473.026689006525,
    "output_throughput": 3063.0180713870545,
    "total_throughput": 6536.044760393579,
    "itl": 68.9701952727748,
    "ttft": 53974.081436586675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.818679499718534,
    "arrivals": 50759,
    "finished_requests": 50219,
    "scheduler_time": 36.970869168336456
}
#Debug simulation 
Total elapsed time: 5.700561222154647. Arrivals time: 0.13177522039040923 Scheduler time: 5.291607040446252 Scheduler overhead time: 0.06711126770824194 Adapter cache time: 0.11396480770781636 Engine time: 0.06487911753356457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.650276659056544,
    "estimated_duration": 3600.066527012801,
    "input_throughput": 3472.86471130136,
    "output_throughput": 3063.096172600476,
    "total_throughput": 6535.960883901836,
    "itl": 68.87499954964908,
    "ttft": 53795.23694921075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.31508899814357,
    "arrivals": 50759,
    "finished_requests": 50220,
    "scheduler_time": 36.95235982882694
}
#Debug simulation 
Total elapsed time: 5.650380459148437. Arrivals time: 0.13021067110821605 Scheduler time: 5.242696017026901 Scheduler overhead time: 0.06741868192330003 Adapter cache time: 0.11389335244894028 Engine time: 0.06480714259669185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.702449708711356,
    "estimated_duration": 3600.0325862390678,
    "input_throughput": 3473.5510583429996,
    "output_throughput": 3063.3569935324053,
    "total_throughput": 6536.908051875404,
    "itl": 68.9824504317357,
    "ttft": 53714.39804438452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8092,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.14132547721045,
    "arrivals": 50759,
    "finished_requests": 50223,
    "scheduler_time": 36.97449362508875
}
#Debug simulation 
Total elapsed time: 5.7025265586562455. Arrivals time: 0.13077400531619787 Scheduler time: 5.295724011491984 Scheduler overhead time: 0.06727799214422703 Adapter cache time: 0.11250186525285244 Engine time: 0.06500612292438745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.235973438248038,
    "estimated_duration": 3600.0444121226205,
    "input_throughput": 3382.8443779724107,
    "output_throughput": 3011.4525708330993,
    "total_throughput": 6394.2969488055105,
    "itl": 67.54078312534338,
    "ttft": 41981.933142137124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.94297511305305,
    "arrivals": 49552,
    "finished_requests": 49137,
    "scheduler_time": 35.62905057290863
}
#Debug simulation 
Total elapsed time: 5.236049683298916. Arrivals time: 0.12659561540931463 Scheduler time: 4.833142007701099 Scheduler overhead time: 0.06647006189450622 Adapter cache time: 0.11365812178701162 Engine time: 0.06505839945748448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.211235099006444,
    "estimated_duration": 3600.0704281850503,
    "input_throughput": 3383.211312935441,
    "output_throughput": 3011.322477228702,
    "total_throughput": 6394.533790164143,
    "itl": 67.60655946130787,
    "ttft": 41947.18480128368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8139,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.560820859113758,
    "arrivals": 49552,
    "finished_requests": 49139,
    "scheduler_time": 35.638371044897795
}
#Debug simulation 
Total elapsed time: 5.211311689112335. Arrivals time: 0.12613977026194334 Scheduler time: 4.808093216270208 Scheduler overhead time: 0.06670684181153774 Adapter cache time: 0.11333745019510388 Engine time: 0.06560633424669504 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.269181631971151,
    "estimated_duration": 3600.0480980459797,
    "input_throughput": 3382.6181396325524,
    "output_throughput": 3011.1519915202944,
    "total_throughput": 6393.770131152846,
    "itl": 67.59914082636968,
    "ttft": 42139.23963771424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.473959810194195,
    "arrivals": 49552,
    "finished_requests": 49136,
    "scheduler_time": 35.64108189735261
}
#Debug simulation 
Total elapsed time: 5.26934160804376. Arrivals time: 0.12895273230969906 Scheduler time: 4.862527613528073 Scheduler overhead time: 0.0664618220180273 Adapter cache time: 0.11390904523432255 Engine time: 0.06597464811056852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.170577455777675,
    "estimated_duration": 3600.0752305061924,
    "input_throughput": 3382.6298675118906,
    "output_throughput": 3011.088187308744,
    "total_throughput": 6393.718054820634,
    "itl": 67.55328933401952,
    "ttft": 42018.20292768738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8132,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.416253381339402,
    "arrivals": 49552,
    "finished_requests": 49138,
    "scheduler_time": 35.62807384476032
}
#Debug simulation 
Total elapsed time: 5.170669756829739. Arrivals time: 0.12626666110008955 Scheduler time: 4.768214139621705 Scheduler overhead time: 0.06620943872258067 Adapter cache time: 0.11340385721996427 Engine time: 0.06517254933714867 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.251467586029321,
    "estimated_duration": 3600.0213910274274,
    "input_throughput": 3382.8201772224465,
    "output_throughput": 3011.4018286169135,
    "total_throughput": 6394.2220058393605,
    "itl": 67.62038700421874,
    "ttft": 42027.441318051904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.896668363622485,
    "arrivals": 49552,
    "finished_requests": 49137,
    "scheduler_time": 35.64008324919614
}
#Debug simulation 
Total elapsed time: 5.251544520724565. Arrivals time: 0.12731110071763396 Scheduler time: 4.847878776025027 Scheduler overhead time: 0.06638472946360707 Adapter cache time: 0.11373386811465025 Engine time: 0.06496493890881538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.18771429779008,
    "estimated_duration": 3600.028057831215,
    "input_throughput": 3382.896412017626,
    "output_throughput": 3011.293752674486,
    "total_throughput": 6394.1901646921115,
    "itl": 67.52141332273332,
    "ttft": 41760.15568647298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8144,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.350969601682383,
    "arrivals": 49552,
    "finished_requests": 49140,
    "scheduler_time": 35.62305103093
}
#Debug simulation 
Total elapsed time: 5.18778797192499. Arrivals time: 0.12616887921467423 Scheduler time: 4.78550045657903 Scheduler overhead time: 0.06614178884774446 Adapter cache time: 0.11382698966190219 Engine time: 0.06476743659004569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.177170090842992,
    "estimated_duration": 3600.0603746392626,
    "input_throughput": 3382.8282674899065,
    "output_throughput": 3011.170333799261,
    "total_throughput": 6393.998601289167,
    "itl": 67.62804780171241,
    "ttft": 42059.89930851116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.191676293795563,
    "arrivals": 49552,
    "finished_requests": 49138,
    "scheduler_time": 35.64596516585526
}
#Debug simulation 
Total elapsed time: 5.177273637149483. Arrivals time: 0.12827031686902046 Scheduler time: 4.774566656444222 Scheduler overhead time: 0.0664945193566382 Adapter cache time: 0.11207379028201103 Engine time: 0.06430603750050068 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.349971235264093,
    "estimated_duration": 3600.0436123997174,
    "input_throughput": 3149.7623975842503,
    "output_throughput": 2799.7324713745434,
    "total_throughput": 5949.494868958794,
    "itl": 62.89026956433473,
    "ttft": 28007.622122380657,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.31185010817918,
    "arrivals": 45990,
    "finished_requests": 45709,
    "scheduler_time": 31.24092680213413
}
#Debug simulation 
Total elapsed time: 4.350051030982286. Arrivals time: 0.11795789981260896 Scheduler time: 3.925713746342808 Scheduler overhead time: 0.0692375972867012 Adapter cache time: 0.13603126630187035 Engine time: 0.0685355244204402 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.300088671967387,
    "estimated_duration": 3600.02962423532,
    "input_throughput": 3149.690192454598,
    "output_throughput": 2799.688350381524,
    "total_throughput": 5949.378542836122,
    "itl": 62.959993919254416,
    "ttft": 28123.788509432277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.38035199529818,
    "arrivals": 45990,
    "finished_requests": 45708,
    "scheduler_time": 31.25451155758038
}
#Debug simulation 
Total elapsed time: 4.300164454150945. Arrivals time: 0.11748307710513473 Scheduler time: 3.8794532511383295 Scheduler overhead time: 0.06810006452724338 Adapter cache time: 0.1360368551686406 Engine time: 0.06655346741899848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.301373751834035,
    "estimated_duration": 3600.04082287602,
    "input_throughput": 3149.7648382056996,
    "output_throughput": 2799.7346407721866,
    "total_throughput": 5949.499478977886,
    "itl": 62.96057290946761,
    "ttft": 28048.18344707041,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.45305839583521,
    "arrivals": 45990,
    "finished_requests": 45709,
    "scheduler_time": 31.255367400156366
}
#Debug simulation 
Total elapsed time: 4.301447464153171. Arrivals time: 0.1176447537727654 Scheduler time: 3.8793505993671715 Scheduler overhead time: 0.06914042169228196 Adapter cache time: 0.13672867370769382 Engine time: 0.06608581403270364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.295244637876749,
    "estimated_duration": 3600.0496514726815,
    "input_throughput": 3149.6104492230065,
    "output_throughput": 2799.7038862719373,
    "total_throughput": 5949.314335494943,
    "itl": 62.91668917029678,
    "ttft": 28104.418285560187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10232,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.02836418516057,
    "arrivals": 45990,
    "finished_requests": 45708,
    "scheduler_time": 31.246355075551865
}
#Debug simulation 
Total elapsed time: 4.295365389902145. Arrivals time: 0.11734030768275261 Scheduler time: 3.875023645348847 Scheduler overhead time: 0.06860449351370335 Adapter cache time: 0.1355239786207676 Engine time: 0.06621344480663538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.2873161737807095,
    "estimated_duration": 3600.0589177790494,
    "input_throughput": 3149.7490066066575,
    "output_throughput": 2799.7205685228178,
    "total_throughput": 5949.469575129476,
    "itl": 62.976588021823126,
    "ttft": 28053.644046969468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.862943199426105,
    "arrivals": 45990,
    "finished_requests": 45709,
    "scheduler_time": 31.25785602158899
}
#Debug simulation 
Total elapsed time: 4.287453797645867. Arrivals time: 0.1180527564138174 Scheduler time: 3.8662104182876647 Scheduler overhead time: 0.06855990272015333 Adapter cache time: 0.13526680506765842 Engine time: 0.06675837840884924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.289242446888238,
    "estimated_duration": 3600.052827092018,
    "input_throughput": 3149.4773950744,
    "output_throughput": 2799.653361792844,
    "total_throughput": 5949.130756867245,
    "itl": 62.86996044411167,
    "ttft": 28148.085971965276,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10241,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.62110507009016,
    "arrivals": 45990,
    "finished_requests": 45707,
    "scheduler_time": 31.235537725421523
}
#Debug simulation 
Total elapsed time: 4.289315179921687. Arrivals time: 0.11747454199939966 Scheduler time: 3.8689934010617435 Scheduler overhead time: 0.06854595290496945 Adapter cache time: 0.1355126854032278 Engine time: 0.06599654071033001 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.31525643216446,
    "estimated_duration": 3600.0249436431377,
    "input_throughput": 3149.5709550627944,
    "output_throughput": 2799.7078236353213,
    "total_throughput": 5949.278778698116,
    "itl": 62.99033706949166,
    "ttft": 28216.539883659254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.26056621931278,
    "arrivals": 45990,
    "finished_requests": 45707,
    "scheduler_time": 31.26050969074261
}
#Debug simulation 
Total elapsed time: 4.315330618061125. Arrivals time: 0.11830733576789498 Scheduler time: 3.8932077172212303 Scheduler overhead time: 0.06868215790018439 Adapter cache time: 0.13577759033069015 Engine time: 0.0667178756557405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.912887331098318,
    "estimated_duration": 3600.0306573908856,
    "input_throughput": 3089.2803585345814,
    "output_throughput": 2706.3886192183923,
    "total_throughput": 5795.668977752974,
    "itl": 60.98375025508869,
    "ttft": 21963.62067274341,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10790,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.022662757036954,
    "arrivals": 44803,
    "finished_requests": 44570,
    "scheduler_time": 29.301566081537736
}
#Debug simulation 
Total elapsed time: 3.912959183100611. Arrivals time: 0.11570302583277225 Scheduler time: 3.4834632207639515 Scheduler overhead time: 0.07013789424672723 Adapter cache time: 0.14160222373902798 Engine time: 0.06866810796782374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.958479745313525,
    "estimated_duration": 3600.035730126454,
    "input_throughput": 3088.8835093893354,
    "output_throughput": 2706.4906379853496,
    "total_throughput": 5795.374147374685,
    "itl": 61.042641247407865,
    "ttft": 22420.27953895867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10668,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.81073257117497,
    "arrivals": 44803,
    "finished_requests": 44567,
    "scheduler_time": 29.327560498241436
}
#Debug simulation 
Total elapsed time: 3.9585536369122565. Arrivals time: 0.11609975434839725 Scheduler time: 3.530245626345277 Scheduler overhead time: 0.07043203664943576 Adapter cache time: 0.14019673690199852 Engine time: 0.06790655199438334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9347099573351443,
    "estimated_duration": 3600.0429580737978,
    "input_throughput": 3089.0606388625306,
    "output_throughput": 2706.507148240609,
    "total_throughput": 5795.567787103139,
    "itl": 61.0430638867057,
    "ttft": 22424.079800060343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10661,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.849168350271285,
    "arrivals": 44803,
    "finished_requests": 44568,
    "scheduler_time": 29.328269376685657
}
#Debug simulation 
Total elapsed time: 3.9347829264588654. Arrivals time: 0.1154413316398859 Scheduler time: 3.507916013710201 Scheduler overhead time: 0.07049878034740686 Adapter cache time: 0.13994672801345587 Engine time: 0.06753958854824305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.8620199728757143,
    "estimated_duration": 3600.0704256715067,
    "input_throughput": 3089.2462327110034,
    "output_throughput": 2706.3587230193316,
    "total_throughput": 5795.604955730335,
    "itl": 61.01447438454561,
    "ttft": 21949.071959916535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10914,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.130910760643765,
    "arrivals": 44803,
    "finished_requests": 44570,
    "scheduler_time": 29.29808216862861
}
#Debug simulation 
Total elapsed time: 3.8621007911860943. Arrivals time: 0.11600694013759494 Scheduler time: 3.4336709156632423 Scheduler overhead time: 0.06995373824611306 Adapter cache time: 0.14129518857225776 Engine time: 0.06775341415777802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.986230354756117,
    "estimated_duration": 3600.060482591302,
    "input_throughput": 3089.045601810376,
    "output_throughput": 2706.4939733975407,
    "total_throughput": 5795.539575207917,
    "itl": 61.05846031116292,
    "ttft": 22427.889428882932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.31480170577833,
    "arrivals": 44803,
    "finished_requests": 44568,
    "scheduler_time": 29.331188094373722
}
#Debug simulation 
Total elapsed time: 3.986317913979292. Arrivals time: 0.1166287837550044 Scheduler time: 3.5566297830082476 Scheduler overhead time: 0.07044714828953147 Adapter cache time: 0.14095060480758548 Engine time: 0.06811889540404081 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.870560518000275,
    "estimated_duration": 3600.02429156052,
    "input_throughput": 3089.285821229586,
    "output_throughput": 2706.393404855782,
    "total_throughput": 5795.679226085368,
    "itl": 60.96851034763351,
    "ttft": 21856.006565554337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10923,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.660319371213546,
    "arrivals": 44803,
    "finished_requests": 44570,
    "scheduler_time": 29.2887856192737
}
#Debug simulation 
Total elapsed time: 3.8706649751402438. Arrivals time: 0.11533836182206869 Scheduler time: 3.442896929103881 Scheduler overhead time: 0.06981491995975375 Adapter cache time: 0.14190139342099428 Engine time: 0.06724190898239613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.9849722450599074,
    "estimated_duration": 3600.0420437262346,
    "input_throughput": 3088.8780922375327,
    "output_throughput": 2706.4858914578117,
    "total_throughput": 5795.363983695344,
    "itl": 61.07191256905641,
    "ttft": 22512.21855164938,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10658,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.73670801691536,
    "arrivals": 44803,
    "finished_requests": 44567,
    "scheduler_time": 29.333459069451102
}
#Debug simulation 
Total elapsed time: 3.985087966080755. Arrivals time: 0.11648338939994574 Scheduler time: 3.555093306582421 Scheduler overhead time: 0.07008985942229629 Adapter cache time: 0.1411487916484475 Engine time: 0.06878535961732268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.476901718880981,
    "estimated_duration": 3600.0461026248263,
    "input_throughput": 2934.641307036895,
    "output_throughput": 2580.63306278947,
    "total_throughput": 5515.274369826365,
    "itl": 56.86519408714004,
    "ttft": 11767.937733989846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.86507637888293,
    "arrivals": 42341,
    "finished_requests": 42208,
    "scheduler_time": 26.31699616772869
}
#Debug simulation 
Total elapsed time: 3.4769763071089983. Arrivals time: 0.10907447012141347 Scheduler time: 3.03670496866107 Scheduler overhead time: 0.07166402786970139 Adapter cache time: 0.15605720411986113 Engine time: 0.06946483347564936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.455963117070496,
    "estimated_duration": 3600.027815607971,
    "input_throughput": 2934.6562140981164,
    "output_throughput": 2580.646171599383,
    "total_throughput": 5515.302385697499,
    "itl": 56.951046296750114,
    "ttft": 11689.39045776508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11372,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.09264975167244,
    "arrivals": 42341,
    "finished_requests": 42208,
    "scheduler_time": 26.335344781722853
}
#Debug simulation 
Total elapsed time: 3.456040844786912. Arrivals time: 0.10973022086545825 Scheduler time: 3.015640532132238 Scheduler overhead time: 0.07129741506651044 Adapter cache time: 0.1552720656618476 Engine time: 0.07001971546560526 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.440694277174771,
    "estimated_duration": 3600.0219262025003,
    "input_throughput": 2934.6610150078654,
    "output_throughput": 2580.650393371359,
    "total_throughput": 5515.311408379224,
    "itl": 56.95466567032041,
    "ttft": 11688.811449900235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.17772848606546,
    "arrivals": 42341,
    "finished_requests": 42208,
    "scheduler_time": 26.33603865783041
}
#Debug simulation 
Total elapsed time: 3.440777888055891. Arrivals time: 0.10851921001449227 Scheduler time: 3.0001538530923426 Scheduler overhead time: 0.0726465224288404 Adapter cache time: 0.15446796733886003 Engine time: 0.07060801796615124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.409112634137273,
    "estimated_duration": 3600.0302794657837,
    "input_throughput": 2934.654205621776,
    "output_throughput": 2580.6444054072294,
    "total_throughput": 5515.298611029006,
    "itl": 57.0012983107285,
    "ttft": 11705.270696827538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11324,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.4561200439357,
    "arrivals": 42341,
    "finished_requests": 42208,
    "scheduler_time": 26.348726485828525
}
#Debug simulation 
Total elapsed time: 3.409186329226941. Arrivals time: 0.10804079519584775 Scheduler time: 2.972827250137925 Scheduler overhead time: 0.07102951733395457 Adapter cache time: 0.15354396170005202 Engine time: 0.06951148668304086 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4456170788034797,
    "estimated_duration": 3600.053863463377,
    "input_throughput": 2934.6349806656094,
    "output_throughput": 2580.627499573663,
    "total_throughput": 5515.262480239272,
    "itl": 56.971063849825406,
    "ttft": 11775.97216311935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.646820667257394,
    "arrivals": 42341,
    "finished_requests": 42208,
    "scheduler_time": 26.340020389464723
}
#Debug simulation 
Total elapsed time: 3.4456906840205193. Arrivals time: 0.10820506792515516 Scheduler time: 3.0079577951692045 Scheduler overhead time: 0.07174496399238706 Adapter cache time: 0.15456777159124613 Engine time: 0.06905409740284085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.4219678696244955,
    "estimated_duration": 3600.010622669043,
    "input_throughput": 2934.6330073235554,
    "output_throughput": 2580.6579407013282,
    "total_throughput": 5515.290948024884,
    "itl": 56.836208725944864,
    "ttft": 11766.004034935066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.06564300981877,
    "arrivals": 42341,
    "finished_requests": 42207,
    "scheduler_time": 26.310211124553188
}
#Debug simulation 
Total elapsed time: 3.422043365892023. Arrivals time: 0.10820081131532788 Scheduler time: 2.9845921620726585 Scheduler overhead time: 0.07149151433259249 Adapter cache time: 0.15424288855865598 Engine time: 0.06936281826347113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.4736096072010696,
    "estimated_duration": 3600.0428528333,
    "input_throughput": 2934.6439561643756,
    "output_throughput": 2580.635392350479,
    "total_throughput": 5515.279348514854,
    "itl": 56.9905847580781,
    "ttft": 11776.669852772984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11377,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.128255631512744,
    "arrivals": 42341,
    "finished_requests": 42208,
    "scheduler_time": 26.343932844559802
}
#Debug simulation 
Total elapsed time: 3.4737208783626556. Arrivals time: 0.10845125000923872 Scheduler time: 3.0337302358821034 Scheduler overhead time: 0.07239320082589984 Adapter cache time: 0.15603653667494655 Engine time: 0.06919216364622116 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.048289001919329,
    "estimated_duration": 3600.0330389770966,
    "input_throughput": 2318.300946030039,
    "output_throughput": 2071.371823331603,
    "total_throughput": 4389.672769361642,
    "itl": 49.15849349249819,
    "ttft": 11325.13871413257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20355,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.29622802772928,
    "arrivals": 33871,
    "finished_requests": 33772,
    "scheduler_time": 17.066921718285176
}
#Debug simulation 
Total elapsed time: 3.048360278829932. Arrivals time: 0.0932363667525351 Scheduler time: 2.51642174879089 Scheduler overhead time: 0.07997947419062257 Adapter cache time: 0.24286219850182533 Engine time: 0.07775356620550156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.977330258116126,
    "estimated_duration": 3600.004983181127,
    "input_throughput": 2318.1926244517404,
    "output_throughput": 2071.3732438810957,
    "total_throughput": 4389.565868332836,
    "itl": 49.30120634481646,
    "ttft": 11458.598937186698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20317,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.33843579781005,
    "arrivals": 33871,
    "finished_requests": 33771,
    "scheduler_time": 17.11003312487553
}
#Debug simulation 
Total elapsed time: 2.9774030661210418. Arrivals time: 0.09184831473976374 Scheduler time: 2.452279414050281 Scheduler overhead time: 0.0789967025630176 Adapter cache time: 0.24005949450656772 Engine time: 0.07621818035840988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.039331175852567,
    "estimated_duration": 3600.0029435966644,
    "input_throughput": 2318.1939378255715,
    "output_throughput": 2071.374417419215,
    "total_throughput": 4389.568355244786,
    "itl": 49.30745019857804,
    "ttft": 11459.531333192348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 66.42809633009153,
    "arrivals": 33871,
    "finished_requests": 33771,
    "scheduler_time": 17.111280016141578
}
#Debug simulation 
Total elapsed time: 3.039405421819538. Arrivals time: 0.09295187331736088 Scheduler time: 2.509709361474961 Scheduler overhead time: 0.07951386459171772 Adapter cache time: 0.2421782393939793 Engine time: 0.07695014216005802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.0354284467175603,
    "estimated_duration": 3600.0450450491626,
    "input_throughput": 2318.293214546716,
    "output_throughput": 2071.364915351543,
    "total_throughput": 4389.658129898259,
    "itl": 49.20498531110551,
    "ttft": 11441.078868058139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20339,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.642112551643315,
    "arrivals": 33871,
    "finished_requests": 33772,
    "scheduler_time": 17.081277855251514
}
#Debug simulation 
Total elapsed time: 3.035502675920725. Arrivals time: 0.0938764913007617 Scheduler time: 2.5044783619232476 Scheduler overhead time: 0.08041922049596906 Adapter cache time: 0.24196996726095676 Engine time: 0.07624950492754579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.0671397992409766,
    "estimated_duration": 3600.033422753302,
    "input_throughput": 2318.300698891017,
    "output_throughput": 2071.371602516092,
    "total_throughput": 4389.672301407109,
    "itl": 49.33685570151821,
    "ttft": 11359.197731300113,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20309,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 67.27412266132848,
    "arrivals": 33871,
    "finished_requests": 33772,
    "scheduler_time": 17.12058464820521
}
#Debug simulation 
Total elapsed time: 3.0672168279998004. Arrivals time: 0.09314159816130996 Scheduler time: 2.528646773658693 Scheduler overhead time: 0.0799914407543838 Adapter cache time: 0.24957546964287758 Engine time: 0.07736328290775418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.0013446621596813,
    "estimated_duration": 3600.0379732818865,
    "input_throughput": 2318.3541568011365,
    "output_throughput": 2071.4873163411703,
    "total_throughput": 4389.841473142306,
    "itl": 49.10821432671026,
    "ttft": 11209.527598020974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20361,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.88041405452442,
    "arrivals": 33871,
    "finished_requests": 33773,
    "scheduler_time": 17.051566978159492
}
#Debug simulation 
Total elapsed time: 3.001420222222805. Arrivals time: 0.09382914239540696 Scheduler time: 2.4723381432704628 Scheduler overhead time: 0.0799573315307498 Adapter cache time: 0.24133740551769733 Engine time: 0.07571869203820825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_320_slots_96_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.986033926717937,
    "estimated_duration": 3600.0066353776892,
    "input_throughput": 2318.191560534289,
    "output_throughput": 2071.372293239583,
    "total_throughput": 4389.563853773872,
    "itl": 49.36681165392189,
    "ttft": 11471.211770463693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 20305,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 68.12972973992133,
    "arrivals": 33871,
    "finished_requests": 33771,
    "scheduler_time": 17.12944009375273
}
#Debug simulation 
Total elapsed time: 2.986149989068508. Arrivals time: 0.09217075165361166 Scheduler time: 2.457430811598897 Scheduler overhead time: 0.08020757464691997 Adapter cache time: 0.24072910705581307 Engine time: 0.07767784269526601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.725610170979053,
    "estimated_duration": 3599.9799919841707,
    "input_throughput": 2154.094194208538,
    "output_throughput": 1927.72738055554,
    "total_throughput": 4081.821574764078,
    "itl": 42.339981389986576,
    "ttft": 9493.076358846485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18406,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.331337414809326,
    "arrivals": 31462,
    "finished_requests": 31380,
    "scheduler_time": 12.607053864085803
}
#Debug simulation 
Total elapsed time: 2.7256840439513326. Arrivals time: 0.0869434792548418 Scheduler time: 2.197281348053366 Scheduler overhead time: 0.08756621228531003 Adapter cache time: 0.2281104656867683 Engine time: 0.0840268163010478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7635082378983498,
    "estimated_duration": 3599.9973680632356,
    "input_throughput": 2154.0837970589832,
    "output_throughput": 1927.71807600891,
    "total_throughput": 4081.8018730678928,
    "itl": 42.45812426954234,
    "ttft": 9495.109991850422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.093256824155624,
    "arrivals": 31462,
    "finished_requests": 31380,
    "scheduler_time": 12.650532956189199
}
#Debug simulation 
Total elapsed time: 2.763583563733846. Arrivals time: 0.08836538717150688 Scheduler time: 2.2290405072271824 Scheduler overhead time: 0.08767743036150932 Adapter cache time: 0.23143515549600124 Engine time: 0.08521294686943293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.731214280705899,
    "estimated_duration": 3599.973814478211,
    "input_throughput": 2153.955389568274,
    "output_throughput": 1927.6181876911264,
    "total_throughput": 4081.5735772594003,
    "itl": 42.462367695916925,
    "ttft": 9609.735608884384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.199223790763185,
    "arrivals": 31462,
    "finished_requests": 31379,
    "scheduler_time": 12.651948883716177
}
#Debug simulation 
Total elapsed time: 2.7312852111645043. Arrivals time: 0.08661663066595793 Scheduler time: 2.200193126220256 Scheduler overhead time: 0.08775522699579597 Adapter cache time: 0.23003069963306189 Engine time: 0.08486463548615575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.7264534761197865,
    "estimated_duration": 3599.988441163283,
    "input_throughput": 2154.0891385457294,
    "output_throughput": 1927.7228561760362,
    "total_throughput": 4081.8119947217656,
    "itl": 42.376437237148714,
    "ttft": 9493.744003555252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18403,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.55591778888336,
    "arrivals": 31462,
    "finished_requests": 31380,
    "scheduler_time": 12.621097280120537
}
#Debug simulation 
Total elapsed time: 2.7265273281373084. Arrivals time: 0.08771946420893073 Scheduler time: 2.1945872474461794 Scheduler overhead time: 0.0881879972293973 Adapter cache time: 0.2288495651446283 Engine time: 0.08508463902398944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7452683420851827,
    "estimated_duration": 3599.9707010940638,
    "input_throughput": 2153.813640106457,
    "output_throughput": 1927.5034649285308,
    "total_throughput": 4081.317105034988,
    "itl": 42.484822231403086,
    "ttft": 9724.491512175504,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 60.947832726809786,
    "arrivals": 31462,
    "finished_requests": 31378,
    "scheduler_time": 12.660389632776521
}
#Debug simulation 
Total elapsed time: 2.745341782923788. Arrivals time: 0.08686706703156233 Scheduler time: 2.215892116073519 Scheduler overhead time: 0.08740125223994255 Adapter cache time: 0.23020288348197937 Engine time: 0.08307699300348759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.7737750690430403,
    "estimated_duration": 3599.9729248430867,
    "input_throughput": 2154.0984229313353,
    "output_throughput": 1927.7311648954933,
    "total_throughput": 4081.8295878268286,
    "itl": 42.29713414706711,
    "ttft": 9492.497996101323,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.04383587887038,
    "arrivals": 31462,
    "finished_requests": 31380,
    "scheduler_time": 12.59183790763368
}
#Debug simulation 
Total elapsed time: 2.773865841794759. Arrivals time: 0.08811560971662402 Scheduler time: 2.2369322101585567 Scheduler overhead time: 0.08802440064027905 Adapter cache time: 0.23369303159415722 Engine time: 0.08487204136326909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.705423958133906,
    "estimated_duration": 3599.989445251692,
    "input_throughput": 2153.946037321748,
    "output_throughput": 1927.6098181767964,
    "total_throughput": 4081.5558554985446,
    "itl": 42.50993557422666,
    "ttft": 9610.579053001988,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.724436673452125,
    "arrivals": 31462,
    "finished_requests": 31379,
    "scheduler_time": 12.669611738652838
}
#Debug simulation 
Total elapsed time: 2.7055408130399883. Arrivals time: 0.08732327679172158 Scheduler time: 2.17710376996547 Scheduler overhead time: 0.08685539662837982 Adapter cache time: 0.22937662666663527 Engine time: 0.08338414551690221 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.6467242101207376,
    "estimated_duration": 3600.038862953988,
    "input_throughput": 2061.456634918236,
    "output_throughput": 1828.8374794369959,
    "total_throughput": 3890.2941143552316,
    "itl": 38.4323779573834,
    "ttft": 13631.65155542238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.024451666834366,
    "arrivals": 30252,
    "finished_requests": 30138,
    "scheduler_time": 9.715250663749257
}
#Debug simulation 
Total elapsed time: 2.646795706823468. Arrivals time: 0.08430789550766349 Scheduler time: 2.109243323560804 Scheduler overhead time: 0.09684007428586483 Adapter cache time: 0.21920175617560744 Engine time: 0.0916910688392818 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.595394914969802,
    "estimated_duration": 3600.0510594283387,
    "input_throughput": 2061.4496509886867,
    "output_throughput": 1828.8312835889255,
    "total_throughput": 3890.2809345776122,
    "itl": 38.52272071680761,
    "ttft": 13632.025076518492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.40965262121744,
    "arrivals": 30252,
    "finished_requests": 30138,
    "scheduler_time": 9.752622952630684
}
#Debug simulation 
Total elapsed time: 2.5954691329970956. Arrivals time: 0.08380337292328477 Scheduler time: 2.0676688626408577 Scheduler overhead time: 0.09333236888051033 Adapter cache time: 0.21562200132757425 Engine time: 0.09036148991435766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.642610506154597,
    "estimated_duration": 3600.0366762883987,
    "input_throughput": 2061.4578870488926,
    "output_throughput": 1828.8385902745636,
    "total_throughput": 3890.2964773234557,
    "itl": 38.523262331521366,
    "ttft": 13632.018494329146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.49236313247587,
    "arrivals": 30252,
    "finished_requests": 30138,
    "scheduler_time": 9.753640057499794
}
#Debug simulation 
Total elapsed time: 2.6426883721724153. Arrivals time: 0.08357771812006831 Scheduler time: 2.108948319219053 Scheduler overhead time: 0.09462103946134448 Adapter cache time: 0.21923659974709153 Engine time: 0.09100009640678763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.625548256095499,
    "estimated_duration": 3600.0071046488288,
    "input_throughput": 2061.47482054037,
    "output_throughput": 1828.8536129548113,
    "total_throughput": 3890.328433495181,
    "itl": 38.46154954487427,
    "ttft": 13513.0868698303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.16564713234322,
    "arrivals": 30252,
    "finished_requests": 30138,
    "scheduler_time": 9.727682952218439
}
#Debug simulation 
Total elapsed time: 2.625620491337031. Arrivals time: 0.08405774459242821 Scheduler time: 2.0931517174467444 Scheduler overhead time: 0.09431483689695597 Adapter cache time: 0.21801966801285744 Engine time: 0.09102178597822785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.598545433022082,
    "estimated_duration": 3600.049338776877,
    "input_throughput": 2061.4506362630596,
    "output_throughput": 1828.8321576828407,
    "total_throughput": 3890.2827939459003,
    "itl": 38.54095511174792,
    "ttft": 13631.977329652706,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.18541767737767,
    "arrivals": 30252,
    "finished_requests": 30138,
    "scheduler_time": 9.76126546290472
}
#Debug simulation 
Total elapsed time: 2.598618992138654. Arrivals time: 0.08381187124177814 Scheduler time: 2.069569727871567 Scheduler overhead time: 0.09382749907672405 Adapter cache time: 0.21716430597007275 Engine time: 0.08919522492215037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.616080066654831,
    "estimated_duration": 3600.041461058934,
    "input_throughput": 2061.4551471907366,
    "output_throughput": 1828.836159587835,
    "total_throughput": 3890.2913067785717,
    "itl": 38.400779105872914,
    "ttft": 13631.609247350762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.82320806396672,
    "arrivals": 30252,
    "finished_requests": 30138,
    "scheduler_time": 9.701886851932253
}
#Debug simulation 
Total elapsed time: 2.6161482827737927. Arrivals time: 0.08433329034596682 Scheduler time: 2.080252494663 Scheduler overhead time: 0.09457499533891678 Adapter cache time: 0.21931435400620103 Engine time: 0.09253549808636308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.6409780369140208,
    "estimated_duration": 3600.0456251300666,
    "input_throughput": 2061.4527627637704,
    "output_throughput": 1828.8340442246838,
    "total_throughput": 3890.286806988454,
    "itl": 38.5604830401894,
    "ttft": 13632.099182107153,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.894280929307975,
    "arrivals": 30252,
    "finished_requests": 30138,
    "scheduler_time": 9.769270651444222
}
#Debug simulation 
Total elapsed time: 2.6410912298597395. Arrivals time: 0.08388331299647689 Scheduler time: 2.1093238554894924 Scheduler overhead time: 0.0938822734169662 Adapter cache time: 0.2191644967533648 Engine time: 0.08978432230651379 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.343962912913412,
    "estimated_duration": 3599.9979525391623,
    "input_throughput": 1837.8493785901746,
    "output_throughput": 1596.6697969774666,
    "total_throughput": 3434.519175567641,
    "itl": 32.30065433029896,
    "ttft": 9400.483900895677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.48569086126912,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.6571068594874094
}
#Debug simulation 
Total elapsed time: 2.3440648377873003. Arrivals time: 0.07563901040703058 Scheduler time: 1.8155991770327091 Scheduler overhead time: 0.10752587486058474 Adapter cache time: 0.19292956497520208 Engine time: 0.10075442353263497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3732762201689184,
    "estimated_duration": 3600.0003375904957,
    "input_throughput": 1837.848160988869,
    "output_throughput": 1596.668739161058,
    "total_throughput": 3434.516900149927,
    "itl": 32.3510671579822,
    "ttft": 9400.777178469638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13884,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.293364989999965,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.679900562633893
}
#Debug simulation 
Total elapsed time: 2.3733502333052456. Arrivals time: 0.07661756267771125 Scheduler time: 1.8375137909315526 Scheduler overhead time: 0.10793655039742589 Adapter cache time: 0.19517370220273733 Engine time: 0.10418204637244344 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.343616438098252,
    "estimated_duration": 3599.9968367942965,
    "input_throughput": 1837.8499481937329,
    "output_throughput": 1596.6702918323815,
    "total_throughput": 3434.5202400261146,
    "itl": 32.35279830320091,
    "ttft": 9400.761200660536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.37913578706754,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.6805614091946466
}
#Debug simulation 
Total elapsed time: 2.3436880107037723. Arrivals time: 0.07644408196210861 Scheduler time: 1.8124827849678695 Scheduler overhead time: 0.10753023670986295 Adapter cache time: 0.19295882619917393 Engine time: 0.10293348273262382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.3789740311913192,
    "estimated_duration": 3600.005322157411,
    "input_throughput": 1837.845616304537,
    "output_throughput": 1596.6665284137232,
    "total_throughput": 3434.51214471826,
    "itl": 32.319866781398346,
    "ttft": 9400.66809904544,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13882,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.445845789199446,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.664968131839599
}
#Debug simulation 
Total elapsed time: 2.3790454608388245. Arrivals time: 0.07625256851315498 Scheduler time: 1.8445007354021072 Scheduler overhead time: 0.10820961929857731 Adapter cache time: 0.1939486009068787 Engine time: 0.1044523655436933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.36412154417485,
    "estimated_duration": 3600.012837645185,
    "input_throughput": 1837.84177956648,
    "output_throughput": 1596.6631951678946,
    "total_throughput": 3434.5049747343746,
    "itl": 32.364126613865665,
    "ttft": 9400.701908656712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13885,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 45.946708351211164,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.6853437067734385
}
#Debug simulation 
Total elapsed time: 2.3641944229602814. Arrivals time: 0.0769827850162983 Scheduler time: 1.8280005091801286 Scheduler overhead time: 0.10861846106126904 Adapter cache time: 0.195156617090106 Engine time: 0.10330892214551568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.3939760620705783,
    "estimated_duration": 3600.026824995429,
    "input_throughput": 1837.834638915059,
    "output_throughput": 1596.65699157875,
    "total_throughput": 3434.4916304938088,
    "itl": 32.28495535450409,
    "ttft": 9400.570041284096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13881,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.50488814354175,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.6492234448789698
}
#Debug simulation 
Total elapsed time: 2.394050380215049. Arrivals time: 0.07741513941437006 Scheduler time: 1.855109286494553 Scheduler overhead time: 0.10918216174468398 Adapter cache time: 0.1952959280461073 Engine time: 0.10480172606185079 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.315630940720439,
    "estimated_duration": 3600.0325381104603,
    "input_throughput": 1837.8317223412253,
    "output_throughput": 1596.6544577446907,
    "total_throughput": 3434.486180085916,
    "itl": 32.37414201418898,
    "ttft": 9400.835159529239,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13887,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 46.54949710544298,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.690230460497272
}
#Debug simulation 
Total elapsed time: 2.3157396307215095. Arrivals time: 0.07512514339759946 Scheduler time: 1.788969038054347 Scheduler overhead time: 0.10792297683656216 Adapter cache time: 0.19202873297035694 Engine time: 0.10004371358081698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.32529329508543,
    "estimated_duration": 3599.9248449839743,
    "input_throughput": 1731.459757746067,
    "output_throughput": 1563.1923560407138,
    "total_throughput": 3294.652113786781,
    "itl": 31.365374122516833,
    "ttft": 5722.937946974537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.567487056773295,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.827084025699206
}
#Debug simulation 
Total elapsed time: 2.325365226250142. Arrivals time: 0.07403031969442964 Scheduler time: 1.7976659112609923 Scheduler overhead time: 0.11023452924564481 Adapter cache time: 0.18396018957719207 Engine time: 0.10679275449365377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.32616103393957,
    "estimated_duration": 3599.9302977402835,
    "input_throughput": 1731.4571351319225,
    "output_throughput": 1563.1899882984862,
    "total_throughput": 3294.6471234304086,
    "itl": 31.40715773104256,
    "ttft": 5723.032882418641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.074019567068866,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.8448391492463787
}
#Debug simulation 
Total elapsed time: 2.326249537989497. Arrivals time: 0.0741440667770803 Scheduler time: 1.7971755480393767 Scheduler overhead time: 0.1107201180420816 Adapter cache time: 0.1861604480072856 Engine time: 0.10483350651338696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3302051229402423,
    "estimated_duration": 3599.938120777496,
    "input_throughput": 1731.4533724968035,
    "output_throughput": 1563.18659132525,
    "total_throughput": 3294.6399638220532,
    "itl": 31.409005506240664,
    "ttft": 5723.179154805505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.149637678178486,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.8451350039753827
}
#Debug simulation 
Total elapsed time: 2.330295931082219. Arrivals time: 0.07401006715372205 Scheduler time: 1.803849518764764 Scheduler overhead time: 0.11021944088861346 Adapter cache time: 0.18447160674259067 Engine time: 0.10488925594836473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.3411745838820934,
    "estimated_duration": 3599.9371095070615,
    "input_throughput": 1731.4538588851904,
    "output_throughput": 1563.18703044525,
    "total_throughput": 3294.6408893304406,
    "itl": 31.378118215001464,
    "ttft": 5722.975819158243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.41283877759797,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.833004040435621
}
#Debug simulation 
Total elapsed time: 2.3412689068354666. Arrivals time: 0.07534610293805599 Scheduler time: 1.8113748244941235 Scheduler overhead time: 0.1100752498023212 Adapter cache time: 0.18498190911486745 Engine time: 0.10674569942057133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3145263832993805,
    "estimated_duration": 3599.918456501242,
    "input_throughput": 1731.4628304269895,
    "output_throughput": 1563.195130111153,
    "total_throughput": 3294.6579605381426,
    "itl": 31.41643932376874,
    "ttft": 5723.140810498168,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12280,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.650172632078736,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.8487871321386375
}
#Debug simulation 
Total elapsed time: 2.3146128873340786. Arrivals time: 0.07557833287864923 Scheduler time: 1.7842081640847027 Scheduler overhead time: 0.11041539907455444 Adapter cache time: 0.18475899193435907 Engine time: 0.10656040906906128 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.3178732749074697,
    "estimated_duration": 3599.9371407056205,
    "input_throughput": 1731.453843879688,
    "output_throughput": 1563.187016898018,
    "total_throughput": 3294.640860777706,
    "itl": 31.350662353565394,
    "ttft": 5722.866295450638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12278,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.71183752080946,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.820781464038903
}
#Debug simulation 
Total elapsed time: 2.3179474156349897. Arrivals time: 0.07352672796696424 Scheduler time: 1.7934295474551618 Scheduler overhead time: 0.10991874430328608 Adapter cache time: 0.182780796661973 Engine time: 0.10594976739957929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3492623097263277,
    "estimated_duration": 3599.9267029528614,
    "input_throughput": 1731.4588641172172,
    "output_throughput": 1563.1915492568535,
    "total_throughput": 3294.6504133740705,
    "itl": 31.424915163865425,
    "ttft": 5723.155398920361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12282,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.18359102226743,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.852881020232431
}
#Debug simulation 
Total elapsed time: 2.349375565070659. Arrivals time: 0.073729591909796 Scheduler time: 1.8181764376349747 Scheduler overhead time: 0.11280417675152421 Adapter cache time: 0.18557242583483458 Engine time: 0.10591309564188123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.144523283932358,
    "estimated_duration": 3599.943530951921,
    "input_throughput": 1576.9225131425587,
    "output_throughput": 1406.7898444676014,
    "total_throughput": 2983.71235761016,
    "itl": 28.484417589284483,
    "ttft": 4904.18235726325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9111,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.88410383497338,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6574946736039682
}
#Debug simulation 
Total elapsed time: 2.1446010121144354. Arrivals time: 0.06797485332936049 Scheduler time: 1.626934609375894 Scheduler overhead time: 0.11842105071991682 Adapter cache time: 0.16156244138255715 Engine time: 0.11294703651219606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1240763519890606,
    "estimated_duration": 3599.945917860309,
    "input_throughput": 1576.9214675797477,
    "output_throughput": 1406.7889117095665,
    "total_throughput": 2983.710379289314,
    "itl": 28.506815639547437,
    "ttft": 4904.215842457091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.705490699474087,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6626892504550325
}
#Debug simulation 
Total elapsed time: 2.124152519274503. Arrivals time: 0.06728624319657683 Scheduler time: 1.6098695462569594 Scheduler overhead time: 0.11755718663334846 Adapter cache time: 0.16097449138760567 Engine time: 0.11157479230314493 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1293893149122596,
    "estimated_duration": 3599.9489126161,
    "input_throughput": 1576.920155757049,
    "output_throughput": 1406.7877414181698,
    "total_throughput": 2983.707897175219,
    "itl": 28.50847989826659,
    "ttft": 4904.351340288227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.769535199740137,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6629442817376201
}
#Debug simulation 
Total elapsed time: 2.1294632302597165. Arrivals time: 0.06798344664275646 Scheduler time: 1.6132057993672788 Scheduler overhead time: 0.11783602787181735 Adapter cache time: 0.16074038529768586 Engine time: 0.11323064379394054 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.1359112290665507,
    "estimated_duration": 3599.9509409287657,
    "input_throughput": 1576.9192672762956,
    "output_throughput": 1406.786948794759,
    "total_throughput": 2983.7062160710548,
    "itl": 28.49236030921613,
    "ttft": 4904.140040973646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.521530295821698,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.659357245386986
}
#Debug simulation 
Total elapsed time: 2.1359872464090586. Arrivals time: 0.06796006904914975 Scheduler time: 1.6186438286677003 Scheduler overhead time: 0.11926013603806496 Adapter cache time: 0.16075476864352822 Engine time: 0.11193215055391192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1261485568247736,
    "estimated_duration": 3599.959780634808,
    "input_throughput": 1576.9153951489318,
    "output_throughput": 1406.7834944275303,
    "total_throughput": 2983.698889576462,
    "itl": 28.513889132868005,
    "ttft": 4904.317486425918,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.129165600910152,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6639708708621044
}
#Debug simulation 
Total elapsed time: 2.126239465083927. Arrivals time: 0.0676228404045105 Scheduler time: 1.6045474484562874 Scheduler overhead time: 0.12351507134735584 Adapter cache time: 0.16127115208655596 Engine time: 0.11178156966343522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.187434270977974,
    "estimated_duration": 3599.9648701791975,
    "input_throughput": 1576.9131657435926,
    "output_throughput": 1406.7815055506105,
    "total_throughput": 2983.694671294203,
    "itl": 28.475440122069884,
    "ttft": 4904.1269139833275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9109,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.236368136262023,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6556574130311946
}
#Debug simulation 
Total elapsed time: 2.1875169398263097. Arrivals time: 0.0686467862688005 Scheduler time: 1.6655491273850203 Scheduler overhead time: 0.1185453743673861 Adapter cache time: 0.16245771944522858 Engine time: 0.11515462026000023 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1633467320352793,
    "estimated_duration": 3599.948571851128,
    "input_throughput": 1576.9203050256128,
    "output_throughput": 1406.7878745822904,
    "total_throughput": 2983.7081796079033,
    "itl": 28.518042061392343,
    "ttft": 4904.241244913273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.50671138331037,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6651962393226167
}
#Debug simulation 
Total elapsed time: 2.1634196168743074. Arrivals time: 0.06855891551822424 Scheduler time: 1.6428287168964744 Scheduler overhead time: 0.11778595391660929 Adapter cache time: 0.16235527163371444 Engine time: 0.11521788034588099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.7539906539022923,
    "estimated_duration": 3599.8095983634025,
    "input_throughput": 1180.8499543788582,
    "output_throughput": 1042.623754797019,
    "total_throughput": 2223.4737091758775,
    "itl": 24.76626989693217,
    "ttft": 7849.519264462136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.554408132215634,
    "arrivals": 17062,
    "finished_requests": 17025,
    "scheduler_time": 0.000500639439170733
}
#Debug simulation 
Total elapsed time: 1.7540639727376401. Arrivals time: 0.05490190163254738 Scheduler time: 1.2371423533186316 Scheduler overhead time: 0.13034990336745977 Adapter cache time: 0.1428957935422659 Engine time: 0.12544472189620137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7523703803308308,
    "estimated_duration": 3599.8105397888057,
    "input_throughput": 1180.8496455620102,
    "output_throughput": 1042.6234821292,
    "total_throughput": 2223.4731276912103,
    "itl": 24.787909414943798,
    "ttft": 7849.548093638699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.711373603872076,
    "arrivals": 17062,
    "finished_requests": 17025,
    "scheduler_time": 0.0005363338475368325
}
#Debug simulation 
Total elapsed time: 1.7524475632235408. Arrivals time: 0.054806051310151815 Scheduler time: 1.2379720257595181 Scheduler overhead time: 0.12945380248129368 Adapter cache time: 0.1433547348715365 Engine time: 0.12386070378124714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7526521300897002,
    "estimated_duration": 3599.7918696867223,
    "input_throughput": 1180.7346518536078,
    "output_throughput": 1042.5708307204477,
    "total_throughput": 2223.3054825740555,
    "itl": 24.791889752699895,
    "ttft": 8060.605714580132,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.76868787022629,
    "arrivals": 17062,
    "finished_requests": 17024,
    "scheduler_time": 0.0005274102454453077
}
#Debug simulation 
Total elapsed time: 1.7527271518483758. Arrivals time: 0.05491855600848794 Scheduler time: 1.2367505291476846 Scheduler overhead time: 0.1297528869472444 Adapter cache time: 0.14338688645511866 Engine time: 0.12469095969572663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.7481964929029346,
    "estimated_duration": 3599.798997317918,
    "input_throughput": 1180.8534318630418,
    "output_throughput": 1042.6268252189666,
    "total_throughput": 2223.4802570820084,
    "itl": 24.77355244161995,
    "ttft": 7849.490465381026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.29232206292836,
    "arrivals": 17062,
    "finished_requests": 17025,
    "scheduler_time": 0.0005152758213215599
}
#Debug simulation 
Total elapsed time: 1.7482687812298536. Arrivals time: 0.05453671654686332 Scheduler time: 1.233380560297519 Scheduler overhead time: 0.13093109196051955 Adapter cache time: 0.14191871043294668 Engine time: 0.12407255312427878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7465675282292068,
    "estimated_duration": 3599.8137634944833,
    "input_throughput": 1180.8485880873861,
    "output_throughput": 1042.6225484388872,
    "total_throughput": 2223.4711365262733,
    "itl": 24.793592109749238,
    "ttft": 7849.6632816187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10633,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.1990064852506,
    "arrivals": 17062,
    "finished_requests": 17025,
    "scheduler_time": 0.0005225314513950319
}
#Debug simulation 
Total elapsed time: 1.7466425579041243. Arrivals time: 0.054912212304770947 Scheduler time: 1.2290805443190038 Scheduler overhead time: 0.13168493006378412 Adapter cache time: 0.14240612788125873 Engine time: 0.12527209194377065 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.7486927476711571,
    "estimated_duration": 3599.8079000904904,
    "input_throughput": 1180.8505114656657,
    "output_throughput": 1042.6242466731774,
    "total_throughput": 2223.4747581388433,
    "itl": 24.758376345049477,
    "ttft": 7849.34108566499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10635,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.799184886281225,
    "arrivals": 17062,
    "finished_requests": 17025,
    "scheduler_time": 0.0004982626031475363
}
#Debug simulation 
Total elapsed time: 1.7487669456750154. Arrivals time: 0.054677726700901985 Scheduler time: 1.2339417021721601 Scheduler overhead time: 0.13000920228660107 Adapter cache time: 0.14274771697819233 Engine time: 0.1241623223759234 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_320_slots_96_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7535281563177705,
    "estimated_duration": 3599.8165011355723,
    "input_throughput": 1180.8476900583855,
    "output_throughput": 1042.6217555300466,
    "total_throughput": 2223.469445588432,
    "itl": 24.797479024210663,
    "ttft": 7849.746175909193,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10634,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.66088555686003,
    "arrivals": 17062,
    "finished_requests": 17025,
    "scheduler_time": 0.0005241994234130848
}
#Debug simulation 
Total elapsed time: 1.753639125265181. Arrivals time: 0.05451828986406326 Scheduler time: 1.2354210685007274 Scheduler overhead time: 0.13222331972792745 Adapter cache time: 0.14319076715037227 Engine time: 0.12445731274783611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.6610645060427487,
    "estimated_duration": 3599.8718169692006,
    "input_throughput": 1091.0244030040703,
    "output_throughput": 973.6980032114263,
    "total_throughput": 2064.722406215497,
    "itl": 23.9784390346661,
    "ttft": 6379.244638492566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.174850170647087,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.0002477761345654222
}
#Debug simulation 
Total elapsed time: 1.6611435050144792. Arrivals time: 0.051433570217341185 Scheduler time: 1.1496492736041546 Scheduler overhead time: 0.13308569649234414 Adapter cache time: 0.13245345512405038 Engine time: 0.12960083596408367 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6739123738370836,
    "estimated_duration": 3599.8637483794655,
    "input_throughput": 1091.0268483822608,
    "output_throughput": 973.700185618946,
    "total_throughput": 2064.727034001207,
    "itl": 23.99802749652401,
    "ttft": 6379.51176121927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.05328634716635,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00024539929854222576
}
#Debug simulation 
Total elapsed time: 1.673985952977091. Arrivals time: 0.05189815768972039 Scheduler time: 1.1619338411837816 Scheduler overhead time: 0.13264283258467913 Adapter cache time: 0.13323706481605768 Engine time: 0.1291580330580473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6559665808454156,
    "estimated_duration": 3599.862072432076,
    "input_throughput": 1091.0273563193878,
    "output_throughput": 973.7006389336151,
    "total_throughput": 2064.727995253003,
    "itl": 24.00014038668893,
    "ttft": 6379.487376075955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.10485581433525,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00025182094260667136
}
#Debug simulation 
Total elapsed time: 1.6560403788462281. Arrivals time: 0.05185308028012514 Scheduler time: 1.148577374406159 Scheduler overhead time: 0.13256155559793115 Adapter cache time: 0.13189042080193758 Engine time: 0.12655194010585546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.6577056497335434,
    "estimated_duration": 3599.860536520077,
    "input_throughput": 1091.0278218157564,
    "output_throughput": 973.7010543715131,
    "total_throughput": 2064.7288761872696,
    "itl": 23.987067384819298,
    "ttft": 6379.287811413689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.79904754874228,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00024539929854222576
}
#Debug simulation 
Total elapsed time: 1.6577826337888837. Arrivals time: 0.05162657890468836 Scheduler time: 1.1495953830890357 Scheduler overhead time: 0.13184885028749704 Adapter cache time: 0.13260485511273146 Engine time: 0.12778660282492638 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6791723095811903,
    "estimated_duration": 3599.84723135483,
    "input_throughput": 1091.0318542939494,
    "output_throughput": 973.7046532057406,
    "total_throughput": 2064.73650749969,
    "itl": 24.001968654452075,
    "ttft": 6379.351974331517,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.485401357914633,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00024944410658347493
}
#Debug simulation 
Total elapsed time: 1.6792476796545088. Arrivals time: 0.052138582803308964 Scheduler time: 1.1655093538574874 Scheduler overhead time: 0.13448313251137733 Adapter cache time: 0.1333061447367072 Engine time: 0.128498331643641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.6539627290330827,
    "estimated_duration": 3599.8613258647365,
    "input_throughput": 1091.0275825851566,
    "output_throughput": 973.7008408672535,
    "total_throughput": 2064.72842345241,
    "itl": 23.973586332083894,
    "ttft": 6379.122909020401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.52939306516234,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.0002445653125331994
}
#Debug simulation 
Total elapsed time: 1.6540802898816764. Arrivals time: 0.051409652922302485 Scheduler time: 1.1471019149757922 Scheduler overhead time: 0.1319968863390386 Adapter cache time: 0.1321912920102477 Engine time: 0.1271882657893002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6658820868469775,
    "estimated_duration": 3599.8676683998024,
    "input_throughput": 1091.0256603254131,
    "output_throughput": 973.699125323157,
    "total_throughput": 2064.72478564857,
    "itl": 24.006552619435606,
    "ttft": 6379.486663381363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.874623912756537,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00024944410658347493
}
#Debug simulation 
Total elapsed time: 1.6659912019968033. Arrivals time: 0.051951078698039055 Scheduler time: 1.1504440726712346 Scheduler overhead time: 0.13811738602817059 Adapter cache time: 0.13217364205047488 Engine time: 0.12812289968132973 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.475052180700004,
    "estimated_duration": 3599.6393123306507,
    "input_throughput": 917.7119464953098,
    "output_throughput": 812.8467177189312,
    "total_throughput": 1730.558664214241,
    "itl": 22.464630958458706,
    "ttft": 5134.643759755581,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.362204452650563,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4751285067759454. Arrivals time: 0.04607842955738306 Scheduler time: 0.9761599465273321 Scheduler overhead time: 0.13885411946102977 Adapter cache time: 0.11325421137735248 Engine time: 0.13262229971587658 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.500843363814056,
    "estimated_duration": 3599.644145511773,
    "input_throughput": 917.7107142990493,
    "output_throughput": 812.8456263234342,
    "total_throughput": 1730.5563406224835,
    "itl": 22.476607885461895,
    "ttft": 5134.7625488874855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.77011069384501,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5009153638966382. Arrivals time: 0.046059926971793175 Scheduler time: 0.9961495324969292 Scheduler overhead time: 0.13997492706403136 Adapter cache time: 0.11418660171329975 Engine time: 0.13658471778035164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4851053562015295,
    "estimated_duration": 3599.6419074075716,
    "input_throughput": 917.71128489253,
    "output_throughput": 812.8461317162644,
    "total_throughput": 1730.5574166087943,
    "itl": 22.474382257258398,
    "ttft": 5134.7720336481425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.80824440013601,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4851761562749743. Arrivals time: 0.045778310392051935 Scheduler time: 0.9801482325419784 Scheduler overhead time: 0.13938823342323303 Adapter cache time: 0.11729571828618646 Engine time: 0.13466702867299318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.5097758518531919,
    "estimated_duration": 3599.6572386596445,
    "input_throughput": 917.7073762806523,
    "output_throughput": 812.84266973416,
    "total_throughput": 1730.5500460148123,
    "itl": 22.46730271916735,
    "ttft": 5134.585477159251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6979,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.8428780332388,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5098493350669742. Arrivals time: 0.04669911228120327 Scheduler time: 1.0066958689130843 Scheduler overhead time: 0.13795042177662253 Adapter cache time: 0.1146355289965868 Engine time: 0.13606762513518333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4815511889755726,
    "estimated_duration": 3599.6543796754445,
    "input_throughput": 917.708105159209,
    "output_throughput": 812.8433153251265,
    "total_throughput": 1730.5514204843355,
    "itl": 22.476101862945175,
    "ttft": 5134.852680266345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.09620598513536,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4816226321272552. Arrivals time: 0.04593541705980897 Scheduler time: 0.9797652009874582 Scheduler overhead time: 0.14020619168877602 Adapter cache time: 0.1129883611574769 Engine time: 0.13386870454996824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.5024303570389748,
    "estimated_duration": 3599.6576919648132,
    "input_throughput": 917.7072607136921,
    "output_throughput": 812.8425673728204,
    "total_throughput": 1730.5498280865124,
    "itl": 22.4595295373454,
    "ttft": 5134.601017677301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6980,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.87055105841741,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5025113737210631. Arrivals time: 0.04663396440446377 Scheduler time: 0.9967198790982366 Scheduler overhead time: 0.13975268602371216 Adapter cache time: 0.11405060160905123 Engine time: 0.13735572062432766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [106 107 107]
Adapter prompts. [66, 270, 270, 33, 270, 270, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 270, 66, 270, 270, 33, 270, 66, 66, 270, 270, 66, 33, 33, 66, 270, 270, 66, 66, 33, 33, 66, 270, 270, 33, 270, 66, 33, 66, 270, 33, 66, 270, 270, 66, 33, 33, 270, 33, 33, 270, 270, 33, 33, 66, 66, 66, 33, 66, 33, 270, 33, 270, 66, 270, 270, 33, 270, 33, 270, 66, 33, 33, 66, 66, 270, 66, 270, 270, 270, 33, 66, 66, 33, 270, 66, 270, 270, 66, 33, 66, 66, 66, 33, 270, 66, 270, 33, 270, 33, 33, 66, 270, 270, 66, 33, 66, 33, 66, 270, 270, 66, 33, 66, 33, 270, 33, 33, 33, 33, 270, 66, 66, 270, 66, 66, 33, 66, 270, 66, 33, 33, 66, 270, 33, 33, 33, 270, 270, 270, 33, 66, 270, 66, 66, 66, 33, 270, 33, 270, 66, 33, 66, 33, 33, 66, 33, 66, 270, 270, 270, 270, 66, 66, 270, 270, 270, 66, 270, 33, 33, 270, 66, 270, 66, 270, 66, 33, 66, 33, 33, 33, 270, 270, 66, 66, 33, 33, 66, 33, 270, 33, 33, 66, 33, 270, 66, 33, 270, 33, 33, 270, 66, 270, 66, 33, 66, 270, 66, 66, 270, 66, 33, 66, 33, 270, 66, 66, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 66, 33, 66, 33, 66, 270, 270, 270, 33, 270, 270, 270, 270, 33, 66, 66, 270, 33, 270, 33, 33, 33, 270, 66, 270, 270, 33, 66, 66, 66, 33, 66, 33, 66, 66, 270, 33, 33, 66, 33, 66, 66, 33, 270, 270, 270, 33, 66, 66, 66, 66, 33, 66, 33, 270, 33, 33, 270, 66, 270, 66, 66, 66, 66, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 66, 270, 66, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 39450 . Total input tokens: 8718347 . Total output tokens: 7929177
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.4909153198823333,
    "estimated_duration": 3599.6366729130714,
    "input_throughput": 917.7126194035127,
    "output_throughput": 812.8473137351714,
    "total_throughput": 1730.559933138684,
    "itl": 22.480521679456437,
    "ttft": 5134.904153487019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6981,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.39929803836905,
    "arrivals": 13422,
    "finished_requests": 13403,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.490986499004066. Arrivals time: 0.04646206274628639 Scheduler time: 0.9884407981298864 Scheduler overhead time: 0.1388879483565688 Adapter cache time: 0.11421912303194404 Engine time: 0.1351092029362917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 632384,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.154487069696188,
    "estimated_duration": 3599.933778798637,
    "input_throughput": 582.652106645133,
    "output_throughput": 507.4965575088127,
    "total_throughput": 1090.1486641539457,
    "itl": 20.132915357740437,
    "ttft": 5505.616766153859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.33076260162348,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1545831048861146. Arrivals time: 0.034987698309123516 Scheduler time: 0.6719849687069654 Scheduler overhead time: 0.14787956373766065 Adapter cache time: 0.08312155259773135 Engine time: 0.1436934475786984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1711728288792074,
    "estimated_duration": 3599.9203965648103,
    "input_throughput": 582.6542725782292,
    "output_throughput": 507.4984440609724,
    "total_throughput": 1090.1527166392016,
    "itl": 20.14009096543991,
    "ttft": 5505.795617718095,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.42965876091562,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1712337266653776. Arrivals time: 0.03560618730261922 Scheduler time: 0.6796942916698754 Scheduler overhead time: 0.15011808183044195 Adapter cache time: 0.08471028972417116 Engine time: 0.14672077866271138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1759070428088307,
    "estimated_duration": 3599.933640689443,
    "input_throughput": 582.6521289982152,
    "output_throughput": 507.49657697859953,
    "total_throughput": 1090.1487059768147,
    "itl": 20.13981617659634,
    "ttft": 5505.792280622514,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.461743585019168,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1759688020683825. Arrivals time: 0.035168807953596115 Scheduler time: 0.6903382828459144 Scheduler overhead time: 0.14686896558851004 Adapter cache time: 0.08472856692969799 Engine time: 0.14454293437302113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.150730089750141,
    "estimated_duration": 3599.925780179606,
    "input_throughput": 582.6534012307753,
    "output_throughput": 507.49768510751085,
    "total_throughput": 1090.1510863382862,
    "itl": 20.135619193477325,
    "ttft": 5505.698803633836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5337,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.70072471281867,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1508010579273105. Arrivals time: 0.03499095793813467 Scheduler time: 0.6670997939072549 Scheduler overhead time: 0.14699826249852777 Adapter cache time: 0.08402034360915422 Engine time: 0.14407674642279744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1456531882286072,
    "estimated_duration": 3599.9340870675746,
    "input_throughput": 582.6520567515678,
    "output_throughput": 507.49651405095466,
    "total_throughput": 1090.1485708025225,
    "itl": 20.14147520751486,
    "ttft": 5505.8547588491865,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.686465601342494,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1457159062847495. Arrivals time: 0.03490832028910518 Scheduler time: 0.6621221308596432 Scheduler overhead time: 0.14792739134281874 Adapter cache time: 0.08336045639589429 Engine time: 0.14453175896778703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 565744,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.1494008069857955,
    "estimated_duration": 3599.940267650489,
    "input_throughput": 582.6510564212625,
    "output_throughput": 507.49564275197446,
    "total_throughput": 1090.146699173237,
    "itl": 20.129550885284626,
    "ttft": 5505.686500758174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.960888474189646,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1494998573325574. Arrivals time: 0.03490024618804455 Scheduler time: 0.6657364261336625 Scheduler overhead time: 0.14784944197162986 Adapter cache time: 0.08351607713848352 Engine time: 0.1437751860357821 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 96,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 430432,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_320_slots_96_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [106 107 107]
Adapter prompts. [66, 135, 135, 33, 135, 135, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 135, 66, 135, 135, 33, 135, 66, 66, 135, 135, 66, 33, 33, 66, 135, 135, 66, 66, 33, 33, 66, 135, 135, 33, 135, 66, 33, 66, 135, 33, 66, 135, 135, 66, 33, 33, 135, 33, 33, 135, 135, 33, 33, 66, 66, 66, 33, 66, 33, 135, 33, 135, 66, 135, 135, 33, 135, 33, 135, 66, 33, 33, 66, 66, 135, 66, 135, 135, 135, 33, 66, 66, 33, 135, 66, 135, 135, 66, 33, 66, 66, 66, 33, 135, 66, 135, 33, 135, 33, 33, 66, 135, 135, 66, 33, 66, 33, 66, 135, 135, 66, 33, 66, 33, 135, 33, 33, 33, 33, 135, 66, 66, 135, 66, 66, 33, 66, 135, 66, 33, 33, 66, 135, 33, 33, 33, 135, 135, 135, 33, 66, 135, 66, 66, 66, 33, 135, 33, 135, 66, 33, 66, 33, 33, 66, 33, 66, 135, 135, 135, 135, 66, 66, 135, 135, 135, 66, 135, 33, 33, 135, 66, 135, 66, 135, 66, 33, 66, 33, 33, 33, 135, 135, 66, 66, 33, 33, 66, 33, 135, 33, 33, 66, 33, 135, 66, 33, 135, 33, 33, 135, 66, 135, 66, 33, 66, 135, 66, 66, 135, 66, 33, 66, 33, 135, 66, 66, 135, 135, 33, 33, 33, 135, 135, 33, 33, 135, 66, 33, 66, 33, 66, 135, 135, 135, 33, 135, 135, 135, 135, 33, 66, 66, 135, 33, 135, 33, 33, 33, 135, 66, 135, 135, 33, 66, 66, 66, 33, 66, 33, 66, 66, 135, 33, 33, 66, 33, 66, 66, 33, 135, 135, 135, 33, 66, 66, 66, 66, 33, 66, 33, 135, 33, 33, 135, 66, 135, 66, 66, 66, 66, 33, 33, 135, 33, 33, 135, 135, 135, 33, 135, 135, 66, 135, 66, 33, 135, 33, 135, 135, 33, 33, 33]
Prompts retrieved: 25005 . Total input tokens: 5548470 . Total output tokens: 4996306
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.1404119320213795,
    "estimated_duration": 3599.9285756438235,
    "input_throughput": 582.6529487810392,
    "output_throughput": 507.4972910186868,
    "total_throughput": 1090.150239799726,
    "itl": 20.14366913225033,
    "ttft": 5505.909855967692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.90794719099868,
    "arrivals": 8555,
    "finished_requests": 8542,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1404739138670266. Arrivals time: 0.03512205881997943 Scheduler time: 0.658821732737124 Scheduler overhead time: 0.14777571661397815 Adapter cache time: 0.08308317139744759 Engine time: 0.1429301812313497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 28.28827249724418,
    "estimated_duration": 3600.1065962107987,
    "input_throughput": 4619.007397587157,
    "output_throughput": 4082.266901615783,
    "total_throughput": 8701.27429920294,
    "itl": 210.36263543700943,
    "ttft": 2232966.1096659726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5861121436232306,
    "arrivals": 2153264,
    "finished_requests": 67407,
    "scheduler_time": 104.06537612414981
}
#Debug simulation 
Total elapsed time: 28.288362427148968. Arrivals time: 0.7935378262773156 Scheduler time: 27.380353092215955 Scheduler overhead time: 0.03905170038342476 Adapter cache time: 0.021916192024946213 Engine time: 0.03818867402151227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 31.227916717994958,
    "estimated_duration": 3600.1039304670644,
    "input_throughput": 4621.552133313395,
    "output_throughput": 4080.9382961602273,
    "total_throughput": 8702.490429473622,
    "itl": 210.41079285001214,
    "ttft": 2232855.836017483,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 837,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.733937047070364,
    "arrivals": 2153264,
    "finished_requests": 67404,
    "scheduler_time": 104.01583822965041
}
#Debug simulation 
Total elapsed time: 31.22806348092854. Arrivals time: 0.34227808890864253 Scheduler time: 30.76993776485324 Scheduler overhead time: 0.039553843438625336 Adapter cache time: 0.021632864139974117 Engine time: 0.03906917292624712 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.028717262204736,
    "estimated_duration": 3600.103092860222,
    "input_throughput": 4429.511485830983,
    "output_throughput": 3918.007800380413,
    "total_throughput": 8347.519286211396,
    "itl": 179.49732249031416,
    "ttft": 2251114.3503397615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.134120699297572,
    "arrivals": 2153264,
    "finished_requests": 64538,
    "scheduler_time": 109.16369979927997
}
#Debug simulation 
Total elapsed time: 14.028780532069504. Arrivals time: 0.29463972756639123 Scheduler time: 13.608541240449995 Scheduler overhead time: 0.036886143032461405 Adapter cache time: 0.0361446738243103 Engine time: 0.036587539594620466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 27.9170111999847,
    "estimated_duration": 3600.1654030383456,
    "input_throughput": 4618.931948506057,
    "output_throughput": 4082.2002199112476,
    "total_throughput": 8701.132168417305,
    "itl": 210.365613223619,
    "ttft": 2232991.5956296893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.644676546221575,
    "arrivals": 2153264,
    "finished_requests": 67407,
    "scheduler_time": 104.06561854902841
}
#Debug simulation 
Total elapsed time: 27.917224019765854. Arrivals time: 0.3273445116356015 Scheduler time: 27.475684353150427 Scheduler overhead time: 0.03915917593985796 Adapter cache time: 0.021788408048450947 Engine time: 0.03779454994946718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 14.095032925251871,
    "estimated_duration": 3600.1704843714588,
    "input_throughput": 4429.428569903983,
    "output_throughput": 3917.934459279526,
    "total_throughput": 8347.363029183509,
    "itl": 179.50053112452295,
    "ttft": 2251139.098990797,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.201398975029526,
    "arrivals": 2153264,
    "finished_requests": 64538,
    "scheduler_time": 109.16381303484918
}
#Debug simulation 
Total elapsed time: 14.095162390265614. Arrivals time: 0.29606037912890315 Scheduler time: 13.671968286391348 Scheduler overhead time: 0.0377775295637548 Adapter cache time: 0.0363312684930861 Engine time: 0.036946532782167196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 28.011196387000382,
    "estimated_duration": 3600.046868568078,
    "input_throughput": 4619.084030596015,
    "output_throughput": 4082.3346296726368,
    "total_throughput": 8701.418660268651,
    "itl": 210.35956434572677,
    "ttft": 2232940.2789614615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 845,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5265924991922857,
    "arrivals": 2153264,
    "finished_requests": 67407,
    "scheduler_time": 104.06516812576312
}
#Debug simulation 
Total elapsed time: 28.011332961264998. Arrivals time: 0.3471226370893419 Scheduler time: 27.550169170834124 Scheduler overhead time: 0.039000785909593105 Adapter cache time: 0.021687848027795553 Engine time: 0.03797253221273422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 8640, 34560, 34560, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 8640, 34560, 17280, 17280, 34560, 34560, 17280, 8640, 8640, 17280, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 34560, 34560, 8640, 34560, 17280, 8640, 17280, 34560, 8640, 17280, 34560, 34560, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 8640, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 8640, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 8640, 34560, 17280, 34560, 34560, 17280, 8640, 17280, 17280, 17280, 8640, 34560, 17280, 34560, 8640, 34560, 8640, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 17280, 8640, 17280, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 17280, 34560, 17280, 17280, 17280, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 17280, 8640, 17280, 8640, 8640, 8640, 34560, 34560, 17280, 17280, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 17280, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 8640, 17280, 34560, 17280, 17280, 34560, 17280, 8640, 17280, 8640, 34560, 17280, 17280, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 8640, 8640, 34560, 17280, 8640, 17280, 8640, 17280, 34560, 34560, 34560, 8640, 34560, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 8640, 34560, 8640, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 17280, 17280, 17280, 8640, 17280, 8640, 17280, 17280, 34560, 8640, 8640, 17280, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 17280, 17280, 17280, 17280, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 8640, 8640, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 34560, 34560, 8640, 8640, 8640]
Prompts retrieved: 6462720 . Total input tokens: 1438948254 . Total output tokens: 1292672847
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.09520788025111,
    "estimated_duration": 3600.036144508884,
    "input_throughput": 4429.328028920475,
    "output_throughput": 3917.855108625339,
    "total_throughput": 8347.183137545813,
    "itl": 179.50539460652973,
    "ttft": 2251111.852644856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.266790943965253,
    "arrivals": 2153264,
    "finished_requests": 64533,
    "scheduler_time": 109.15786636309888
}
#Debug simulation 
Total elapsed time: 14.095275647006929. Arrivals time: 0.3099174494855106 Scheduler time: 13.658195179887116 Scheduler overhead time: 0.03731910511851311 Adapter cache time: 0.03634648164734244 Engine time: 0.03735330421477556 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 20.138246675021946,
    "estimated_duration": 3600.1528079913282,
    "input_throughput": 4634.925762862284,
    "output_throughput": 4075.4445109751414,
    "total_throughput": 8710.370273837425,
    "itl": 209.631370683954,
    "ttft": 2231625.2185714343,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.38795993253364,
    "arrivals": 2000260,
    "finished_requests": 67646,
    "scheduler_time": 104.03084971858522
}
#Debug simulation 
Total elapsed time: 20.138313482981175. Arrivals time: 0.31799441389739513 Scheduler time: 19.70580506604165 Scheduler overhead time: 0.03699664445593953 Adapter cache time: 0.026211025193333626 Engine time: 0.036534508690238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 26.921629207208753,
    "estimated_duration": 3600.213531842396,
    "input_throughput": 4632.228575471633,
    "output_throughput": 4078.663632066703,
    "total_throughput": 8710.892207538336,
    "itl": 209.85237824167257,
    "ttft": 2229419.4294064995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2267027687630683,
    "arrivals": 2000260,
    "finished_requests": 67581,
    "scheduler_time": 104.01851861933422
}
#Debug simulation 
Total elapsed time: 26.921727864071727. Arrivals time: 0.3314718217588961 Scheduler time: 26.47249663481489 Scheduler overhead time: 0.03976585390046239 Adapter cache time: 0.023857100401073694 Engine time: 0.03874767245724797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.388086779043078,
    "estimated_duration": 3600.032105097395,
    "input_throughput": 4436.865987218153,
    "output_throughput": 3909.342636159421,
    "total_throughput": 8346.208623377575,
    "itl": 178.3410614717232,
    "ttft": 2249811.965472598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.591922894008409,
    "arrivals": 2000260,
    "finished_requests": 64758,
    "scheduler_time": 109.28827457842851
}
#Debug simulation 
Total elapsed time: 12.388179139234126. Arrivals time: 0.2946103257127106 Scheduler time: 11.964176575187594 Scheduler overhead time: 0.036815001629292965 Adapter cache time: 0.040080346167087555 Engine time: 0.03635340416803956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 26.989822863135487,
    "estimated_duration": 3600.0750570498085,
    "input_throughput": 4632.406751448812,
    "output_throughput": 4078.8205154903912,
    "total_throughput": 8711.227266939204,
    "itl": 209.8454049082156,
    "ttft": 2229365.054026139,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 988,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.088597551130192,
    "arrivals": 2000260,
    "finished_requests": 67581,
    "scheduler_time": 104.0181490443461
}
#Debug simulation 
Total elapsed time: 26.98999392706901. Arrivals time: 0.33604148821905255 Scheduler time: 26.53622152004391 Scheduler overhead time: 0.03965195966884494 Adapter cache time: 0.024068112019449472 Engine time: 0.03843120625242591 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 12.37683914322406,
    "estimated_duration": 3600.103396775318,
    "input_throughput": 4436.778125402509,
    "output_throughput": 3909.26522071731,
    "total_throughput": 8346.043346119819,
    "itl": 178.34439051676725,
    "ttft": 2249838.7870314447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.663099537119192,
    "arrivals": 2000260,
    "finished_requests": 64758,
    "scheduler_time": 109.28838961329174
}
#Debug simulation 
Total elapsed time: 12.376931926235557. Arrivals time: 0.30037208227440715 Scheduler time: 11.94870082847774 Scheduler overhead time: 0.036660964135080576 Adapter cache time: 0.03833402320742607 Engine time: 0.0366857904009521 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 20.090828898828477,
    "estimated_duration": 3600.0746290956913,
    "input_throughput": 4635.026414491717,
    "output_throughput": 4075.5330129602175,
    "total_throughput": 8710.559427451934,
    "itl": 209.62721387648728,
    "ttft": 2231594.1578338495,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.309985676456628,
    "arrivals": 2000260,
    "finished_requests": 67646,
    "scheduler_time": 104.03064507888068
}
#Debug simulation 
Total elapsed time: 20.090924179647118. Arrivals time: 0.33802526723593473 Scheduler time: 19.638706770259887 Scheduler overhead time: 0.036703589372336864 Adapter cache time: 0.02568114222958684 Engine time: 0.036666165105998516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 4320, 34560, 34560, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 4320, 34560, 17280, 17280, 34560, 34560, 17280, 4320, 4320, 17280, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 34560, 34560, 4320, 34560, 17280, 4320, 17280, 34560, 4320, 17280, 34560, 34560, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 4320, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 4320, 34560, 17280, 34560, 34560, 17280, 4320, 17280, 17280, 17280, 4320, 34560, 17280, 34560, 4320, 34560, 4320, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 17280, 4320, 17280, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 17280, 34560, 17280, 17280, 17280, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 17280, 4320, 17280, 4320, 4320, 4320, 34560, 34560, 17280, 17280, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 17280, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 4320, 17280, 34560, 17280, 17280, 34560, 17280, 4320, 17280, 4320, 34560, 17280, 17280, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 17280, 4320, 17280, 4320, 17280, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 17280, 17280, 17280, 4320, 17280, 4320, 17280, 17280, 34560, 4320, 4320, 17280, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 17280, 17280, 17280, 17280, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 6004800 . Total input tokens: 1336758239 . Total output tokens: 1201018668
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 12.340826378203928,
    "estimated_duration": 3600.1756977222603,
    "input_throughput": 4436.689023290064,
    "output_throughput": 3909.1867124440923,
    "total_throughput": 8345.875735734156,
    "itl": 178.34777867600286,
    "ttft": 2249866.3017719146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1711,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.735282210521291,
    "arrivals": 2000260,
    "finished_requests": 64758,
    "scheduler_time": 109.28850788688418
}
#Debug simulation 
Total elapsed time: 12.34089077822864. Arrivals time: 0.294690462294966 Scheduler time: 11.919480097014457 Scheduler overhead time: 0.03690922632813454 Adapter cache time: 0.0382254128344357 Engine time: 0.035910882987082005 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 19.16455481108278,
    "estimated_duration": 3600.1602750113475,
    "input_throughput": 4619.171017309107,
    "output_throughput": 4079.18533570112,
    "total_throughput": 8698.356353010227,
    "itl": 210.34453322919973,
    "ttft": 2228655.299998548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.370376498336088,
    "arrivals": 1885868,
    "finished_requests": 67338,
    "scheduler_time": 103.96640593613206
}
#Debug simulation 
Total elapsed time: 19.164653109852225. Arrivals time: 0.31477924436330795 Scheduler time: 18.731308498885483 Scheduler overhead time: 0.03643771447241306 Adapter cache time: 0.030900075566023588 Engine time: 0.03629915555939078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.65193797275424,
    "estimated_duration": 3600.220081330083,
    "input_throughput": 4618.699586236613,
    "output_throughput": 4078.605381972959,
    "total_throughput": 8697.304968209572,
    "itl": 210.3585795371045,
    "ttft": 2228738.928082073,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.664903494052072,
    "arrivals": 1885868,
    "finished_requests": 67331,
    "scheduler_time": 103.96013259504153
}
#Debug simulation 
Total elapsed time: 18.652084965724498. Arrivals time: 0.31376410415396094 Scheduler time: 18.218266846146435 Scheduler overhead time: 0.03683212725445628 Adapter cache time: 0.03203096520155668 Engine time: 0.03648383729159832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.149019374977797,
    "estimated_duration": 3600.073761086867,
    "input_throughput": 4431.732530719953,
    "output_throughput": 3921.1816026064416,
    "total_throughput": 8352.914133326394,
    "itl": 179.0764408893212,
    "ttft": 2247624.7216493166,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1895,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.199819506406745,
    "arrivals": 1885868,
    "finished_requests": 64617,
    "scheduler_time": 109.25869359233278
}
#Debug simulation 
Total elapsed time: 11.149130268022418. Arrivals time: 0.44558948976919055 Scheduler time: 10.57648083101958 Scheduler overhead time: 0.035629396326839924 Adapter cache time: 0.04064753791317344 Engine time: 0.03494491660967469 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 18.719765963964164,
    "estimated_duration": 3600.0235633311954,
    "input_throughput": 4618.951711697511,
    "output_throughput": 4078.828024784545,
    "total_throughput": 8697.779736482056,
    "itl": 210.34783288566956,
    "ttft": 2228672.630466294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.46877774120068,
    "arrivals": 1885868,
    "finished_requests": 67331,
    "scheduler_time": 103.95974034894898
}
#Debug simulation 
Total elapsed time: 18.719855803996325. Arrivals time: 0.3187027629464865 Scheduler time: 18.28207699628547 Scheduler overhead time: 0.03610526584088802 Adapter cache time: 0.03154216334223747 Engine time: 0.03655785275623202 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.476804411970079,
    "estimated_duration": 3600.1559989819852,
    "input_throughput": 4431.631297230305,
    "output_throughput": 3921.092031565224,
    "total_throughput": 8352.72332879553,
    "itl": 179.08031469273962,
    "ttft": 2247653.3191252677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1895,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.281936728935587,
    "arrivals": 1885868,
    "finished_requests": 64617,
    "scheduler_time": 109.25881426498388
}
#Debug simulation 
Total elapsed time: 11.476898665074259. Arrivals time: 0.7736839028075337 Scheduler time: 10.575950370170176 Scheduler overhead time: 0.03544521797448397 Adapter cache time: 0.041025021113455296 Engine time: 0.03495675418525934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.769666380714625,
    "estimated_duration": 3600.059493131713,
    "input_throughput": 4619.300328710311,
    "output_throughput": 4079.299530471038,
    "total_throughput": 8698.59985918135,
    "itl": 210.33904682395817,
    "ttft": 2228621.404710735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1428,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.269791821120192,
    "arrivals": 1885868,
    "finished_requests": 67338,
    "scheduler_time": 103.96620873350939
}
#Debug simulation 
Total elapsed time: 18.76982125872746. Arrivals time: 0.3165755970403552 Scheduler time: 18.33358730887994 Scheduler overhead time: 0.03683471446856856 Adapter cache time: 0.031802852638065815 Engine time: 0.0359950577840209 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 1080, 34560, 34560, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 1080, 34560, 17280, 17280, 34560, 34560, 17280, 1080, 1080, 17280, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 34560, 34560, 1080, 34560, 17280, 1080, 17280, 34560, 1080, 17280, 34560, 34560, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 1080, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 1080, 34560, 17280, 34560, 34560, 17280, 1080, 17280, 17280, 17280, 1080, 34560, 17280, 34560, 1080, 34560, 1080, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 17280, 1080, 17280, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 17280, 34560, 17280, 17280, 17280, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 17280, 1080, 17280, 1080, 1080, 1080, 34560, 34560, 17280, 17280, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 17280, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 1080, 17280, 34560, 17280, 17280, 34560, 17280, 1080, 17280, 1080, 34560, 17280, 17280, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 17280, 1080, 17280, 1080, 17280, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 17280, 17280, 17280, 1080, 17280, 1080, 17280, 17280, 34560, 1080, 1080, 17280, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 17280, 17280, 17280, 17280, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 5661360 . Total input tokens: 1260518946 . Total output tokens: 1132323398
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.15334932366386,
    "estimated_duration": 3600.039061192518,
    "input_throughput": 4431.689692476595,
    "output_throughput": 3920.991622608713,
    "total_throughput": 8352.681315085309,
    "itl": 179.08330374465513,
    "ttft": 2247686.6282563643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1895,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.361035860590469,
    "arrivals": 1885868,
    "finished_requests": 64614,
    "scheduler_time": 109.25292393263473
}
#Debug simulation 
Total elapsed time: 11.153440875932574. Arrivals time: 0.4326386475004256 Scheduler time: 10.592242908664048 Scheduler overhead time: 0.03585083968937397 Adapter cache time: 0.04137261351570487 Engine time: 0.0354388952255249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.20985771296546,
    "estimated_duration": 3600.058938206167,
    "input_throughput": 4682.605004350237,
    "output_throughput": 4119.29728222431,
    "total_throughput": 8801.902286574548,
    "itl": 208.0760483234539,
    "ttft": 2224247.8322988427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.739916023085919,
    "arrivals": 1866718,
    "finished_requests": 67970,
    "scheduler_time": 105.03260732759244
}
#Debug simulation 
Total elapsed time: 18.209952553734183. Arrivals time: 0.4509548177011311 Scheduler time: 17.644376893527806 Scheduler overhead time: 0.03620687499642372 Adapter cache time: 0.027289974503219128 Engine time: 0.03626661607995629 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.5933309616521,
    "estimated_duration": 3600.2389104700637,
    "input_throughput": 4678.45562999063,
    "output_throughput": 4109.765037250861,
    "total_throughput": 8788.22066724149,
    "itl": 208.3601302038874,
    "ttft": 2223610.3108131383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.96671453735093,
    "arrivals": 1866718,
    "finished_requests": 67873,
    "scheduler_time": 104.85931236895065
}
#Debug simulation 
Total elapsed time: 18.593464434612542. Arrivals time: 0.322921272367239 Scheduler time: 18.15375468879938 Scheduler overhead time: 0.036944763734936714 Adapter cache time: 0.02738798037171364 Engine time: 0.03743375791236758 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.949082280974835,
    "estimated_duration": 3600.1684903510377,
    "input_throughput": 4457.20166792398,
    "output_throughput": 3923.5483111021526,
    "total_throughput": 8380.749979026132,
    "itl": 178.3504338189661,
    "ttft": 2243123.280318107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.401908900998472,
    "arrivals": 1866718,
    "finished_requests": 64674,
    "scheduler_time": 109.57339819389736
}
#Debug simulation 
Total elapsed time: 10.949217455927283. Arrivals time: 0.28553020814433694 Scheduler time: 10.541598787531257 Scheduler overhead time: 0.03532516909763217 Adapter cache time: 0.0357433264143765 Engine time: 0.0351239163428545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 18.33840682776645,
    "estimated_duration": 3600.130331898758,
    "input_throughput": 4682.512144250356,
    "output_throughput": 4119.21559300288,
    "total_throughput": 8801.727737253237,
    "itl": 208.07981604992565,
    "ttft": 2224276.1279008933,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.811150657969945,
    "arrivals": 1866718,
    "finished_requests": 67970,
    "scheduler_time": 105.03276638518226
}
#Debug simulation 
Total elapsed time: 18.338502863887697. Arrivals time: 0.4683765200898051 Scheduler time: 17.754211395978928 Scheduler overhead time: 0.03673179028555751 Adapter cache time: 0.027440697886049747 Engine time: 0.036758460104465485 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.078322092071176,
    "estimated_duration": 3600.0412970288417,
    "input_throughput": 4457.337756998359,
    "output_throughput": 3923.45915910943,
    "total_throughput": 8380.796916107789,
    "itl": 178.35438068729445,
    "ttft": 2243079.6952856984,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.4713249910994675,
    "arrivals": 1866718,
    "finished_requests": 64671,
    "scheduler_time": 109.56750988157025
}
#Debug simulation 
Total elapsed time: 11.078412801027298. Arrivals time: 0.41940247965976596 Scheduler time: 10.53583080880344 Scheduler overhead time: 0.035955388098955154 Adapter cache time: 0.03586391033604741 Engine time: 0.03561860928311944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.588427076116204,
    "estimated_duration": 3600.2038133096034,
    "input_throughput": 4682.795717751825,
    "output_throughput": 4119.432334683939,
    "total_throughput": 8802.228052435763,
    "itl": 208.0703751516184,
    "ttft": 2224260.602283107,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1222,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.6538414603703657,
    "arrivals": 1866718,
    "finished_requests": 67977,
    "scheduler_time": 105.03913123606912
}
#Debug simulation 
Total elapsed time: 18.588564503006637. Arrivals time: 0.8059311248362064 Scheduler time: 17.668380643241107 Scheduler overhead time: 0.036347825080156326 Adapter cache time: 0.027289465069770813 Engine time: 0.0357655487023294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 540, 34560, 34560, 17280, 17280, 17280, 17280, 540, 17280, 540, 17280, 540, 17280, 17280, 34560, 17280, 34560, 34560, 540, 34560, 17280, 17280, 34560, 34560, 17280, 540, 540, 17280, 34560, 34560, 17280, 17280, 540, 540, 17280, 34560, 34560, 540, 34560, 17280, 540, 17280, 34560, 540, 17280, 34560, 34560, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 540, 540, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 34560, 17280, 540, 540, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 540, 34560, 17280, 34560, 34560, 17280, 540, 17280, 17280, 17280, 540, 34560, 17280, 34560, 540, 34560, 540, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 17280, 540, 17280, 540, 34560, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 17280, 540, 17280, 34560, 17280, 540, 540, 17280, 34560, 540, 540, 540, 34560, 34560, 34560, 540, 17280, 34560, 17280, 17280, 17280, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 540, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 17280, 540, 17280, 540, 540, 540, 34560, 34560, 17280, 17280, 540, 540, 17280, 540, 34560, 540, 540, 17280, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 540, 17280, 34560, 17280, 17280, 34560, 17280, 540, 17280, 540, 34560, 17280, 17280, 34560, 34560, 540, 540, 540, 34560, 34560, 540, 540, 34560, 17280, 540, 17280, 540, 17280, 34560, 34560, 34560, 540, 34560, 34560, 34560, 34560, 540, 17280, 17280, 34560, 540, 34560, 540, 540, 540, 34560, 17280, 34560, 34560, 540, 17280, 17280, 17280, 540, 17280, 540, 17280, 17280, 34560, 540, 540, 17280, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 17280, 17280, 17280, 17280, 540, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 540, 540, 34560, 540, 540, 34560, 34560, 34560, 540, 34560, 34560, 17280, 34560, 17280, 540, 34560, 540, 34560, 34560, 540, 540, 540]
Prompts retrieved: 5604120 . Total input tokens: 1247723528 . Total output tokens: 1120869396
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.977651528082788,
    "estimated_duration": 3600.110320100575,
    "input_throughput": 4457.252298743921,
    "output_throughput": 3923.3839366359766,
    "total_throughput": 8380.636235379898,
    "itl": 178.35761433409562,
    "ttft": 2243104.1620783675,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.540238066054792,
    "arrivals": 1866718,
    "finished_requests": 64671,
    "scheduler_time": 109.56761987841026
}
#Debug simulation 
Total elapsed time: 10.977743315976113. Arrivals time: 0.30473760422319174 Scheduler time: 10.549560262355953 Scheduler overhead time: 0.03574195923283696 Adapter cache time: 0.036038432735949755 Engine time: 0.03561330633237958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.380956979002804,
    "estimated_duration": 3600.1026123669535,
    "input_throughput": 4699.91603624751,
    "output_throughput": 4149.339785117599,
    "total_throughput": 8849.255821365108,
    "itl": 206.97266366320193,
    "ttft": 2224236.737401711,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.2502379840566613,
    "arrivals": 1857211,
    "finished_requests": 68635,
    "scheduler_time": 105.70209968492328
}
#Debug simulation 
Total elapsed time: 18.3810534379445. Arrivals time: 0.3197905379347503 Scheduler time: 17.947494812775403 Scheduler overhead time: 0.037035960238426924 Adapter cache time: 0.024674543645232916 Engine time: 0.03717780206352472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.390465480275452,
    "estimated_duration": 3600.084951521768,
    "input_throughput": 4699.187443576554,
    "output_throughput": 4148.840430469961,
    "total_throughput": 8848.027874046515,
    "itl": 206.9815379812822,
    "ttft": 2224254.367744094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.4683962565078463,
    "arrivals": 1857211,
    "finished_requests": 68628,
    "scheduler_time": 105.69587692561501
}
#Debug simulation 
Total elapsed time: 18.390583199914545. Arrivals time: 0.3198408489115536 Scheduler time: 17.955936348065734 Scheduler overhead time: 0.037623719312250614 Adapter cache time: 0.024182400200515985 Engine time: 0.0379469683393836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.687746031209826,
    "estimated_duration": 3600.0169112904846,
    "input_throughput": 4454.686295973897,
    "output_throughput": 3930.6654242708923,
    "total_throughput": 8385.35172024479,
    "itl": 178.1324912129556,
    "ttft": 2250658.1295945817,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.312972359396457,
    "arrivals": 1857211,
    "finished_requests": 64984,
    "scheduler_time": 109.67690737479964
}
#Debug simulation 
Total elapsed time: 10.687841046135873. Arrivals time: 0.27926089940592647 Scheduler time: 10.287844436708838 Scheduler overhead time: 0.035089829005301 Adapter cache time: 0.034976796712726355 Engine time: 0.034931355621665716 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 18.580783443059772,
    "estimated_duration": 3600.1726754506744,
    "input_throughput": 4699.824571020586,
    "output_throughput": 4149.259034673951,
    "total_throughput": 8849.083605694537,
    "itl": 206.97627042796387,
    "ttft": 2224262.0354882255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.3200761559139567,
    "arrivals": 1857211,
    "finished_requests": 68635,
    "scheduler_time": 105.70232459667359
}
#Debug simulation 
Total elapsed time: 18.580883120186627. Arrivals time: 0.3382143285125494 Scheduler time: 18.128333445172757 Scheduler overhead time: 0.03736406797543168 Adapter cache time: 0.024188019335269928 Engine time: 0.037777071818709373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 10.26882751332596,
    "estimated_duration": 3600.0872072540787,
    "input_throughput": 4454.599312951638,
    "output_throughput": 3930.588673376356,
    "total_throughput": 8385.187986327994,
    "itl": 178.13582139700853,
    "ttft": 2250684.638650314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.383142972215941,
    "arrivals": 1857211,
    "finished_requests": 64984,
    "scheduler_time": 109.67703272561515
}
#Debug simulation 
Total elapsed time: 10.268927277997136. Arrivals time: 0.28293859120458364 Scheduler time: 9.864472201094031 Scheduler overhead time: 0.03539250139147043 Adapter cache time: 0.03525407053530216 Engine time: 0.034994788467884064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.460153515916318,
    "estimated_duration": 3600.027614552057,
    "input_throughput": 4700.01394756116,
    "output_throughput": 4149.42622651485,
    "total_throughput": 8849.440174076011,
    "itl": 206.96871069452328,
    "ttft": 2224211.081504618,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1062,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 3.1754334131860347,
    "arrivals": 1857211,
    "finished_requests": 68635,
    "scheduler_time": 105.70190644074742
}
#Debug simulation 
Total elapsed time: 18.46032130997628. Arrivals time: 0.4523715949617326 Scheduler time: 17.894556265324354 Scheduler overhead time: 0.037099423818290234 Adapter cache time: 0.02463125390931964 Engine time: 0.03676043730229139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 270, 34560, 34560, 17280, 17280, 17280, 17280, 270, 17280, 270, 17280, 270, 17280, 17280, 34560, 17280, 34560, 34560, 270, 34560, 17280, 17280, 34560, 34560, 17280, 270, 270, 17280, 34560, 34560, 17280, 17280, 270, 270, 17280, 34560, 34560, 270, 34560, 17280, 270, 17280, 34560, 270, 17280, 34560, 34560, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 270, 270, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 34560, 17280, 270, 270, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 270, 34560, 17280, 34560, 34560, 17280, 270, 17280, 17280, 17280, 270, 34560, 17280, 34560, 270, 34560, 270, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 17280, 270, 17280, 270, 34560, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 17280, 270, 17280, 34560, 17280, 270, 270, 17280, 34560, 270, 270, 270, 34560, 34560, 34560, 270, 17280, 34560, 17280, 17280, 17280, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 270, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 17280, 270, 17280, 270, 270, 270, 34560, 34560, 17280, 17280, 270, 270, 17280, 270, 34560, 270, 270, 17280, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 270, 17280, 34560, 17280, 17280, 34560, 17280, 270, 17280, 270, 34560, 17280, 17280, 34560, 34560, 270, 270, 270, 34560, 34560, 270, 270, 34560, 17280, 270, 17280, 270, 17280, 34560, 34560, 34560, 270, 34560, 34560, 34560, 34560, 270, 17280, 17280, 34560, 270, 34560, 270, 270, 270, 34560, 17280, 34560, 34560, 270, 17280, 17280, 17280, 270, 17280, 270, 17280, 17280, 34560, 270, 270, 17280, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 17280, 17280, 17280, 17280, 270, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 270, 270, 34560, 270, 270, 34560, 34560, 34560, 270, 34560, 34560, 17280, 34560, 17280, 270, 34560, 270, 34560, 34560, 270, 270, 270]
Prompts retrieved: 5575500 . Total input tokens: 1241274911 . Total output tokens: 1115173761
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.320312488824129,
    "estimated_duration": 3600.1552462469313,
    "input_throughput": 4454.515125901335,
    "output_throughput": 3930.5143895534757,
    "total_throughput": 8385.029515454811,
    "itl": 178.13901052038463,
    "ttft": 2250710.9256524625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.451050016879953,
    "arrivals": 1857211,
    "finished_requests": 64984,
    "scheduler_time": 109.677164673842
}
#Debug simulation 
Total elapsed time: 10.320419936906546. Arrivals time: 0.30630247900262475 Scheduler time: 9.892129695042968 Scheduler overhead time: 0.035119437612593174 Adapter cache time: 0.03548645880073309 Engine time: 0.035512556321918964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 21.688257121946663,
    "estimated_duration": 3600.1358976593488,
    "input_throughput": 4822.895438832938,
    "output_throughput": 4203.296050529218,
    "total_throughput": 9026.191489362156,
    "itl": 202.53498160955638,
    "ttft": 2216467.0330934636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.573870192647499,
    "arrivals": 1852456,
    "finished_requests": 69839,
    "scheduler_time": 107.39991824642306
}
#Debug simulation 
Total elapsed time: 21.688350073061883. Arrivals time: 0.33018716564401984 Scheduler time: 21.243500276003033 Scheduler overhead time: 0.03935202118009329 Adapter cache time: 0.02015570318326354 Engine time: 0.03940656129270792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 23.318532006815076,
    "estimated_duration": 3600.0323904682905,
    "input_throughput": 4820.283296879645,
    "output_throughput": 4202.259135238536,
    "total_throughput": 9022.542432118182,
    "itl": 202.75068157681753,
    "ttft": 2215808.8168500923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 763,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.489383392096503,
    "arrivals": 1852456,
    "finished_requests": 69761,
    "scheduler_time": 107.33816520380564
}
#Debug simulation 
Total elapsed time: 23.318600550759584. Arrivals time: 0.8219482484273612 Scheduler time: 22.381778290029615 Scheduler overhead time: 0.04016903415322304 Adapter cache time: 0.019016385078430176 Engine time: 0.03980005858466029 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.164986740332097,
    "estimated_duration": 3600.071659115401,
    "input_throughput": 4548.349185922445,
    "output_throughput": 3971.8167730898626,
    "total_throughput": 8520.165959012307,
    "itl": 176.09912739458136,
    "ttft": 2244492.278776655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.52520405301819,
    "arrivals": 1852456,
    "finished_requests": 65908,
    "scheduler_time": 110.86816010046228
}
#Debug simulation 
Total elapsed time: 11.165084855165333. Arrivals time: 0.2830074508674443 Scheduler time: 10.762950387317687 Scheduler overhead time: 0.036272785160690546 Adapter cache time: 0.031073332764208317 Engine time: 0.035714379977434874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 22.29671521205455,
    "estimated_duration": 3600.194945692615,
    "input_throughput": 4822.816336869126,
    "output_throughput": 4203.227110827684,
    "total_throughput": 9026.04344769681,
    "itl": 202.53777887759367,
    "ttft": 2216488.4139179303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6327163450419673,
    "arrivals": 1852456,
    "finished_requests": 69839,
    "scheduler_time": 107.40012012721014
}
#Debug simulation 
Total elapsed time: 22.296852691099048. Arrivals time: 0.8473580894060433 Scheduler time: 21.33377919252962 Scheduler overhead time: 0.03995644999668002 Adapter cache time: 0.020660762675106525 Engine time: 0.039534234907478094 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.185914294794202,
    "estimated_duration": 3600.1288516150603,
    "input_throughput": 4548.276929769961,
    "output_throughput": 3971.7536758678452,
    "total_throughput": 8520.030605637805,
    "itl": 176.10178055890788,
    "ttft": 2244513.933879277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.582296272050568,
    "arrivals": 1852456,
    "finished_requests": 65908,
    "scheduler_time": 110.86826038111468
}
#Debug simulation 
Total elapsed time: 11.185977378860116. Arrivals time: 0.29483626084402204 Scheduler time: 10.772192846983671 Scheduler overhead time: 0.03603888629004359 Adapter cache time: 0.031049462500959635 Engine time: 0.03589928150177002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 22.207428524736315,
    "estimated_duration": 3600.0764864328366,
    "input_throughput": 4822.9750299567495,
    "output_throughput": 4203.365416548161,
    "total_throughput": 9026.34044650491,
    "itl": 202.532091954353,
    "ttft": 2216445.4839764335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 841,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5146322980126774,
    "arrivals": 1852456,
    "finished_requests": 69839,
    "scheduler_time": 107.39974491443415
}
#Debug simulation 
Total elapsed time: 22.207494447007775. Arrivals time: 0.8196539706550539 Scheduler time: 21.273965482134372 Scheduler overhead time: 0.039217214565724134 Adapter cache time: 0.020151414908468723 Engine time: 0.039092447608709335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 135, 34560, 34560, 17280, 17280, 17280, 17280, 135, 17280, 135, 17280, 135, 17280, 17280, 34560, 17280, 34560, 34560, 135, 34560, 17280, 17280, 34560, 34560, 17280, 135, 135, 17280, 34560, 34560, 17280, 17280, 135, 135, 17280, 34560, 34560, 135, 34560, 17280, 135, 17280, 34560, 135, 17280, 34560, 34560, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 135, 135, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 34560, 17280, 135, 135, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 135, 34560, 17280, 34560, 34560, 17280, 135, 17280, 17280, 17280, 135, 34560, 17280, 34560, 135, 34560, 135, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 17280, 135, 17280, 135, 34560, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 17280, 135, 17280, 34560, 17280, 135, 135, 17280, 34560, 135, 135, 135, 34560, 34560, 34560, 135, 17280, 34560, 17280, 17280, 17280, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 135, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 17280, 135, 17280, 135, 135, 135, 34560, 34560, 17280, 17280, 135, 135, 17280, 135, 34560, 135, 135, 17280, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 135, 17280, 34560, 17280, 17280, 34560, 17280, 135, 17280, 135, 34560, 17280, 17280, 34560, 34560, 135, 135, 135, 34560, 34560, 135, 135, 34560, 17280, 135, 17280, 135, 17280, 34560, 34560, 34560, 135, 34560, 34560, 34560, 34560, 135, 17280, 17280, 34560, 135, 34560, 135, 135, 135, 34560, 17280, 34560, 34560, 135, 17280, 17280, 17280, 135, 17280, 135, 17280, 17280, 34560, 135, 135, 17280, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 17280, 17280, 17280, 17280, 135, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 135, 135, 34560, 135, 135, 34560, 34560, 34560, 135, 34560, 34560, 17280, 34560, 17280, 135, 34560, 135, 34560, 34560, 135, 135, 135]
Prompts retrieved: 5561190 . Total input tokens: 1238053653 . Total output tokens: 1112294447
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.211908648256212,
    "estimated_duration": 3600.025049612889,
    "input_throughput": 4548.256963312153,
    "output_throughput": 3971.811529905197,
    "total_throughput": 8520.06849321735,
    "itl": 176.1045924605427,
    "ttft": 2244508.1156530012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.640771782733498,
    "arrivals": 1852456,
    "finished_requests": 65907,
    "scheduler_time": 110.86243018830487
}
#Debug simulation 
Total elapsed time: 11.212003745138645. Arrivals time: 0.28784621972590685 Scheduler time: 10.805651292204857 Scheduler overhead time: 0.0361186359077692 Adapter cache time: 0.03036515600979328 Engine time: 0.036040478851646185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.92142325313762,
    "estimated_duration": 3600.207058969749,
    "input_throughput": 4754.575978443419,
    "output_throughput": 4208.265455802859,
    "total_throughput": 8962.841434246278,
    "itl": 204.27023021244304,
    "ttft": 2225436.0261713783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.754438969539538,
    "arrivals": 1850068,
    "finished_requests": 69454,
    "scheduler_time": 107.06750261014933
}
#Debug simulation 
Total elapsed time: 18.921572625171393. Arrivals time: 0.32878632517531514 Scheduler time: 18.48217962682247 Scheduler overhead time: 0.037522188387811184 Adapter cache time: 0.02082257205620408 Engine time: 0.03697873651981354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.60485432576388,
    "estimated_duration": 3600.126758868369,
    "input_throughput": 4753.9298325650325,
    "output_throughput": 4207.2554702937905,
    "total_throughput": 8961.185302858823,
    "itl": 204.29263064931732,
    "ttft": 2225645.7467818246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 911,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.975221939496702,
    "arrivals": 1850068,
    "finished_requests": 69484,
    "scheduler_time": 107.03909816785756
}
#Debug simulation 
Total elapsed time: 18.60495508601889. Arrivals time: 0.33026428427547216 Scheduler time: 18.163826521020383 Scheduler overhead time: 0.03731444524601102 Adapter cache time: 0.0211610347032547 Engine time: 0.03710370557382703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.187465849798173,
    "estimated_duration": 3600.1817199955985,
    "input_throughput": 4447.145795745992,
    "output_throughput": 3937.2959762757005,
    "total_throughput": 8384.441772021692,
    "itl": 177.05444810485804,
    "ttft": 2245912.9567156695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.220893625132675,
    "arrivals": 1850068,
    "finished_requests": 64941,
    "scheduler_time": 110.0605003433601
}
#Debug simulation 
Total elapsed time: 10.187558856792748. Arrivals time: 0.2785191726870835 Scheduler time: 9.790796014945954 Scheduler overhead time: 0.03522420022636652 Adapter cache time: 0.029338963329792023 Engine time: 0.03514999710023403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 18.83447860972956,
    "estimated_duration": 3600.044890519034,
    "input_throughput": 4754.384881443051,
    "output_throughput": 4208.073638163958,
    "total_throughput": 8962.45851960701,
    "itl": 204.27161593857838,
    "ttft": 2225428.480020424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8181184094468796,
    "arrivals": 1850068,
    "finished_requests": 69448,
    "scheduler_time": 107.06110137981001
}
#Debug simulation 
Total elapsed time: 18.834642722737044. Arrivals time: 0.32380891777575016 Scheduler time: 18.399732523132116 Scheduler overhead time: 0.0376059771515429 Adapter cache time: 0.020919007249176502 Engine time: 0.03725463151931763 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 10.275939454790205,
    "estimated_duration": 3600.039285953721,
    "input_throughput": 4447.321467426291,
    "output_throughput": 3937.282866690976,
    "total_throughput": 8384.604334117266,
    "itl": 177.05669590723133,
    "ttft": 2245907.1086176326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.275470768436778,
    "arrivals": 1850068,
    "finished_requests": 64940,
    "scheduler_time": 110.05459326560582
}
#Debug simulation 
Total elapsed time: 10.276032832916826. Arrivals time: 0.2975850091315806 Scheduler time: 9.864052512217313 Scheduler overhead time: 0.035108862444758415 Adapter cache time: 0.028342206496745348 Engine time: 0.03510318649932742 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 19.101926454808563,
    "estimated_duration": 3600.143466383777,
    "input_throughput": 4754.659962813624,
    "output_throughput": 4208.339790196832,
    "total_throughput": 8962.999753010456,
    "itl": 204.26694996264882,
    "ttft": 2225412.642028385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 900,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6910452654118995,
    "arrivals": 1850068,
    "finished_requests": 69454,
    "scheduler_time": 107.06730372818558
}
#Debug simulation 
Total elapsed time: 19.10202570585534. Arrivals time: 0.45531293004751205 Scheduler time: 18.535784034989774 Scheduler overhead time: 0.03687237622216344 Adapter cache time: 0.021426770370453596 Engine time: 0.03752846736460924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 66, 34560, 34560, 17280, 17280, 17280, 17280, 66, 17280, 66, 17280, 66, 17280, 17280, 34560, 17280, 34560, 34560, 66, 34560, 17280, 17280, 34560, 34560, 17280, 66, 66, 17280, 34560, 34560, 17280, 17280, 66, 66, 17280, 34560, 34560, 66, 34560, 17280, 66, 17280, 34560, 66, 17280, 34560, 34560, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 66, 66, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 34560, 17280, 66, 66, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 66, 34560, 17280, 34560, 34560, 17280, 66, 17280, 17280, 17280, 66, 34560, 17280, 34560, 66, 34560, 66, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 17280, 66, 17280, 66, 34560, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 17280, 66, 17280, 34560, 17280, 66, 66, 17280, 34560, 66, 66, 66, 34560, 34560, 34560, 66, 17280, 34560, 17280, 17280, 17280, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 66, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 17280, 66, 17280, 66, 66, 66, 34560, 34560, 17280, 17280, 66, 66, 17280, 66, 34560, 66, 66, 17280, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 66, 17280, 34560, 17280, 17280, 34560, 17280, 66, 17280, 66, 34560, 17280, 17280, 34560, 34560, 66, 66, 66, 34560, 34560, 66, 66, 34560, 17280, 66, 17280, 66, 17280, 34560, 34560, 34560, 66, 34560, 34560, 34560, 34560, 66, 17280, 17280, 34560, 66, 34560, 66, 66, 66, 34560, 17280, 34560, 34560, 66, 17280, 17280, 17280, 66, 17280, 66, 17280, 17280, 34560, 66, 66, 17280, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 17280, 17280, 17280, 17280, 66, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 66, 66, 34560, 66, 66, 34560, 34560, 34560, 66, 34560, 34560, 17280, 34560, 17280, 66, 34560, 66, 34560, 34560, 66, 66, 66]
Prompts retrieved: 5553876 . Total input tokens: 1236376758 . Total output tokens: 1110845870
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.359627296216786,
    "estimated_duration": 3600.094744170049,
    "input_throughput": 4447.252957974861,
    "output_throughput": 3937.22221420806,
    "total_throughput": 8384.47517218292,
    "itl": 177.05925363100877,
    "ttft": 2245928.951527726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.33080243445936,
    "arrivals": 1850068,
    "finished_requests": 64940,
    "scheduler_time": 110.05471981595066
}
#Debug simulation 
Total elapsed time: 10.359744450077415. Arrivals time: 0.4179887999780476 Scheduler time: 9.82683111494407 Scheduler overhead time: 0.03503148816525936 Adapter cache time: 0.02813260955736041 Engine time: 0.03580000111833215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.593058255966753,
    "estimated_duration": 3600.16301254626,
    "input_throughput": 4754.627760006201,
    "output_throughput": 4208.029177346963,
    "total_throughput": 8962.656937353164,
    "itl": 204.10395693781848,
    "ttft": 2223513.8768988405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4820555603295134,
    "arrivals": 1848950,
    "finished_requests": 69297,
    "scheduler_time": 107.1974434398528
}
#Debug simulation 
Total elapsed time: 18.593200576025993. Arrivals time: 0.3378502447158098 Scheduler time: 18.147250928450376 Scheduler overhead time: 0.037175577599555254 Adapter cache time: 0.018909804988652468 Engine time: 0.036909155547618866 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 18.662150448188186,
    "estimated_duration": 3600.0880694775456,
    "input_throughput": 4754.149806808428,
    "output_throughput": 4208.002056515937,
    "total_throughput": 8962.151863324365,
    "itl": 204.1134672905546,
    "ttft": 2223458.791320796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.6492496189894217,
    "arrivals": 1848950,
    "finished_requests": 69292,
    "scheduler_time": 107.19103079040872
}
#Debug simulation 
Total elapsed time: 18.66224781330675. Arrivals time: 0.33189617237076163 Scheduler time: 18.220186164602637 Scheduler overhead time: 0.03781582461670041 Adapter cache time: 0.019374916795641184 Engine time: 0.03758428944274783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.224834349006414,
    "estimated_duration": 3600.1810657888013,
    "input_throughput": 4459.390154723351,
    "output_throughput": 3959.815281367381,
    "total_throughput": 8419.205436090731,
    "itl": 176.2832445972978,
    "ttft": 2249076.331141358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.530928969029275,
    "arrivals": 1848950,
    "finished_requests": 65012,
    "scheduler_time": 110.66881708284392
}
#Debug simulation 
Total elapsed time: 10.22493556002155. Arrivals time: 0.2834700741805136 Scheduler time: 9.823406003415585 Scheduler overhead time: 0.035563953686505556 Adapter cache time: 0.030965421814471483 Engine time: 0.03551491862162948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 18.651256358250976,
    "estimated_duration": 3600.2180330178085,
    "input_throughput": 4754.555097223282,
    "output_throughput": 4207.964867978057,
    "total_throughput": 8962.519965201338,
    "itl": 204.10669212806854,
    "ttft": 2223535.6096918136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.5368859064182976,
    "arrivals": 1848950,
    "finished_requests": 69297,
    "scheduler_time": 107.1976335652524
}
#Debug simulation 
Total elapsed time: 18.65143187623471. Arrivals time: 0.32355334190651774 Scheduler time: 18.218736436218023 Scheduler overhead time: 0.03745149169117212 Adapter cache time: 0.01915376214310527 Engine time: 0.037245411425828934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 10.265299511142075,
    "estimated_duration": 3600.041006649715,
    "input_throughput": 4459.297816426796,
    "output_throughput": 3959.7454511403675,
    "total_throughput": 8419.043267567164,
    "itl": 176.28595484193556,
    "ttft": 2249061.2759155044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.590033248644298,
    "arrivals": 1848950,
    "finished_requests": 65008,
    "scheduler_time": 110.66286431267183
}
#Debug simulation 
Total elapsed time: 10.265394142828882. Arrivals time: 0.2949029025621712 Scheduler time: 9.851925093214959 Scheduler overhead time: 0.0354506722651422 Adapter cache time: 0.031122714281082153 Engine time: 0.035928267519921064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 18.700892403256148,
    "estimated_duration": 3600.1056814561334,
    "input_throughput": 4754.703476670306,
    "output_throughput": 4208.096189518651,
    "total_throughput": 8962.799666188957,
    "itl": 204.10109736567875,
    "ttft": 2223491.0689401245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 811,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4249307891656153,
    "arrivals": 1848950,
    "finished_requests": 69297,
    "scheduler_time": 107.19723712080719
}
#Debug simulation 
Total elapsed time: 18.70098818698898. Arrivals time: 0.45925718545913696 Scheduler time: 18.133544340729713 Scheduler overhead time: 0.0371265085414052 Adapter cache time: 0.01893139723688364 Engine time: 0.03717953711748123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_320_slots_128_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [106 107 107]
Adapter prompts. [17280, 34560, 34560, 33, 34560, 34560, 17280, 17280, 17280, 17280, 33, 17280, 33, 17280, 33, 17280, 17280, 34560, 17280, 34560, 34560, 33, 34560, 17280, 17280, 34560, 34560, 17280, 33, 33, 17280, 34560, 34560, 17280, 17280, 33, 33, 17280, 34560, 34560, 33, 34560, 17280, 33, 17280, 34560, 33, 17280, 34560, 34560, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 33, 33, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 34560, 17280, 33, 33, 17280, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 33, 34560, 17280, 34560, 34560, 17280, 33, 17280, 17280, 17280, 33, 34560, 17280, 34560, 33, 34560, 33, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 17280, 33, 17280, 33, 34560, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 17280, 33, 17280, 34560, 17280, 33, 33, 17280, 34560, 33, 33, 33, 34560, 34560, 34560, 33, 17280, 34560, 17280, 17280, 17280, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 33, 17280, 34560, 34560, 34560, 34560, 17280, 17280, 34560, 34560, 34560, 17280, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 17280, 33, 17280, 33, 33, 33, 34560, 34560, 17280, 17280, 33, 33, 17280, 33, 34560, 33, 33, 17280, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 33, 17280, 34560, 17280, 17280, 34560, 17280, 33, 17280, 33, 34560, 17280, 17280, 34560, 34560, 33, 33, 33, 34560, 34560, 33, 33, 34560, 17280, 33, 17280, 33, 17280, 34560, 34560, 34560, 33, 34560, 34560, 34560, 34560, 33, 17280, 17280, 34560, 33, 34560, 33, 33, 33, 34560, 17280, 34560, 34560, 33, 17280, 17280, 17280, 33, 17280, 33, 17280, 17280, 34560, 33, 33, 17280, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 17280, 17280, 17280, 17280, 33, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 17280, 17280, 17280, 33, 33, 34560, 33, 33, 34560, 34560, 34560, 33, 34560, 34560, 17280, 34560, 17280, 33, 34560, 33, 34560, 34560, 33, 33, 33]
Prompts retrieved: 5550378 . Total input tokens: 1235586938 . Total output tokens: 1110148840
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 10.189925691578537,
    "estimated_duration": 3600.1008570121853,
    "input_throughput": 4459.22368222854,
    "output_throughput": 3959.6796218178147,
    "total_throughput": 8418.903304046355,
    "itl": 176.28872142412118,
    "ttft": 2249083.1915292363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1384,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 4.649766297191381,
    "arrivals": 1848950,
    "finished_requests": 65008,
    "scheduler_time": 110.6629816266408
}
#Debug simulation 
Total elapsed time: 10.190039660781622. Arrivals time: 0.280595020391047 Scheduler time: 9.7917474755086 Scheduler overhead time: 0.03548099519684911 Adapter cache time: 0.030776601284742355 Engine time: 0.0355090550146997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 21.391985272057354,
    "estimated_duration": 3600.165115028856,
    "input_throughput": 4645.692201777236,
    "output_throughput": 4082.252210780117,
    "total_throughput": 8727.944412557352,
    "itl": 209.82455548091403,
    "ttft": 2224300.94230143,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 919,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8125882366742623,
    "arrivals": 1692537,
    "finished_requests": 67337,
    "scheduler_time": 103.99726258569753
}
#Debug simulation 
Total elapsed time: 21.392123732250184. Arrivals time: 0.3434112728573382 Scheduler time: 20.934953299351037 Scheduler overhead time: 0.03746517514809966 Adapter cache time: 0.02416908321902156 Engine time: 0.037264879792928696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 21.29102479899302,
    "estimated_duration": 3600.0773839688436,
    "input_throughput": 4643.71129199724,
    "output_throughput": 4078.052617806467,
    "total_throughput": 8721.763909803707,
    "itl": 209.74257433838775,
    "ttft": 2224751.699955496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 903,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9476241792715223,
    "arrivals": 1692537,
    "finished_requests": 67316,
    "scheduler_time": 103.99900381505721
}
#Debug simulation 
Total elapsed time: 21.29111931612715. Arrivals time: 0.33784390380606055 Scheduler time: 20.837877064943314 Scheduler overhead time: 0.03799954382702708 Adapter cache time: 0.024022304452955723 Engine time: 0.03823059005662799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.872916606720537,
    "estimated_duration": 3600.0176403228234,
    "input_throughput": 4441.473236382861,
    "output_throughput": 3909.0550119465706,
    "total_throughput": 8350.528248329432,
    "itl": 178.10177906747802,
    "ttft": 2244611.661204382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.1750354343093425,
    "arrivals": 1692537,
    "finished_requests": 64404,
    "scheduler_time": 109.33014656234457
}
#Debug simulation 
Total elapsed time: 11.873009520117193. Arrivals time: 0.2869281037710607 Scheduler time: 11.460455923806876 Scheduler overhead time: 0.03613254940137267 Adapter cache time: 0.03761751810088754 Engine time: 0.03595900163054466 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 21.290306761860847,
    "estimated_duration": 3600.006649321214,
    "input_throughput": 4645.62919714423,
    "output_throughput": 4082.0110714992184,
    "total_throughput": 8727.640268643449,
    "itl": 209.82786550063332,
    "ttft": 2224234.700300005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 919,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.8781981275975443,
    "arrivals": 1692537,
    "finished_requests": 67331,
    "scheduler_time": 103.99091011378275
}
#Debug simulation 
Total elapsed time: 21.29045605286956. Arrivals time: 0.321695105638355 Scheduler time: 20.853902153205127 Scheduler overhead time: 0.03800344280898571 Adapter cache time: 0.02418802911415696 Engine time: 0.03754623560234904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_320_slots_128_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.89758505532518,
    "estimated_duration": 3600.0847671316674,
    "input_throughput": 4441.390421131496,
    "output_throughput": 3908.9821241104446,
    "total_throughput": 8350.37254524194,
    "itl": 178.10494129874743,
    "ttft": 2244635.861359957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.242062202468459,
    "arrivals": 1692537,
    "finished_requests": 64404,
    "scheduler_time": 109.3302466030911
}
#Debug simulation 
Total elapsed time: 11.897704349365085. Arrivals time: 0.3052408737130463 Scheduler time: 11.465574700385332 Scheduler overhead time: 0.03626074129715562 Adapter cache time: 0.037943809758871794 Engine time: 0.03646558290347457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_320_slots_128_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 21.447870850097388,
    "estimated_duration": 3600.1001950470804,
    "input_throughput": 4645.775976738135,
    "output_throughput": 4082.3258253254817,
    "total_throughput": 8728.101802063617,
    "itl": 209.82118526687213,
    "ttft": 2224276.4383257246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 919,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.747856221015039,
    "arrivals": 1692537,
    "finished_requests": 67337,
    "scheduler_time": 103.99707461945074
}
#Debug simulation 
Total elapsed time: 21.447963878978044. Arrivals time: 0.3215398881584406 Scheduler time: 21.011962374206632 Scheduler overhead time: 0.03802083991467953 Adapter cache time: 0.023914350662380457 Engine time: 0.03738594800233841 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_320_slots_128_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 4320, 34560, 34560, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 4320, 34560, 8640, 8640, 34560, 34560, 8640, 4320, 4320, 8640, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 34560, 34560, 4320, 34560, 8640, 4320, 8640, 34560, 4320, 8640, 34560, 34560, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 4320, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 4320, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 4320, 34560, 8640, 34560, 34560, 8640, 4320, 8640, 8640, 8640, 4320, 34560, 8640, 34560, 4320, 34560, 4320, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 8640, 4320, 8640, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 4320, 4320, 34560, 34560, 34560, 4320, 8640, 34560, 8640, 8640, 8640, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 8640, 4320, 8640, 4320, 4320, 4320, 34560, 34560, 8640, 8640, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 8640, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 4320, 8640, 34560, 8640, 8640, 34560, 8640, 4320, 8640, 4320, 34560, 8640, 8640, 34560, 34560, 4320, 4320, 4320, 34560, 34560, 4320, 4320, 34560, 8640, 4320, 8640, 4320, 8640, 34560, 34560, 34560, 4320, 34560, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 4320, 34560, 4320, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 8640, 8640, 8640, 4320, 8640, 4320, 8640, 8640, 34560, 4320, 4320, 8640, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 8640, 8640, 8640, 8640, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 4320, 4320, 34560, 4320, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 34560, 34560, 4320, 4320, 4320]
Prompts retrieved: 5080320 . Total input tokens: 1131055520 . Total output tokens: 1016056051
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.842862021643668,
    "estimated_duration": 3600.1510422128094,
    "input_throughput": 4441.308659697853,
    "output_throughput": 3908.910163766442,
    "total_throughput": 8350.218823464294,
    "itl": 178.1079732253698,
    "ttft": 2244660.2509508487,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.308208694122665,
    "arrivals": 1692537,
    "finished_requests": 64404,
    "scheduler_time": 109.33037519263581
}
#Debug simulation 
Total elapsed time: 11.842977466993034. Arrivals time: 0.2841788846999407 Scheduler time: 11.430180407129228 Scheduler overhead time: 0.038969848304986954 Adapter cache time: 0.037550066132098436 Engine time: 0.03617025865241885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 320,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_320_slots_128_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [106 107 107]
Adapter prompts. [8640, 34560, 34560, 1080, 34560, 34560, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 1080, 34560, 8640, 8640, 34560, 34560, 8640, 1080, 1080, 8640, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 34560, 34560, 1080, 34560, 8640, 1080, 8640, 34560, 1080, 8640, 34560, 34560, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 1080, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 1080, 8640, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 1080, 34560, 8640, 34560, 34560, 8640, 1080, 8640, 8640, 8640, 1080, 34560, 8640, 34560, 1080, 34560, 1080, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 8640, 1080, 8640, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 1080, 1080, 34560, 34560, 34560, 1080, 8640, 34560, 8640, 8640, 8640, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 34560, 8640, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 8640, 1080, 8640, 1080, 1080, 1080, 34560, 34560, 8640, 8640, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 8640, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 1080, 8640, 34560, 8640, 8640, 34560, 8640, 1080, 8640, 1080, 34560, 8640, 8640, 34560, 34560, 1080, 1080, 1080, 34560, 34560, 1080, 1080, 34560, 8640, 1080, 8640, 1080, 8640, 34560, 34560, 34560, 1080, 34560, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 1080, 34560, 1080, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 8640, 8640, 8640, 1080, 8640, 1080, 8640, 8640, 34560, 1080, 1080, 8640, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 8640, 8640, 8640, 8640, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 8640, 8640, 8640, 1080, 1080, 34560, 1080, 1080, 34560, 34560, 34560, 1080, 34560, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 34560, 34560, 1080, 1080, 1080]
Prompts retrieved: 4736880 . Total input tokens: 1054592875 . Total output tokens: 947295802
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 16.921812146902084,
    "estimated_duration": 3600.033718458425,
    "input_throughput": 4618.7247954777795,
    "output_throughput": 4078.7484641359683,
    "total_throughput": 8697.473259613747,
    "itl": 210.16073458200233,
    "ttft": 2220154.381722155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 960,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.9380682341755096,
    "arrivals": 1577546,
    "finished_requests": 67464,
    "scheduler_time": 103.88444431214256
}
#Debug simulation 
Total elapsed time: 16.921948119066656. Arrivals time: 0.5275057945400476 Scheduler time: 16.284231988247484 Scheduler overhead time: 0.035195829812437296 Adapter cache time: 0.025013616774231195 Engine time: 0.0353948762640357 
