INFO 06-01 00:47:15 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:16 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 164.6425001830794,
    "estimated_duration": 3600.0921928769685,
    "input_throughput": 7396.761408690412,
    "output_throughput": 6545.5579294953095,
    "total_throughput": 13942.319338185722,
    "itl": 103.00014550337941,
    "ttft": 1601464.5958208777,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2537619409267784,
    "arrivals": 252137,
    "finished_requests": 107018,
    "scheduler_time": 284.31837133974284
}
#Debug simulation 
Total elapsed time: 164.64273728104308. Arrivals time: 0.9501592465676367 Scheduler time: 163.27416926249862 Scheduler overhead time: 0.1720306989736855 Adapter cache time: 0.03526657819747925 Engine time: 0.16320226388052106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 164.4630137057975,
    "estimated_duration": 3600.064941915889,
    "input_throughput": 7396.401573197542,
    "output_throughput": 6545.112207742644,
    "total_throughput": 13941.513780940188,
    "itl": 103.00189189099594,
    "ttft": 1601548.8292014524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.3286103968322325,
    "arrivals": 252137,
    "finished_requests": 107013,
    "scheduler_time": 284.3120001613386
}
#Debug simulation 
Total elapsed time: 164.46323616988957. Arrivals time: 0.9580895989201963 Scheduler time: 163.08755517192185 Scheduler overhead time: 0.1719909878447652 Adapter cache time: 0.03516260953620076 Engine time: 0.16189588885754347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 165.69936214899644,
    "estimated_duration": 3600.0369510986866,
    "input_throughput": 7396.874910373671,
    "output_throughput": 6545.658369647671,
    "total_throughput": 13942.533280021342,
    "itl": 102.99950435660422,
    "ttft": 1601442.469322148,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 401,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1990101682557668,
    "arrivals": 252137,
    "finished_requests": 107018,
    "scheduler_time": 284.31768125695027
}
#Debug simulation 
Total elapsed time: 165.6995491744019. Arrivals time: 0.974290182814002 Scheduler time: 164.31423986051232 Scheduler overhead time: 0.17032170947641134 Adapter cache time: 0.035804253071546555 Engine time: 0.15895209042355418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 8640, 33, 8640, 8640, 33, 8640, 135, 8640, 33, 135, 33, 8640, 135, 135, 135, 135, 8640, 33, 33, 33, 135, 8640, 33, 8640, 8640, 135, 135, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 33, 135, 135, 8640, 135, 33, 135, 8640, 135, 135, 8640, 135, 8640, 33, 8640, 8640, 135, 33, 33, 8640, 135, 33, 135, 135, 8640, 135, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 8640, 8640, 33, 8640, 33, 135, 8640, 8640, 8640, 135, 33, 8640, 135, 33, 33, 33, 33, 33, 8640, 135, 33, 8640, 33, 8640, 33, 33, 135, 135, 8640, 135, 8640, 33, 135, 33, 8640, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 33, 135, 8640, 8640, 33, 8640, 135, 33, 135, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 135, 8640, 8640, 135, 33, 8640, 33, 135, 135, 33, 135, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 135, 8640, 135, 33, 135, 8640, 135, 8640, 33, 8640, 33, 135, 8640, 135, 8640, 135, 8640, 135, 8640, 135, 33, 8640, 33, 8640, 135, 135, 33, 135, 8640, 135, 135, 8640, 33, 8640, 8640, 135, 33, 8640, 8640, 135, 135, 8640, 8640, 135, 135, 135, 135, 8640, 8640, 135, 135, 8640, 33, 8640, 135, 8640, 8640, 33, 8640, 135, 135, 8640, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 8640, 135, 33, 33, 33, 33]
Prompts retrieved: 757320 . Total input tokens: 168812283 . Total output tokens: 151525896
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 169.32247797818854,
    "estimated_duration": 3600.010788872215,
    "input_throughput": 7396.3614448893095,
    "output_throughput": 6552.933972564649,
    "total_throughput": 13949.295417453959,
    "itl": 103.8619591547579,
    "ttft": 1602621.9064497277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 385,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2925980911031387,
    "arrivals": 252137,
    "finished_requests": 107044,
    "scheduler_time": 284.04854367569453
}
#Debug simulation 
Total elapsed time: 169.32281235605478. Arrivals time: 0.9722185558639467 Scheduler time: 167.93238997925073 Scheduler overhead time: 0.17274466762319207 Adapter cache time: 0.03532246919348836 Engine time: 0.16279781656339765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 162.89524303842336,
    "estimated_duration": 3600.0557263287587,
    "input_throughput": 7400.378501131863,
    "output_throughput": 6523.821792045015,
    "total_throughput": 13924.200293176878,
    "itl": 103.34835115786255,
    "ttft": 1604753.7520145783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1109570510475921,
    "arrivals": 250206,
    "finished_requests": 107499,
    "scheduler_time": 284.25975727297316
}
#Debug simulation 
Total elapsed time: 162.89540846413. Arrivals time: 0.9626064458861947 Scheduler time: 161.52017971407622 Scheduler overhead time: 0.17400450725108385 Adapter cache time: 0.034609292168170214 Engine time: 0.1586044542491436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 164.2180296741426,
    "estimated_duration": 3600.132197187937,
    "input_throughput": 7400.221308764686,
    "output_throughput": 6523.683218728748,
    "total_throughput": 13923.904527493434,
    "itl": 103.34976373044837,
    "ttft": 1604785.6316861457,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1854941100673815,
    "arrivals": 250206,
    "finished_requests": 107499,
    "scheduler_time": 284.2610908416222
}
#Debug simulation 
Total elapsed time: 164.2181980391033. Arrivals time: 0.949340901337564 Scheduler time: 162.85460041463375 Scheduler overhead time: 0.1749843591824174 Adapter cache time: 0.03283735224977136 Engine time: 0.16031728871166706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 161.93923072703183,
    "estimated_duration": 3600.000151445718,
    "input_throughput": 7400.386910900858,
    "output_throughput": 6523.706947781255,
    "total_throughput": 13924.093858682114,
    "itl": 103.34914875028117,
    "ttft": 1604786.4194578687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.187422978263355,
    "arrivals": 250206,
    "finished_requests": 107496,
    "scheduler_time": 284.2517556194849
}
#Debug simulation 
Total elapsed time: 161.93942784704268. Arrivals time: 0.9643679521977901 Scheduler time: 160.57276136195287 Scheduler overhead time: 0.16723030898720026 Adapter cache time: 0.033626739867031574 Engine time: 0.1556296139024198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 163.69590607797727,
    "estimated_duration": 3600.0793448884883,
    "input_throughput": 7400.329950457029,
    "output_throughput": 6523.778992078709,
    "total_throughput": 13924.108942535737,
    "itl": 103.34876604427876,
    "ttft": 1604763.4629965767,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1340110999438928,
    "arrivals": 250206,
    "finished_requests": 107499,
    "scheduler_time": 284.26022174518107
}
#Debug simulation 
Total elapsed time: 163.69611235894263. Arrivals time: 0.9561330182477832 Scheduler time: 162.33347502350807 Scheduler overhead time: 0.16794588835909963 Adapter cache time: 0.03376298490911722 Engine time: 0.1562714665196836 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 164.8870273041539,
    "estimated_duration": 3600.016246210663,
    "input_throughput": 7400.353825636879,
    "output_throughput": 6523.677781932349,
    "total_throughput": 13924.031607569228,
    "itl": 103.34944918326521,
    "ttft": 1604793.1278133611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 363,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2032679553516252,
    "arrivals": 250206,
    "finished_requests": 107496,
    "scheduler_time": 284.2520054073458
}
#Debug simulation 
Total elapsed time: 164.8872083518654. Arrivals time: 0.9729544902220368 Scheduler time: 163.4945141612552 Scheduler overhead time: 0.1765888244844973 Adapter cache time: 0.034723708871752024 Engine time: 0.16206841077655554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 170.19870732259005,
    "estimated_duration": 3600.070189846146,
    "input_throughput": 7395.412754754599,
    "output_throughput": 6526.698581119653,
    "total_throughput": 13922.111335874251,
    "itl": 104.08642104142056,
    "ttft": 1604167.3641982928,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 380,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1362191120628233,
    "arrivals": 250206,
    "finished_requests": 107444,
    "scheduler_time": 284.3497130808583
}
#Debug simulation 
Total elapsed time: 170.19889311073348. Arrivals time: 0.9543403824791312 Scheduler time: 168.83057668153197 Scheduler overhead time: 0.17244465555995703 Adapter cache time: 0.035384843591600657 Engine time: 0.15892674075439572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 8640, 33, 8640, 8640, 33, 8640, 66, 8640, 33, 66, 33, 8640, 66, 66, 66, 66, 8640, 33, 33, 33, 66, 8640, 33, 8640, 8640, 66, 66, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 33, 66, 66, 8640, 66, 33, 66, 8640, 66, 66, 8640, 66, 8640, 33, 8640, 8640, 66, 33, 33, 8640, 66, 33, 66, 66, 8640, 66, 33, 33, 8640, 8640, 8640, 8640, 8640, 8640, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 8640, 8640, 33, 8640, 33, 66, 8640, 8640, 8640, 66, 33, 8640, 66, 33, 33, 33, 33, 33, 8640, 66, 33, 8640, 33, 8640, 33, 33, 66, 66, 8640, 66, 8640, 33, 66, 33, 8640, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 33, 66, 8640, 8640, 33, 8640, 66, 33, 66, 8640, 33, 33, 33, 33, 33, 33, 8640, 33, 33, 33, 8640, 33, 66, 8640, 8640, 66, 33, 8640, 33, 66, 66, 33, 66, 33, 8640, 33, 33, 8640, 33, 8640, 8640, 66, 8640, 66, 33, 66, 8640, 66, 8640, 33, 8640, 33, 66, 8640, 66, 8640, 66, 8640, 66, 8640, 66, 33, 8640, 33, 8640, 66, 66, 33, 66, 8640, 66, 66, 8640, 33, 8640, 8640, 66, 33, 8640, 8640, 66, 66, 8640, 8640, 66, 66, 66, 66, 8640, 8640, 66, 66, 8640, 33, 8640, 66, 8640, 8640, 33, 8640, 66, 66, 8640, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 8640, 66, 33, 33, 33, 33]
Prompts retrieved: 751455 . Total input tokens: 167503193 . Total output tokens: 150337789
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 174.44566446868703,
    "estimated_duration": 3600.0467370042725,
    "input_throughput": 7397.742014361074,
    "output_throughput": 6519.737301947184,
    "total_throughput": 13917.47931630826,
    "itl": 104.02959368137302,
    "ttft": 1611316.0920507826,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 358,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.2016260578483373,
    "arrivals": 250206,
    "finished_requests": 107326,
    "scheduler_time": 284.8146476473449
}
#Debug simulation 
Total elapsed time: 174.44584476482123. Arrivals time: 0.9771363013423979 Scheduler time: 173.03318009944633 Scheduler overhead time: 0.18002266576513648 Adapter cache time: 0.03674702998250723 Engine time: 0.17006155382841825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 143.16085668373853,
    "estimated_duration": 3600.107576895285,
    "input_throughput": 6834.832147216058,
    "output_throughput": 6095.6525690616345,
    "total_throughput": 12930.484716277691,
    "itl": 88.41807824924675,
    "ttft": 1433191.2267393186,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8944419134944044,
    "arrivals": 169450,
    "finished_requests": 99560,
    "scheduler_time": 289.52374280653197
}
#Debug simulation 
Total elapsed time: 143.16105112573132. Arrivals time: 0.8585298880934715 Scheduler time: 141.91340333176777 Scheduler overhead time: 0.16128886863589287 Adapter cache time: 0.03435632027685642 Engine time: 0.1469074096530676 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 144.20831331191584,
    "estimated_duration": 3600.060475407505,
    "input_throughput": 6858.505341415168,
    "output_throughput": 6133.754182976736,
    "total_throughput": 12992.259524391904,
    "itl": 88.19932277850367,
    "ttft": 1426725.893504837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9996077206987015,
    "arrivals": 169450,
    "finished_requests": 99861,
    "scheduler_time": 289.0547378659864
}
#Debug simulation 
Total elapsed time: 144.20853526191786. Arrivals time: 0.8688143971376121 Scheduler time: 142.95110160438344 Scheduler overhead time: 0.15995423775166273 Adapter cache time: 0.034785833675414324 Engine time: 0.14717399422079325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 145.0732659092173,
    "estimated_duration": 3600.06423274569,
    "input_throughput": 6858.498183286216,
    "output_throughput": 6133.747781260733,
    "total_throughput": 12992.24596454695,
    "itl": 88.19930623329613,
    "ttft": 1426727.6768404653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0032740320637945,
    "arrivals": 169450,
    "finished_requests": 99861,
    "scheduler_time": 289.05492893136454
}
#Debug simulation 
Total elapsed time: 145.07345751812682. Arrivals time: 0.8555609048344195 Scheduler time: 143.82797735230997 Scheduler overhead time: 0.16298746643587947 Adapter cache time: 0.03513910202309489 Engine time: 0.14592781197279692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 148.36519855167717,
    "estimated_duration": 3600.0969598431293,
    "input_throughput": 6858.566387355275,
    "output_throughput": 6133.726465234481,
    "total_throughput": 12992.292852589757,
    "itl": 88.19823291364489,
    "ttft": 1426756.549033935,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9158456804184125,
    "arrivals": 169450,
    "finished_requests": 99862,
    "scheduler_time": 289.0633430674281
}
#Debug simulation 
Total elapsed time: 148.36538072489202. Arrivals time: 0.8755060010589659 Scheduler time: 147.08703616727144 Scheduler overhead time: 0.1663731848821044 Adapter cache time: 0.03606392303481698 Engine time: 0.15122506255283952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 142.24328072741628,
    "estimated_duration": 3600.0946492747453,
    "input_throughput": 6794.533583978901,
    "output_throughput": 6058.427381733951,
    "total_throughput": 12852.960965712851,
    "itl": 87.41369094717335,
    "ttft": 1440858.896723169,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0260100394301146,
    "arrivals": 169450,
    "finished_requests": 98985,
    "scheduler_time": 291.5286297481271
}
#Debug simulation 
Total elapsed time: 142.24349911417812. Arrivals time: 0.8763882876373827 Scheduler time: 140.97657020855695 Scheduler overhead time: 0.16045089019462466 Adapter cache time: 0.03461598604917526 Engine time: 0.1475084493868053 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 146.7446363028139,
    "estimated_duration": 3600.061749901621,
    "input_throughput": 6858.633466682827,
    "output_throughput": 6133.786455358282,
    "total_throughput": 12992.419922041108,
    "itl": 88.19562582760128,
    "ttft": 1426747.7199462836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8329008307750054,
    "arrivals": 169450,
    "finished_requests": 99862,
    "scheduler_time": 289.06935141897304
}
#Debug simulation 
Total elapsed time: 146.74484133906662. Arrivals time: 0.8433113442733884 Scheduler time: 145.51732803042978 Scheduler overhead time: 0.1594976452179253 Adapter cache time: 0.033735901582986116 Engine time: 0.1442389297299087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 540, 4320, 4320, 540, 4320, 1080, 4320, 540, 1080, 540, 4320, 1080, 1080, 1080, 1080, 4320, 540, 540, 540, 1080, 4320, 540, 4320, 4320, 1080, 1080, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 540, 1080, 1080, 4320, 1080, 540, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 540, 4320, 4320, 1080, 540, 540, 4320, 1080, 540, 1080, 1080, 4320, 1080, 540, 540, 4320, 4320, 4320, 4320, 4320, 4320, 540, 1080, 540, 1080, 540, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 4320, 540, 4320, 540, 1080, 4320, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 540, 540, 540, 4320, 1080, 540, 4320, 540, 4320, 540, 540, 1080, 1080, 4320, 1080, 4320, 540, 1080, 540, 4320, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 4320, 540, 4320, 1080, 540, 1080, 4320, 540, 540, 540, 540, 540, 540, 4320, 540, 540, 540, 4320, 540, 1080, 4320, 4320, 1080, 540, 4320, 540, 1080, 1080, 540, 1080, 540, 4320, 540, 540, 4320, 540, 4320, 4320, 1080, 4320, 1080, 540, 1080, 4320, 1080, 4320, 540, 4320, 540, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 4320, 1080, 1080, 540, 1080, 4320, 1080, 1080, 4320, 540, 4320, 4320, 1080, 540, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 540, 4320, 1080, 4320, 4320, 540, 4320, 1080, 1080, 4320, 540, 1080, 540, 540, 540, 540, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 540, 540, 540, 540]
Prompts retrieved: 509220 . Total input tokens: 113498046 . Total output tokens: 101959663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 145.3263744879514,
    "estimated_duration": 3600.092386982105,
    "input_throughput": 6858.444546946215,
    "output_throughput": 6133.699812773656,
    "total_throughput": 12992.14435971987,
    "itl": 88.20039872179736,
    "ttft": 1426736.0640250368,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0545815769210427,
    "arrivals": 169450,
    "finished_requests": 99861,
    "scheduler_time": 289.0526430191209
}
#Debug simulation 
Total elapsed time: 145.32657115114853. Arrivals time: 0.8640326457098126 Scheduler time: 144.07178493402898 Scheduler overhead time: 0.16154845710843801 Adapter cache time: 0.03499616216868162 Engine time: 0.14684199448674917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 152.1002948009409,
    "estimated_duration": 3600.1104730200404,
    "input_throughput": 6916.598306249084,
    "output_throughput": 6135.176452369118,
    "total_throughput": 13051.774758618201,
    "itl": 89.65154220369094,
    "ttft": 1381696.5586010672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8760789870308072,
    "arrivals": 161934,
    "finished_requests": 100647,
    "scheduler_time": 283.74907906942633
}
#Debug simulation 
Total elapsed time: 152.10046895314008. Arrivals time: 0.8600527006201446 Scheduler time: 150.84198215976357 Scheduler overhead time: 0.1638251836411655 Adapter cache time: 0.0351816164329648 Engine time: 0.15078146709129214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 147.69526870315894,
    "estimated_duration": 3600.0424383462328,
    "input_throughput": 6806.155599447821,
    "output_throughput": 6053.947800129773,
    "total_throughput": 12860.103399577594,
    "itl": 87.49838031649129,
    "ttft": 1403093.245568435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9557040399778696,
    "arrivals": 161934,
    "finished_requests": 99052,
    "scheduler_time": 289.0330135529963
}
#Debug simulation 
Total elapsed time: 147.6954564768821. Arrivals time: 0.8608763990923762 Scheduler time: 146.43791576987132 Scheduler overhead time: 0.1615473018027842 Adapter cache time: 0.03583222720772028 Engine time: 0.15043588960543275 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 147.79167235596105,
    "estimated_duration": 3600.0461715776332,
    "input_throughput": 6806.1485414956205,
    "output_throughput": 6053.941522213617,
    "total_throughput": 12860.090063709236,
    "itl": 87.49770198837302,
    "ttft": 1403095.0844324096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9589785307087126,
    "arrivals": 161934,
    "finished_requests": 99052,
    "scheduler_time": 289.03317217791573
}
#Debug simulation 
Total elapsed time: 147.79196348506957. Arrivals time: 0.845267235301435 Scheduler time: 146.54911065241322 Scheduler overhead time: 0.16388918925076723 Adapter cache time: 0.03503346676006913 Engine time: 0.15022372175008059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 147.2552334619686,
    "estimated_duration": 3600.006474289023,
    "input_throughput": 6806.22359292814,
    "output_throughput": 6054.008279055737,
    "total_throughput": 12860.231871983877,
    "itl": 87.49801073154612,
    "ttft": 1403085.5889935493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8711248090607,
    "arrivals": 161934,
    "finished_requests": 99052,
    "scheduler_time": 289.0386032338563
}
#Debug simulation 
Total elapsed time: 147.25543101411313. Arrivals time: 0.8435473600402474 Scheduler time: 146.02055172948167 Scheduler overhead time: 0.1615041228942573 Adapter cache time: 0.034916444681584835 Engine time: 0.14699197001755238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 151.53226133296266,
    "estimated_duration": 3600.0776984146264,
    "input_throughput": 6839.769322435343,
    "output_throughput": 6076.089415968126,
    "total_throughput": 12915.858738403469,
    "itl": 88.35542553644056,
    "ttft": 1391570.2847646007,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.025070033278319,
    "arrivals": 161934,
    "finished_requests": 99622,
    "scheduler_time": 287.3082011676701
}
#Debug simulation 
Total elapsed time: 151.53243764815852. Arrivals time: 0.8522684639319777 Scheduler time: 150.2787639349699 Scheduler overhead time: 0.16554969549179077 Adapter cache time: 0.035156334284693 Engine time: 0.15199433593079448 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 148.94909570692107,
    "estimated_duration": 3600.0969648727587,
    "input_throughput": 6839.894936238285,
    "output_throughput": 6076.144396508814,
    "total_throughput": 12916.039332747097,
    "itl": 88.35107322398115,
    "ttft": 1391530.4312979619,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8269207301852013,
    "arrivals": 161934,
    "finished_requests": 99625,
    "scheduler_time": 287.32733549016444
}
#Debug simulation 
Total elapsed time: 148.94926100084558. Arrivals time: 0.8755913465283811 Scheduler time: 147.67869631154463 Scheduler overhead time: 0.16321818018332124 Adapter cache time: 0.03365288255736232 Engine time: 0.14981070114299655 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 270, 4320, 4320, 270, 4320, 1080, 4320, 270, 1080, 270, 4320, 1080, 1080, 1080, 1080, 4320, 270, 270, 270, 1080, 4320, 270, 4320, 4320, 1080, 1080, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 270, 1080, 1080, 4320, 1080, 270, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 270, 4320, 4320, 1080, 270, 270, 4320, 1080, 270, 1080, 1080, 4320, 1080, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 1080, 270, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 4320, 270, 4320, 270, 1080, 4320, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 270, 270, 270, 4320, 1080, 270, 4320, 270, 4320, 270, 270, 1080, 1080, 4320, 1080, 4320, 270, 1080, 270, 4320, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 4320, 270, 4320, 1080, 270, 1080, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 1080, 4320, 4320, 1080, 270, 4320, 270, 1080, 1080, 270, 1080, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 1080, 4320, 1080, 270, 1080, 4320, 1080, 4320, 270, 4320, 270, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 4320, 1080, 1080, 270, 1080, 4320, 1080, 1080, 4320, 270, 4320, 4320, 1080, 270, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 270, 4320, 1080, 4320, 4320, 270, 4320, 1080, 1080, 4320, 270, 1080, 270, 270, 270, 270, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 270, 270, 270, 270]
Prompts retrieved: 486270 . Total input tokens: 108366334 . Total output tokens: 97337453
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 150.0003552059643,
    "estimated_duration": 3600.103962517008,
    "input_throughput": 6839.719423764744,
    "output_throughput": 6076.045088627537,
    "total_throughput": 12915.764512392281,
    "itl": 88.35542828959144,
    "ttft": 1391582.5985907046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.050346544347699,
    "arrivals": 161934,
    "finished_requests": 99622,
    "scheduler_time": 287.30939046947486
}
#Debug simulation 
Total elapsed time: 150.0005265660584. Arrivals time: 0.8366778907366097 Scheduler time: 148.76568422373384 Scheduler overhead time: 0.16587341204285622 Adapter cache time: 0.033252269960939884 Engine time: 0.14987833891063929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 151.13175525702536,
    "estimated_duration": 3600.112855871965,
    "input_throughput": 6820.301746916469,
    "output_throughput": 6051.77306163172,
    "total_throughput": 12872.074808548188,
    "itl": 87.03198160206601,
    "ttft": 1372128.990819453,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.90056288898227,
    "arrivals": 158124,
    "finished_requests": 99375,
    "scheduler_time": 286.9058516323125
}
#Debug simulation 
Total elapsed time: 151.1319227879867. Arrivals time: 0.731149266473949 Scheduler time: 150.03305284306407 Scheduler overhead time: 0.15046622091904283 Adapter cache time: 0.032057315576821566 Engine time: 0.1398712107911706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 149.00209626276046,
    "estimated_duration": 3600.0777020997707,
    "input_throughput": 6820.164738577509,
    "output_throughput": 6051.689103069314,
    "total_throughput": 12871.853841646824,
    "itl": 87.03622309666756,
    "ttft": 1372115.3341054213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.02557109965012,
    "arrivals": 158124,
    "finished_requests": 99370,
    "scheduler_time": 286.8941626395076
}
#Debug simulation 
Total elapsed time: 149.00231424579397. Arrivals time: 0.761196387000382 Scheduler time: 147.86964180739596 Scheduler overhead time: 0.14820831967517734 Adapter cache time: 0.034322164952754974 Engine time: 0.14368442725390196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 149.95040989434347,
    "estimated_duration": 3600.0811031232392,
    "input_throughput": 6820.158295517013,
    "output_throughput": 6051.683385993483,
    "total_throughput": 12871.841681510497,
    "itl": 87.0347971814452,
    "ttft": 1372117.693552372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0293084203265725,
    "arrivals": 158124,
    "finished_requests": 99370,
    "scheduler_time": 286.89432653517525
}
#Debug simulation 
Total elapsed time: 149.95060176309198. Arrivals time: 0.7673999671824276 Scheduler time: 148.81106919050217 Scheduler overhead time: 0.14903453178703785 Adapter cache time: 0.034083375707268715 Engine time: 0.14279799396172166 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 149.97235515108332,
    "estimated_duration": 3600.0403113038137,
    "input_throughput": 6820.235574281023,
    "output_throughput": 6051.751957218958,
    "total_throughput": 12871.98753149998,
    "itl": 87.03452811267832,
    "ttft": 1372106.1472979528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.94017467809607,
    "arrivals": 158124,
    "finished_requests": 99370,
    "scheduler_time": 286.8991272558501
}
#Debug simulation 
Total elapsed time: 149.97251342702657. Arrivals time: 0.7712143589742482 Scheduler time: 148.83151618298143 Scheduler overhead time: 0.14963476546108723 Adapter cache time: 0.0333735067397356 Engine time: 0.1404277617111802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 152.2430372601375,
    "estimated_duration": 3600.0303057953124,
    "input_throughput": 6874.702960183126,
    "output_throughput": 6096.4886780727775,
    "total_throughput": 12971.191638255903,
    "itl": 88.23016738243972,
    "ttft": 1367625.7432966796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.056516964249316,
    "arrivals": 158124,
    "finished_requests": 100145,
    "scheduler_time": 283.9013778434607
}
#Debug simulation 
Total elapsed time: 152.24318426800892. Arrivals time: 0.7659175680018961 Scheduler time: 151.1048212046735 Scheduler overhead time: 0.15055104065686464 Adapter cache time: 0.034222199115902185 Engine time: 0.1414299039170146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 152.8129108157009,
    "estimated_duration": 3600.054546462257,
    "input_throughput": 6874.7700015604405,
    "output_throughput": 6096.485682853833,
    "total_throughput": 12971.255684414275,
    "itl": 88.22582122782777,
    "ttft": 1367616.1683704213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.856821233134222,
    "arrivals": 158124,
    "finished_requests": 100148,
    "scheduler_time": 283.9197365876553
}
#Debug simulation 
Total elapsed time: 152.81308792391792. Arrivals time: 0.7926162895746529 Scheduler time: 151.64265778381377 Scheduler overhead time: 0.1534056500531733 Adapter cache time: 0.03350565629079938 Engine time: 0.14480348769575357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 135, 4320, 4320, 135, 4320, 1080, 4320, 135, 1080, 135, 4320, 1080, 1080, 1080, 1080, 4320, 135, 135, 135, 1080, 4320, 135, 4320, 4320, 1080, 1080, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 135, 1080, 1080, 4320, 1080, 135, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 135, 4320, 4320, 1080, 135, 135, 4320, 1080, 135, 1080, 1080, 4320, 1080, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 1080, 135, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 4320, 135, 4320, 135, 1080, 4320, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 135, 135, 135, 4320, 1080, 135, 4320, 135, 4320, 135, 135, 1080, 1080, 4320, 1080, 4320, 135, 1080, 135, 4320, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 4320, 135, 4320, 1080, 135, 1080, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 1080, 4320, 4320, 1080, 135, 4320, 135, 1080, 1080, 135, 1080, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 1080, 4320, 1080, 135, 1080, 4320, 1080, 4320, 135, 4320, 135, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 4320, 1080, 1080, 135, 1080, 4320, 1080, 1080, 4320, 135, 4320, 4320, 1080, 135, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 135, 4320, 1080, 4320, 4320, 135, 4320, 1080, 1080, 4320, 135, 1080, 135, 135, 135, 135, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 135, 135, 135, 135]
Prompts retrieved: 474795 . Total input tokens: 105806663 . Total output tokens: 95022632
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 153.03776572272182,
    "estimated_duration": 3600.057873749116,
    "input_throughput": 6874.650316170095,
    "output_throughput": 6096.441993345994,
    "total_throughput": 12971.092309516089,
    "itl": 88.2307646949171,
    "ttft": 1367638.439828887,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 621,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0821707366779423,
    "arrivals": 158124,
    "finished_requests": 100145,
    "scheduler_time": 283.9027918319576
}
#Debug simulation 
Total elapsed time: 153.03792724059895. Arrivals time: 0.811180726159364 Scheduler time: 151.84744473267347 Scheduler overhead time: 0.15532947797328234 Adapter cache time: 0.03361375164240599 Engine time: 0.14329952048137784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 153.4245262858458,
    "estimated_duration": 3600.085976874717,
    "input_throughput": 6954.917510535703,
    "output_throughput": 6183.713984332635,
    "total_throughput": 13138.631494868338,
    "itl": 90.57451412552912,
    "ttft": 1335731.220344565,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9097443522140687,
    "arrivals": 156118,
    "finished_requests": 101510,
    "scheduler_time": 277.42611131674124
}
#Debug simulation 
Total elapsed time: 153.42466373788193. Arrivals time: 0.8058650502935052 Scheduler time: 152.24343781918287 Scheduler overhead time: 0.15135019551962614 Adapter cache time: 0.03429577127099037 Engine time: 0.14346636179834604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 157.83239797130227,
    "estimated_duration": 3600.036789636858,
    "input_throughput": 6987.799144835285,
    "output_throughput": 6221.521420135069,
    "total_throughput": 13209.320564970354,
    "itl": 90.02759077799223,
    "ttft": 1323935.8839581294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0439199967379738,
    "arrivals": 156118,
    "finished_requests": 101909,
    "scheduler_time": 275.6928890978703
}
#Debug simulation 
Total elapsed time: 157.83253986714408. Arrivals time: 0.8067204379476607 Scheduler time: 156.65248747263104 Scheduler overhead time: 0.15158526366576552 Adapter cache time: 0.0342567153275013 Engine time: 0.1425794716924429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 160.30296316882595,
    "estimated_duration": 3600.040623685711,
    "input_throughput": 6987.791702818347,
    "output_throughput": 6221.514794205098,
    "total_throughput": 13209.306497023445,
    "itl": 90.02859664709065,
    "ttft": 1323937.9025876583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.047906780913483,
    "arrivals": 156118,
    "finished_requests": 101909,
    "scheduler_time": 275.6930545126478
}
#Debug simulation 
Total elapsed time: 160.3031232370995. Arrivals time: 0.8195798457600176 Scheduler time: 159.09939503856003 Scheduler overhead time: 0.15494410414248705 Adapter cache time: 0.03516262024641037 Engine time: 0.14705095579847693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 159.23525668121874,
    "estimated_duration": 3600.0679004146655,
    "input_throughput": 6998.2552265467175,
    "output_throughput": 6220.918499181752,
    "total_throughput": 13219.17372572847,
    "itl": 92.70957428167178,
    "ttft": 1328241.3674233663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9598792442050632,
    "arrivals": 156118,
    "finished_requests": 102100,
    "scheduler_time": 275.5368224575539
}
#Debug simulation 
Total elapsed time: 159.23539228690788. Arrivals time: 0.859481408726424 Scheduler time: 157.98311965214089 Scheduler overhead time: 0.15931558888405561 Adapter cache time: 0.035908217541873455 Engine time: 0.15098733082413673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 152.00305212987587,
    "estimated_duration": 3600.0432518938082,
    "input_throughput": 6954.652277255064,
    "output_throughput": 6183.536263985042,
    "total_throughput": 13138.188541240106,
    "itl": 90.57809148898559,
    "ttft": 1335775.120878947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 624,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0637097757495972,
    "arrivals": 156118,
    "finished_requests": 101505,
    "scheduler_time": 277.410397758147
}
#Debug simulation 
Total elapsed time: 152.00320384884253. Arrivals time: 0.8052736460231245 Scheduler time: 150.82326548127457 Scheduler overhead time: 0.15202296618372202 Adapter cache time: 0.033250950276851654 Engine time: 0.1428614091128111 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 157.42796177510172,
    "estimated_duration": 3600.018859871221,
    "input_throughput": 6937.542544122507,
    "output_throughput": 6190.619234921792,
    "total_throughput": 13128.1617790443,
    "itl": 89.88207177660435,
    "ttft": 1319613.5383125683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8508411325444178,
    "arrivals": 156118,
    "finished_requests": 101157,
    "scheduler_time": 278.4377992312658
}
#Debug simulation 
Total elapsed time: 157.42811650410295. Arrivals time: 0.788824281655252 Scheduler time: 156.2654400067404 Scheduler overhead time: 0.14983076276257634 Adapter cache time: 0.03390084160491824 Engine time: 0.14400132559239864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 66, 4320, 4320, 66, 4320, 1080, 4320, 66, 1080, 66, 4320, 1080, 1080, 1080, 1080, 4320, 66, 66, 66, 1080, 4320, 66, 4320, 4320, 1080, 1080, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 66, 1080, 1080, 4320, 1080, 66, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 66, 4320, 4320, 1080, 66, 66, 4320, 1080, 66, 1080, 1080, 4320, 1080, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 1080, 66, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 4320, 66, 4320, 66, 1080, 4320, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 66, 66, 66, 4320, 1080, 66, 4320, 66, 4320, 66, 66, 1080, 1080, 4320, 1080, 4320, 66, 1080, 66, 4320, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 4320, 66, 4320, 1080, 66, 1080, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 1080, 4320, 4320, 1080, 66, 4320, 66, 1080, 1080, 66, 1080, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 1080, 4320, 1080, 66, 1080, 4320, 1080, 4320, 66, 4320, 66, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 4320, 1080, 1080, 66, 1080, 4320, 1080, 1080, 4320, 66, 4320, 4320, 1080, 66, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 66, 4320, 1080, 4320, 4320, 66, 4320, 1080, 1080, 4320, 66, 1080, 66, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 66, 66, 66, 66]
Prompts retrieved: 468930 . Total input tokens: 104482091 . Total output tokens: 93835645
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 154.5819649337791,
    "estimated_duration": 3600.036702489318,
    "input_throughput": 6886.6786782637155,
    "output_throughput": 6116.21431103044,
    "total_throughput": 13002.892989294154,
    "itl": 88.8901134646905,
    "ttft": 1350592.384813902,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 604,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.022096893191334,
    "arrivals": 156118,
    "finished_requests": 100499,
    "scheduler_time": 281.1083725503447
}
#Debug simulation 
Total elapsed time: 154.58212077710778. Arrivals time: 0.812082284130156 Scheduler time: 153.38346539856866 Scheduler overhead time: 0.15526879206299782 Adapter cache time: 0.034794704988598824 Engine time: 0.14893638109788299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 155.2515452168882,
    "estimated_duration": 3600.083050327788,
    "input_throughput": 7032.103605969579,
    "output_throughput": 6224.986392455453,
    "total_throughput": 13257.089998425032,
    "itl": 91.90017071553817,
    "ttft": 1325436.5084892893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8332321586157472,
    "arrivals": 155196,
    "finished_requests": 102359,
    "scheduler_time": 274.41400284669857
}
#Debug simulation 
Total elapsed time: 155.25168997002766. Arrivals time: 0.8309658970683813 Scheduler time: 154.04591599991545 Scheduler overhead time: 0.15068204328417778 Adapter cache time: 0.034171569626778364 Engine time: 0.1435387204401195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 156.43472532136366,
    "estimated_duration": 3600.022716480292,
    "input_throughput": 6903.344216754765,
    "output_throughput": 6123.705525267812,
    "total_throughput": 13027.049742022577,
    "itl": 87.51687769252271,
    "ttft": 1351927.2358389066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.855249169785535,
    "arrivals": 155196,
    "finished_requests": 100517,
    "scheduler_time": 280.6188693820316
}
#Debug simulation 
Total elapsed time: 156.43487374903634. Arrivals time: 0.8040030817501247 Scheduler time: 155.2546263267286 Scheduler overhead time: 0.15093870740383863 Adapter cache time: 0.03337856708094478 Engine time: 0.14394138660281897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 155.59519349457696,
    "estimated_duration": 3600.026310180111,
    "input_throughput": 6903.33732554211,
    "output_throughput": 6123.699412323755,
    "total_throughput": 13027.036737865865,
    "itl": 87.51700174646827,
    "ttft": 1351928.9327879776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8582217440009232,
    "arrivals": 155196,
    "finished_requests": 100517,
    "scheduler_time": 280.6190903532928
}
#Debug simulation 
Total elapsed time: 155.5953616979532. Arrivals time: 0.8057960891164839 Scheduler time: 154.41556498920545 Scheduler overhead time: 0.1506325132213533 Adapter cache time: 0.03274289146065712 Engine time: 0.1444690483622253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 156.499697139021,
    "estimated_duration": 3600.0293845129568,
    "input_throughput": 6882.110214595342,
    "output_throughput": 6113.602598545897,
    "total_throughput": 12995.71281314124,
    "itl": 87.09432605820915,
    "ttft": 1351310.3188189531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.772174437076309,
    "arrivals": 155196,
    "finished_requests": 100135,
    "scheduler_time": 282.1613185143921
}
#Debug simulation 
Total elapsed time: 156.49984505400062. Arrivals time: 0.8142227460630238 Scheduler time: 155.30750209093094 Scheduler overhead time: 0.15288869058713317 Adapter cache time: 0.032602167688310146 Engine time: 0.1455626250244677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 157.3309388277121,
    "estimated_duration": 3600.0897130928875,
    "input_throughput": 6881.994887487058,
    "output_throughput": 6113.500149720334,
    "total_throughput": 12995.49503720739,
    "itl": 87.09824693090101,
    "ttft": 1351328.9340605615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.879825967289512,
    "arrivals": 155196,
    "finished_requests": 100135,
    "scheduler_time": 282.1572949037728
}
#Debug simulation 
Total elapsed time: 157.3310959408991. Arrivals time: 0.8015483017079532 Scheduler time: 156.15324029931799 Scheduler overhead time: 0.15180247882381082 Adapter cache time: 0.03292369470000267 Engine time: 0.14408529037609696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 154.44559985399246,
    "estimated_duration": 3600.0648582840936,
    "input_throughput": 7032.13914097828,
    "output_throughput": 6225.017848895519,
    "total_throughput": 13257.1569898738,
    "itl": 91.90015005778429,
    "ttft": 1325433.6083699882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7910401266463765,
    "arrivals": 155196,
    "finished_requests": 102359,
    "scheduler_time": 274.4166802977884
}
#Debug simulation 
Total elapsed time: 154.44573461916298. Arrivals time: 0.8078111237846315 Scheduler time: 153.27017111703753 Scheduler overhead time: 0.14780220668762922 Adapter cache time: 0.03246756596490741 Engine time: 0.14146265713497996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [85 85 86]
Adapter prompts. [1080, 1080, 4320, 33, 4320, 4320, 33, 4320, 1080, 4320, 33, 1080, 33, 4320, 1080, 1080, 1080, 1080, 4320, 33, 33, 33, 1080, 4320, 33, 4320, 4320, 1080, 1080, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 33, 1080, 1080, 4320, 1080, 33, 1080, 4320, 1080, 1080, 4320, 1080, 4320, 33, 4320, 4320, 1080, 33, 33, 4320, 1080, 33, 1080, 1080, 4320, 1080, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 1080, 33, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 4320, 33, 4320, 33, 1080, 4320, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 33, 33, 33, 4320, 1080, 33, 4320, 33, 4320, 33, 33, 1080, 1080, 4320, 1080, 4320, 33, 1080, 33, 4320, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 4320, 33, 4320, 1080, 33, 1080, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 1080, 4320, 4320, 1080, 33, 4320, 33, 1080, 1080, 33, 1080, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 1080, 4320, 1080, 33, 1080, 4320, 1080, 4320, 33, 4320, 33, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 4320, 1080, 1080, 33, 1080, 4320, 1080, 1080, 4320, 33, 4320, 4320, 1080, 33, 4320, 4320, 1080, 1080, 4320, 4320, 1080, 1080, 1080, 1080, 4320, 4320, 1080, 1080, 4320, 33, 4320, 1080, 4320, 4320, 33, 4320, 1080, 1080, 4320, 33, 1080, 33, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 4320, 1080, 33, 33, 33, 33]
Prompts retrieved: 466125 . Total input tokens: 103857742 . Total output tokens: 93269464
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 158.65253788605332,
    "estimated_duration": 3600.076816771919,
    "input_throughput": 6903.240476486338,
    "output_throughput": 6123.613501049547,
    "total_throughput": 13026.853977535886,
    "itl": 87.51761467609343,
    "ttft": 1351950.5945883228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.906511197984215,
    "arrivals": 155196,
    "finished_requests": 100517,
    "scheduler_time": 280.621807684054
}
#Debug simulation 
Total elapsed time: 158.6526881507598. Arrivals time: 0.8028576681390405 Scheduler time: 157.47015577554703 Scheduler overhead time: 0.15377345215529203 Adapter cache time: 0.03353278944268823 Engine time: 0.14488881034776568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 157.48316282825544,
    "estimated_duration": 3600.1246978160784,
    "input_throughput": 6809.371912831557,
    "output_throughput": 6056.820479920493,
    "total_throughput": 12866.19239275205,
    "itl": 88.50896217676944,
    "ttft": 1320506.176233733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.903623376726203,
    "arrivals": 146502,
    "finished_requests": 99230,
    "scheduler_time": 278.7336089314342
}
#Debug simulation 
Total elapsed time: 157.48331551905721. Arrivals time: 0.8024119702167809 Scheduler time: 156.2978040012531 Scheduler overhead time: 0.15345522575080395 Adapter cache time: 0.03440619446337223 Engine time: 0.14738146355375648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 157.959221302066,
    "estimated_duration": 3600.0485991314904,
    "input_throughput": 6809.483073621312,
    "output_throughput": 6056.710735866263,
    "total_throughput": 12866.193809487575,
    "itl": 88.51079372786461,
    "ttft": 1320487.613009838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0289697452634634,
    "arrivals": 146502,
    "finished_requests": 99227,
    "scheduler_time": 278.7169300059959
}
#Debug simulation 
Total elapsed time: 157.95946879312396. Arrivals time: 0.809828036930412 Scheduler time: 156.76355976099148 Scheduler overhead time: 0.1552314953878522 Adapter cache time: 0.03511206479743123 Engine time: 0.1480926708318293 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 157.3132286448963,
    "estimated_duration": 3600.052732576165,
    "input_throughput": 6809.47525522985,
    "output_throughput": 6056.703781779588,
    "total_throughput": 12866.179037009439,
    "itl": 88.51092541682434,
    "ttft": 1320490.384142209,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0326891866698973,
    "arrivals": 146502,
    "finished_requests": 99227,
    "scheduler_time": 278.7171974006272
}
#Debug simulation 
Total elapsed time: 157.31338399183005. Arrivals time: 0.7880477332510054 Scheduler time: 156.1474209530279 Scheduler overhead time: 0.15250671887770295 Adapter cache time: 0.033850239124149084 Engine time: 0.14385089790448546 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 152.15786218922585,
    "estimated_duration": 3600.0816222402923,
    "input_throughput": 6837.776634820124,
    "output_throughput": 6072.286768430628,
    "total_throughput": 12910.063403250753,
    "itl": 88.95817134965291,
    "ttft": 1312467.789324987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.988702790385565,
    "arrivals": 146502,
    "finished_requests": 99543,
    "scheduler_time": 277.72451071159855
}
#Debug simulation 
Total elapsed time: 152.1580027230084. Arrivals time: 0.7999290428124368 Scheduler time: 150.97942895628512 Scheduler overhead time: 0.1510389274917543 Adapter cache time: 0.03369135456159711 Engine time: 0.1453006905503571 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_256_slots_16_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 158.49349447200075,
    "estimated_duration": 3600.079724212709,
    "input_throughput": 6809.424201115712,
    "output_throughput": 6056.658371577688,
    "total_throughput": 12866.0825726934,
    "itl": 88.51160393588161,
    "ttft": 1320502.9701570387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.058468712884936,
    "arrivals": 146502,
    "finished_requests": 99227,
    "scheduler_time": 278.71880966530847
}
#Debug simulation 
Total elapsed time: 158.49364386685193. Arrivals time: 0.8127746707759798 Scheduler time: 157.29267379501835 Scheduler overhead time: 0.15626779198646545 Adapter cache time: 0.034600418992340565 Engine time: 0.14869248075410724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_256_slots_16_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_256_slots_16_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 157.54051828198135,
    "estimated_duration": 3600.1048816217312,
    "input_throughput": 6809.409393916593,
    "output_throughput": 6056.853818708029,
    "total_throughput": 12866.263212624623,
    "itl": 88.5081503142095,
    "ttft": 1320500.2141394531,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.859811283429124,
    "arrivals": 146502,
    "finished_requests": 99230,
    "scheduler_time": 278.7359347423267
}
#Debug simulation 
Total elapsed time: 157.5406618011184. Arrivals time: 0.7988786334171891 Scheduler time: 156.3661527587101 Scheduler overhead time: 0.1523987241089344 Adapter cache time: 0.03323027677834034 Engine time: 0.14248625468462706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_256_slots_16_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_256_slots_16_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 270, 4320, 4320, 270, 4320, 540, 4320, 270, 540, 270, 4320, 540, 540, 540, 540, 4320, 270, 270, 270, 540, 4320, 270, 4320, 4320, 540, 540, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 270, 540, 540, 4320, 540, 270, 540, 4320, 540, 540, 4320, 540, 4320, 270, 4320, 4320, 540, 270, 270, 4320, 540, 270, 540, 540, 4320, 540, 270, 270, 4320, 4320, 4320, 4320, 4320, 4320, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 4320, 4320, 270, 4320, 270, 540, 4320, 4320, 4320, 540, 270, 4320, 540, 270, 270, 270, 270, 270, 4320, 540, 270, 4320, 270, 4320, 270, 270, 540, 540, 4320, 540, 4320, 270, 540, 270, 4320, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 270, 540, 4320, 4320, 270, 4320, 540, 270, 540, 4320, 270, 270, 270, 270, 270, 270, 4320, 270, 270, 270, 4320, 270, 540, 4320, 4320, 540, 270, 4320, 270, 540, 540, 270, 540, 270, 4320, 270, 270, 4320, 270, 4320, 4320, 540, 4320, 540, 270, 540, 4320, 540, 4320, 270, 4320, 270, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 270, 4320, 270, 4320, 540, 540, 270, 540, 4320, 540, 540, 4320, 270, 4320, 4320, 540, 270, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 270, 4320, 540, 4320, 4320, 270, 4320, 540, 540, 4320, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 4320, 540, 270, 270, 270, 270]
Prompts retrieved: 440370 . Total input tokens: 98122611 . Total output tokens: 88123439
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 157.9577576899901,
    "estimated_duration": 3600.081141364886,
    "input_throughput": 6809.421520623258,
    "output_throughput": 6056.655987407371,
    "total_throughput": 12866.07750803063,
    "itl": 88.51294666693931,
    "ttft": 1320499.5473629506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 622,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0847512542456363,
    "arrivals": 146502,
    "finished_requests": 99227,
    "scheduler_time": 278.71534384951167
}
#Debug simulation 
Total elapsed time: 157.95790572371334. Arrivals time: 0.8057412412017584 Scheduler time: 156.76573245227337 Scheduler overhead time: 0.15554763609543443 Adapter cache time: 0.03469364158809185 Engine time: 0.1477185026742518 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 156.9305292670615,
    "estimated_duration": 3600.106433964804,
    "input_throughput": 6773.933339838145,
    "output_throughput": 5996.95575561727,
    "total_throughput": 12770.889095455415,
    "itl": 88.29071337544424,
    "ttft": 1319561.6882667814,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8546555728232772,
    "arrivals": 142715,
    "finished_requests": 98250,
    "scheduler_time": 280.01110021508896
}
#Debug simulation 
Total elapsed time: 156.9306645570323. Arrivals time: 0.8134662630036473 Scheduler time: 155.72464474337175 Scheduler overhead time: 0.1580086383037269 Adapter cache time: 0.034722681157290936 Engine time: 0.15198489278554916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 156.37508164485916,
    "estimated_duration": 3600.0623061162264,
    "input_throughput": 6766.326782349187,
    "output_throughput": 5989.016624342812,
    "total_throughput": 12755.343406691998,
    "itl": 88.35149160832424,
    "ttft": 1314205.8035671897,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.959919876228093,
    "arrivals": 142715,
    "finished_requests": 98192,
    "scheduler_time": 279.86433214434936
}
#Debug simulation 
Total elapsed time: 156.37521920306608. Arrivals time: 0.8054347084835172 Scheduler time: 155.18088308442384 Scheduler overhead time: 0.15580174326896667 Adapter cache time: 0.03445026418194175 Engine time: 0.1500811781734228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 156.24541976302862,
    "estimated_duration": 3600.0654330184807,
    "input_throughput": 6766.320905333098,
    "output_throughput": 5989.011422473587,
    "total_throughput": 12755.332327806685,
    "itl": 88.35153360109618,
    "ttft": 1314207.240965475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9630337920412544,
    "arrivals": 142715,
    "finished_requests": 98192,
    "scheduler_time": 279.86444516934387
}
#Debug simulation 
Total elapsed time: 156.24554880801588. Arrivals time: 0.7754772929474711 Scheduler time: 155.08486478216946 Scheduler overhead time: 0.15542541444301605 Adapter cache time: 0.033108712173998356 Engine time: 0.1485331798903644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 155.8884370503947,
    "estimated_duration": 3600.00061763992,
    "input_throughput": 6774.007448917383,
    "output_throughput": 5996.934526681622,
    "total_throughput": 12770.941975599006,
    "itl": 88.29159663684756,
    "ttft": 1319561.6578222886,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8969583049462992,
    "arrivals": 142715,
    "finished_requests": 98246,
    "scheduler_time": 279.99952632241593
}
#Debug simulation 
Total elapsed time: 155.88858634699136. Arrivals time: 0.7965441681444645 Scheduler time: 154.7017537560314 Scheduler overhead time: 0.15685209957882762 Adapter cache time: 0.03470563841983676 Engine time: 0.14911379851400852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 158.303474558983,
    "estimated_duration": 3600.092039139377,
    "input_throughput": 6766.270899513783,
    "output_throughput": 5988.967161282422,
    "total_throughput": 12755.238060796204,
    "itl": 88.35159559224768,
    "ttft": 1314218.7716925838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9884360568970476,
    "arrivals": 142715,
    "finished_requests": 98192,
    "scheduler_time": 279.86604917972096
}
#Debug simulation 
Total elapsed time: 158.3036199118942. Arrivals time: 0.7888835924677551 Scheduler time: 157.1293654027395 Scheduler overhead time: 0.1563224485144019 Adapter cache time: 0.03360307402908802 Engine time: 0.1465135421603918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 157.99082385003567,
    "estimated_duration": 3600.117043188236,
    "input_throughput": 6766.3691784940465,
    "output_throughput": 5989.343885582275,
    "total_throughput": 12755.71306407632,
    "itl": 88.34772700769946,
    "ttft": 1314128.3873246668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7940301769412785,
    "arrivals": 142715,
    "finished_requests": 98196,
    "scheduler_time": 279.8839149153704
}
#Debug simulation 
Total elapsed time: 157.99096526997164. Arrivals time: 0.8155893073417246 Scheduler time: 156.7815606938675 Scheduler overhead time: 0.15825501456856728 Adapter cache time: 0.03519783867523074 Engine time: 0.15141717856749892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 135, 4320, 4320, 135, 4320, 540, 4320, 135, 540, 135, 4320, 540, 540, 540, 540, 4320, 135, 135, 135, 540, 4320, 135, 4320, 4320, 540, 540, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 135, 540, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 4320, 135, 4320, 4320, 540, 135, 135, 4320, 540, 135, 540, 540, 4320, 540, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 4320, 4320, 135, 4320, 135, 540, 4320, 4320, 4320, 540, 135, 4320, 540, 135, 135, 135, 135, 135, 4320, 540, 135, 4320, 135, 4320, 135, 135, 540, 540, 4320, 540, 4320, 135, 540, 135, 4320, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 540, 4320, 4320, 540, 135, 4320, 135, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 540, 4320, 540, 4320, 135, 4320, 135, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 540, 540, 135, 540, 4320, 540, 540, 4320, 135, 4320, 4320, 540, 135, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 4320, 540, 135, 135, 135, 135]
Prompts retrieved: 428895 . Total input tokens: 95549549 . Total output tokens: 85845104
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 156.68295676680282,
    "estimated_duration": 3600.0323957864102,
    "input_throughput": 6712.55292821363,
    "output_throughput": 5935.585197791587,
    "total_throughput": 12648.138126005217,
    "itl": 86.14714372331976,
    "ttft": 1327325.3720930233,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.00357026893645,
    "arrivals": 142715,
    "finished_requests": 97377,
    "scheduler_time": 283.2095663423293
}
#Debug simulation 
Total elapsed time: 156.6831147079356. Arrivals time: 0.7876132843084633 Scheduler time: 155.50593812344596 Scheduler overhead time: 0.15907259192317724 Adapter cache time: 0.033644234761595726 Engine time: 0.1475497940555215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 152.7169356807135,
    "estimated_duration": 3600.0714448365425,
    "input_throughput": 6747.673309328715,
    "output_throughput": 5955.252091107717,
    "total_throughput": 12702.925400436432,
    "itl": 87.25999002705346,
    "ttft": 1320151.8000508507,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8638370360550758,
    "arrivals": 140795,
    "finished_requests": 97605,
    "scheduler_time": 279.9463990871584
}
#Debug simulation 
Total elapsed time: 152.71710753813386. Arrivals time: 0.7988022724166512 Scheduler time: 151.53283501695842 Scheduler overhead time: 0.15604799892753363 Adapter cache time: 0.034496596083045006 Engine time: 0.14559036493301392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 155.95711572887376,
    "estimated_duration": 3600.031720897805,
    "input_throughput": 6757.367958394878,
    "output_throughput": 5990.846101384182,
    "total_throughput": 12748.21405977906,
    "itl": 87.8692858542942,
    "ttft": 1297758.4566384605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 602,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9658999768178969,
    "arrivals": 140795,
    "finished_requests": 97766,
    "scheduler_time": 279.3929033618485
}
#Debug simulation 
Total elapsed time: 155.95724926283583. Arrivals time: 0.7969364929012954 Scheduler time: 154.77829405805096 Scheduler overhead time: 0.152256662491709 Adapter cache time: 0.03451130399480462 Engine time: 0.14652988547459245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 160.04886980215088,
    "estimated_duration": 3600.0169452563455,
    "input_throughput": 6755.448479776051,
    "output_throughput": 5966.9471912639565,
    "total_throughput": 12722.395671040007,
    "itl": 86.99738638574476,
    "ttft": 1309829.2568069403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9495107266679528,
    "arrivals": 140795,
    "finished_requests": 97740,
    "scheduler_time": 279.2155747432231
}
#Debug simulation 
Total elapsed time: 160.04906558198854. Arrivals time: 0.7659925520420074 Scheduler time: 158.89165745163336 Scheduler overhead time: 0.15702257631346583 Adapter cache time: 0.03402251424267888 Engine time: 0.1511268001049757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 162.55520478682593,
    "estimated_duration": 3600.0947860083675,
    "input_throughput": 6812.347023560562,
    "output_throughput": 6013.576943623751,
    "total_throughput": 12825.923967184313,
    "itl": 86.7250110813084,
    "ttft": 1301027.253957031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8270912452740493,
    "arrivals": 140795,
    "finished_requests": 98462,
    "scheduler_time": 277.1526049061056
}
#Debug simulation 
Total elapsed time: 162.55536411795765. Arrivals time: 0.7958157584071159 Scheduler time: 161.36778936581686 Scheduler overhead time: 0.15871331933885813 Adapter cache time: 0.03474075859412551 Engine time: 0.15010932367295027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 154.41020001797006,
    "estimated_duration": 3600.0221639114943,
    "input_throughput": 6747.639568309392,
    "output_throughput": 5955.330279607434,
    "total_throughput": 12702.969847916827,
    "itl": 87.26218660324994,
    "ttft": 1320142.2472966467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 609,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0169652228057426,
    "arrivals": 140795,
    "finished_requests": 97604,
    "scheduler_time": 279.9313578572115
}
#Debug simulation 
Total elapsed time: 154.41038069315255. Arrivals time: 0.7735822359099984 Scheduler time: 153.25421419274062 Scheduler overhead time: 0.15464974660426378 Adapter cache time: 0.034508260898292065 Engine time: 0.14543482894077897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 159.85641775419936,
    "estimated_duration": 3600.0841527060215,
    "input_throughput": 6789.052411907838,
    "output_throughput": 6005.266844595735,
    "total_throughput": 12794.319256503573,
    "itl": 87.47757719987467,
    "ttft": 1305092.515037828,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7820699757616703,
    "arrivals": 140795,
    "finished_requests": 98232,
    "scheduler_time": 278.0425847698158
}
#Debug simulation 
Total elapsed time: 159.85664303274825. Arrivals time: 0.805363783147186 Scheduler time: 158.65323320496827 Scheduler overhead time: 0.159401701297611 Adapter cache time: 0.03471351694315672 Engine time: 0.1543111763894558 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 66, 4320, 4320, 66, 4320, 540, 4320, 66, 540, 66, 4320, 540, 540, 540, 540, 4320, 66, 66, 66, 540, 4320, 66, 4320, 4320, 540, 540, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 66, 540, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 4320, 66, 4320, 4320, 540, 66, 66, 4320, 540, 66, 540, 540, 4320, 540, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 4320, 4320, 66, 4320, 66, 540, 4320, 4320, 4320, 540, 66, 4320, 540, 66, 66, 66, 66, 66, 4320, 540, 66, 4320, 66, 4320, 66, 66, 540, 540, 4320, 540, 4320, 66, 540, 66, 4320, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 540, 4320, 4320, 540, 66, 4320, 66, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 540, 4320, 540, 4320, 66, 4320, 66, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 540, 540, 66, 540, 4320, 540, 540, 4320, 66, 4320, 4320, 540, 66, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 4320, 540, 66, 66, 66, 66]
Prompts retrieved: 423030 . Total input tokens: 94249363 . Total output tokens: 84650939
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 161.1233030720614,
    "estimated_duration": 3600.0354368262915,
    "input_throughput": 6812.182943848987,
    "output_throughput": 6013.516916679339,
    "total_throughput": 12825.699860528326,
    "itl": 86.72778049471151,
    "ttft": 1301024.9755200117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9593745110928968,
    "arrivals": 140795,
    "finished_requests": 98458,
    "scheduler_time": 277.13683590342015
}
#Debug simulation 
Total elapsed time: 161.12344198999926. Arrivals time: 0.7885545948520303 Scheduler time: 159.95115707395598 Scheduler overhead time: 0.15471161343157291 Adapter cache time: 0.033111343160271645 Engine time: 0.14709416590631008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 158.77562895137817,
    "estimated_duration": 3600.0317117327804,
    "input_throughput": 6851.623256431717,
    "output_throughput": 6037.647648814205,
    "total_throughput": 12889.270905245921,
    "itl": 90.38541082315939,
    "ttft": 1277540.6757248603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8332321586157472,
    "arrivals": 139799,
    "finished_requests": 99343,
    "scheduler_time": 273.99002535719
}
#Debug simulation 
Total elapsed time: 158.77578810509294. Arrivals time: 0.8171198382042348 Scheduler time: 157.567660338711 Scheduler overhead time: 0.1586078703403473 Adapter cache time: 0.03436009818688035 Engine time: 0.15002401219680905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 166.02999108703807,
    "estimated_duration": 3600.1316112770214,
    "input_throughput": 6774.049849624635,
    "output_throughput": 5968.621239482393,
    "total_throughput": 12742.671089107027,
    "itl": 85.97553490437149,
    "ttft": 1312384.9960209893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.80672105749604,
    "arrivals": 139799,
    "finished_requests": 98131,
    "scheduler_time": 278.1249557492052
}
#Debug simulation 
Total elapsed time: 166.03014912083745. Arrivals time: 0.8031705268658698 Scheduler time: 164.83390614995733 Scheduler overhead time: 0.1584156551398337 Adapter cache time: 0.03453270858153701 Engine time: 0.14978615194559097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 166.83453670609742,
    "estimated_duration": 3600.0020847825813,
    "input_throughput": 6774.090799303749,
    "output_throughput": 5968.67154350487,
    "total_throughput": 12742.762342808619,
    "itl": 85.9750891835919,
    "ttft": 1312371.7367446388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8095337338186912,
    "arrivals": 139799,
    "finished_requests": 98130,
    "scheduler_time": 278.11585542657855
}
#Debug simulation 
Total elapsed time: 166.8346740361303. Arrivals time: 0.7887412700802088 Scheduler time: 165.65252584544942 Scheduler overhead time: 0.15868128556758165 Adapter cache time: 0.03401413979008794 Engine time: 0.15156754851341248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 157.54396655177698,
    "estimated_duration": 3600.0416971434743,
    "input_throughput": 6853.882281301989,
    "output_throughput": 6044.734986616111,
    "total_throughput": 12898.6172679181,
    "itl": 90.27469347092138,
    "ttft": 1279152.838272837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8459786207461624,
    "arrivals": 139799,
    "finished_requests": 99354,
    "scheduler_time": 274.2907711119412
}
#Debug simulation 
Total elapsed time: 157.54411292169243. Arrivals time: 0.8089889022521675 Scheduler time: 156.3410343816504 Scheduler overhead time: 0.15890664933249354 Adapter cache time: 0.0351950298063457 Engine time: 0.15151941683143377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 165.93737575225532,
    "estimated_duration": 3600.101267916485,
    "input_throughput": 6774.596930745499,
    "output_throughput": 5969.183753666152,
    "total_throughput": 12743.780684411651,
    "itl": 85.9874698430303,
    "ttft": 1312286.425254651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8338042145967526,
    "arrivals": 139799,
    "finished_requests": 98136,
    "scheduler_time": 278.08294838326646
}
#Debug simulation 
Total elapsed time: 165.93752100504935. Arrivals time: 0.79462003801018 Scheduler time: 164.74951211595908 Scheduler overhead time: 0.1584748118184507 Adapter cache time: 0.03433520067483187 Engine time: 0.15089493477717042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 162.52981093199924,
    "estimated_duration": 3600.0472103687343,
    "input_throughput": 6832.637341297692,
    "output_throughput": 6016.565821030298,
    "total_throughput": 12849.20316232799,
    "itl": 89.68111273780939,
    "ttft": 1283622.8925236005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 579,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.731239120748335,
    "arrivals": 139799,
    "finished_requests": 98974,
    "scheduler_time": 275.38640801023666
}
#Debug simulation 
Total elapsed time: 162.52995701972395. Arrivals time: 0.78703060047701 Scheduler time: 161.3523626695387 Scheduler overhead time: 0.15772706642746925 Adapter cache time: 0.03453407483175397 Engine time: 0.15001643169671297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 4320, 33, 4320, 4320, 33, 4320, 540, 4320, 33, 540, 33, 4320, 540, 540, 540, 540, 4320, 33, 33, 33, 540, 4320, 33, 4320, 4320, 540, 540, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 33, 540, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 4320, 33, 4320, 4320, 540, 33, 33, 4320, 540, 33, 540, 540, 4320, 540, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 4320, 4320, 33, 4320, 33, 540, 4320, 4320, 4320, 540, 33, 4320, 540, 33, 33, 33, 33, 33, 4320, 540, 33, 4320, 33, 4320, 33, 33, 540, 540, 4320, 540, 4320, 33, 540, 33, 4320, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 540, 4320, 4320, 540, 33, 4320, 33, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 540, 4320, 540, 4320, 33, 4320, 33, 540, 4320, 540, 4320, 540, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 540, 540, 33, 540, 4320, 540, 540, 4320, 33, 4320, 4320, 540, 33, 4320, 4320, 540, 540, 4320, 4320, 540, 540, 540, 540, 4320, 4320, 540, 540, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 4320, 540, 33, 33, 33, 33]
Prompts retrieved: 420225 . Total input tokens: 93627813 . Total output tokens: 84090312
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 166.9011066108942,
    "estimated_duration": 3600.0256953167277,
    "input_throughput": 6774.046371870263,
    "output_throughput": 5968.632398361137,
    "total_throughput": 12742.6787702314,
    "itl": 85.97748528115164,
    "ttft": 1312377.507377752,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 553,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8566914037242497,
    "arrivals": 139799,
    "finished_requests": 98130,
    "scheduler_time": 278.1136185101532
}
#Debug simulation 
Total elapsed time: 166.9012480652891. Arrivals time: 0.7850985662080348 Scheduler time: 165.7191647682339 Scheduler overhead time: 0.15944927232339978 Adapter cache time: 0.03336172131821513 Engine time: 0.15294622210785747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 160.82599061215296,
    "estimated_duration": 3600.120769622604,
    "input_throughput": 6676.669628091324,
    "output_throughput": 5900.888431091986,
    "total_throughput": 12577.55805918331,
    "itl": 85.60965338564606,
    "ttft": 1284589.090712518,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8852604502626058,
    "arrivals": 135085,
    "finished_requests": 96914,
    "scheduler_time": 276.92153322910013
}
#Debug simulation 
Total elapsed time: 160.8261254131794. Arrivals time: 0.7773991827853024 Scheduler time: 159.65844781603664 Scheduler overhead time: 0.15689543262124062 Adapter cache time: 0.034554529935121536 Engine time: 0.149592453148216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 157.2188551160507,
    "estimated_duration": 3600.0238341294817,
    "input_throughput": 6843.625246708263,
    "output_throughput": 6063.163469382445,
    "total_throughput": 12906.788716090708,
    "itl": 88.00405392728422,
    "ttft": 1234241.7205600333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.108494263391482,
    "arrivals": 135085,
    "finished_requests": 99343,
    "scheduler_time": 267.0424453082391
}
#Debug simulation 
Total elapsed time: 157.219037883915. Arrivals time: 0.7934539266861975 Scheduler time: 156.03263663686812 Scheduler overhead time: 0.15811051288619637 Adapter cache time: 0.0365448659285903 Engine time: 0.14940318744629622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 164.43104032892734,
    "estimated_duration": 3600.068816137436,
    "input_throughput": 6799.362526148312,
    "output_throughput": 6013.701711187929,
    "total_throughput": 12813.06423733624,
    "itl": 87.21318245293995,
    "ttft": 1242462.3029650273,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1324259394966134,
    "arrivals": 135085,
    "finished_requests": 98670,
    "scheduler_time": 268.96637412984995
}
#Debug simulation 
Total elapsed time: 164.4312036279589. Arrivals time: 0.7607016684487462 Scheduler time: 163.27592128468677 Scheduler overhead time: 0.1587216816842556 Adapter cache time: 0.035449085757136345 Engine time: 0.15108098788186908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 160.52516298694536,
    "estimated_duration": 3600.00234727738,
    "input_throughput": 6676.529257870527,
    "output_throughput": 5900.835319195203,
    "total_throughput": 12577.36457706573,
    "itl": 85.61017515134232,
    "ttft": 1284607.3856854138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9244072359846787,
    "arrivals": 135085,
    "finished_requests": 96910,
    "scheduler_time": 276.9094028282778
}
#Debug simulation 
Total elapsed time: 160.52531801210716. Arrivals time: 0.7942851213738322 Scheduler time: 159.33358801202849 Scheduler overhead time: 0.15952678117901087 Adapter cache time: 0.035664528608322144 Engine time: 0.1525246212258935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 159.45567297469825,
    "estimated_duration": 3600.100190794388,
    "input_throughput": 6775.640039789424,
    "output_throughput": 5994.346228247099,
    "total_throughput": 12769.986268036524,
    "itl": 86.35928092557157,
    "ttft": 1255589.2632901198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 636,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.105959497150039,
    "arrivals": 135085,
    "finished_requests": 98425,
    "scheduler_time": 270.0116406091127
}
#Debug simulation 
Total elapsed time: 159.45581330172718. Arrivals time: 0.8047404792159796 Scheduler time: 158.25528961792588 Scheduler overhead time: 0.16072437353432178 Adapter cache time: 0.03504259930923581 Engine time: 0.1514294925145805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 160.6399416513741,
    "estimated_duration": 3600.1012260173684,
    "input_throughput": 6676.705873237586,
    "output_throughput": 5900.920464811817,
    "total_throughput": 12577.626338049404,
    "itl": 85.6087504187653,
    "ttft": 1284583.9967203257,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8418709816597116,
    "arrivals": 135085,
    "finished_requests": 96914,
    "scheduler_time": 276.92357936470364
}
#Debug simulation 
Total elapsed time: 160.640094013419. Arrivals time: 0.783702814951539 Scheduler time: 159.46106288488954 Scheduler overhead time: 0.15888448199257255 Adapter cache time: 0.035732701420784 Engine time: 0.1511366139166057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 135, 4320, 4320, 135, 4320, 270, 4320, 135, 270, 135, 4320, 270, 270, 270, 270, 4320, 135, 135, 135, 270, 4320, 135, 4320, 4320, 270, 270, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 135, 270, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 4320, 135, 4320, 4320, 270, 135, 135, 4320, 270, 135, 270, 270, 4320, 270, 135, 135, 4320, 4320, 4320, 4320, 4320, 4320, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 4320, 4320, 135, 4320, 135, 270, 4320, 4320, 4320, 270, 135, 4320, 270, 135, 135, 135, 135, 135, 4320, 270, 135, 4320, 135, 4320, 135, 135, 270, 270, 4320, 270, 4320, 135, 270, 135, 4320, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 135, 135, 135, 135, 135, 4320, 135, 135, 135, 4320, 135, 270, 4320, 4320, 270, 135, 4320, 135, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 270, 4320, 270, 4320, 135, 4320, 135, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 270, 270, 135, 270, 4320, 270, 270, 4320, 135, 4320, 4320, 270, 135, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 4320, 270, 135, 135, 135, 135]
Prompts retrieved: 405945 . Total input tokens: 90403984 . Total output tokens: 81246146
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 155.81511572003365,
    "estimated_duration": 3600.1130642770136,
    "input_throughput": 6835.960304747347,
    "output_throughput": 6047.37562717969,
    "total_throughput": 12883.335931927037,
    "itl": 88.2131552668586,
    "ttft": 1238379.7477275948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.162623209543527,
    "arrivals": 135085,
    "finished_requests": 99246,
    "scheduler_time": 266.9931248606382
}
#Debug simulation 
Total elapsed time: 155.81525040930137. Arrivals time: 0.7915890580043197 Scheduler time: 154.6326217916794 Scheduler overhead time: 0.1568430894985795 Adapter cache time: 0.03540692152455449 Engine time: 0.14985816460102797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 158.00718026515096,
    "estimated_duration": 3600.0310591731286,
    "input_throughput": 6750.444537992888,
    "output_throughput": 5939.751532285783,
    "total_throughput": 12690.196070278671,
    "itl": 86.45754260985923,
    "ttft": 1237629.3862284734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9740145948366588,
    "arrivals": 133166,
    "finished_requests": 98193,
    "scheduler_time": 268.94274202683465
}
#Debug simulation 
Total elapsed time: 158.00733743282035. Arrivals time: 0.7901499145664275 Scheduler time: 156.81961514567956 Scheduler overhead time: 0.15958019020035863 Adapter cache time: 0.035006883554160595 Engine time: 0.15264421654865146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 155.35311953630298,
    "estimated_duration": 3600.066678584008,
    "input_throughput": 6764.8666467419425,
    "output_throughput": 5955.317196633891,
    "total_throughput": 12720.183843375833,
    "itl": 86.53690265270248,
    "ttft": 1240234.2043030558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1068598821177202,
    "arrivals": 133166,
    "finished_requests": 98390,
    "scheduler_time": 268.0881772122775
}
#Debug simulation 
Total elapsed time: 155.35338477930054. Arrivals time: 0.8000999880023301 Scheduler time: 154.15744120860472 Scheduler overhead time: 0.16109962901100516 Adapter cache time: 0.03518102178350091 Engine time: 0.14983806805685163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 153.85816108901054,
    "estimated_duration": 3600.0729760131485,
    "input_throughput": 6764.854813296166,
    "output_throughput": 5955.306779292825,
    "total_throughput": 12720.161592588991,
    "itl": 86.53709072504263,
    "ttft": 1240236.9869629005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.11079235145823,
    "arrivals": 133166,
    "finished_requests": 98390,
    "scheduler_time": 268.08874147759616
}
#Debug simulation 
Total elapsed time: 153.85830624913797. Arrivals time: 0.7769632493145764 Scheduler time: 152.69908235548064 Scheduler overhead time: 0.1529518309980631 Adapter cache time: 0.033757378812879324 Engine time: 0.14653805643320084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 154.21069287788123,
    "estimated_duration": 3600.0377748743504,
    "input_throughput": 6815.266542822967,
    "output_throughput": 6009.937770932181,
    "total_throughput": 12825.204313755148,
    "itl": 87.93576023164094,
    "ttft": 1212835.3798479629,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0722943155770044,
    "arrivals": 133166,
    "finished_requests": 99295,
    "scheduler_time": 264.22626965598766
}
#Debug simulation 
Total elapsed time: 154.21085392078385. Arrivals time: 0.7784844147972763 Scheduler time: 153.04821608029306 Scheduler overhead time: 0.15534922713413835 Adapter cache time: 0.03516625380143523 Engine time: 0.14537079399451613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 156.41920384019613,
    "estimated_duration": 3600.0529493492827,
    "input_throughput": 6700.874220297336,
    "output_throughput": 5904.773151695544,
    "total_throughput": 12605.64737199288,
    "itl": 86.85025755012006,
    "ttft": 1249228.7366426873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1385439243912736,
    "arrivals": 133166,
    "finished_requests": 97537,
    "scheduler_time": 271.1193211593601
}
#Debug simulation 
Total elapsed time: 156.4194696242921. Arrivals time: 0.7870326098054647 Scheduler time: 155.23453620728105 Scheduler overhead time: 0.16014008736237884 Adapter cache time: 0.034715835470706224 Engine time: 0.15206096833571792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 155.20235620206222,
    "estimated_duration": 3600.1164561023716,
    "input_throughput": 6765.1455993087575,
    "output_throughput": 5955.544844572195,
    "total_throughput": 12720.690443880952,
    "itl": 86.53527655850799,
    "ttft": 1240203.9864404874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 646,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9315724905067737,
    "arrivals": 133166,
    "finished_requests": 98395,
    "scheduler_time": 268.1051381196145
}
#Debug simulation 
Total elapsed time: 155.20249798335135. Arrivals time: 0.7814132855273783 Scheduler time: 154.03231758018956 Scheduler overhead time: 0.15571717638522387 Adapter cache time: 0.0352183198556304 Engine time: 0.14893583115190268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 66, 4320, 4320, 66, 4320, 270, 4320, 66, 270, 66, 4320, 270, 270, 270, 270, 4320, 66, 66, 66, 270, 4320, 66, 4320, 4320, 270, 270, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 66, 270, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 4320, 66, 4320, 4320, 270, 66, 66, 4320, 270, 66, 270, 270, 4320, 270, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 4320, 4320, 66, 4320, 66, 270, 4320, 4320, 4320, 270, 66, 4320, 270, 66, 66, 66, 66, 66, 4320, 270, 66, 4320, 66, 4320, 66, 66, 270, 270, 4320, 270, 4320, 66, 270, 66, 4320, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 270, 4320, 4320, 270, 66, 4320, 66, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 270, 4320, 270, 4320, 66, 4320, 66, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 270, 270, 66, 270, 4320, 270, 270, 4320, 66, 4320, 4320, 270, 66, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 4320, 270, 66, 66, 66, 66]
Prompts retrieved: 400080 . Total input tokens: 89083538 . Total output tokens: 80076302
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 155.5132615272887,
    "estimated_duration": 3600.1210086824626,
    "input_throughput": 6815.1089757338905,
    "output_throughput": 6009.798822822941,
    "total_throughput": 12824.907798556831,
    "itl": 87.93859217070653,
    "ttft": 1212859.0897701222,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 663,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2229625641927147,
    "arrivals": 133166,
    "finished_requests": 99295,
    "scheduler_time": 264.2223007966
}
#Debug simulation 
Total elapsed time: 155.51340669114143. Arrivals time: 0.78075419832021 Scheduler time: 154.3459868123755 Scheduler overhead time: 0.1557531962171197 Adapter cache time: 0.034303038846701384 Engine time: 0.14813443832099438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 159.76845115981996,
    "estimated_duration": 3600.011534904372,
    "input_throughput": 6748.396988301687,
    "output_throughput": 5988.901644053401,
    "total_throughput": 12737.298632355089,
    "itl": 88.5555950251203,
    "ttft": 1227840.988718493,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.839353134103613,
    "arrivals": 132222,
    "finished_requests": 98380,
    "scheduler_time": 265.80498168607454
}
#Debug simulation 
Total elapsed time: 159.76860729511827. Arrivals time: 0.7951727854087949 Scheduler time: 158.57776278303936 Scheduler overhead time: 0.15842116810381413 Adapter cache time: 0.0351454047486186 Engine time: 0.15060321055352688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 165.60483201639727,
    "estimated_duration": 3600.0671314629385,
    "input_throughput": 6617.059107539378,
    "output_throughput": 5870.512195535588,
    "total_throughput": 12487.571303074965,
    "itl": 85.28924764437693,
    "ttft": 1277420.1128183638,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8600034844200184,
    "arrivals": 132222,
    "finished_requests": 96383,
    "scheduler_time": 274.7999310559021
}
#Debug simulation 
Total elapsed time: 165.60495952144265. Arrivals time: 0.780836284160614 Scheduler time: 164.4224672256969 Scheduler overhead time: 0.16155809815973043 Adapter cache time: 0.03541219653561711 Engine time: 0.15392817556858063 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 164.52335255406797,
    "estimated_duration": 3600.07069526747,
    "input_throughput": 6617.052557138781,
    "output_throughput": 5870.5063841613855,
    "total_throughput": 12487.558941300165,
    "itl": 85.2898288473956,
    "ttft": 1277421.6046812367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 570,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8632970392145332,
    "arrivals": 132222,
    "finished_requests": 96383,
    "scheduler_time": 274.8002013056098
}
#Debug simulation 
Total elapsed time: 164.52349229808897. Arrivals time: 0.7816150086000562 Scheduler time: 163.34448980307207 Scheduler overhead time: 0.15962107200175524 Adapter cache time: 0.03460641158744693 Engine time: 0.1530527831055224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 161.42590513080359,
    "estimated_duration": 3600.055907343669,
    "input_throughput": 6818.94965851055,
    "output_throughput": 6049.188279431096,
    "total_throughput": 12868.137937941647,
    "itl": 89.44445286232364,
    "ttft": 1202622.0842159654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8765664312662445,
    "arrivals": 132222,
    "finished_requests": 99307,
    "scheduler_time": 262.28348704410945
}
#Debug simulation 
Total elapsed time: 161.4261405407451. Arrivals time: 0.7901257309131324 Scheduler time: 160.23959433101118 Scheduler overhead time: 0.16101406840607524 Adapter cache time: 0.03545707929879427 Engine time: 0.1509403265081346 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 169.96752128889784,
    "estimated_duration": 3600.0165726113087,
    "input_throughput": 6613.361777590505,
    "output_throughput": 5869.502424171597,
    "total_throughput": 12482.864201762102,
    "itl": 85.56395059267072,
    "ttft": 1271256.7346122751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.798401765804742,
    "arrivals": 132222,
    "finished_requests": 96434,
    "scheduler_time": 274.5798570642777
}
#Debug simulation 
Total elapsed time: 169.9676663079299. Arrivals time: 0.7938117389567196 Scheduler time: 168.76569429505616 Scheduler overhead time: 0.16671160701662302 Adapter cache time: 0.03531672013923526 Engine time: 0.15610074065625668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 163.8250264977105,
    "estimated_duration": 3600.1174289017804,
    "input_throughput": 6754.158296280227,
    "output_throughput": 5984.653952405231,
    "total_throughput": 12738.812248685459,
    "itl": 87.46390273613066,
    "ttft": 1228590.8541604269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 584,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7461893722228454,
    "arrivals": 132222,
    "finished_requests": 98334,
    "scheduler_time": 266.4589549344791
}
#Debug simulation 
Total elapsed time: 163.82516978681087. Arrivals time: 0.7753059216775 Scheduler time: 162.65651355311275 Scheduler overhead time: 0.1575903003104031 Adapter cache time: 0.034941503778100014 Engine time: 0.15160947339609265 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 4320, 33, 4320, 4320, 33, 4320, 270, 4320, 33, 270, 33, 4320, 270, 270, 270, 270, 4320, 33, 33, 33, 270, 4320, 33, 4320, 4320, 270, 270, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 33, 270, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 4320, 33, 4320, 4320, 270, 33, 33, 4320, 270, 33, 270, 270, 4320, 270, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 4320, 4320, 33, 4320, 33, 270, 4320, 4320, 4320, 270, 33, 4320, 270, 33, 33, 33, 33, 33, 4320, 270, 33, 4320, 33, 4320, 33, 33, 270, 270, 4320, 270, 4320, 33, 270, 33, 4320, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 270, 4320, 4320, 270, 33, 4320, 33, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 270, 4320, 270, 4320, 33, 4320, 33, 270, 4320, 270, 4320, 270, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 270, 270, 33, 270, 4320, 270, 270, 4320, 33, 4320, 4320, 270, 33, 4320, 4320, 270, 270, 4320, 4320, 270, 270, 270, 270, 4320, 4320, 270, 270, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 4320, 270, 33, 33, 33, 33]
Prompts retrieved: 397275 . Total input tokens: 88477227 . Total output tokens: 79493181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 160.7859558640048,
    "estimated_duration": 3600.1219149484245,
    "input_throughput": 6806.8058746146835,
    "output_throughput": 6032.639591959801,
    "total_throughput": 12839.445466574483,
    "itl": 89.25951211900902,
    "ttft": 1210414.0465844497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.001255262531335,
    "arrivals": 132222,
    "finished_requests": 99089,
    "scheduler_time": 262.9014529661467
}
#Debug simulation 
Total elapsed time: 160.78610856132582. Arrivals time: 0.7977208797819912 Scheduler time: 159.59305131435394 Scheduler overhead time: 0.15979603119194508 Adapter cache time: 0.03427458228543401 Engine time: 0.15203926246613264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 162.81909310165793,
    "estimated_duration": 3600.107540220145,
    "input_throughput": 6779.788305575856,
    "output_throughput": 5946.325425237421,
    "total_throughput": 12726.113730813277,
    "itl": 85.84955079730243,
    "ttft": 1227853.617803014,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8760789870308072,
    "arrivals": 129353,
    "finished_requests": 98081,
    "scheduler_time": 263.3922894185589
}
#Debug simulation 
Total elapsed time: 162.81922827800736. Arrivals time: 0.7821883428841829 Scheduler time: 161.6392902014777 Scheduler overhead time: 0.16036174120381474 Adapter cache time: 0.03491014614701271 Engine time: 0.1524372585117817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 159.40692919120193,
    "estimated_duration": 3600.022100376473,
    "input_throughput": 6758.682397381821,
    "output_throughput": 5936.990219522509,
    "total_throughput": 12695.672616904329,
    "itl": 85.6412723469836,
    "ttft": 1217025.3945798927,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9837103955214908,
    "arrivals": 129353,
    "finished_requests": 97762,
    "scheduler_time": 265.1262506368327
}
#Debug simulation 
Total elapsed time: 159.40707491105422. Arrivals time: 0.7404634924605489 Scheduler time: 158.2782025290653 Scheduler overhead time: 0.15459679253399372 Adapter cache time: 0.03439645515754819 Engine time: 0.14864319562911987 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 169.0256241876632,
    "estimated_duration": 3600.0252437276276,
    "input_throughput": 6758.676496058725,
    "output_throughput": 5936.9850356574525,
    "total_throughput": 12695.661531716178,
    "itl": 85.64140069769229,
    "ttft": 1217026.6847025075,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9866991564445322,
    "arrivals": 129353,
    "finished_requests": 97762,
    "scheduler_time": 265.1265052656153
}
#Debug simulation 
Total elapsed time: 169.02577430568635. Arrivals time: 0.7809763383120298 Scheduler time: 167.8379583535716 Scheduler overhead time: 0.16549114789813757 Adapter cache time: 0.035229512955993414 Engine time: 0.15478151198476553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 172.33752135420218,
    "estimated_duration": 3600.048881905485,
    "input_throughput": 6701.957054324641,
    "output_throughput": 5877.703524069963,
    "total_throughput": 12579.660578394603,
    "itl": 84.20737270475392,
    "ttft": 1239058.1145118035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8538718148623488,
    "arrivals": 129353,
    "finished_requests": 96964,
    "scheduler_time": 268.67769315115356
}
#Debug simulation 
Total elapsed time: 172.3376792659983. Arrivals time: 0.7877498101443052 Scheduler time: 171.1410461794585 Scheduler overhead time: 0.1667727492749691 Adapter cache time: 0.036249218974262476 Engine time: 0.15542564447969198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 169.7703314498067,
    "estimated_duration": 3600.0298407447217,
    "input_throughput": 6758.667865643767,
    "output_throughput": 5936.977454492045,
    "total_throughput": 12695.645320135813,
    "itl": 85.64132288117904,
    "ttft": 1217034.1370575158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 607,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0119756675139104,
    "arrivals": 129353,
    "finished_requests": 97762,
    "scheduler_time": 265.1280256536755
}
#Debug simulation 
Total elapsed time: 169.7704777419567. Arrivals time: 0.7806716086342931 Scheduler time: 168.58508109208196 Scheduler overhead time: 0.16281296405941248 Adapter cache time: 0.03589485213160515 Engine time: 0.15470850374549627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 165.34325501229614,
    "estimated_duration": 3600.0798372255795,
    "input_throughput": 6758.8781638664905,
    "output_throughput": 5919.788716803565,
    "total_throughput": 12678.666880670056,
    "itl": 85.02128596526178,
    "ttft": 1220902.9912014056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8717714846087323,
    "arrivals": 129353,
    "finished_requests": 97743,
    "scheduler_time": 264.17836855032266
}
#Debug simulation 
Total elapsed time: 165.34339646343142. Arrivals time: 0.7751411735080183 Scheduler time: 164.1672161547467 Scheduler overhead time: 0.16217970149591565 Adapter cache time: 0.03595202788710594 Engine time: 0.15198578871786594 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 66, 4320, 4320, 66, 4320, 135, 4320, 66, 135, 66, 4320, 135, 135, 135, 135, 4320, 66, 66, 66, 135, 4320, 66, 4320, 4320, 135, 135, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 66, 135, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 4320, 66, 4320, 4320, 135, 66, 66, 4320, 135, 66, 135, 135, 4320, 135, 66, 66, 4320, 4320, 4320, 4320, 4320, 4320, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 4320, 4320, 66, 4320, 66, 135, 4320, 4320, 4320, 135, 66, 4320, 135, 66, 66, 66, 66, 66, 4320, 135, 66, 4320, 66, 4320, 66, 66, 135, 135, 4320, 135, 4320, 66, 135, 66, 4320, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 66, 66, 66, 66, 66, 4320, 66, 66, 66, 4320, 66, 135, 4320, 4320, 135, 66, 4320, 66, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 135, 4320, 135, 4320, 66, 4320, 66, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 135, 135, 66, 135, 4320, 135, 135, 4320, 66, 4320, 4320, 135, 66, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 4320, 135, 66, 66, 66, 66]
Prompts retrieved: 388605 . Total input tokens: 86555962 . Total output tokens: 77766423
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 163.39503557328135,
    "estimated_duration": 3600.0183034926617,
    "input_throughput": 6779.7146965393895,
    "output_throughput": 5946.330600383748,
    "total_throughput": 12726.045296923137,
    "itl": 85.8542586163789,
    "ttft": 1227881.6439564403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 613,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0587485884502494,
    "arrivals": 129353,
    "finished_requests": 98078,
    "scheduler_time": 263.3665336572114
}
#Debug simulation 
Total elapsed time: 163.39518353901803. Arrivals time: 0.761701398063451 Scheduler time: 162.23781438777223 Scheduler overhead time: 0.16060901107266545 Adapter cache time: 0.034532589837908745 Engine time: 0.15063798055052757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 168.2790507869795,
    "estimated_duration": 3600.027401902875,
    "input_throughput": 6715.60499434561,
    "output_throughput": 5948.293057069827,
    "total_throughput": 12663.898051415437,
    "itl": 86.23938768983342,
    "ttft": 1198561.342406846,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 586,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.79344581794462,
    "arrivals": 128453,
    "finished_requests": 97319,
    "scheduler_time": 265.2646623000778
}
#Debug simulation 
Total elapsed time: 168.27920976281166. Arrivals time: 0.7861321121454239 Scheduler time: 167.08846337907016 Scheduler overhead time: 0.16238864744082093 Adapter cache time: 0.03610027115792036 Engine time: 0.15568927209824324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 171.58822941593826,
    "estimated_duration": 3600.015681359671,
    "input_throughput": 6844.482963666913,
    "output_throughput": 6022.642932436113,
    "total_throughput": 12867.125896103025,
    "itl": 88.1646554609547,
    "ttft": 1208516.4929722494,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9251162294577866,
    "arrivals": 128453,
    "finished_requests": 99196,
    "scheduler_time": 258.3882504759667
}
#Debug simulation 
Total elapsed time: 171.5883699688129. Arrivals time: 0.8020880063995719 Scheduler time: 170.3718516919762 Scheduler overhead time: 0.16805012710392475 Adapter cache time: 0.03626553388312459 Engine time: 0.16002651769667864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 173.20846442412585,
    "estimated_duration": 3600.0182891267054,
    "input_throughput": 6844.478005687367,
    "output_throughput": 6022.638569777804,
    "total_throughput": 12867.116575465172,
    "itl": 88.1701696629504,
    "ttft": 1208519.7097464737,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.928551633618784,
    "arrivals": 128453,
    "finished_requests": 99196,
    "scheduler_time": 258.38882337893114
}
#Debug simulation 
Total elapsed time: 173.20862211333588. Arrivals time: 0.8026529266498983 Scheduler time: 171.99722868856043 Scheduler overhead time: 0.16664269706234336 Adapter cache time: 0.036079227458685637 Engine time: 0.1559807639569044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 165.34090224001557,
    "estimated_duration": 3600.1063169312483,
    "input_throughput": 6669.329149275379,
    "output_throughput": 5873.240993066982,
    "total_throughput": 12542.570142342362,
    "itl": 84.57750554036095,
    "ttft": 1235583.1939592895,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 573,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7913405248010439,
    "arrivals": 128453,
    "finished_requests": 96800,
    "scheduler_time": 266.90233775642673
}
#Debug simulation 
Total elapsed time: 165.34108707495034. Arrivals time: 0.7845954028889537 Scheduler time: 164.14897424448282 Scheduler overhead time: 0.16449273843318224 Adapter cache time: 0.034937265794724226 Engine time: 0.15515900263562799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 162.04607012495399,
    "estimated_duration": 3600.027688754774,
    "input_throughput": 6735.266808013615,
    "output_throughput": 5969.969638604075,
    "total_throughput": 12705.23644661769,
    "itl": 85.32046783408589,
    "ttft": 1196476.3404766177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0269760558567964,
    "arrivals": 128453,
    "finished_requests": 97718,
    "scheduler_time": 262.28619501074746
}
#Debug simulation 
Total elapsed time: 162.04620756488293. Arrivals time: 0.7883754032664001 Scheduler time: 160.8554517221637 Scheduler overhead time: 0.16240647761151195 Adapter cache time: 0.034860963467508554 Engine time: 0.15491578169167042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 166.26009108917788,
    "estimated_duration": 3600.095444351379,
    "input_throughput": 6719.244912785429,
    "output_throughput": 5932.652989384298,
    "total_throughput": 12651.897902169727,
    "itl": 86.63240603723423,
    "ttft": 1206835.1627308733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 599,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7910401266463765,
    "arrivals": 128453,
    "finished_requests": 97405,
    "scheduler_time": 264.90319706351283
}
#Debug simulation 
Total elapsed time: 166.2602411331609. Arrivals time: 0.7741609993390739 Scheduler time: 165.08322630589828 Scheduler overhead time: 0.1625944902189076 Adapter cache time: 0.035146762151271105 Engine time: 0.1543926685117185 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 4320, 33, 4320, 4320, 33, 4320, 135, 4320, 33, 135, 33, 4320, 135, 135, 135, 135, 4320, 33, 33, 33, 135, 4320, 33, 4320, 4320, 135, 135, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 33, 135, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 4320, 33, 4320, 4320, 135, 33, 33, 4320, 135, 33, 135, 135, 4320, 135, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 4320, 4320, 33, 4320, 33, 135, 4320, 4320, 4320, 135, 33, 4320, 135, 33, 33, 33, 33, 33, 4320, 135, 33, 4320, 33, 4320, 33, 33, 135, 135, 4320, 135, 4320, 33, 135, 33, 4320, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 135, 4320, 4320, 135, 33, 4320, 33, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 135, 4320, 135, 4320, 33, 4320, 33, 135, 4320, 135, 4320, 135, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 135, 135, 33, 135, 4320, 135, 135, 4320, 33, 4320, 4320, 135, 33, 4320, 4320, 135, 135, 4320, 4320, 135, 135, 135, 135, 4320, 4320, 135, 135, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 4320, 135, 33, 33, 33, 33]
Prompts retrieved: 385800 . Total input tokens: 85943615 . Total output tokens: 77196567
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 170.32282129395753,
    "estimated_duration": 3600.0374098704838,
    "input_throughput": 6811.512272835576,
    "output_throughput": 5991.732458351322,
    "total_throughput": 12803.244731186898,
    "itl": 87.86171281327064,
    "ttft": 1215005.5847819466,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 591,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.981605145595963,
    "arrivals": 128453,
    "finished_requests": 98761,
    "scheduler_time": 259.8892404047979
}
#Debug simulation 
Total elapsed time: 170.32296657701954. Arrivals time: 0.813224139623344 Scheduler time: 169.09598542610183 Scheduler overhead time: 0.1672402499243617 Adapter cache time: 0.03631820809096098 Engine time: 0.15887874457985163 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 169.03545602597296,
    "estimated_duration": 3600.0851480853876,
    "input_throughput": 6763.934462203016,
    "output_throughput": 5954.369721338483,
    "total_throughput": 12718.304183541499,
    "itl": 86.42597744836092,
    "ttft": 1205714.2082853634,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7138731366023656,
    "arrivals": 126425,
    "finished_requests": 98316,
    "scheduler_time": 259.497305709809
}
#Debug simulation 
Total elapsed time: 169.03563677426428. Arrivals time: 0.7818540125153959 Scheduler time: 167.84263358963653 Scheduler overhead time: 0.16563007701188326 Adapter cache time: 0.036609561648219824 Engine time: 0.15828295052051544 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 170.60471996013075,
    "estimated_duration": 3600.0228254176122,
    "input_throughput": 6784.423095197109,
    "output_throughput": 6002.196110379775,
    "total_throughput": 12786.619205576884,
    "itl": 87.02321265770459,
    "ttft": 1171928.2671301067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8617677487595994,
    "arrivals": 126425,
    "finished_requests": 98620,
    "scheduler_time": 258.24320152799123
}
#Debug simulation 
Total elapsed time: 170.60488128196448. Arrivals time: 0.783480241894722 Scheduler time: 169.41422959789634 Scheduler overhead time: 0.16320377914234996 Adapter cache time: 0.03649027552455664 Engine time: 0.15606457507237792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 171.0526986378245,
    "estimated_duration": 3600.087465290428,
    "input_throughput": 6780.086938257449,
    "output_throughput": 5973.406815066132,
    "total_throughput": 12753.49375332358,
    "itl": 87.03439752260277,
    "ttft": 1190466.1504834301,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 588,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9211156059429169,
    "arrivals": 126425,
    "finished_requests": 98582,
    "scheduler_time": 258.18334690686606
}
#Debug simulation 
Total elapsed time: 171.0528519549407. Arrivals time: 0.7895642947405577 Scheduler time: 169.8469215161167 Scheduler overhead time: 0.16871914779767394 Adapter cache time: 0.036775543354451656 Engine time: 0.16033032955601811 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 169.24824396008626,
    "estimated_duration": 3600.120452094033,
    "input_throughput": 6757.72750488087,
    "output_throughput": 5953.798014600469,
    "total_throughput": 12711.52551948134,
    "itl": 86.14988208275834,
    "ttft": 1206333.1986143452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 565,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7653771458496244,
    "arrivals": 126425,
    "finished_requests": 98288,
    "scheduler_time": 259.4424068989668
}
#Debug simulation 
Total elapsed time: 169.24839132931083. Arrivals time: 0.7836671592667699 Scheduler time: 168.05715595604852 Scheduler overhead time: 0.16497886553406715 Adapter cache time: 0.03649045340716839 Engine time: 0.15554060135036707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 173.98196250386536,
    "estimated_duration": 3600.0556139234586,
    "input_throughput": 6658.200753148039,
    "output_throughput": 5862.022497202646,
    "total_throughput": 12520.223250350686,
    "itl": 83.35017699714601,
    "ttft": 1226704.8807724882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.903922610506419,
    "arrivals": 126425,
    "finished_requests": 96825,
    "scheduler_time": 265.5083154673395
}
#Debug simulation 
Total elapsed time: 173.98210520902649. Arrivals time: 0.7765618646517396 Scheduler time: 172.7962732836604 Scheduler overhead time: 0.1637529623694718 Adapter cache time: 0.036067504435777664 Engine time: 0.15679181879386306 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 170.16067720390856,
    "estimated_duration": 3600.1097371132428,
    "input_throughput": 6671.767738741146,
    "output_throughput": 5880.629910180446,
    "total_throughput": 12552.397648921593,
    "itl": 84.10760666857627,
    "ttft": 1231680.9481677914,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 568,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6983485675044123,
    "arrivals": 126425,
    "finished_requests": 97137,
    "scheduler_time": 264.63408774724076
}
#Debug simulation 
Total elapsed time: 170.16082495590672. Arrivals time: 0.7836991539224982 Scheduler time: 168.96818855777383 Scheduler overhead time: 0.16598613699898124 Adapter cache time: 0.03526212181895971 Engine time: 0.1566245397552848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 4320, 33, 4320, 4320, 33, 4320, 66, 4320, 33, 66, 33, 4320, 66, 66, 66, 66, 4320, 33, 33, 33, 66, 4320, 33, 4320, 4320, 66, 66, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 33, 66, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 4320, 33, 4320, 4320, 66, 33, 33, 4320, 66, 33, 66, 66, 4320, 66, 33, 33, 4320, 4320, 4320, 4320, 4320, 4320, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 4320, 4320, 33, 4320, 33, 66, 4320, 4320, 4320, 66, 33, 4320, 66, 33, 33, 33, 33, 33, 4320, 66, 33, 4320, 33, 4320, 33, 33, 66, 66, 4320, 66, 4320, 33, 66, 33, 4320, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 33, 33, 33, 33, 33, 4320, 33, 33, 33, 4320, 33, 66, 4320, 4320, 66, 33, 4320, 33, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 66, 4320, 66, 4320, 33, 4320, 33, 66, 4320, 66, 4320, 66, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 66, 66, 33, 66, 4320, 66, 66, 4320, 33, 4320, 4320, 66, 33, 4320, 4320, 66, 66, 4320, 4320, 66, 66, 66, 66, 4320, 4320, 66, 66, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 4320, 66, 33, 33, 33, 33]
Prompts retrieved: 379935 . Total input tokens: 84650362 . Total output tokens: 76040480
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 171.81924101198092,
    "estimated_duration": 3600.004212958697,
    "input_throughput": 6774.130961351681,
    "output_throughput": 5962.718855364373,
    "total_throughput": 12736.849816716054,
    "itl": 86.82905655405659,
    "ttft": 1204327.22164242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 560,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8747550266981092,
    "arrivals": 126425,
    "finished_requests": 98448,
    "scheduler_time": 258.9983882321721
}
#Debug simulation 
Total elapsed time: 171.81939940620214. Arrivals time: 0.7902301354333758 Scheduler time: 170.61301305005327 Scheduler overhead time: 0.1684661926701665 Adapter cache time: 0.03676719032227993 Engine time: 0.15977256605401635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.448020997922868,
    "estimated_duration": 3600.017343997725,
    "input_throughput": 3583.5041243646165,
    "output_throughput": 3168.2758470641434,
    "total_throughput": 6751.779971428759,
    "itl": 30.894089290903946,
    "ttft": 300870.4557082117,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.312284712521521,
    "arrivals": 54189,
    "finished_requests": 51772,
    "scheduler_time": 74.46944657444911
}
#Debug simulation 
Total elapsed time: 10.4481470878236. Arrivals time: 0.23436397220939398 Scheduler time: 9.848568905610591 Scheduler overhead time: 0.14084525173529983 Adapter cache time: 0.03743526851758361 Engine time: 0.12626141728833318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 10.583066138904542,
    "estimated_duration": 3599.998503114513,
    "input_throughput": 3580.01204413002,
    "output_throughput": 3166.0368719985127,
    "total_throughput": 6746.048916128532,
    "itl": 30.872009099565172,
    "ttft": 304441.03706305684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.850338190491108,
    "arrivals": 54189,
    "finished_requests": 51717,
    "scheduler_time": 74.49063272014841
}
#Debug simulation 
Total elapsed time: 10.583180811721832. Arrivals time: 0.26087727630510926 Scheduler time: 9.953296476509422 Scheduler overhead time: 0.14215880306437612 Adapter cache time: 0.03909469489008188 Engine time: 0.12669065361842513 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 10.415613138116896,
    "estimated_duration": 3600.0177497585396,
    "input_throughput": 3580.681789934117,
    "output_throughput": 3166.852441426065,
    "total_throughput": 6747.534231360182,
    "itl": 30.880204697699803,
    "ttft": 303630.7784897187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.869516378175282,
    "arrivals": 54189,
    "finished_requests": 51730,
    "scheduler_time": 74.48906167241998
}
#Debug simulation 
Total elapsed time: 10.41570524405688. Arrivals time: 0.23239507619291544 Scheduler time: 9.81850455654785 Scheduler overhead time: 0.1422534491866827 Adapter cache time: 0.03747310908511281 Engine time: 0.12477740133181214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 10.340290818363428,
    "estimated_duration": 3600.0005057033654,
    "input_throughput": 3580.216441520138,
    "output_throughput": 3166.3759440980634,
    "total_throughput": 6746.592385618202,
    "itl": 30.88171444187357,
    "ttft": 301250.1101617604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2751,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.599901672967071,
    "arrivals": 54189,
    "finished_requests": 51749,
    "scheduler_time": 74.06898774886614
}
#Debug simulation 
Total elapsed time: 10.340435543097556. Arrivals time: 0.22867372585460544 Scheduler time: 9.746202510315925 Scheduler overhead time: 0.1403177035972476 Adapter cache time: 0.03887099493294954 Engine time: 0.1259029796347022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_256_slots_16_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 10.282533313147724,
    "estimated_duration": 3599.992725625106,
    "input_throughput": 3582.797795170648,
    "output_throughput": 3169.4619599595862,
    "total_throughput": 6752.259755130234,
    "itl": 30.896929404052276,
    "ttft": 300725.2346056428,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.057537225987431,
    "arrivals": 54189,
    "finished_requests": 51768,
    "scheduler_time": 74.33797114840073
}
#Debug simulation 
Total elapsed time: 10.28263612324372. Arrivals time: 0.22499597631394863 Scheduler time: 9.694352039135993 Scheduler overhead time: 0.13945684675127268 Adapter cache time: 0.0375686758197844 Engine time: 0.12577392859384418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_16_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_256_slots_16_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 10.475352881941944,
    "estimated_duration": 3600.0314445756117,
    "input_throughput": 3583.4900885208217,
    "output_throughput": 3168.2634375835496,
    "total_throughput": 6751.753526104371,
    "itl": 30.89232086251441,
    "ttft": 300867.5916303269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2716,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.120976600954092,
    "arrivals": 54189,
    "finished_requests": 51772,
    "scheduler_time": 74.47104083108333
}
#Debug simulation 
Total elapsed time: 10.47545634675771. Arrivals time: 0.23750301031395793 Scheduler time: 9.86673826770857 Scheduler overhead time: 0.14100173441693187 Adapter cache time: 0.037541883531957865 Engine time: 0.13189518777653575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_16_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_256_slots_16_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 270, 1080, 1080, 270, 1080, 540, 1080, 270, 540, 270, 1080, 540, 540, 540, 540, 1080, 270, 270, 270, 540, 1080, 270, 1080, 1080, 540, 540, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 270, 540, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 1080, 270, 1080, 1080, 540, 270, 270, 1080, 540, 270, 540, 540, 1080, 540, 270, 270, 1080, 1080, 1080, 1080, 1080, 1080, 270, 540, 270, 540, 270, 270, 270, 540, 540, 540, 270, 270, 1080, 1080, 270, 1080, 270, 540, 1080, 1080, 1080, 540, 270, 1080, 540, 270, 270, 270, 270, 270, 1080, 540, 270, 1080, 270, 1080, 270, 270, 540, 540, 1080, 540, 1080, 270, 540, 270, 1080, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 270, 270, 270, 270, 270, 1080, 270, 270, 270, 1080, 270, 540, 1080, 1080, 540, 270, 1080, 270, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 540, 1080, 540, 1080, 270, 1080, 270, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 540, 540, 270, 540, 1080, 540, 540, 1080, 270, 1080, 1080, 540, 270, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 270, 540, 270, 270, 270, 270, 540, 540, 540, 540, 540, 1080, 540, 270, 270, 270, 270]
Prompts retrieved: 161730 . Total input tokens: 36052490 . Total output tokens: 32364050
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 10.347356729209423,
    "estimated_duration": 3600.0011644128417,
    "input_throughput": 3580.0093976086346,
    "output_throughput": 3166.0345315079817,
    "total_throughput": 6746.043929116616,
    "itl": 30.873998275534202,
    "ttft": 304446.60418671067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2713,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.093709951377964,
    "arrivals": 54189,
    "finished_requests": 51717,
    "scheduler_time": 74.48971926228977
}
#Debug simulation 
Total elapsed time: 10.347450951114297. Arrivals time: 0.22754742624238133 Scheduler time: 9.756085104309022 Scheduler overhead time: 0.14205838181078434 Adapter cache time: 0.03692137962207198 Engine time: 0.12448998261243105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 9.146699293982238,
    "estimated_duration": 3599.880930283849,
    "input_throughput": 3350.7513813932987,
    "output_throughput": 2939.126378039879,
    "total_throughput": 6289.877759433178,
    "itl": 29.74690516414184,
    "ttft": 269395.4468822695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2793,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.547942268804283,
    "arrivals": 50289,
    "finished_requests": 48342,
    "scheduler_time": 64.9297484577236
}
#Debug simulation 
Total elapsed time: 9.146817475091666. Arrivals time: 0.20210437662899494 Scheduler time: 8.576294617261738 Scheduler overhead time: 0.14229888515546918 Adapter cache time: 0.03715594206005335 Engine time: 0.1271172547712922 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.033178279176354,
    "estimated_duration": 3599.8868170419,
    "input_throughput": 3353.462098544497,
    "output_throughput": 2943.013083035129,
    "total_throughput": 6296.475181579626,
    "itl": 29.721880659310095,
    "ttft": 264731.4512147334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2809,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.163941714500396,
    "arrivals": 50289,
    "finished_requests": 48396,
    "scheduler_time": 64.64140890243507
}
#Debug simulation 
Total elapsed time: 9.033264171332121. Arrivals time: 0.2032897537574172 Scheduler time: 8.46194847021252 Scheduler overhead time: 0.14150339784100652 Adapter cache time: 0.0370708703994751 Engine time: 0.12765440996736288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 9.122713130898774,
    "estimated_duration": 3599.8715514938217,
    "input_throughput": 3353.7357728750394,
    "output_throughput": 2943.315573469062,
    "total_throughput": 6297.051346344102,
    "itl": 29.72502630258994,
    "ttft": 264431.0316702155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.18395252229622,
    "arrivals": 50289,
    "finished_requests": 48402,
    "scheduler_time": 64.67119235499459
}
#Debug simulation 
Total elapsed time: 9.122819454874843. Arrivals time: 0.21040686825290322 Scheduler time: 8.540422870777547 Scheduler overhead time: 0.14251296781003475 Adapter cache time: 0.038007759023457766 Engine time: 0.12980400724336505 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.769568907096982,
    "estimated_duration": 3599.8839153007534,
    "input_throughput": 3356.8801895631145,
    "output_throughput": 2945.1471907016303,
    "total_throughput": 6302.027380264745,
    "itl": 29.579777627311348,
    "ttft": 252192.04575671154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3042,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.51331741253848,
    "arrivals": 50289,
    "finished_requests": 48432,
    "scheduler_time": 61.317272955274355
}
#Debug simulation 
Total elapsed time: 8.769667521119118. Arrivals time: 0.19837821600958705 Scheduler time: 8.201319155283272 Scheduler overhead time: 0.142210659570992 Adapter cache time: 0.038087045308202505 Engine time: 0.12785811442881823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 9.085448634345084,
    "estimated_duration": 3599.873488443747,
    "input_throughput": 3353.978699184687,
    "output_throughput": 2942.80730531443,
    "total_throughput": 6296.786004499117,
    "itl": 29.69986552019414,
    "ttft": 263933.2679623848,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.334916988610859,
    "arrivals": 50289,
    "finished_requests": 48398,
    "scheduler_time": 64.39600750605338
}
#Debug simulation 
Total elapsed time: 9.085538919083774. Arrivals time: 0.20939630921930075 Scheduler time: 8.509890952613205 Scheduler overhead time: 0.1414581798017025 Adapter cache time: 0.03697636630386114 Engine time: 0.12627539690583944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.845680322032422,
    "estimated_duration": 3599.882170874404,
    "input_throughput": 3355.401212219683,
    "output_throughput": 2942.556310788088,
    "total_throughput": 6297.957523007772,
    "itl": 29.550943555025558,
    "ttft": 253612.28565231463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3036,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.077792695323039,
    "arrivals": 50289,
    "finished_requests": 48412,
    "scheduler_time": 61.318285603014985
}
#Debug simulation 
Total elapsed time: 8.84579776506871. Arrivals time: 0.2089807135052979 Scheduler time: 8.263878064230084 Scheduler overhead time: 0.14284400641918182 Adapter cache time: 0.03902876656502485 Engine time: 0.1289229253306985 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 135, 1080, 1080, 135, 1080, 540, 1080, 135, 540, 135, 1080, 540, 540, 540, 540, 1080, 135, 135, 135, 540, 1080, 135, 1080, 1080, 540, 540, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 135, 540, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 1080, 135, 1080, 1080, 540, 135, 135, 1080, 540, 135, 540, 540, 1080, 540, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 540, 135, 540, 135, 135, 135, 540, 540, 540, 135, 135, 1080, 1080, 135, 1080, 135, 540, 1080, 1080, 1080, 540, 135, 1080, 540, 135, 135, 135, 135, 135, 1080, 540, 135, 1080, 135, 1080, 135, 135, 540, 540, 1080, 540, 1080, 135, 540, 135, 1080, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 540, 1080, 1080, 540, 135, 1080, 135, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 540, 1080, 540, 1080, 135, 1080, 135, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 540, 540, 135, 540, 1080, 540, 540, 1080, 135, 1080, 1080, 540, 135, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 135, 540, 135, 135, 135, 135, 540, 540, 540, 540, 540, 1080, 540, 135, 135, 135, 135]
Prompts retrieved: 150255 . Total input tokens: 33450605 . Total output tokens: 30090347
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 8.829464751295745,
    "estimated_duration": 3599.8945911889637,
    "input_throughput": 3356.84884484599,
    "output_throughput": 2944.2923206535734,
    "total_throughput": 6301.141165499564,
    "itl": 29.570440200200437,
    "ttft": 253793.11554716906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3029,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.155933185554495,
    "arrivals": 50289,
    "finished_requests": 48416,
    "scheduler_time": 61.473917908448314
}
#Debug simulation 
Total elapsed time: 8.82956251502037. Arrivals time: 0.19675944279879332 Scheduler time: 8.25969619769603 Scheduler overhead time: 0.14308227319270372 Adapter cache time: 0.03868899121880531 Engine time: 0.1289591258391738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 8.129034991841763,
    "estimated_duration": 3600.015004678022,
    "input_throughput": 3216.097428748221,
    "output_throughput": 2859.7572472953566,
    "total_throughput": 6075.8546760435775,
    "itl": 29.084795992162363,
    "ttft": 230264.6147041303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3122,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.554842736557902,
    "arrivals": 48457,
    "finished_requests": 46802,
    "scheduler_time": 54.84724851075844
}
#Debug simulation 
Total elapsed time: 8.12918470799923. Arrivals time: 0.19818617217242718 Scheduler time: 7.556586489547044 Scheduler overhead time: 0.14390648901462555 Adapter cache time: 0.038474883418530226 Engine time: 0.12954815616831183 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.918024287093431,
    "estimated_duration": 3600.0005251309417,
    "input_throughput": 3213.4300868134533,
    "output_throughput": 2859.304305136344,
    "total_throughput": 6072.734391949797,
    "itl": 29.10563200076324,
    "ttft": 232413.68481568803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.174749229266347,
    "arrivals": 48457,
    "finished_requests": 46770,
    "scheduler_time": 54.78966182419669
}
#Debug simulation 
Total elapsed time: 7.918207899201661. Arrivals time: 0.17563151102513075 Scheduler time: 7.38105099927634 Scheduler overhead time: 0.1385176908224821 Adapter cache time: 0.036488568875938654 Engine time: 0.1252820286899805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.91344139399007,
    "estimated_duration": 3600.0215024854174,
    "input_throughput": 3214.520522172041,
    "output_throughput": 2859.137644842913,
    "total_throughput": 6073.6581670149535,
    "itl": 29.097626998033196,
    "ttft": 231358.69663373756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3115,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.177314537614171,
    "arrivals": 48457,
    "finished_requests": 46790,
    "scheduler_time": 54.89431566779052
}
#Debug simulation 
Total elapsed time: 7.913539109285921. Arrivals time: 0.17082919273525476 Scheduler time: 7.382673036772758 Scheduler overhead time: 0.1381072993390262 Adapter cache time: 0.036362535785883665 Engine time: 0.1245348653756082 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 7.9695750661194324,
    "estimated_duration": 3600.0096830965986,
    "input_throughput": 3213.705244828243,
    "output_throughput": 2860.1503624688203,
    "total_throughput": 6073.855607297063,
    "itl": 29.09432801306418,
    "ttft": 230949.87424818953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.751444479362187,
    "arrivals": 48457,
    "finished_requests": 46792,
    "scheduler_time": 54.847658845172866
}
#Debug simulation 
Total elapsed time: 7.969680623151362. Arrivals time: 0.18461215775460005 Scheduler time: 7.419459295924753 Scheduler overhead time: 0.14129537576809525 Adapter cache time: 0.03681046515703201 Engine time: 0.1258455803617835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.919165470637381,
    "estimated_duration": 3600.025409941305,
    "input_throughput": 3217.715621676366,
    "output_throughput": 2861.965077120937,
    "total_throughput": 6079.680698797303,
    "itl": 29.117518001638956,
    "ttft": 228075.97779558937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3127,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.34660417277315,
    "arrivals": 48457,
    "finished_requests": 46830,
    "scheduler_time": 54.78065547920437
}
#Debug simulation 
Total elapsed time: 7.919254770036787. Arrivals time: 0.18088691122829914 Scheduler time: 7.373307584784925 Scheduler overhead time: 0.1419870015233755 Adapter cache time: 0.036207211669534445 Engine time: 0.1259299786761403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.99370995676145,
    "estimated_duration": 3600.015349102904,
    "input_throughput": 3214.6871270656893,
    "output_throughput": 2859.417530696132,
    "total_throughput": 6074.104657761822,
    "itl": 29.15316744551641,
    "ttft": 231804.46206480116,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.328956920094887,
    "arrivals": 48457,
    "finished_requests": 46781,
    "scheduler_time": 54.84427996212882
}
#Debug simulation 
Total elapsed time: 7.993882107082754. Arrivals time: 0.18520774831995368 Scheduler time: 7.445688547566533 Scheduler overhead time: 0.1388960164040327 Adapter cache time: 0.03663674369454384 Engine time: 0.1261684480123222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 66, 1080, 1080, 66, 1080, 540, 1080, 66, 540, 66, 1080, 540, 540, 540, 540, 1080, 66, 66, 66, 540, 1080, 66, 1080, 1080, 540, 540, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 66, 540, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 1080, 66, 1080, 1080, 540, 66, 66, 1080, 540, 66, 540, 540, 1080, 540, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 540, 66, 540, 66, 66, 66, 540, 540, 540, 66, 66, 1080, 1080, 66, 1080, 66, 540, 1080, 1080, 1080, 540, 66, 1080, 540, 66, 66, 66, 66, 66, 1080, 540, 66, 1080, 66, 1080, 66, 66, 540, 540, 1080, 540, 1080, 66, 540, 66, 1080, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 540, 1080, 1080, 540, 66, 1080, 66, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 540, 1080, 540, 1080, 66, 1080, 66, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 540, 540, 66, 540, 1080, 540, 540, 1080, 66, 1080, 1080, 540, 66, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 66, 540, 66, 66, 66, 66, 540, 540, 540, 540, 540, 1080, 540, 66, 66, 66, 66]
Prompts retrieved: 144390 . Total input tokens: 32113289 . Total output tokens: 28897004
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.925516812130809,
    "estimated_duration": 3600.0294357279963,
    "input_throughput": 3213.5062244735727,
    "output_throughput": 2859.2818985988247,
    "total_throughput": 6072.788123072397,
    "itl": 29.10899623483597,
    "ttft": 232418.22146037317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3120,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.45419145971479,
    "arrivals": 48457,
    "finished_requests": 46771,
    "scheduler_time": 54.79163288161508
}
#Debug simulation 
Total elapsed time: 7.925603542011231. Arrivals time: 0.17973426263779402 Scheduler time: 7.382433775346726 Scheduler overhead time: 0.13934697629883885 Adapter cache time: 0.03634526487439871 Engine time: 0.12654375191777945 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.585305002052337,
    "estimated_duration": 3599.9290532873647,
    "input_throughput": 3164.792925459509,
    "output_throughput": 2833.834180894247,
    "total_throughput": 5998.627106353756,
    "itl": 28.844259801244974,
    "ttft": 212046.37626170175,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3077,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.417120788080963,
    "arrivals": 47448,
    "finished_requests": 45977,
    "scheduler_time": 51.42609752910376
}
#Debug simulation 
Total elapsed time: 7.585409606806934. Arrivals time: 0.1647114078514278 Scheduler time: 7.056936925277114 Scheduler overhead time: 0.1395006636157632 Adapter cache time: 0.036032396368682384 Engine time: 0.12685005879029632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.972618465777487,
    "estimated_duration": 3599.914558298927,
    "input_throughput": 3143.234045351029,
    "output_throughput": 2817.6482624057126,
    "total_throughput": 5960.882307756741,
    "itl": 29.030339788579244,
    "ttft": 251758.59266901913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.721747081689314,
    "arrivals": 47448,
    "finished_requests": 45682,
    "scheduler_time": 57.02025631522057
}
#Debug simulation 
Total elapsed time: 7.97272084094584. Arrivals time: 0.16882353741675615 Scheduler time: 7.442997871432453 Scheduler overhead time: 0.13913468550890684 Adapter cache time: 0.03431444987654686 Engine time: 0.12617117119953036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.9265050841495395,
    "estimated_duration": 3599.926717724687,
    "input_throughput": 3141.0733847234883,
    "output_throughput": 2815.2534189378116,
    "total_throughput": 5956.3268036613,
    "itl": 29.01219984002353,
    "ttft": 255637.01653302833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2671,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.730551127809866,
    "arrivals": 47448,
    "finished_requests": 45627,
    "scheduler_time": 56.95936881621143
}
#Debug simulation 
Total elapsed time: 7.926618358120322. Arrivals time: 0.17785437544807792 Scheduler time: 7.390006987378001 Scheduler overhead time: 0.13819089205935597 Adapter cache time: 0.034550835844129324 Engine time: 0.12481111520901322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 8.020685898140073,
    "estimated_duration": 3599.923338859668,
    "input_throughput": 3140.079922807671,
    "output_throughput": 2815.3249516725555,
    "total_throughput": 5955.404874480227,
    "itl": 28.98715477147933,
    "ttft": 256607.2193892631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.33417684591818,
    "arrivals": 47448,
    "finished_requests": 45612,
    "scheduler_time": 56.91292539321821
}
#Debug simulation 
Total elapsed time: 8.020776744000614. Arrivals time: 0.18765938328579068 Scheduler time: 7.470067578367889 Scheduler overhead time: 0.1395569695159793 Adapter cache time: 0.035765230655670166 Engine time: 0.1264346344396472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 7.983573035337031,
    "estimated_duration": 3599.9353332062196,
    "input_throughput": 3140.5178020047406,
    "output_throughput": 2815.5139084048055,
    "total_throughput": 5956.031710409547,
    "itl": 28.99829282621994,
    "ttft": 254982.7069756983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.859713076930197,
    "arrivals": 47448,
    "finished_requests": 45635,
    "scheduler_time": 56.93993812713416
}
#Debug simulation 
Total elapsed time: 7.983682397287339. Arrivals time: 0.1790059069171548 Scheduler time: 7.444391423370689 Scheduler overhead time: 0.1388510619290173 Adapter cache time: 0.03437012992799282 Engine time: 0.12577263498678803 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 7.601515317801386,
    "estimated_duration": 3599.9359129979102,
    "input_throughput": 3164.7868949178746,
    "output_throughput": 2833.8287809975027,
    "total_throughput": 5998.615675915377,
    "itl": 28.843675464406143,
    "ttft": 212054.88697295391,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3077,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.20038475741406,
    "arrivals": 47448,
    "finished_requests": 45977,
    "scheduler_time": 51.42989529853698
}
#Debug simulation 
Total elapsed time: 7.601626584772021. Arrivals time: 0.16621909942477942 Scheduler time: 7.073912578634918 Scheduler overhead time: 0.1386439111083746 Adapter cache time: 0.03584160888567567 Engine time: 0.12571209715679288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [85 85 86]
Adapter prompts. [540, 540, 1080, 33, 1080, 1080, 33, 1080, 540, 1080, 33, 540, 33, 1080, 540, 540, 540, 540, 1080, 33, 33, 33, 540, 1080, 33, 1080, 1080, 540, 540, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 33, 540, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 1080, 33, 1080, 1080, 540, 33, 33, 1080, 540, 33, 540, 540, 1080, 540, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 540, 33, 540, 33, 33, 33, 540, 540, 540, 33, 33, 1080, 1080, 33, 1080, 33, 540, 1080, 1080, 1080, 540, 33, 1080, 540, 33, 33, 33, 33, 33, 1080, 540, 33, 1080, 33, 1080, 33, 33, 540, 540, 1080, 540, 1080, 33, 540, 33, 1080, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 540, 1080, 1080, 540, 33, 1080, 33, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 540, 1080, 540, 1080, 33, 1080, 33, 540, 1080, 540, 1080, 540, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 540, 540, 33, 540, 1080, 540, 540, 1080, 33, 1080, 1080, 540, 33, 1080, 1080, 540, 540, 1080, 1080, 540, 540, 540, 540, 1080, 1080, 540, 540, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 33, 540, 33, 33, 33, 33, 540, 540, 540, 540, 540, 1080, 540, 33, 33, 33, 33]
Prompts retrieved: 141585 . Total input tokens: 31494608 . Total output tokens: 28327874
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 7.878132836893201,
    "estimated_duration": 3599.9128896665547,
    "input_throughput": 3141.1326736429437,
    "output_throughput": 2814.0361476742087,
    "total_throughput": 5955.168821317152,
    "itl": 28.939137508800776,
    "ttft": 256187.46325489433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2690,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.02000500760929,
    "arrivals": 47448,
    "finished_requests": 45606,
    "scheduler_time": 56.64887749546339
}
#Debug simulation 
Total elapsed time: 7.878234388772398. Arrivals time: 0.16869039135053754 Scheduler time: 7.348709662910551 Scheduler overhead time: 0.1389600271359086 Adapter cache time: 0.034209045581519604 Engine time: 0.1264530890621245 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.848295993637294,
    "estimated_duration": 3599.8287088736743,
    "input_throughput": 2854.5222095345534,
    "output_throughput": 2521.9572191368366,
    "total_throughput": 5376.47942867139,
    "itl": 27.604990745694387,
    "ttft": 231948.8705780231,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.09654906723386,
    "arrivals": 42675,
    "finished_requests": 41189,
    "scheduler_time": 46.03993274789293
}
#Debug simulation 
Total elapsed time: 6.848402423784137. Arrivals time: 0.1563103199005127 Scheduler time: 6.319881391245872 Scheduler overhead time: 0.14152891607955098 Adapter cache time: 0.03766530239954591 Engine time: 0.12972712563350797 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.855755616910756,
    "estimated_duration": 3599.816007172431,
    "input_throughput": 2856.8448997141736,
    "output_throughput": 2522.4833663464083,
    "total_throughput": 5379.328266060582,
    "itl": 27.619008584107025,
    "ttft": 229613.53820671077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.81270963863019,
    "arrivals": 42675,
    "finished_requests": 41213,
    "scheduler_time": 45.920506843982075
}
#Debug simulation 
Total elapsed time: 6.855876279994845. Arrivals time: 0.15691493451595306 Scheduler time: 6.324381165206432 Scheduler overhead time: 0.14272124087437987 Adapter cache time: 0.03769668750464916 Engine time: 0.1305553149431944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.872612453997135,
    "estimated_duration": 3599.821468329257,
    "input_throughput": 2850.4569157876545,
    "output_throughput": 2519.495780497534,
    "total_throughput": 5369.952696285188,
    "itl": 27.607585318222753,
    "ttft": 236456.28788820238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3275,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.706770737729464,
    "arrivals": 42675,
    "finished_requests": 41138,
    "scheduler_time": 46.12784352797206
}
#Debug simulation 
Total elapsed time: 6.8727059829980135. Arrivals time: 0.15877421433106065 Scheduler time: 6.3400342389941216 Scheduler overhead time: 0.1420476557686925 Adapter cache time: 0.0374736743979156 Engine time: 0.1308502061292529 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.7963827373459935,
    "estimated_duration": 3599.8072110736507,
    "input_throughput": 2856.976887085185,
    "output_throughput": 2522.934831638178,
    "total_throughput": 5379.911718723363,
    "itl": 27.611564064066265,
    "ttft": 228902.30936860765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.38758378602353,
    "arrivals": 42675,
    "finished_requests": 41222,
    "scheduler_time": 45.93712940704579
}
#Debug simulation 
Total elapsed time: 6.796479773242027. Arrivals time: 0.15701545169577003 Scheduler time: 6.267139909323305 Scheduler overhead time: 0.14154342794790864 Adapter cache time: 0.03780056117102504 Engine time: 0.12967137387022376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.8351248241961,
    "estimated_duration": 3599.806120595551,
    "input_throughput": 2856.865246481272,
    "output_throughput": 2522.9217062660787,
    "total_throughput": 5379.78695274735,
    "itl": 27.61862159892502,
    "ttft": 228984.0004754134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3321,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.998711711204953,
    "arrivals": 42675,
    "finished_requests": 41221,
    "scheduler_time": 45.93583964090692
}
#Debug simulation 
Total elapsed time: 6.835219808388501. Arrivals time: 0.16495257383212447 Scheduler time: 6.2976069445721805 Scheduler overhead time: 0.14161700010299683 Adapter cache time: 0.03779974114149809 Engine time: 0.13016924168914557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.838402931578457,
    "estimated_duration": 3599.8103890867665,
    "input_throughput": 2854.5367364770727,
    "output_throughput": 2521.9700536236155,
    "total_throughput": 5376.506790100688,
    "itl": 27.603943233366174,
    "ttft": 231948.06906806948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3299,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.864175922882517,
    "arrivals": 42675,
    "finished_requests": 41189,
    "scheduler_time": 46.04029048694357
}
#Debug simulation 
Total elapsed time: 6.838514574803412. Arrivals time: 0.16325605986639857 Scheduler time: 6.304186390712857 Scheduler overhead time: 0.1416279566474259 Adapter cache time: 0.03741041570901871 Engine time: 0.1286365115083754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 135, 1080, 1080, 135, 1080, 270, 1080, 135, 270, 135, 1080, 270, 270, 270, 270, 1080, 135, 135, 135, 270, 1080, 135, 1080, 1080, 270, 270, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 135, 270, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 1080, 135, 1080, 1080, 270, 135, 135, 1080, 270, 135, 270, 270, 1080, 270, 135, 135, 1080, 1080, 1080, 1080, 1080, 1080, 135, 270, 135, 270, 135, 135, 135, 270, 270, 270, 135, 135, 1080, 1080, 135, 1080, 135, 270, 1080, 1080, 1080, 270, 135, 1080, 270, 135, 135, 135, 135, 135, 1080, 270, 135, 1080, 135, 1080, 135, 135, 270, 270, 1080, 270, 1080, 135, 270, 135, 1080, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 135, 135, 135, 135, 135, 1080, 135, 135, 135, 1080, 135, 270, 1080, 1080, 270, 135, 1080, 135, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 270, 1080, 270, 1080, 135, 1080, 135, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 270, 270, 135, 270, 1080, 270, 270, 1080, 135, 1080, 1080, 270, 135, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 135, 270, 135, 135, 135, 135, 270, 270, 270, 270, 270, 1080, 270, 135, 135, 135, 135]
Prompts retrieved: 127305 . Total input tokens: 28344011 . Total output tokens: 25460583
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.825382063165307,
    "estimated_duration": 3599.8143667664276,
    "input_throughput": 2857.174829611806,
    "output_throughput": 2521.84059372888,
    "total_throughput": 5379.0154233406865,
    "itl": 27.5790834736452,
    "ttft": 228882.47938539463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3314,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.113621307238295,
    "arrivals": 42675,
    "finished_requests": 41222,
    "scheduler_time": 45.904861262655075
}
#Debug simulation 
Total elapsed time: 6.825491066090763. Arrivals time: 0.15644048666581511 Scheduler time: 6.296443359460682 Scheduler overhead time: 0.14154884312301874 Adapter cache time: 0.03761733137071133 Engine time: 0.13020567269995809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.0526645090430975,
    "estimated_duration": 3599.867330169988,
    "input_throughput": 2724.3073426089013,
    "output_throughput": 2429.580092216065,
    "total_throughput": 5153.8874348249665,
    "itl": 26.976251325588105,
    "ttft": 184780.5776796845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.241171483464418,
    "arrivals": 40673,
    "finished_requests": 39571,
    "scheduler_time": 37.232776672429175
}
#Debug simulation 
Total elapsed time: 6.052753997035325. Arrivals time: 0.14185809576883912 Scheduler time: 5.531963857356459 Scheduler overhead time: 0.1459600762464106 Adapter cache time: 0.0392012745141983 Engine time: 0.13008353812620044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.081444899085909,
    "estimated_duration": 3599.853247370701,
    "input_throughput": 2720.863692750243,
    "output_throughput": 2426.3919665002204,
    "total_throughput": 5147.255659250463,
    "itl": 26.982451488615684,
    "ttft": 189308.91122349387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.966390152222376,
    "arrivals": 40673,
    "finished_requests": 39519,
    "scheduler_time": 37.21185596100366
}
#Debug simulation 
Total elapsed time: 6.0816029738634825. Arrivals time: 0.13719921233132482 Scheduler time: 5.5689333523623645 Scheduler overhead time: 0.142383745405823 Adapter cache time: 0.03911816654726863 Engine time: 0.1300865770317614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.055390167981386,
    "estimated_duration": 3599.866563055059,
    "input_throughput": 2724.0884705675726,
    "output_throughput": 2428.1300006247784,
    "total_throughput": 5152.218471192351,
    "itl": 27.02580718668546,
    "ttft": 185974.70972522662,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3669,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.993938760216547,
    "arrivals": 40673,
    "finished_requests": 39559,
    "scheduler_time": 37.269481686044394
}
#Debug simulation 
Total elapsed time: 6.055491601116955. Arrivals time: 0.13640591548755765 Scheduler time: 5.542987433262169 Scheduler overhead time: 0.14273449638858438 Adapter cache time: 0.03928594850003719 Engine time: 0.13018883997574449 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 6.0708675952628255,
    "estimated_duration": 3599.8772125545534,
    "input_throughput": 2724.2998638391423,
    "output_throughput": 2429.5734225316883,
    "total_throughput": 5153.87328637083,
    "itl": 26.97847818540288,
    "ttft": 184784.19902022425,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3673,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.48747854676842,
    "arrivals": 40673,
    "finished_requests": 39571,
    "scheduler_time": 37.23374807195377
}
#Debug simulation 
Total elapsed time: 6.070983827114105. Arrivals time: 0.1381692006252706 Scheduler time: 5.5570301418192685 Scheduler overhead time: 0.14311187388375401 Adapter cache time: 0.0391311114653945 Engine time: 0.12949853762984276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 6.06038070935756,
    "estimated_duration": 3599.8560650403506,
    "input_throughput": 2722.8046963289166,
    "output_throughput": 2427.1703762972706,
    "total_throughput": 5149.975072626187,
    "itl": 26.999866173541665,
    "ttft": 189394.36544007668,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.149350142142913,
    "arrivals": 40673,
    "finished_requests": 39521,
    "scheduler_time": 37.301217948418866
}
#Debug simulation 
Total elapsed time: 6.060477163176984. Arrivals time: 0.13910682732239366 Scheduler time: 5.542203387711197 Scheduler overhead time: 0.14630515547469258 Adapter cache time: 0.03910285513848066 Engine time: 0.12983591062948108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 6.095703789964318,
    "estimated_duration": 3599.8514633961377,
    "input_throughput": 2722.5309431945034,
    "output_throughput": 2428.8079908028853,
    "total_throughput": 5151.338933997389,
    "itl": 26.98108272612965,
    "ttft": 187466.77890709174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.961524381111902,
    "arrivals": 40673,
    "finished_requests": 39541,
    "scheduler_time": 37.26465436087072
}
#Debug simulation 
Total elapsed time: 6.09583460399881. Arrivals time: 0.1466210586950183 Scheduler time: 5.5717401364818215 Scheduler overhead time: 0.14326289296150208 Adapter cache time: 0.03939728019759059 Engine time: 0.13100287411361933 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 66, 1080, 1080, 66, 1080, 270, 1080, 66, 270, 66, 1080, 270, 270, 270, 270, 1080, 66, 66, 66, 270, 1080, 66, 1080, 1080, 270, 270, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 66, 270, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 1080, 66, 1080, 1080, 270, 66, 66, 1080, 270, 66, 270, 270, 1080, 270, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 270, 66, 270, 66, 66, 66, 270, 270, 270, 66, 66, 1080, 1080, 66, 1080, 66, 270, 1080, 1080, 1080, 270, 66, 1080, 270, 66, 66, 66, 66, 66, 1080, 270, 66, 1080, 66, 1080, 66, 66, 270, 270, 1080, 270, 1080, 66, 270, 66, 1080, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 270, 1080, 1080, 270, 66, 1080, 66, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 270, 1080, 270, 1080, 66, 1080, 66, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 270, 270, 66, 270, 1080, 270, 270, 1080, 66, 1080, 1080, 270, 66, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 66, 270, 66, 66, 66, 66, 270, 270, 270, 270, 270, 1080, 270, 66, 66, 66, 66]
Prompts retrieved: 121440 . Total input tokens: 27011072 . Total output tokens: 24310264
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 6.075675666797906,
    "estimated_duration": 3599.8604661183354,
    "input_throughput": 2723.3324992096327,
    "output_throughput": 2427.058793592916,
    "total_throughput": 5150.391292802549,
    "itl": 27.014944747052677,
    "ttft": 186503.38738827608,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.329075955487026,
    "arrivals": 40673,
    "finished_requests": 39550,
    "scheduler_time": 37.19431129171895
}
#Debug simulation 
Total elapsed time: 6.07580799004063. Arrivals time: 0.14580237679183483 Scheduler time: 5.551753079984337 Scheduler overhead time: 0.14324570866301656 Adapter cache time: 0.039525188971310854 Engine time: 0.13170392019674182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.537007877137512,
    "estimated_duration": 3599.867961171476,
    "input_throughput": 2672.80608727351,
    "output_throughput": 2342.3923018709675,
    "total_throughput": 5015.198389144477,
    "itl": 26.63174539315466,
    "ttft": 158883.18091412974,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3843,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.761454399932854,
    "arrivals": 39791,
    "finished_requests": 38849,
    "scheduler_time": 31.38524892901254
}
#Debug simulation 
Total elapsed time: 5.5371258850209415. Arrivals time: 0.13874908396974206 Scheduler time: 5.01747683994472 Scheduler overhead time: 0.1440491951070726 Adapter cache time: 0.03999213129281998 Engine time: 0.13212037784978747 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.600324877072126,
    "estimated_duration": 3599.891252391976,
    "input_throughput": 2669.6959230682737,
    "output_throughput": 2340.2206926118247,
    "total_throughput": 5009.916615680098,
    "itl": 26.654790729770117,
    "ttft": 160566.7839386098,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3808,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.427620989692379,
    "arrivals": 39791,
    "finished_requests": 38840,
    "scheduler_time": 31.651340993570365
}
#Debug simulation 
Total elapsed time: 5.600413402076811. Arrivals time: 0.13936238270252943 Scheduler time: 5.080204101279378 Scheduler overhead time: 0.14391071442514658 Adapter cache time: 0.04010713845491409 Engine time: 0.1325017986819148 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.565655347891152,
    "estimated_duration": 3599.8899235051463,
    "input_throughput": 2671.964200125979,
    "output_throughput": 2342.5463498031163,
    "total_throughput": 5014.510549929096,
    "itl": 26.64646728047398,
    "ttft": 159513.8398067998,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3804,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.435840574297245,
    "arrivals": 39791,
    "finished_requests": 38853,
    "scheduler_time": 31.681351034047456
}
#Debug simulation 
Total elapsed time: 5.565773298963904. Arrivals time: 0.13901373744010925 Scheduler time: 5.0478766658343375 Scheduler overhead time: 0.1427950165234506 Adapter cache time: 0.040196210611611605 Engine time: 0.1313616600818932 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.6177318948321044,
    "estimated_duration": 3599.8913886084815,
    "input_throughput": 2670.7608541813293,
    "output_throughput": 2340.030320541475,
    "total_throughput": 5010.7911747228045,
    "itl": 26.636755278348737,
    "ttft": 161745.53203985593,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3782,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.825243293147606,
    "arrivals": 39791,
    "finished_requests": 38831,
    "scheduler_time": 31.75723684291082
}
#Debug simulation 
Total elapsed time: 5.617831435054541. Arrivals time: 0.1400640532374382 Scheduler time: 5.096144188661128 Scheduler overhead time: 0.14433628832921386 Adapter cache time: 0.039944959338754416 Engine time: 0.13241731189191341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.577256555203348,
    "estimated_duration": 3599.8846613815276,
    "input_throughput": 2668.529106794592,
    "output_throughput": 2339.5421776562857,
    "total_throughput": 5008.071284450878,
    "itl": 26.653943236300677,
    "ttft": 162279.6778686162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3807,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.606278937141521,
    "arrivals": 39791,
    "finished_requests": 38820,
    "scheduler_time": 31.63333038730719
}
#Debug simulation 
Total elapsed time: 5.57738430891186. Arrivals time: 0.14264560397714376 Scheduler time: 5.054473047610372 Scheduler overhead time: 0.14417324401438236 Adapter cache time: 0.04009640170261264 Engine time: 0.13123008934780955 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.550698939245194,
    "estimated_duration": 3599.8663819154613,
    "input_throughput": 2670.0149339669906,
    "output_throughput": 2342.243046119263,
    "total_throughput": 5012.257980086254,
    "itl": 26.617655621964072,
    "ttft": 160153.97048311724,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 11.433952327706569,
    "arrivals": 39791,
    "finished_requests": 38837,
    "scheduler_time": 31.42973923709159
}
#Debug simulation 
Total elapsed time: 5.550791570916772. Arrivals time: 0.14155311230570078 Scheduler time: 5.027448719833046 Scheduler overhead time: 0.14397684717550874 Adapter cache time: 0.04023715667426586 Engine time: 0.13280896050855517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [85 85 86]
Adapter prompts. [270, 270, 1080, 33, 1080, 1080, 33, 1080, 270, 1080, 33, 270, 33, 1080, 270, 270, 270, 270, 1080, 33, 33, 33, 270, 1080, 33, 1080, 1080, 270, 270, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 33, 270, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 1080, 33, 1080, 1080, 270, 33, 33, 1080, 270, 33, 270, 270, 1080, 270, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 270, 33, 270, 33, 33, 33, 270, 270, 270, 33, 33, 1080, 1080, 33, 1080, 33, 270, 1080, 1080, 1080, 270, 33, 1080, 270, 33, 33, 33, 33, 33, 1080, 270, 33, 1080, 33, 1080, 33, 33, 270, 270, 1080, 270, 1080, 33, 270, 33, 1080, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 270, 1080, 1080, 270, 33, 1080, 33, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 270, 1080, 270, 1080, 33, 1080, 33, 270, 1080, 270, 1080, 270, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 270, 270, 33, 270, 1080, 270, 270, 1080, 33, 1080, 1080, 270, 33, 1080, 1080, 270, 270, 1080, 1080, 270, 270, 270, 270, 1080, 1080, 270, 270, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 33, 270, 33, 33, 33, 33, 270, 270, 270, 270, 270, 1080, 270, 33, 33, 33, 33]
Prompts retrieved: 118635 . Total input tokens: 26372899 . Total output tokens: 23739096
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.622056703083217,
    "estimated_duration": 3599.8964370106255,
    "input_throughput": 2671.028227685545,
    "output_throughput": 2339.4284106110085,
    "total_throughput": 5010.456638296554,
    "itl": 26.64576891598823,
    "ttft": 162071.92346963187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.669344450160066,
    "arrivals": 39791,
    "finished_requests": 38827,
    "scheduler_time": 31.7540080084354
}
#Debug simulation 
Total elapsed time: 5.622169769369066. Arrivals time: 0.14118611067533493 Scheduler time: 5.09984449390322 Scheduler overhead time: 0.14415964297950268 Adapter cache time: 0.039964706636965275 Engine time: 0.13230429869145155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.1371795339509845,
    "estimated_duration": 3599.985826015172,
    "input_throughput": 2487.8253506663264,
    "output_throughput": 2198.426711240792,
    "total_throughput": 4686.252061907118,
    "itl": 26.033279252923467,
    "ttft": 151288.76975102382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.890774377443751,
    "arrivals": 36981,
    "finished_requests": 36122,
    "scheduler_time": 25.981841499427592
}
#Debug simulation 
Total elapsed time: 5.137281619943678. Arrivals time: 0.13020084146410227 Scheduler time: 4.616322887595743 Scheduler overhead time: 0.14918988570570946 Adapter cache time: 0.04236420150846243 Engine time: 0.13318903325125575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.099591806065291,
    "estimated_duration": 3600.002196876541,
    "input_throughput": 2488.162370504016,
    "output_throughput": 2197.8042143598555,
    "total_throughput": 4685.9665848638715,
    "itl": 26.04402955707506,
    "ttft": 152921.569594432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4228,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.795397230804197,
    "arrivals": 36981,
    "finished_requests": 36101,
    "scheduler_time": 25.88445222669937
}
#Debug simulation 
Total elapsed time: 5.09969876287505. Arrivals time: 0.12718748161569238 Scheduler time: 4.581408791709691 Scheduler overhead time: 0.15012905932962894 Adapter cache time: 0.04201253456994891 Engine time: 0.13359258836135268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.081410011276603,
    "estimated_duration": 3599.988025682497,
    "input_throughput": 2489.50244724798,
    "output_throughput": 2197.9473108108205,
    "total_throughput": 4687.4497580588,
    "itl": 26.046659001655684,
    "ttft": 152134.03333306394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.79232674391836,
    "arrivals": 36981,
    "finished_requests": 36113,
    "scheduler_time": 25.984364139780027
}
#Debug simulation 
Total elapsed time: 5.081541761290282. Arrivals time: 0.1264636442065239 Scheduler time: 4.57015767833218 Scheduler overhead time: 0.1453733080998063 Adapter cache time: 0.042187382001429796 Engine time: 0.1317667313851416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 5.105139546096325,
    "estimated_duration": 3599.98168869267,
    "input_throughput": 2487.8087652863555,
    "output_throughput": 2197.3328433436113,
    "total_throughput": 4685.141608629967,
    "itl": 26.024247744167393,
    "ttft": 153644.24943450387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4220,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.1798308073435,
    "arrivals": 36981,
    "finished_requests": 36095,
    "scheduler_time": 25.907463142295722
}
#Debug simulation 
Total elapsed time: 5.105242874938995. Arrivals time: 0.12210598774254322 Scheduler time: 4.598388979677111 Scheduler overhead time: 0.1444964725524187 Adapter cache time: 0.04212491773068905 Engine time: 0.1326820170506835 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 5.1025239219889045,
    "estimated_duration": 3599.9930294160554,
    "input_throughput": 2489.7392652601525,
    "output_throughput": 2198.455090143265,
    "total_throughput": 4688.194355403418,
    "itl": 26.040830711360567,
    "ttft": 150114.81128010963,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.898272522686922,
    "arrivals": 36981,
    "finished_requests": 36136,
    "scheduler_time": 26.02218428870515
}
#Debug simulation 
Total elapsed time: 5.102628540247679. Arrivals time: 0.12200566800311208 Scheduler time: 4.5916218515485525 Scheduler overhead time: 0.14800104452297091 Adapter cache time: 0.041940624825656414 Engine time: 0.133205097168684 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 5.081189038231969,
    "estimated_duration": 3599.977428430277,
    "input_throughput": 2489.2981076016104,
    "output_throughput": 2197.956003143659,
    "total_throughput": 4687.254110745269,
    "itl": 26.041941161750668,
    "ttft": 151056.2278579591,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4221,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.621002294783043,
    "arrivals": 36981,
    "finished_requests": 36123,
    "scheduler_time": 25.951147792816123
}
#Debug simulation 
Total elapsed time: 5.081276601180434. Arrivals time: 0.12292425846680999 Scheduler time: 4.572581441141665 Scheduler overhead time: 0.1478470698930323 Adapter cache time: 0.04166096914559603 Engine time: 0.13095375522971153 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_256_slots_16_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 66, 1080, 1080, 66, 1080, 135, 1080, 66, 135, 66, 1080, 135, 135, 135, 135, 1080, 66, 66, 66, 135, 1080, 66, 1080, 1080, 135, 135, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 66, 135, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 1080, 66, 1080, 1080, 135, 66, 66, 1080, 135, 66, 135, 135, 1080, 135, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 66, 135, 66, 135, 66, 66, 66, 135, 135, 135, 66, 66, 1080, 1080, 66, 1080, 66, 135, 1080, 1080, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 66, 1080, 135, 66, 1080, 66, 1080, 66, 66, 135, 135, 1080, 135, 1080, 66, 135, 66, 1080, 1080, 66, 1080, 135, 66, 1080, 66, 66, 1080, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 66, 66, 66, 66, 66, 1080, 66, 66, 66, 1080, 66, 135, 1080, 1080, 135, 66, 1080, 66, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 135, 1080, 135, 1080, 66, 1080, 66, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 135, 135, 66, 135, 1080, 135, 135, 1080, 66, 1080, 1080, 135, 66, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 66, 135, 66, 66, 66, 66, 135, 135, 135, 135, 135, 1080, 135, 66, 66, 66, 66]
Prompts retrieved: 109965 . Total input tokens: 24446343 . Total output tokens: 22011364
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 5.1212631347589195,
    "estimated_duration": 3599.992631006704,
    "input_throughput": 2489.739540798329,
    "output_throughput": 2198.4553334451707,
    "total_throughput": 4688.1948742435,
    "itl": 26.041236573798855,
    "ttft": 150117.99820139137,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.070052194929678,
    "arrivals": 36981,
    "finished_requests": 36136,
    "scheduler_time": 26.023405276326283
}
#Debug simulation 
Total elapsed time: 5.12136647477746. Arrivals time: 0.12287223851308227 Scheduler time: 4.612339152023196 Scheduler overhead time: 0.14510047668591142 Adapter cache time: 0.04216702515259385 Engine time: 0.133205390535295 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.813403239939362,
    "estimated_duration": 3599.9825080318083,
    "input_throughput": 2433.442101581066,
    "output_throughput": 2153.399351998047,
    "total_throughput": 4586.841453579113,
    "itl": 25.806356787209932,
    "ttft": 127283.00565535235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4108,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.572483652074826,
    "arrivals": 35945,
    "finished_requests": 35277,
    "scheduler_time": 22.676243789866415
}
#Debug simulation 
Total elapsed time: 4.8135037631727755. Arrivals time: 0.1198587385006249 Scheduler time: 4.3043173099868 Scheduler overhead time: 0.14658536855131388 Adapter cache time: 0.04206652054563165 Engine time: 0.13483018521219492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.8865175363607705,
    "estimated_duration": 3599.9782228953727,
    "input_throughput": 2429.6641419583966,
    "output_throughput": 2148.3738292671273,
    "total_throughput": 4578.037971225524,
    "itl": 25.8559990028038,
    "ttft": 138649.62601263326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.555673620109916,
    "arrivals": 35945,
    "finished_requests": 35221,
    "scheduler_time": 24.23177280336734
}
#Debug simulation 
Total elapsed time: 4.886616490315646. Arrivals time: 0.11672576051205397 Scheduler time: 4.386811759788543 Scheduler overhead time: 0.14461503271013498 Adapter cache time: 0.04012448247522116 Engine time: 0.13290193444117904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.9296647952869534,
    "estimated_duration": 3599.9844342406536,
    "input_throughput": 2429.953006684368,
    "output_throughput": 2148.152899341964,
    "total_throughput": 4578.105906026332,
    "itl": 25.839228858840602,
    "ttft": 138025.63866409176,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3852,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.593395893852326,
    "arrivals": 35945,
    "finished_requests": 35227,
    "scheduler_time": 24.20640311468813
}
#Debug simulation 
Total elapsed time: 4.929862131364644. Arrivals time: 0.11821734393015504 Scheduler time: 4.42547671450302 Scheduler overhead time: 0.14552917052060366 Adapter cache time: 0.04090580902993679 Engine time: 0.1339495242573321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.800182353705168,
    "estimated_duration": 3599.979169429123,
    "input_throughput": 2434.1907515508274,
    "output_throughput": 2153.3002373536706,
    "total_throughput": 4587.4909889044975,
    "itl": 25.798462280323122,
    "ttft": 126362.9244905102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4098,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.80360400244902,
    "arrivals": 35945,
    "finished_requests": 35290,
    "scheduler_time": 22.76971583020638
}
#Debug simulation 
Total elapsed time: 4.800279237795621. Arrivals time: 0.11981024779379368 Scheduler time: 4.295419448520988 Scheduler overhead time: 0.14510216377675533 Adapter cache time: 0.04169138427823782 Engine time: 0.13254933897405863 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.933107253164053,
    "estimated_duration": 3599.9763498597067,
    "input_throughput": 2430.125686892618,
    "output_throughput": 2149.032173586778,
    "total_throughput": 4579.157860479396,
    "itl": 25.874682606327124,
    "ttft": 137127.82264189102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3850,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.753132374378957,
    "arrivals": 35945,
    "finished_requests": 35235,
    "scheduler_time": 24.194634128096357
}
#Debug simulation 
Total elapsed time: 4.9331997418776155. Arrivals time: 0.12130930228158832 Scheduler time: 4.425845625810325 Scheduler overhead time: 0.1462126118130982 Adapter cache time: 0.04045493295416236 Engine time: 0.1332484744489193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [16]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.836016941815615,
    "estimated_duration": 3599.971589148601,
    "input_throughput": 2433.959764130325,
    "output_throughput": 2154.2145008522402,
    "total_throughput": 4588.174264982565,
    "itl": 25.800298033936315,
    "ttft": 126299.71618187572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4095,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.24425595762527,
    "arrivals": 35945,
    "finished_requests": 35291,
    "scheduler_time": 22.79260054819797
}
#Debug simulation 
Total elapsed time: 4.836105873808265. Arrivals time: 0.12174276728183031 Scheduler time: 4.328059756197035 Scheduler overhead time: 0.1449433588422835 Adapter cache time: 0.041742270812392235 Engine time: 0.13387293461710215 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_256_slots_16_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [85 85 86]
Adapter prompts. [135, 135, 1080, 33, 1080, 1080, 33, 1080, 135, 1080, 33, 135, 33, 1080, 135, 135, 135, 135, 1080, 33, 33, 33, 135, 1080, 33, 1080, 1080, 135, 135, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 33, 135, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 1080, 33, 1080, 1080, 135, 33, 33, 1080, 135, 33, 135, 135, 1080, 135, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 135, 33, 135, 33, 33, 33, 135, 135, 135, 33, 33, 1080, 1080, 33, 1080, 33, 135, 1080, 1080, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 33, 1080, 135, 33, 1080, 33, 1080, 33, 33, 135, 135, 1080, 135, 1080, 33, 135, 33, 1080, 1080, 33, 1080, 135, 33, 1080, 33, 33, 1080, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 135, 1080, 1080, 135, 33, 1080, 33, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 135, 1080, 135, 1080, 33, 1080, 33, 135, 1080, 135, 1080, 135, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 135, 135, 33, 135, 1080, 135, 135, 1080, 33, 1080, 1080, 135, 33, 1080, 1080, 135, 135, 1080, 1080, 135, 135, 135, 135, 1080, 1080, 135, 135, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 33, 135, 33, 33, 33, 33, 135, 135, 135, 135, 135, 1080, 135, 33, 33, 33, 33]
Prompts retrieved: 107160 . Total input tokens: 23830713 . Total output tokens: 21444082
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.917900423053652,
    "estimated_duration": 3599.9784139513545,
    "input_throughput": 2429.663735233217,
    "output_throughput": 2148.324826067834,
    "total_throughput": 4577.988561301051,
    "itl": 25.859317781835664,
    "ttft": 138753.8200810089,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3847,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.901571312210637,
    "arrivals": 35945,
    "finished_requests": 35220,
    "scheduler_time": 24.2341615403619
}
#Debug simulation 
Total elapsed time: 4.91799079021439. Arrivals time: 0.12209945823997259 Scheduler time: 4.411662521306425 Scheduler overhead time: 0.145595311652869 Adapter cache time: 0.04045052034780383 Engine time: 0.13266448210924864 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [8]. Counts: [256]
---Simulation End---
#Simulation results
{
    "duration": 4.339427009690553,
    "estimated_duration": 3600.0222525654444,
    "input_throughput": 2298.3207934628144,
    "output_throughput": 2054.954797773299,
    "total_throughput": 4353.2755912361135,
    "itl": 25.370288647613997,
    "ttft": 104777.66412393813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.924439742627003,
    "arrivals": 34024,
    "finished_requests": 33505,
    "scheduler_time": 17.429143149863087
}
#Debug simulation 
Total elapsed time: 4.339521118905395. Arrivals time: 0.11643260857090354 Scheduler time: 3.8361399406567216 Scheduler overhead time: 0.14606872526928782 Adapter cache time: 0.042155619245022535 Engine time: 0.13251633988693357 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.303821878042072,
    "estimated_duration": 3600.004144326632,
    "input_throughput": 2296.9079113509365,
    "output_throughput": 2054.235690715644,
    "total_throughput": 4351.143602066581,
    "itl": 25.375295733006784,
    "ttft": 105697.53234868488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4234,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.81987505766866,
    "arrivals": 34024,
    "finished_requests": 33493,
    "scheduler_time": 17.39913655428643
}
#Debug simulation 
Total elapsed time: 4.3039134200662374. Arrivals time: 0.12301285658031702 Scheduler time: 3.7960614506155252 Scheduler overhead time: 0.14442419214174151 Adapter cache time: 0.041969961021095514 Engine time: 0.13220816617831588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [171  85]
---Simulation End---
#Simulation results
{
    "duration": 4.369238365907222,
    "estimated_duration": 3600.000678074731,
    "input_throughput": 2298.153733800007,
    "output_throughput": 2054.3279463922586,
    "total_throughput": 4352.481680192265,
    "itl": 25.379251207735322,
    "ttft": 104957.88178142857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4231,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.833899391124833,
    "arrivals": 34024,
    "finished_requests": 33500,
    "scheduler_time": 17.38885742937317
}
#Debug simulation 
Total elapsed time: 4.369404292199761. Arrivals time: 0.12543244333937764 Scheduler time: 3.8491817652247846 Scheduler overhead time: 0.15183987887576222 Adapter cache time: 0.04223542986437678 Engine time: 0.13422455731779337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 86 170]
---Simulation End---
#Simulation results
{
    "duration": 4.329141982831061,
    "estimated_duration": 3600.024096210262,
    "input_throughput": 2298.319616446465,
    "output_throughput": 2054.9537453895755,
    "total_throughput": 4353.27336183604,
    "itl": 25.37261691364258,
    "ttft": 104784.09590342578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4223,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.183897814406922,
    "arrivals": 34024,
    "finished_requests": 33505,
    "scheduler_time": 17.431924991732732
}
#Debug simulation 
Total elapsed time: 4.32926454488188. Arrivals time: 0.12422090861946344 Scheduler time: 3.8175496822223067 Scheduler overhead time: 0.14571182802319527 Adapter cache time: 0.04253477789461613 Engine time: 0.13292921474203467 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 256,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_256_slots_16_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [85 85 86]
Adapter prompts. [66, 66, 1080, 33, 1080, 1080, 33, 1080, 66, 1080, 33, 66, 33, 1080, 66, 66, 66, 66, 1080, 33, 33, 33, 66, 1080, 33, 1080, 1080, 66, 66, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 33, 66, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 1080, 33, 1080, 1080, 66, 33, 33, 1080, 66, 33, 66, 66, 1080, 66, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 33, 66, 33, 66, 33, 33, 33, 66, 66, 66, 33, 33, 1080, 1080, 33, 1080, 33, 66, 1080, 1080, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 33, 1080, 66, 33, 1080, 33, 1080, 33, 33, 66, 66, 1080, 66, 1080, 33, 66, 33, 1080, 1080, 33, 1080, 66, 33, 1080, 33, 33, 1080, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 33, 33, 33, 33, 33, 1080, 33, 33, 33, 1080, 33, 66, 1080, 1080, 66, 33, 1080, 33, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 66, 1080, 66, 1080, 33, 1080, 33, 66, 1080, 66, 1080, 66, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 66, 66, 33, 66, 1080, 66, 66, 1080, 33, 1080, 1080, 66, 33, 1080, 1080, 66, 66, 1080, 1080, 66, 66, 66, 66, 1080, 1080, 66, 66, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 33, 66, 33, 33, 33, 33, 66, 66, 66, 66, 66, 1080, 66, 33, 33, 33, 33]
Prompts retrieved: 101295 . Total input tokens: 22527924 . Total output tokens: 20249375
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [86 85 85]
---Simulation End---
#Simulation results
{
    "duration": 4.334763410035521,
    "estimated_duration": 3600.0097548398353,
    "input_throughput": 2297.923217813071,
    "output_throughput": 2054.7169323792828,
    "total_throughput": 4352.640150192354,
    "itl": 25.390226738025117,
    "ttft": 105054.09513862715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4226,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.002065119146296,
    "arrivals": 34024,
    "finished_requests": 33501,
    "scheduler_time": 17.39064371422351
}
#Debug simulation 
Total elapsed time: 4.33496595127508. Arrivals time: 0.11702731577679515 Scheduler time: 3.8307028305716813 Scheduler overhead time: 0.14503688598051667 Adapter cache time: 0.042389726266264915 Engine time: 0.133803594391793 
