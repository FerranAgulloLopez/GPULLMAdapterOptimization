INFO 06-01 00:47:00 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:01 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.2321405997499824,
    "estimated_duration": 3599.81631746108,
    "input_throughput": 596.7196130482077,
    "output_throughput": 526.5063083376314,
    "total_throughput": 1123.2259213858392,
    "itl": 19.674986079552067,
    "ttft": 5790.680894612956,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2322671408765018. Arrivals time: 0.036337622441351414 Scheduler time: 0.7714065224863589 Scheduler overhead time: 0.14900531573221087 Adapter cache time: 0.04850091086700559 Engine time: 0.1511021088808775 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 1080, 1080, 33, 1080, 33, 66, 33, 1080, 66, 1080, 33, 66, 1080, 1080, 1080, 33, 1080, 66, 66, 33, 33, 33, 1080, 33, 33, 33, 1080, 66, 33, 1080, 1080, 1080, 1080, 66, 66, 66, 1080, 33, 66, 66, 1080, 1080, 66, 1080, 33, 1080, 66, 66, 66, 1080, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 1080, 66]
Prompts retrieved: 25839 . Total input tokens: 5688973 . Total output tokens: 5166475
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.2123656212352216,
    "estimated_duration": 3599.824417361481,
    "input_throughput": 596.7182703801016,
    "output_throughput": 526.5051236552237,
    "total_throughput": 1123.223394035325,
    "itl": 19.675162013889647,
    "ttft": 5790.725616771021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 8753,
    "finished_requests": 8739,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.212452501989901. Arrivals time: 0.03544177394360304 Scheduler time: 0.7582775880582631 Scheduler overhead time: 0.14833526173606515 Adapter cache time: 0.048535692505538464 Engine time: 0.1482767746783793 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0760254156775773,
    "estimated_duration": 3599.723914927402,
    "input_throughput": 470.5071944480381,
    "output_throughput": 415.33268532071645,
    "total_throughput": 885.8398797687545,
    "itl": 19.45532604344655,
    "ttft": 5269.093683726899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0761054106988013. Arrivals time: 0.030693504959344864 Scheduler time: 0.6233660224825144 Scheduler overhead time: 0.1482043587602675 Adapter cache time: 0.05075791850686073 Engine time: 0.14830108266323805 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0649992707185447,
    "estimated_duration": 3599.723914927402,
    "input_throughput": 470.5071944480381,
    "output_throughput": 415.33268532071645,
    "total_throughput": 885.8398797687545,
    "itl": 19.455457131405872,
    "ttft": 5269.1031580647505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0650716219097376. Arrivals time: 0.030892870388925076 Scheduler time: 0.6147825364023447 Scheduler overhead time: 0.14809835236519575 Adapter cache time: 0.049803410191088915 Engine time: 0.1471624025143683 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0724773951806128,
    "estimated_duration": 3599.723914927402,
    "input_throughput": 470.5071944480381,
    "output_throughput": 415.33268532071645,
    "total_throughput": 885.8398797687545,
    "itl": 19.45549545771885,
    "ttft": 5269.069306273429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2092868485860525,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0725343679077923. Arrivals time: 0.0313011109828949 Scheduler time: 0.6202123952098191 Scheduler overhead time: 0.14742105919867754 Adapter cache time: 0.0503049879334867 Engine time: 0.14878174755722284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.079785907175392,
    "estimated_duration": 3599.723914927402,
    "input_throughput": 470.5071944480381,
    "output_throughput": 415.33268532071645,
    "total_throughput": 885.8398797687545,
    "itl": 19.455350860763517,
    "ttft": 5269.158273250403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.079868908971548. Arrivals time: 0.03111680643633008 Scheduler time: 0.6247219946235418 Scheduler overhead time: 0.14876854000613093 Adapter cache time: 0.05057042604312301 Engine time: 0.1502966727130115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0810837037861347,
    "estimated_duration": 3599.723914927402,
    "input_throughput": 470.5071944480381,
    "output_throughput": 415.33268532071645,
    "total_throughput": 885.8398797687545,
    "itl": 19.455475223153258,
    "ttft": 5269.143594456786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0811697118915617. Arrivals time: 0.031169875524938107 Scheduler time: 0.6275555337779224 Scheduler overhead time: 0.14859884697943926 Adapter cache time: 0.050523295532912016 Engine time: 0.14899734733626246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.103567363228649,
    "estimated_duration": 3599.723914927402,
    "input_throughput": 470.5071944480381,
    "output_throughput": 415.33268532071645,
    "total_throughput": 885.8398797687545,
    "itl": 19.45531929978769,
    "ttft": 5269.163845526772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.10363290598616. Arrivals time: 0.031695482321083546 Scheduler time: 0.6464024423621595 Scheduler overhead time: 0.1485671610571444 Adapter cache time: 0.05044797994196415 Engine time: 0.15061138616874814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [21 21 22]
Adapter prompts. [135, 270, 540, 540, 135, 540, 135, 270, 135, 540, 270, 540, 135, 270, 540, 540, 540, 135, 540, 270, 270, 135, 135, 135, 540, 135, 135, 135, 540, 270, 135, 540, 540, 540, 540, 270, 270, 270, 540, 135, 270, 270, 540, 540, 270, 540, 135, 540, 270, 270, 270, 540, 270, 135, 135, 270, 270, 135, 270, 135, 135, 135, 540, 270]
Prompts retrieved: 20385 . Total input tokens: 4475713 . Total output tokens: 4106726
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0987929999828339,
    "estimated_duration": 3599.723914927402,
    "input_throughput": 470.5071944480381,
    "output_throughput": 415.33268532071645,
    "total_throughput": 885.8398797687545,
    "itl": 19.45546512733646,
    "ttft": 5269.089829389835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189138,
    "arrivals": 6874,
    "finished_requests": 6864,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0988803771324456. Arrivals time: 0.03133796574547887 Scheduler time: 0.6434489749372005 Scheduler overhead time: 0.14788012858480215 Adapter cache time: 0.05026626121252775 Engine time: 0.15049439296126366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.03987154411152,
    "estimated_duration": 3599.623737447201,
    "input_throughput": 437.7743661390426,
    "output_throughput": 389.0217706456993,
    "total_throughput": 826.7961367847419,
    "itl": 19.111065027019087,
    "ttft": 3403.995109953746,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0399309550412. Arrivals time: 0.03021929506212473 Scheduler time: 0.5891754543408751 Scheduler overhead time: 0.1482337974011898 Adapter cache time: 0.048070425633341074 Engine time: 0.14947726717218757 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0424678530544043,
    "estimated_duration": 3599.623737447201,
    "input_throughput": 437.7743661390426,
    "output_throughput": 389.0217706456993,
    "total_throughput": 826.7961367847419,
    "itl": 19.111138464431473,
    "ttft": 3404.014727235805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0425374857150018. Arrivals time: 0.02996416436508298 Scheduler time: 0.590082264970988 Scheduler overhead time: 0.14966510562226176 Adapter cache time: 0.04832368716597557 Engine time: 0.14936961652711034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.061095295008272,
    "estimated_duration": 3599.623737447201,
    "input_throughput": 437.7743661390426,
    "output_throughput": 389.0217706456993,
    "total_throughput": 826.7961367847419,
    "itl": 19.111115648121007,
    "ttft": 3404.024349245665,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0611483831889927. Arrivals time: 0.030404680874198675 Scheduler time: 0.6053771884180605 Scheduler overhead time: 0.14913132367655635 Adapter cache time: 0.048469478730112314 Engine time: 0.15229129139333963 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0642649037763476,
    "estimated_duration": 3599.623737447201,
    "input_throughput": 437.7743661390426,
    "output_throughput": 389.0217706456993,
    "total_throughput": 826.7961367847419,
    "itl": 19.110988133226094,
    "ttft": 3404.021128969085,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0643335366621614. Arrivals time: 0.030252864118665457 Scheduler time: 0.6100693759508431 Scheduler overhead time: 0.1489360798150301 Adapter cache time: 0.04822601331397891 Engine time: 0.15143311209976673 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0489294580183923,
    "estimated_duration": 3599.623737447201,
    "input_throughput": 437.7743661390426,
    "output_throughput": 389.0217706456993,
    "total_throughput": 826.7961367847419,
    "itl": 19.111164819932068,
    "ttft": 3403.998934167484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0489805289544165. Arrivals time: 0.03051767125725746 Scheduler time: 0.5957540883682668 Scheduler overhead time: 0.14935299940407276 Adapter cache time: 0.048148765694350004 Engine time: 0.15037142718210816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0698806759901345,
    "estimated_duration": 3599.623737447201,
    "input_throughput": 437.7743661390426,
    "output_throughput": 389.0217706456993,
    "total_throughput": 826.7961367847419,
    "itl": 19.111020874772702,
    "ttft": 3403.9981379649653,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.07001749612391. Arrivals time: 0.03092181496322155 Scheduler time: 0.6107185916043818 Scheduler overhead time: 0.14950040262192488 Adapter cache time: 0.04892695555463433 Engine time: 0.15393811743706465 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 270, 540, 540, 66, 540, 66, 270, 66, 540, 270, 540, 66, 270, 540, 540, 540, 66, 540, 270, 270, 66, 66, 66, 540, 66, 66, 66, 540, 270, 66, 540, 540, 540, 540, 270, 270, 270, 540, 66, 270, 270, 540, 540, 270, 540, 66, 540, 270, 270, 270, 540, 270, 66, 66, 270, 270, 66, 270, 66, 66, 66, 540, 270]
Prompts retrieved: 18936 . Total input tokens: 4146856 . Total output tokens: 3813691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0645469729788601,
    "estimated_duration": 3599.623737447201,
    "input_throughput": 437.7743661390426,
    "output_throughput": 389.0217706456993,
    "total_throughput": 826.7961367847419,
    "itl": 19.111171308864453,
    "ttft": 3404.016475615326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 6405,
    "finished_requests": 6399,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0646258210763335. Arrivals time: 0.030877902638167143 Scheduler time: 0.6085467250086367 Scheduler overhead time: 0.15079643577337265 Adapter cache time: 0.048519936855882406 Engine time: 0.15015317080542445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0372910122387111,
    "estimated_duration": 3597.8432365624,
    "input_throughput": 414.6895520177074,
    "output_throughput": 380.4985125777747,
    "total_throughput": 795.188064595482,
    "itl": 19.11695457508968,
    "ttft": 5307.633911852903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0374316722154617. Arrivals time: 0.02989056007936597 Scheduler time: 0.5875487453304231 Scheduler overhead time: 0.14864726038649678 Adapter cache time: 0.04623768478631973 Engine time: 0.15006382949650288 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0339086982421577,
    "estimated_duration": 3597.8432365624,
    "input_throughput": 414.6895520177074,
    "output_throughput": 380.4985125777747,
    "total_throughput": 795.188064595482,
    "itl": 19.11704056183431,
    "ttft": 5307.59304243157,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0339749748818576. Arrivals time: 0.02956585818901658 Scheduler time: 0.5848260689526796 Scheduler overhead time: 0.1478119227103889 Adapter cache time: 0.04597496520727873 Engine time: 0.15061591193079948 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.0392283401452005,
    "estimated_duration": 3597.8432365624,
    "input_throughput": 414.6895520177074,
    "output_throughput": 380.4985125777747,
    "total_throughput": 795.188064595482,
    "itl": 19.1170419265397,
    "ttft": 5307.591889099329,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0392860490828753. Arrivals time: 0.02961245132610202 Scheduler time: 0.5870128986425698 Scheduler overhead time: 0.1492059607990086 Adapter cache time: 0.04690866358578205 Engine time: 0.151380795519799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0401596780866385,
    "estimated_duration": 3597.8432365624,
    "input_throughput": 414.6895520177074,
    "output_throughput": 380.4985125777747,
    "total_throughput": 795.188064595482,
    "itl": 19.11705119955041,
    "ttft": 5307.551211813302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.040231830906123. Arrivals time: 0.029936126433312893 Scheduler time: 0.5882297242060304 Scheduler overhead time: 0.1492634997703135 Adapter cache time: 0.046895490027964115 Engine time: 0.15038240095600486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 1.032226580195129,
    "estimated_duration": 3597.8432365624,
    "input_throughput": 414.6895520177074,
    "output_throughput": 380.4985125777747,
    "total_throughput": 795.188064595482,
    "itl": 19.116989925970028,
    "ttft": 5307.600588406327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0322811189107597. Arrivals time: 0.03048216411843896 Scheduler time: 0.5785235413350165 Scheduler overhead time: 0.14908752357587218 Adapter cache time: 0.04666767455637455 Engine time: 0.1523590451106429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 1.0272532082162797,
    "estimated_duration": 3597.8432365624,
    "input_throughput": 414.6895520177074,
    "output_throughput": 380.4985125777747,
    "total_throughput": 795.188064595482,
    "itl": 19.116961559769813,
    "ttft": 5307.58095764373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0273318872787058. Arrivals time: 0.029498792719095945 Scheduler time: 0.5800439775921404 Scheduler overhead time: 0.1482919310219586 Adapter cache time: 0.046436423901468515 Engine time: 0.14804084226489067 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 270, 540, 540, 33, 540, 33, 270, 33, 540, 270, 540, 33, 270, 540, 540, 540, 33, 540, 270, 270, 33, 33, 33, 540, 33, 33, 33, 540, 270, 33, 540, 540, 540, 540, 270, 270, 270, 540, 33, 270, 270, 540, 540, 270, 540, 33, 540, 270, 270, 270, 540, 270, 33, 33, 270, 270, 33, 270, 33, 33, 33, 540, 270]
Prompts retrieved: 18243 . Total input tokens: 3999459 . Total output tokens: 3674488
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 1.026354996021837,
    "estimated_duration": 3597.8432365624,
    "input_throughput": 414.6895520177074,
    "output_throughput": 380.4985125777747,
    "total_throughput": 795.188064595482,
    "itl": 19.11697160073423,
    "ttft": 5307.6136142464275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 6141,
    "finished_requests": 6132,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0264062681235373. Arrivals time: 0.029304514173418283 Scheduler time: 0.578296557534486 Scheduler overhead time: 0.14811158878728747 Adapter cache time: 0.04664154816418886 Engine time: 0.1489947522059083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3531683 . Total output tokens: 3251275
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9740659520030022,
    "estimated_duration": 3599.897520743846,
    "input_throughput": 358.79132463001736,
    "output_throughput": 327.655993872924,
    "total_throughput": 686.4473185029414,
    "itl": 18.84282934307259,
    "ttft": 4014.092545171019,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9741471759043634. Arrivals time: 0.028423183131963015 Scheduler time: 0.5220821714028716 Scheduler overhead time: 0.14933539181947708 Adapter cache time: 0.04521814966574311 Engine time: 0.15309741022065282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3531683 . Total output tokens: 3251275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9705330831930041,
    "estimated_duration": 3599.897520743846,
    "input_throughput": 358.79132463001736,
    "output_throughput": 327.655993872924,
    "total_throughput": 686.4473185029414,
    "itl": 18.84282363055969,
    "ttft": 4014.127285269316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9706822619773448. Arrivals time: 0.02773856045678258 Scheduler time: 0.5187834459356964 Scheduler overhead time: 0.151321470271796 Adapter cache time: 0.04473509732633829 Engine time: 0.15200844639912248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3531683 . Total output tokens: 3251275
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9794603199698031,
    "estimated_duration": 3599.897520743846,
    "input_throughput": 358.79132463001736,
    "output_throughput": 327.655993872924,
    "total_throughput": 686.4473185029414,
    "itl": 18.842820682891233,
    "ttft": 4014.1236321970287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9795664688572288. Arrivals time: 0.027753169182687998 Scheduler time: 0.5272357878275216 Scheduler overhead time: 0.15022348100319505 Adapter cache time: 0.04478602623566985 Engine time: 0.1534022674895823 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3531683 . Total output tokens: 3251275
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9877237202599645,
    "estimated_duration": 3599.897520743846,
    "input_throughput": 358.79132463001736,
    "output_throughput": 327.655993872924,
    "total_throughput": 686.4473185029414,
    "itl": 18.842813003328974,
    "ttft": 4014.0691931210667,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9879219341091812. Arrivals time: 0.03092947555705905 Scheduler time: 0.5271317106671631 Scheduler overhead time: 0.15363196143880486 Adapter cache time: 0.04473972413688898 Engine time: 0.14883325900882483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3531683 . Total output tokens: 3251275
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9737091548740864,
    "estimated_duration": 3599.897520743846,
    "input_throughput": 358.79132463001736,
    "output_throughput": 327.655993872924,
    "total_throughput": 686.4473185029414,
    "itl": 18.84284748918518,
    "ttft": 4014.146178681326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9737750049680471. Arrivals time: 0.027894374448806047 Scheduler time: 0.5231908056885004 Scheduler overhead time: 0.15014612302184105 Adapter cache time: 0.04484927747398615 Engine time: 0.15158565808087587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3531683 . Total output tokens: 3251275
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9688059510663152,
    "estimated_duration": 3599.897520743846,
    "input_throughput": 358.79132463001736,
    "output_throughput": 327.655993872924,
    "total_throughput": 686.4473185029414,
    "itl": 18.842706046509214,
    "ttft": 4014.081676551764,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9688713881187141. Arrivals time: 0.02797313081100583 Scheduler time: 0.5181927746161819 Scheduler overhead time: 0.14899624045938253 Adapter cache time: 0.04460181761533022 Engine time: 0.15343702910467982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 540, 540, 66, 540, 66, 135, 66, 540, 135, 540, 66, 135, 540, 540, 540, 66, 540, 135, 135, 66, 66, 66, 540, 66, 66, 66, 540, 135, 66, 540, 540, 540, 540, 135, 135, 135, 540, 66, 135, 135, 540, 540, 135, 540, 66, 540, 135, 135, 135, 540, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 540, 135]
Prompts retrieved: 16101 . Total input tokens: 3531683 . Total output tokens: 3251275
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9666479206643999,
    "estimated_duration": 3599.897520743846,
    "input_throughput": 358.79132463001736,
    "output_throughput": 327.655993872924,
    "total_throughput": 686.4473185029414,
    "itl": 18.842863493952976,
    "ttft": 4014.154139432381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 5423,
    "finished_requests": 5417,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9667098890058696. Arrivals time: 0.027709858026355505 Scheduler time: 0.5176903419196606 Scheduler overhead time: 0.15005295211449265 Adapter cache time: 0.04465627996250987 Engine time: 0.1507550603710115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3371371 . Total output tokens: 3108384
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9608940123580396,
    "estimated_duration": 3598.504024158369,
    "input_throughput": 351.0853375509242,
    "output_throughput": 312.59073005013136,
    "total_throughput": 663.6760676010556,
    "itl": 18.820410990396095,
    "ttft": 2126.3914924097403,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9609667602926493. Arrivals time: 0.027255774475634098 Scheduler time: 0.5097599481232464 Scheduler overhead time: 0.15020520705729723 Adapter cache time: 0.04298446513712406 Engine time: 0.15419583627954125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3371371 . Total output tokens: 3108384
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9454653291031718,
    "estimated_duration": 3598.504024158369,
    "input_throughput": 351.0853375509242,
    "output_throughput": 312.59073005013136,
    "total_throughput": 663.6760676010556,
    "itl": 18.82052873810924,
    "ttft": 2126.4286020382406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9455136670731008. Arrivals time: 0.02744492795318365 Scheduler time: 0.49764711735770106 Scheduler overhead time: 0.15061599761247635 Adapter cache time: 0.04285400779917836 Engine time: 0.15091258008033037 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3371371 . Total output tokens: 3108384
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9466111781075597,
    "estimated_duration": 3598.504024158369,
    "input_throughput": 351.0853375509242,
    "output_throughput": 312.59073005013136,
    "total_throughput": 663.6760676010556,
    "itl": 18.820535515586148,
    "ttft": 2126.437024535053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9466730691492558. Arrivals time: 0.027256384026259184 Scheduler time: 0.498396382201463 Scheduler overhead time: 0.14996367180719972 Adapter cache time: 0.042998545337468386 Engine time: 0.15159004414454103 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3371371 . Total output tokens: 3108384
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9444725988432765,
    "estimated_duration": 3598.504024158369,
    "input_throughput": 351.0853375509242,
    "output_throughput": 312.59073005013136,
    "total_throughput": 663.6760676010556,
    "itl": 18.82040276444748,
    "ttft": 2126.47240305801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.944815665949136. Arrivals time: 0.027204579673707485 Scheduler time: 0.49723219219595194 Scheduler overhead time: 0.15063669811934233 Adapter cache time: 0.043070708867162466 Engine time: 0.15024307509884238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3371371 . Total output tokens: 3108384
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9433931042440236,
    "estimated_duration": 3598.504024158369,
    "input_throughput": 351.0853375509242,
    "output_throughput": 312.59073005013136,
    "total_throughput": 663.6760676010556,
    "itl": 18.820562325878402,
    "ttft": 2126.4846805989855,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9434794532135129. Arrivals time: 0.0272492584772408 Scheduler time: 0.49643242778256536 Scheduler overhead time: 0.14988703513517976 Adapter cache time: 0.043239458464086056 Engine time: 0.1502718636766076 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3371371 . Total output tokens: 3108384
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9468611110933125,
    "estimated_duration": 3598.504024158369,
    "input_throughput": 351.0853375509242,
    "output_throughput": 312.59073005013136,
    "total_throughput": 663.6760676010556,
    "itl": 18.820467251820958,
    "ttft": 2126.484816669853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9469132428057492. Arrivals time: 0.027285293210297823 Scheduler time: 0.4984744372777641 Scheduler overhead time: 0.15051653468981385 Adapter cache time: 0.043067813385277987 Engine time: 0.15165375033393502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 540, 540, 33, 540, 33, 135, 33, 540, 135, 540, 33, 135, 540, 540, 540, 33, 540, 135, 135, 33, 33, 33, 540, 33, 33, 33, 540, 135, 33, 540, 540, 540, 540, 135, 135, 135, 540, 33, 135, 135, 540, 540, 135, 540, 33, 540, 135, 135, 135, 540, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 540, 135]
Prompts retrieved: 15408 . Total input tokens: 3371371 . Total output tokens: 3108384
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9490295061841607,
    "estimated_duration": 3598.504024158369,
    "input_throughput": 351.0853375509242,
    "output_throughput": 312.59073005013136,
    "total_throughput": 663.6760676010556,
    "itl": 18.82049675143823,
    "ttft": 2126.392395583773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 5154,
    "finished_requests": 5151,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9493306772783399. Arrivals time: 0.027413212694227695 Scheduler time: 0.5003265989944339 Scheduler overhead time: 0.14984063990414143 Adapter cache time: 0.04304685816168785 Engine time: 0.15206038020551205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3052536 . Total output tokens: 2814890
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.9167195768095553,
    "estimated_duration": 3599.404632436796,
    "input_throughput": 319.4411624740248,
    "output_throughput": 281.00647281637924,
    "total_throughput": 600.447635290404,
    "itl": 18.651414693100474,
    "ttft": 3878.6233964590756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9167811539955437. Arrivals time: 0.026909722480922937 Scheduler time: 0.46540414122864604 Scheduler overhead time: 0.15202624909579754 Adapter cache time: 0.04131684824824333 Engine time: 0.1540949516929686 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3052536 . Total output tokens: 2814890
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9175333031453192,
    "estimated_duration": 3599.404632436796,
    "input_throughput": 319.4411624740248,
    "output_throughput": 281.00647281637924,
    "total_throughput": 600.447635290404,
    "itl": 18.65142449302339,
    "ttft": 3878.567390209733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9175830311141908. Arrivals time: 0.02607773896306753 Scheduler time: 0.46728804288432 Scheduler overhead time: 0.15215442841872573 Adapter cache time: 0.04108323995023966 Engine time: 0.15423938306048512 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3052536 . Total output tokens: 2814890
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.904360513202846,
    "estimated_duration": 3599.404632436796,
    "input_throughput": 319.4411624740248,
    "output_throughput": 281.00647281637924,
    "total_throughput": 600.447635290404,
    "itl": 18.651469154686012,
    "ttft": 3878.5328262614435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.904434435069561. Arrivals time: 0.026233796030282974 Scheduler time: 0.45935266511514783 Scheduler overhead time: 0.15013258857652545 Adapter cache time: 0.04108230210840702 Engine time: 0.1514942212961614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3052536 . Total output tokens: 2814890
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9155853493139148,
    "estimated_duration": 3599.404632436796,
    "input_throughput": 319.4411624740248,
    "output_throughput": 281.00647281637924,
    "total_throughput": 600.447635290404,
    "itl": 18.651395982210015,
    "ttft": 3878.592407179524,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9156361073255539. Arrivals time: 0.026232890784740448 Scheduler time: 0.4656198350712657 Scheduler overhead time: 0.15043704630807042 Adapter cache time: 0.041045664343982935 Engine time: 0.1553947888314724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3052536 . Total output tokens: 2814890
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9081116602756083,
    "estimated_duration": 3599.404632436796,
    "input_throughput": 319.4411624740248,
    "output_throughput": 281.00647281637924,
    "total_throughput": 600.447635290404,
    "itl": 18.65147819907853,
    "ttft": 3878.5566208263167,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076457,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9082760703749955. Arrivals time: 0.026229912415146828 Scheduler time: 0.46141214203089476 Scheduler overhead time: 0.15075119212269783 Adapter cache time: 0.040851629339158535 Engine time: 0.15203369408845901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3052536 . Total output tokens: 2814890
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.916277710814029,
    "estimated_duration": 3599.404632436796,
    "input_throughput": 319.4411624740248,
    "output_throughput": 281.00647281637924,
    "total_throughput": 600.447635290404,
    "itl": 18.651327090016945,
    "ttft": 3878.6221762783352,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9163340288214386. Arrivals time: 0.026269133668392897 Scheduler time: 0.46911638556048274 Scheduler overhead time: 0.15038790181279182 Adapter cache time: 0.04091949248686433 Engine time: 0.1529828878119588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 540, 540, 33, 540, 33, 66, 33, 540, 66, 540, 33, 66, 540, 540, 540, 33, 540, 66, 66, 33, 33, 33, 540, 33, 33, 33, 540, 66, 33, 540, 540, 540, 540, 66, 66, 66, 540, 33, 66, 66, 540, 540, 66, 540, 33, 540, 66, 66, 66, 540, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 540, 66]
Prompts retrieved: 13959 . Total input tokens: 3052536 . Total output tokens: 2814890
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.9115728340111673,
    "estimated_duration": 3599.404632436796,
    "input_throughput": 319.4411624740248,
    "output_throughput": 281.00647281637924,
    "total_throughput": 600.447635290404,
    "itl": 18.651511986644646,
    "ttft": 3878.5620780055287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2146942614018914,
    "arrivals": 4678,
    "finished_requests": 4673,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9117947118356824. Arrivals time: 0.025831887032836676 Scheduler time: 0.4652834562584758 Scheduler overhead time: 0.15172168798744678 Adapter cache time: 0.041248912923038006 Engine time: 0.15095618879422545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2245831 . Total output tokens: 2048489
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8033092049881816,
    "estimated_duration": 3599.843809163575,
    "input_throughput": 221.60433682409,
    "output_throughput": 205.27418387402105,
    "total_throughput": 426.87852069811106,
    "itl": 18.302041238115258,
    "ttft": 4392.1504876350655,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8033729461021721. Arrivals time: 0.022978906985372305 Scheduler time: 0.3705723248422146 Scheduler overhead time: 0.1484906473197043 Adapter cache time: 0.03696106048300862 Engine time: 0.1484406222589314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2245831 . Total output tokens: 2048489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8047329219989479,
    "estimated_duration": 3599.843809163575,
    "input_throughput": 221.60433682409,
    "output_throughput": 205.27418387402105,
    "total_throughput": 426.87852069811106,
    "itl": 18.302113307676745,
    "ttft": 4392.107583032039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8047869428992271. Arrivals time: 0.02262844191864133 Scheduler time: 0.36889788834378123 Scheduler overhead time: 0.1481959316879511 Adapter cache time: 0.03711538529023528 Engine time: 0.15190976345911622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2245831 . Total output tokens: 2048489
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8086785203777254,
    "estimated_duration": 3599.843809163575,
    "input_throughput": 221.60433682409,
    "output_throughput": 205.27418387402105,
    "total_throughput": 426.87852069811106,
    "itl": 18.302115135889874,
    "ttft": 4392.12080344021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2092868485860526,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8087435490451753. Arrivals time: 0.022780912462621927 Scheduler time: 0.3737838827073574 Scheduler overhead time: 0.14853095170110464 Adapter cache time: 0.03688238374888897 Engine time: 0.1510505424812436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2245831 . Total output tokens: 2048489
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.81005495833233,
    "estimated_duration": 3599.843809163575,
    "input_throughput": 221.60433682409,
    "output_throughput": 205.27418387402105,
    "total_throughput": 426.87852069811106,
    "itl": 18.30207250545318,
    "ttft": 4392.116405991161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8101194282062352. Arrivals time: 0.02307398710399866 Scheduler time: 0.37216751696541905 Scheduler overhead time: 0.1492505120113492 Adapter cache time: 0.03721075318753719 Engine time: 0.15200624708086252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2245831 . Total output tokens: 2048489
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8064298541285098,
    "estimated_duration": 3599.843809163575,
    "input_throughput": 221.60433682409,
    "output_throughput": 205.27418387402105,
    "total_throughput": 426.87852069811106,
    "itl": 18.30212436342612,
    "ttft": 4392.11200912686,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8065764778293669. Arrivals time: 0.023254343774169683 Scheduler time: 0.36902593122795224 Scheduler overhead time: 0.1499167582951486 Adapter cache time: 0.03749681077897549 Engine time: 0.1507636345922947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2245831 . Total output tokens: 2048489
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.8234443310648203,
    "estimated_duration": 3599.843809163575,
    "input_throughput": 221.60433682409,
    "output_throughput": 205.27418387402105,
    "total_throughput": 426.87852069811106,
    "itl": 18.302016122143215,
    "ttft": 4392.1559768892275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8235183749347925. Arrivals time: 0.02333614742383361 Scheduler time: 0.3778939303010702 Scheduler overhead time: 0.15436061145737767 Adapter cache time: 0.037136595230549574 Engine time: 0.15366898523643613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [21 21 22]
Adapter prompts. [66, 135, 270, 270, 66, 270, 66, 135, 66, 270, 135, 270, 66, 135, 270, 270, 270, 66, 270, 135, 135, 66, 66, 66, 270, 66, 66, 66, 270, 135, 66, 270, 270, 270, 270, 135, 135, 135, 270, 66, 135, 135, 270, 270, 135, 270, 66, 270, 135, 135, 135, 270, 135, 66, 66, 135, 135, 66, 135, 66, 66, 66, 270, 135]
Prompts retrieved: 10161 . Total input tokens: 2245831 . Total output tokens: 2048489
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.8070323430001736,
    "estimated_duration": 3599.843809163575,
    "input_throughput": 221.60433682409,
    "output_throughput": 205.27418387402105,
    "total_throughput": 426.87852069811106,
    "itl": 18.30213986155979,
    "ttft": 4392.113409432547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189146,
    "arrivals": 3301,
    "finished_requests": 3297,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.8071455764584243. Arrivals time: 0.02266115415841341 Scheduler time: 0.3713456494733691 Scheduler overhead time: 0.14827965339645743 Adapter cache time: 0.037060684990137815 Engine time: 0.1517912494018674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2092242 . Total output tokens: 1915446
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7818687781691551,
    "estimated_duration": 3599.365807727008,
    "input_throughput": 207.28707218318604,
    "output_throughput": 187.42829599362756,
    "total_throughput": 394.7153681768136,
    "itl": 18.19205808989632,
    "ttft": 5881.716194156123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7819206649437547. Arrivals time: 0.022260031197220087 Scheduler time: 0.3477234593592584 Scheduler overhead time: 0.14877845253795385 Adapter cache time: 0.03609615098685026 Engine time: 0.15120092267170548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2092242 . Total output tokens: 1915446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7838777299039066,
    "estimated_duration": 3599.365807727008,
    "input_throughput": 207.28707218318604,
    "output_throughput": 187.42829599362756,
    "total_throughput": 394.7153681768136,
    "itl": 18.192119167550395,
    "ttft": 5881.669553322162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7839265088550746. Arrivals time: 0.022250955924391747 Scheduler time: 0.3505974393337965 Scheduler overhead time: 0.14850213238969445 Adapter cache time: 0.035841339733451605 Engine time: 0.15027827583253384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2092242 . Total output tokens: 1915446
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7829932831227779,
    "estimated_duration": 3599.365807727008,
    "input_throughput": 207.28707218318604,
    "output_throughput": 187.42829599362756,
    "total_throughput": 394.7153681768136,
    "itl": 18.192116639266267,
    "ttft": 5881.659721729561,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7830695831216872. Arrivals time: 0.022524367086589336 Scheduler time: 0.35001165932044387 Scheduler overhead time: 0.14752586837857962 Adapter cache time: 0.03589725820347667 Engine time: 0.15101135149598122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2092242 . Total output tokens: 1915446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7827715976163745,
    "estimated_duration": 3599.365807727008,
    "input_throughput": 207.28707218318604,
    "output_throughput": 187.42829599362756,
    "total_throughput": 394.7153681768136,
    "itl": 18.19212476822601,
    "ttft": 5881.799161405557,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942695,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7828208757564425. Arrivals time: 0.02238555857911706 Scheduler time: 0.3496620082296431 Scheduler overhead time: 0.1483996077440679 Adapter cache time: 0.035757784731686115 Engine time: 0.15050546126440167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2092242 . Total output tokens: 1915446
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7849433170631528,
    "estimated_duration": 3599.365807727008,
    "input_throughput": 207.28707218318604,
    "output_throughput": 187.42829599362756,
    "total_throughput": 394.7153681768136,
    "itl": 18.192111000356885,
    "ttft": 5881.684799795006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2119276781007646,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7849966906942427. Arrivals time: 0.022388404700905085 Scheduler time: 0.35013498552143574 Scheduler overhead time: 0.1500472272746265 Adapter cache time: 0.03558427933603525 Engine time: 0.15103763481602073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2092242 . Total output tokens: 1915446
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7845075102522969,
    "estimated_duration": 3599.365807727008,
    "input_throughput": 207.28707218318604,
    "output_throughput": 187.42829599362756,
    "total_throughput": 394.7153681768136,
    "itl": 18.191973032421075,
    "ttft": 5881.751772643364,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7845696089789271. Arrivals time: 0.022483190521597862 Scheduler time: 0.3485854365862906 Scheduler overhead time: 0.1485285721719265 Adapter cache time: 0.03600482502952218 Engine time: 0.15307939145714045 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 135, 270, 270, 33, 270, 33, 135, 33, 270, 135, 270, 33, 135, 270, 270, 270, 33, 270, 135, 135, 33, 33, 33, 270, 33, 33, 33, 270, 135, 33, 270, 270, 270, 270, 135, 135, 135, 270, 33, 135, 135, 270, 270, 135, 270, 33, 270, 135, 135, 135, 270, 135, 33, 33, 135, 135, 33, 135, 33, 33, 33, 270, 135]
Prompts retrieved: 9468 . Total input tokens: 2092242 . Total output tokens: 1915446
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7839598087593913,
    "estimated_duration": 3599.365807727008,
    "input_throughput": 207.28707218318604,
    "output_throughput": 187.42829599362756,
    "total_throughput": 394.7153681768136,
    "itl": 18.191525724996815,
    "ttft": 5881.727477472245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 3076,
    "finished_requests": 3071,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7840131828561425. Arrivals time: 0.022479500621557236 Scheduler time: 0.3507866286672652 Scheduler overhead time: 0.14809343591332436 Adapter cache time: 0.0356915257871151 Engine time: 0.15078604174777865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1768810 . Total output tokens: 1619736
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7330986713059247,
    "estimated_duration": 3599.4317759773685,
    "input_throughput": 175.99916859876694,
    "output_throughput": 157.61237753866155,
    "total_throughput": 333.6115461374285,
    "itl": 18.07763881739774,
    "ttft": 16702.23513103784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7331577441655099. Arrivals time: 0.02116161398589611 Scheduler time: 0.3104855976998806 Scheduler overhead time: 0.1454236344434321 Adapter cache time: 0.0332318190485239 Engine time: 0.1478131664916873 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1768810 . Total output tokens: 1619736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7316559660248458,
    "estimated_duration": 3599.4317759773685,
    "input_throughput": 175.99916859876694,
    "output_throughput": 157.61237753866155,
    "total_throughput": 333.6115461374285,
    "itl": 18.077698202701654,
    "ttft": 16702.265743974047,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.2089328175666742,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7317211399786174. Arrivals time: 0.021164915058761835 Scheduler time: 0.3107250388711691 Scheduler overhead time: 0.14544673170894384 Adapter cache time: 0.03311230894178152 Engine time: 0.14636709541082382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1768810 . Total output tokens: 1619736
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7409523772075772,
    "estimated_duration": 3599.4317759773685,
    "input_throughput": 175.99916859876694,
    "output_throughput": 157.61237753866155,
    "total_throughput": 333.6115461374285,
    "itl": 18.07770527860767,
    "ttft": 16702.255837758326,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605254,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7410544781014323. Arrivals time: 0.02108187647536397 Scheduler time: 0.3143171416595578 Scheduler overhead time: 0.14734679460525513 Adapter cache time: 0.033324421383440495 Engine time: 0.1498795012012124 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1768810 . Total output tokens: 1619736
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7380357529036701,
    "estimated_duration": 3599.4317759773685,
    "input_throughput": 175.99916859876694,
    "output_throughput": 157.61237753866155,
    "total_throughput": 333.6115461374285,
    "itl": 18.077659764293255,
    "ttft": 16702.254973902272,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7380877612158656. Arrivals time: 0.021038950886577368 Scheduler time: 0.31366840563714504 Scheduler overhead time: 0.14611167600378394 Adapter cache time: 0.033177439123392105 Engine time: 0.1487742247991264 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1768810 . Total output tokens: 1619736
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7389949578791857,
    "estimated_duration": 3599.4317759773685,
    "input_throughput": 175.99916859876694,
    "output_throughput": 157.61237753866155,
    "total_throughput": 333.6115461374285,
    "itl": 18.0777127784558,
    "ttft": 16702.242514793812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7390465689823031. Arrivals time: 0.02094287145882845 Scheduler time: 0.3154200194403529 Scheduler overhead time: 0.14522465458139777 Adapter cache time: 0.03315683826804161 Engine time: 0.1491431719623506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1768810 . Total output tokens: 1619736
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.7314957878552377,
    "estimated_duration": 3599.4317759773685,
    "input_throughput": 175.99916859876694,
    "output_throughput": 157.61237753866155,
    "total_throughput": 333.6115461374285,
    "itl": 18.077615434122592,
    "ttft": 16702.23123910601,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7315690200775862. Arrivals time: 0.020869711879640818 Scheduler time: 0.30981296906247735 Scheduler overhead time: 0.14567101560533047 Adapter cache time: 0.03325474634766579 Engine time: 0.14710491057485342 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 270, 270, 33, 270, 33, 66, 33, 270, 66, 270, 33, 66, 270, 270, 270, 33, 270, 66, 66, 33, 33, 33, 270, 33, 33, 33, 270, 66, 33, 270, 270, 270, 270, 66, 66, 66, 270, 33, 66, 66, 270, 270, 66, 270, 33, 270, 66, 66, 66, 270, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 270, 66]
Prompts retrieved: 8019 . Total input tokens: 1768810 . Total output tokens: 1619736
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.7365077170543373,
    "estimated_duration": 3599.4317759773685,
    "input_throughput": 175.99916859876694,
    "output_throughput": 157.61237753866155,
    "total_throughput": 333.6115461374285,
    "itl": 18.077739285674173,
    "ttft": 16702.23472994602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 2591,
    "finished_requests": 2579,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7365550687536597. Arrivals time: 0.021458332892507315 Scheduler time: 0.31278920406475663 Scheduler overhead time: 0.1461295299232006 Adapter cache time: 0.033115128986537457 Engine time: 0.14818448526784778 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1136537 . Total output tokens: 1002507
Prompts distributed
Adapter sizes. Values: [8]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.592684930190444,
    "estimated_duration": 3599.288886061684,
    "input_throughput": 115.53032089485735,
    "output_throughput": 97.39840593445271,
    "total_throughput": 212.92872682931005,
    "itl": 17.733076323869888,
    "ttft": 8781.55791418893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19587121561169607,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5927430731244385. Arrivals time: 0.0172373172827065 Scheduler time: 0.22427651658654213 Scheduler overhead time: 0.12840336840599775 Adapter cache time: 0.026908168103545904 Engine time: 0.1301383525133133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1136537 . Total output tokens: 1002507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5971857099793851,
    "estimated_duration": 3599.288886061684,
    "input_throughput": 115.53032089485735,
    "output_throughput": 97.39840593445271,
    "total_throughput": 212.92872682931005,
    "itl": 17.733135386310916,
    "ttft": 8781.550232168303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20893281756667417,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5972418109886348. Arrivals time: 0.017192337196320295 Scheduler time: 0.22539831278845668 Scheduler overhead time: 0.1288159377872944 Adapter cache time: 0.027109424117952585 Engine time: 0.13225148478522897 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1136537 . Total output tokens: 1002507
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5940212258137763,
    "estimated_duration": 3599.288886061684,
    "input_throughput": 115.53032089485735,
    "output_throughput": 97.39840593445271,
    "total_throughput": 212.92872682931005,
    "itl": 17.733137274201763,
    "ttft": 8781.563568875496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20928684858605257,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5941109769046307. Arrivals time: 0.017163380049169064 Scheduler time: 0.22491323808208108 Scheduler overhead time: 0.12823666166514158 Adapter cache time: 0.027231954503804445 Engine time: 0.13082118658348918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1136537 . Total output tokens: 1002507
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [22 42]
---Simulation End---
#Simulation results
{
    "duration": 0.6022351272404194,
    "estimated_duration": 3599.288886061684,
    "input_throughput": 115.53032089485735,
    "output_throughput": 97.39840593445271,
    "total_throughput": 212.92872682931005,
    "itl": 17.73309874604976,
    "ttft": 8781.60109815884,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.20035231587942698,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.6023024041205645. Arrivals time: 0.017267022747546434 Scheduler time: 0.22808957006782293 Scheduler overhead time: 0.12921751150861382 Adapter cache time: 0.027478977106511593 Engine time: 0.13331516040489078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1136537 . Total output tokens: 1002507
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [22 21 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5972965420223773,
    "estimated_duration": 3599.288886061684,
    "input_throughput": 115.53032089485735,
    "output_throughput": 97.39840593445271,
    "total_throughput": 212.92872682931005,
    "itl": 17.733141652564008,
    "ttft": 8781.537290124445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21192767810076454,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.597343890927732. Arrivals time: 0.01729119662195444 Scheduler time: 0.22705814987421036 Scheduler overhead time: 0.12954951683059335 Adapter cache time: 0.026954893488436937 Engine time: 0.129854965955019 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1136537 . Total output tokens: 1002507
Prompts distributed
Adapter sizes. Values: [16]. Counts: [64]
---Simulation End---
#Simulation results
{
    "duration": 0.591893661301583,
    "estimated_duration": 3599.288886061684,
    "input_throughput": 115.53032089485735,
    "output_throughput": 97.39840593445271,
    "total_throughput": 212.92872682931005,
    "itl": 17.733050761003025,
    "ttft": 8781.576293324708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.19136321887373942,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.5919435513205826. Arrivals time: 0.01697132410481572 Scheduler time: 0.22326206043362617 Scheduler overhead time: 0.1289255595766008 Adapter cache time: 0.0270399684086442 Engine time: 0.13014986226335168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 64,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_64_slots_64_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [21 21 22]
Adapter prompts. [33, 66, 135, 135, 33, 135, 33, 66, 33, 135, 66, 135, 33, 66, 135, 135, 135, 33, 135, 66, 66, 33, 33, 33, 135, 33, 33, 33, 135, 66, 33, 135, 135, 135, 135, 66, 66, 66, 135, 33, 66, 66, 135, 135, 66, 135, 33, 135, 66, 66, 66, 135, 66, 33, 33, 66, 66, 33, 66, 33, 33, 33, 135, 66]
Prompts retrieved: 5049 . Total input tokens: 1136537 . Total output tokens: 1002507
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [43 21]
---Simulation End---
#Simulation results
{
    "duration": 0.5970014599151909,
    "estimated_duration": 3599.288886061684,
    "input_throughput": 115.53032089485735,
    "output_throughput": 97.39840593445271,
    "total_throughput": 212.92872682931005,
    "itl": 17.733161487713872,
    "ttft": 8781.528642269503,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 64,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.21469426140189143,
    "arrivals": 1645,
    "finished_requests": 1641,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.597049290779978. Arrivals time: 0.01730821980163455 Scheduler time: 0.22554217046126723 Scheduler overhead time: 0.12850828934460878 Adapter cache time: 0.02714061690494418 Engine time: 0.13263474637642503 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 115.83236510213464,
    "estimated_duration": 3600.0766603356865,
    "input_throughput": 8248.534629046226,
    "output_throughput": 7287.963695071296,
    "total_throughput": 15536.498324117523,
    "itl": 107.78910348954844,
    "ttft": 1834881.1782768136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6641258404334067,
    "arrivals": 644954,
    "finished_requests": 120155,
    "scheduler_time": 246.81386812132843
}
#Debug simulation 
Total elapsed time: 115.8325292239897. Arrivals time: 0.6362110003829002 Scheduler time: 114.98097485955805 Scheduler overhead time: 0.08365958603098989 Adapter cache time: 0.016706913243979216 Engine time: 0.08308086544275284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 113.82565100304782,
    "estimated_duration": 3600.0554517855367,
    "input_throughput": 8220.364212812954,
    "output_throughput": 7251.189974602401,
    "total_throughput": 15471.554187415355,
    "itl": 107.11387794536168,
    "ttft": 1842624.5935144564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6749179696710802,
    "arrivals": 644954,
    "finished_requests": 119690,
    "scheduler_time": 247.81100899058438
}
#Debug simulation 
Total elapsed time: 113.8258304479532. Arrivals time: 0.5758091025054455 Scheduler time: 113.02303916029632 Scheduler overhead time: 0.08338195690885186 Adapter cache time: 0.01716942898929119 Engine time: 0.09477012092247605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 114.33421580400318,
    "estimated_duration": 3600.056696896945,
    "input_throughput": 8220.36136972738,
    "output_throughput": 7251.187466714297,
    "total_throughput": 15471.548836441678,
    "itl": 107.11394201902317,
    "ttft": 1842625.28101684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6762113084457845,
    "arrivals": 644954,
    "finished_requests": 119690,
    "scheduler_time": 247.8110608017883
}
#Debug simulation 
Total elapsed time: 114.33439121302217. Arrivals time: 0.5748095503076911 Scheduler time: 113.5446438039653 Scheduler overhead time: 0.08428826788440347 Adapter cache time: 0.016878284979611635 Engine time: 0.08206860348582268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 114.38819925673306,
    "estimated_duration": 3600.0245819492593,
    "input_throughput": 8220.43470158091,
    "output_throughput": 7251.252152802087,
    "total_throughput": 15471.686854382997,
    "itl": 107.11304514547511,
    "ttft": 1842610.5106892847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6467248926986955,
    "arrivals": 644954,
    "finished_requests": 119690,
    "scheduler_time": 247.81030183403104
}
#Debug simulation 
Total elapsed time: 114.38837689487264. Arrivals time: 0.5967601737938821 Scheduler time: 113.57790213217959 Scheduler overhead time: 0.08297551888972521 Adapter cache time: 0.01695085223764181 Engine time: 0.08261869894340634 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 114.56665558926761,
    "estimated_duration": 3600.0653081175633,
    "input_throughput": 8220.34170693261,
    "output_throughput": 7251.1701221469975,
    "total_throughput": 15471.511829079607,
    "itl": 107.11411501275636,
    "ttft": 1842628.9218714654,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6848883197084094,
    "arrivals": 644954,
    "finished_requests": 119690,
    "scheduler_time": 247.81120577281618
}
#Debug simulation 
Total elapsed time: 114.56683212937787. Arrivals time: 0.5912194037809968 Scheduler time: 113.75901835178956 Scheduler overhead time: 0.08504897262901068 Adapter cache time: 0.017041238490492105 Engine time: 0.08274716790765524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 116.25345075968653,
    "estimated_duration": 3600.0617947258397,
    "input_throughput": 8248.56868943313,
    "output_throughput": 7287.99378900608,
    "total_throughput": 15536.56247843921,
    "itl": 107.78875016177828,
    "ttft": 1834875.0408939812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 217,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.648840913993773,
    "arrivals": 644954,
    "finished_requests": 120155,
    "scheduler_time": 246.81367325529072
}
#Debug simulation 
Total elapsed time: 116.25361603591591. Arrivals time: 0.6639690017327666 Scheduler time: 115.37445179419592 Scheduler overhead time: 0.08403736399486661 Adapter cache time: 0.017029707320034504 Engine time: 0.08278848510235548 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [8640, 8640, 8640, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 8640, 34560, 17280, 8640, 8640, 17280, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 8640, 8640, 34560, 17280, 17280, 8640, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 8640, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 8640, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 8640, 17280, 34560, 8640, 34560, 17280, 8640, 34560, 8640, 8640, 34560, 8640, 8640, 17280]
Prompts retrieved: 1935360 . Total input tokens: 431807893 . Total output tokens: 386940663
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 114.59743277262896,
    "estimated_duration": 3600.073892376169,
    "input_throughput": 8220.322105796313,
    "output_throughput": 7251.152831968689,
    "total_throughput": 15471.474937765002,
    "itl": 107.11435428306417,
    "ttft": 1842632.5057098672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6934395771846197,
    "arrivals": 644954,
    "finished_requests": 119690,
    "scheduler_time": 247.81133881253427
}
#Debug simulation 
Total elapsed time: 114.59761014860123. Arrivals time: 0.5825445959344506 Scheduler time: 113.79960403684527 Scheduler overhead time: 0.08365213545039296 Adapter cache time: 0.016889231745153666 Engine time: 0.08296856191009283 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 112.9891724428162,
    "estimated_duration": 3600.0459207642834,
    "input_throughput": 8282.389629538366,
    "output_throughput": 7298.40384769924,
    "total_throughput": 15580.793477237607,
    "itl": 108.17633128287093,
    "ttft": 1808530.916683691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.648823401713743,
    "arrivals": 599169,
    "finished_requests": 120326,
    "scheduler_time": 245.89785558899064
}
#Debug simulation 
Total elapsed time: 112.98935764981434. Arrivals time: 0.5976214087568223 Scheduler time: 112.17970921145752 Scheduler overhead time: 0.08238487876951694 Adapter cache time: 0.01699891546741128 Engine time: 0.08137785224243999 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 112.32473087124527,
    "estimated_duration": 3600.086173402948,
    "input_throughput": 8282.297023967005,
    "output_throughput": 7298.322244093449,
    "total_throughput": 15580.619268060453,
    "itl": 108.17725757599273,
    "ttft": 1808545.7546849456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6906854117824719,
    "arrivals": 599169,
    "finished_requests": 120326,
    "scheduler_time": 245.89804691201883
}
#Debug simulation 
Total elapsed time: 112.32489885715768. Arrivals time: 0.5866573443636298 Scheduler time: 111.52733790036291 Scheduler overhead time: 0.08153480663895607 Adapter cache time: 0.016545696649700403 Engine time: 0.08147360617294908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 112.30624580895528,
    "estimated_duration": 3600.087405126396,
    "input_throughput": 8282.294190285958,
    "output_throughput": 7298.319747066675,
    "total_throughput": 15580.613937352633,
    "itl": 108.17725597597459,
    "ttft": 1808546.3234155178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6921033976785869,
    "arrivals": 599169,
    "finished_requests": 120326,
    "scheduler_time": 245.89806072672118
}
#Debug simulation 
Total elapsed time: 112.30641689617187. Arrivals time: 0.5923629957251251 Scheduler time: 111.50556536857039 Scheduler overhead time: 0.0809173951856792 Adapter cache time: 0.016350189223885536 Engine time: 0.08056191261857748 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 111.88630001991987,
    "estimated_duration": 3600.059310740511,
    "input_throughput": 8282.358824212488,
    "output_throughput": 7298.376702187018,
    "total_throughput": 15580.735526399505,
    "itl": 108.17672715536466,
    "ttft": 1808536.066486492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6620837394916466,
    "arrivals": 599169,
    "finished_requests": 120326,
    "scheduler_time": 245.89788518883682
}
#Debug simulation 
Total elapsed time: 111.88647119514644. Arrivals time: 0.5892988280393183 Scheduler time: 111.08578894240782 Scheduler overhead time: 0.08206424443051219 Adapter cache time: 0.016695411410182714 Engine time: 0.08137888880446553 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 112.08391246013343,
    "estimated_duration": 3600.096965248949,
    "input_throughput": 8282.272196504056,
    "output_throughput": 7298.30036624669,
    "total_throughput": 15580.572562750745,
    "itl": 108.17741607502462,
    "ttft": 1808550.2718096587,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7009061627276267,
    "arrivals": 599169,
    "finished_requests": 120326,
    "scheduler_time": 245.89821785275151
}
#Debug simulation 
Total elapsed time: 112.08407808514312. Arrivals time: 0.6057468755170703 Scheduler time: 111.26416475977749 Scheduler overhead time: 0.08399077225476503 Adapter cache time: 0.017180698923766613 Engine time: 0.08169920649379492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 109.48349184496328,
    "estimated_duration": 3600.0234033888783,
    "input_throughput": 8320.861462123166,
    "output_throughput": 7334.717317432864,
    "total_throughput": 15655.57877955603,
    "itl": 108.97402751985607,
    "ttft": 1811108.9691940537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 218,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6518309642886752,
    "arrivals": 599169,
    "finished_requests": 120957,
    "scheduler_time": 244.1738178198984
}
#Debug simulation 
Total elapsed time: 109.48366182111204. Arrivals time: 0.5818286295980215 Scheduler time: 108.69295793864876 Scheduler overhead time: 0.08124557556584477 Adapter cache time: 0.016599288675934076 Engine time: 0.08039020793512464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 4320, 34560, 17280, 4320, 4320, 17280, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 4320, 4320, 34560, 17280, 17280, 4320, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 4320, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 4320, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 4320, 17280, 34560, 4320, 34560, 17280, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 17280]
Prompts retrieved: 1797120 . Total input tokens: 400994416 . Total output tokens: 359255850
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 112.23285411810502,
    "estimated_duration": 3600.1062468262344,
    "input_throughput": 8282.250843648273,
    "output_throughput": 7298.281550207868,
    "total_throughput": 15580.532393856141,
    "itl": 108.17763861711987,
    "ttft": 1808554.1346766476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7095831739902518,
    "arrivals": 599169,
    "finished_requests": 120326,
    "scheduler_time": 245.89832222588166
}
#Debug simulation 
Total elapsed time: 112.23302239738405. Arrivals time: 0.5830074180848897 Scheduler time: 111.43732466967776 Scheduler overhead time: 0.08324025897309184 Adapter cache time: 0.016989203169941902 Engine time: 0.08176705846562982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 110.626973179169,
    "estimated_duration": 3600.0247194477465,
    "input_throughput": 8250.931122649792,
    "output_throughput": 7259.780983950921,
    "total_throughput": 15510.712106600713,
    "itl": 108.9840184023973,
    "ttft": 1784638.1973632295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6886097423848687,
    "arrivals": 564644,
    "finished_requests": 119599,
    "scheduler_time": 247.48820104673428
}
#Debug simulation 
Total elapsed time: 110.62715380406007. Arrivals time: 0.6094591747969389 Scheduler time: 109.8072639843449 Scheduler overhead time: 0.08196065807715058 Adapter cache time: 0.016275292728096247 Engine time: 0.08100015856325626 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 110.7091985847801,
    "estimated_duration": 3600.0690197548765,
    "input_throughput": 8250.829591601128,
    "output_throughput": 7259.691649406078,
    "total_throughput": 15510.521241007205,
    "itl": 108.98465377215865,
    "ttft": 1784654.3149059091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7332334234821637,
    "arrivals": 564644,
    "finished_requests": 119599,
    "scheduler_time": 247.48847790423162
}
#Debug simulation 
Total elapsed time: 110.7093632449396. Arrivals time: 0.5653735739178956 Scheduler time: 109.93366579338908 Scheduler overhead time: 0.08182216016575694 Adapter cache time: 0.01656540483236313 Engine time: 0.0810694214887917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 110.43282379815355,
    "estimated_duration": 3600.0708352315887,
    "input_throughput": 8250.82543079717,
    "output_throughput": 7259.687988422244,
    "total_throughput": 15510.513419219415,
    "itl": 108.9846780158376,
    "ttft": 1784655.2871207553,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7347043701633844,
    "arrivals": 564644,
    "finished_requests": 119599,
    "scheduler_time": 247.4885223185091
}
#Debug simulation 
Total elapsed time: 110.43299198290333. Arrivals time: 0.5670964429154992 Scheduler time: 109.6555449492298 Scheduler overhead time: 0.0817978959530592 Adapter cache time: 0.016479191835969687 Engine time: 0.0806184527464211 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 110.39999341731891,
    "estimated_duration": 3600.0387743142173,
    "input_throughput": 8250.89891029252,
    "output_throughput": 7259.7526411305425,
    "total_throughput": 15510.651551423063,
    "itl": 108.98422980832488,
    "ttft": 1784643.0584703926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7029973699175768,
    "arrivals": 564644,
    "finished_requests": 119599,
    "scheduler_time": 247.48826843996775
}
#Debug simulation 
Total elapsed time: 110.40016136830673. Arrivals time: 0.5765586225315928 Scheduler time: 109.6128021273762 Scheduler overhead time: 0.08225193060934544 Adapter cache time: 0.016609591897577047 Engine time: 0.08036055276170373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 110.73331530066207,
    "estimated_duration": 3600.0800033038863,
    "input_throughput": 8250.804418996322,
    "output_throughput": 7259.669500681895,
    "total_throughput": 15510.473919678217,
    "itl": 108.98480368007488,
    "ttft": 1784658.6198852796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7440101503580839,
    "arrivals": 564644,
    "finished_requests": 119599,
    "scheduler_time": 247.4885846877839
}
#Debug simulation 
Total elapsed time: 110.73347739409655. Arrivals time: 0.5751294600777328 Scheduler time: 109.94650670746341 Scheduler overhead time: 0.08272047620266676 Adapter cache time: 0.01621609413996339 Engine time: 0.08171615516766906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 111.32895390689373,
    "estimated_duration": 3600.0083025402323,
    "input_throughput": 8250.96874888889,
    "output_throughput": 7259.814090305955,
    "total_throughput": 15510.782839194846,
    "itl": 108.98377802297212,
    "ttft": 1784631.6467713432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6727613163529904,
    "arrivals": 564644,
    "finished_requests": 119599,
    "scheduler_time": 247.48803271953807
}
#Debug simulation 
Total elapsed time: 111.32912300387397. Arrivals time: 0.5749831558205187 Scheduler time: 110.5429819971323 Scheduler overhead time: 0.08161910716444254 Adapter cache time: 0.016793340910226107 Engine time: 0.08139527263119817 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 1080, 34560, 17280, 1080, 1080, 17280, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 1080, 1080, 34560, 17280, 17280, 1080, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 1080, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 1080, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 1080, 17280, 34560, 1080, 34560, 17280, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 17280]
Prompts retrieved: 1693440 . Total input tokens: 377834478 . Total output tokens: 338505042
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 110.65457609202713,
    "estimated_duration": 3600.0889764765016,
    "input_throughput": 8250.783853978972,
    "output_throughput": 7259.651406054794,
    "total_throughput": 15510.435260033766,
    "itl": 108.98486562778182,
    "ttft": 1784661.742973641,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 225,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.7533159305527833,
    "arrivals": 564644,
    "finished_requests": 119599,
    "scheduler_time": 247.48865223453706
}
#Debug simulation 
Total elapsed time: 110.65474283089861. Arrivals time: 0.5781724541448057 Scheduler time: 109.86717167776078 Scheduler overhead time: 0.0814998890273273 Adapter cache time: 0.016372322104871273 Engine time: 0.08070644130930305 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 117.81483788508922,
    "estimated_duration": 3600.033221072242,
    "input_throughput": 8272.577548917672,
    "output_throughput": 7321.929377126447,
    "total_throughput": 15594.50692604412,
    "itl": 110.11142882554175,
    "ttft": 1779846.1724140036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5447668184200295,
    "arrivals": 558915,
    "finished_requests": 120425,
    "scheduler_time": 245.02527483961805
}
#Debug simulation 
Total elapsed time: 117.81501353997737. Arrivals time: 0.5810278984718025 Scheduler time: 117.02084065973759 Scheduler overhead time: 0.08220872050151229 Adapter cache time: 0.016825100872665644 Engine time: 0.08238899661228061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 118.05008387798443,
    "estimated_duration": 3600.0671166630927,
    "input_throughput": 8272.499660396488,
    "output_throughput": 7321.860439211025,
    "total_throughput": 15594.360099607513,
    "itl": 110.11193264340417,
    "ttft": 1779862.1506928776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5775830328394667,
    "arrivals": 558915,
    "finished_requests": 120425,
    "scheduler_time": 245.02566708043742
}
#Debug simulation 
Total elapsed time: 118.0502509647049. Arrivals time: 0.5838998113758862 Scheduler time: 117.25448442576453 Scheduler overhead time: 0.08326127333566546 Adapter cache time: 0.0163625655695796 Engine time: 0.08131125383079052 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 117.7701298375614,
    "estimated_duration": 3600.068734718725,
    "input_throughput": 8272.495942310625,
    "output_throughput": 7321.857148391211,
    "total_throughput": 15594.353090701838,
    "itl": 110.111959574115,
    "ttft": 1779862.9131460837,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5791808269731722,
    "arrivals": 558915,
    "finished_requests": 120425,
    "scheduler_time": 245.02568734193196
}
#Debug simulation 
Total elapsed time: 117.7703030128032. Arrivals time: 0.5919661843217909 Scheduler time: 116.96494006365538 Scheduler overhead time: 0.08324114745482802 Adapter cache time: 0.016653578262776136 Engine time: 0.08263364154845476 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 118.20340820774436,
    "estimated_duration": 3600.0441714114436,
    "input_throughput": 8272.552386023575,
    "output_throughput": 7321.907105841299,
    "total_throughput": 15594.459491864873,
    "itl": 110.11160054738548,
    "ttft": 1779851.4268474681,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5555188856436877,
    "arrivals": 558915,
    "finished_requests": 120425,
    "scheduler_time": 245.02537307299528
}
#Debug simulation 
Total elapsed time: 118.20358127262443. Arrivals time: 0.5950448275543749 Scheduler time: 117.39815505919978 Scheduler overhead time: 0.08220993774011731 Adapter cache time: 0.016331220977008343 Engine time: 0.08085508737713099 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 118.28802881482989,
    "estimated_duration": 3600.075503115922,
    "input_throughput": 8272.480389431721,
    "output_throughput": 7321.843382780641,
    "total_throughput": 15594.323772212361,
    "itl": 110.11205160456417,
    "ttft": 1779865.9729652537,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5859715314395741,
    "arrivals": 558915,
    "finished_requests": 120425,
    "scheduler_time": 245.02576507324602
}
#Debug simulation 
Total elapsed time: 118.28820758173242. Arrivals time: 0.5833663465455174 Scheduler time: 117.49238317785785 Scheduler overhead time: 0.08274460816755891 Adapter cache time: 0.016420962288975716 Engine time: 0.0816810242831707 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 118.09728645486757,
    "estimated_duration": 3600.0190233373314,
    "input_throughput": 8272.61017426279,
    "output_throughput": 7321.958253310617,
    "total_throughput": 15594.568427573407,
    "itl": 110.11121763717541,
    "ttft": 1779839.1624398404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.532228952492588,
    "arrivals": 558915,
    "finished_requests": 120425,
    "scheduler_time": 245.0249154721523
}
#Debug simulation 
Total elapsed time: 118.09745101397857. Arrivals time: 0.5948072983883321 Scheduler time: 117.29115945287049 Scheduler overhead time: 0.08294304879382253 Adapter cache time: 0.016329062171280384 Engine time: 0.08081255294382572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 540, 34560, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 540, 34560, 17280, 540, 540, 17280, 34560, 540, 17280, 540, 540, 17280, 17280, 17280, 540, 540, 34560, 17280, 17280, 540, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 540, 34560, 17280, 17280, 17280, 34560, 34560, 540, 540, 17280, 540, 34560, 540, 540, 34560, 540, 17280, 17280, 540, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 540, 540, 34560, 17280, 34560, 540, 17280, 34560, 540, 34560, 17280, 540, 34560, 540, 540, 34560, 540, 540, 17280]
Prompts retrieved: 1676160 . Total input tokens: 373978445 . Total output tokens: 335072734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 118.40075675724074,
    "estimated_duration": 3600.0844975194823,
    "input_throughput": 8272.459721575975,
    "output_throughput": 7321.825089983837,
    "total_throughput": 15594.284811559812,
    "itl": 110.11254728347129,
    "ttft": 1779870.4848601292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5931394972652204,
    "arrivals": 558915,
    "finished_requests": 120425,
    "scheduler_time": 245.02619097085997
}
#Debug simulation 
Total elapsed time: 118.40093159209937. Arrivals time: 0.5755742788314819 Scheduler time: 117.61424714000896 Scheduler overhead time: 0.08220368763431907 Adapter cache time: 0.016600674483925104 Engine time: 0.08115418255329132 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 123.35414742911234,
    "estimated_duration": 3600.0671473742955,
    "input_throughput": 8221.320266647459,
    "output_throughput": 7326.362514998328,
    "total_throughput": 15547.682781645786,
    "itl": 110.59357806738751,
    "ttft": 1775319.284047363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.514161940980702,
    "arrivals": 556029,
    "finished_requests": 120077,
    "scheduler_time": 244.8882642254461
}
#Debug simulation 
Total elapsed time: 123.35431949235499. Arrivals time: 0.6017874577082694 Scheduler time: 122.53852033149451 Scheduler overhead time: 0.08354982500895858 Adapter cache time: 0.016879828181117773 Engine time: 0.08198761940002441 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 118.7073167571798,
    "estimated_duration": 3600.0382180854654,
    "input_throughput": 8259.905089511487,
    "output_throughput": 7356.478569298143,
    "total_throughput": 15616.38365880963,
    "itl": 111.04350405480692,
    "ttft": 1775321.5605507516,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5762273638183261,
    "arrivals": 556029,
    "finished_requests": 120639,
    "scheduler_time": 243.35977483967548
}
#Debug simulation 
Total elapsed time: 118.70748927304521. Arrivals time: 0.6067099906504154 Scheduler time: 117.88944634050131 Scheduler overhead time: 0.08218555757775903 Adapter cache time: 0.016721307765692472 Engine time: 0.08149471879005432 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 118.97417382104322,
    "estimated_duration": 3600.0394810355474,
    "input_throughput": 8259.902191807763,
    "output_throughput": 7356.475988530554,
    "total_throughput": 15616.378180338317,
    "itl": 111.04353959814551,
    "ttft": 1775322.2104650901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5774862981028877,
    "arrivals": 556029,
    "finished_requests": 120639,
    "scheduler_time": 243.3597788554672
}
#Debug simulation 
Total elapsed time: 118.97435368597507. Arrivals time: 0.5954891378059983 Scheduler time: 118.16871436219662 Scheduler overhead time: 0.08209757134318352 Adapter cache time: 0.016362363938242197 Engine time: 0.08080517640337348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 123.57650890015066,
    "estimated_duration": 3600.0776815950658,
    "input_throughput": 8221.296210165801,
    "output_throughput": 7326.341077260868,
    "total_throughput": 15547.637287426669,
    "itl": 110.5937690585238,
    "ttft": 1775324.1259474016,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5235754061024641,
    "arrivals": 556029,
    "finished_requests": 120077,
    "scheduler_time": 244.88838459527244
}
#Debug simulation 
Total elapsed time: 123.57667606789619. Arrivals time: 0.605982503388077 Scheduler time: 122.75808646576479 Scheduler overhead time: 0.0826964364387095 Adapter cache time: 0.016729735303670168 Engine time: 0.08201862033456564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 118.5661777718924,
    "estimated_duration": 3600.045481543561,
    "input_throughput": 8259.88842431245,
    "output_throughput": 7356.463726854043,
    "total_throughput": 15616.352151166493,
    "itl": 111.04358051594158,
    "ttft": 1775324.2391099194,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5850315252877787,
    "arrivals": 556029,
    "finished_requests": 120639,
    "scheduler_time": 243.35983475358623
}
#Debug simulation 
Total elapsed time: 118.56634426210076. Arrivals time: 0.5919289295561612 Scheduler time: 117.76323955366388 Scheduler overhead time: 0.08212956739589572 Adapter cache time: 0.016449563670903444 Engine time: 0.08088089479133487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 123.03683166997507,
    "estimated_duration": 3600.055533990251,
    "input_throughput": 8221.346787724344,
    "output_throughput": 7326.3861490397285,
    "total_throughput": 15547.732936764072,
    "itl": 110.59343041267327,
    "ttft": 1775314.2018749146,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 168,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5023284495435661,
    "arrivals": 556029,
    "finished_requests": 120077,
    "scheduler_time": 244.88808417849245
}
#Debug simulation 
Total elapsed time: 123.03700789902359. Arrivals time: 0.8799709966406226 Scheduler time: 121.94553106697276 Scheduler overhead time: 0.08273093169555068 Adapter cache time: 0.016831728629767895 Engine time: 0.08115376392379403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 270, 34560, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 270, 34560, 17280, 270, 270, 17280, 34560, 270, 17280, 270, 270, 17280, 17280, 17280, 270, 270, 34560, 17280, 17280, 270, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 270, 34560, 17280, 17280, 17280, 34560, 34560, 270, 270, 17280, 270, 34560, 270, 270, 34560, 270, 17280, 17280, 270, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 270, 270, 34560, 17280, 34560, 270, 17280, 34560, 270, 34560, 17280, 270, 34560, 270, 270, 34560, 270, 270, 17280]
Prompts retrieved: 1667520 . Total input tokens: 372043367 . Total output tokens: 333338958
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 118.66352141089737,
    "estimated_duration": 3600.053010599425,
    "input_throughput": 8259.871149799772,
    "output_throughput": 7356.448341739935,
    "total_throughput": 15616.319491539707,
    "itl": 111.04372082243933,
    "ttft": 1775327.5999933013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 177,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5919479835405954,
    "arrivals": 556029,
    "finished_requests": 120639,
    "scheduler_time": 243.3599471582998
}
#Debug simulation 
Total elapsed time: 118.6637109159492. Arrivals time: 0.5888646589592099 Scheduler time: 117.86483219219372 Scheduler overhead time: 0.08142123883590102 Adapter cache time: 0.016721089836210012 Engine time: 0.08019925886765122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 123.25788271101192,
    "estimated_duration": 3600.002117896949,
    "input_throughput": 8314.781497263788,
    "output_throughput": 7334.27096299164,
    "total_throughput": 15649.052460255427,
    "itl": 109.91865873375133,
    "ttft": 1779851.4333461004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5600692571396932,
    "arrivals": 554568,
    "finished_requests": 120821,
    "scheduler_time": 243.79592367183466
}
#Debug simulation 
Total elapsed time: 123.25805916823447. Arrivals time: 0.5961148026399314 Scheduler time: 122.44714279752225 Scheduler overhead time: 0.0843993448652327 Adapter cache time: 0.01691215392202139 Engine time: 0.08205747092142701 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 123.24747151788324,
    "estimated_duration": 3600.0352952736266,
    "input_throughput": 8314.704869504585,
    "output_throughput": 7334.203371468103,
    "total_throughput": 15648.908240972689,
    "itl": 109.91912490565679,
    "ttft": 1779865.1696863293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5929418796324182,
    "arrivals": 554568,
    "finished_requests": 120821,
    "scheduler_time": 243.79624652840073
}
#Debug simulation 
Total elapsed time: 123.24764380278066. Arrivals time: 0.5934312916360795 Scheduler time: 122.44015188934281 Scheduler overhead time: 0.08332638815045357 Adapter cache time: 0.01688529271632433 Engine time: 0.08239393215626478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 123.09017476206645,
    "estimated_duration": 3600.037158243849,
    "input_throughput": 8314.700566758003,
    "output_throughput": 7334.199576117699,
    "total_throughput": 15648.900142875702,
    "itl": 109.9191027164733,
    "ttft": 1779866.0891194467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5947356687113665,
    "arrivals": 554568,
    "finished_requests": 120821,
    "scheduler_time": 243.79631570953975
}
#Debug simulation 
Total elapsed time: 123.09034901298583. Arrivals time: 0.6162089686840773 Scheduler time: 122.26031015114859 Scheduler overhead time: 0.08298310404643416 Adapter cache time: 0.01677439734339714 Engine time: 0.08217151835560799 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 123.05477901082486,
    "estimated_duration": 3600.012251944585,
    "input_throughput": 8314.758091123509,
    "output_throughput": 7334.250316992096,
    "total_throughput": 15649.008408115604,
    "itl": 109.91874300281246,
    "ttft": 1779856.0678179322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5696519464813179,
    "arrivals": 554568,
    "finished_requests": 120821,
    "scheduler_time": 243.79609297818146
}
#Debug simulation 
Total elapsed time: 123.05494333896786. Arrivals time: 0.5893048956058919 Scheduler time: 122.25148115772754 Scheduler overhead time: 0.08399217296391726 Adapter cache time: 0.016846293583512306 Engine time: 0.08164842054247856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 121.45802962779999,
    "estimated_duration": 3600.0443779918573,
    "input_throughput": 8314.683891951652,
    "output_throughput": 7334.184867667684,
    "total_throughput": 15648.868759619336,
    "itl": 109.91921354118291,
    "ttft": 1779868.9960748476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6019036345370131,
    "arrivals": 554568,
    "finished_requests": 120821,
    "scheduler_time": 243.79636749172735
}
#Debug simulation 
Total elapsed time: 121.45819486305118. Arrivals time: 0.5913839899003506 Scheduler time: 120.65539555856958 Scheduler overhead time: 0.0813845475204289 Adapter cache time: 0.016937997192144394 Engine time: 0.08208824461326003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 126.76779817091301,
    "estimated_duration": 3600.0591948876167,
    "input_throughput": 8275.451148777574,
    "output_throughput": 7296.567244589436,
    "total_throughput": 15572.01839336701,
    "itl": 109.84007817793879,
    "ttft": 1783665.0705131742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48438814777415307,
    "arrivals": 554568,
    "finished_requests": 120293,
    "scheduler_time": 245.5362435696622
}
#Debug simulation 
Total elapsed time: 126.76797478599474. Arrivals time: 0.8614551713690162 Scheduler time: 125.69272860139608 Scheduler overhead time: 0.08326855255290866 Adapter cache time: 0.016772961243987083 Engine time: 0.08302686735987663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 135, 34560, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 135, 34560, 17280, 135, 135, 17280, 34560, 135, 17280, 135, 135, 17280, 17280, 17280, 135, 135, 34560, 17280, 17280, 135, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 135, 34560, 17280, 17280, 17280, 34560, 34560, 135, 135, 17280, 135, 34560, 135, 135, 34560, 135, 17280, 17280, 135, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 135, 135, 34560, 17280, 34560, 135, 17280, 34560, 135, 34560, 17280, 135, 34560, 135, 135, 34560, 135, 135, 17280]
Prompts retrieved: 1663200 . Total input tokens: 371069728 . Total output tokens: 332471114
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 119.52677895408124,
    "estimated_duration": 3600.051452564147,
    "input_throughput": 8314.667552509554,
    "output_throughput": 7334.170455034499,
    "total_throughput": 15648.838007544053,
    "itl": 109.91934385929444,
    "ttft": 1779872.1202707586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6088200927898298,
    "arrivals": 554568,
    "finished_requests": 120821,
    "scheduler_time": 243.7964255671875
}
#Debug simulation 
Total elapsed time: 119.52694202587008. Arrivals time: 0.5169577491469681 Scheduler time: 118.80942576797679 Scheduler overhead time: 0.07822162378579378 Adapter cache time: 0.015325949061661959 Engine time: 0.07778012845665216 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 109.99690556200221,
    "estimated_duration": 3600.027435750646,
    "input_throughput": 8312.12387517834,
    "output_throughput": 7397.801676599409,
    "total_throughput": 15709.92555177775,
    "itl": 111.3632856064572,
    "ttft": 1770811.6474364693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 175,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5355853551882312,
    "arrivals": 553859,
    "finished_requests": 120796,
    "scheduler_time": 242.17160375172992
}
#Debug simulation 
Total elapsed time: 109.99707372114062. Arrivals time: 0.4600749211385846 Scheduler time: 109.34561267448589 Scheduler overhead time: 0.0750342020764947 Adapter cache time: 0.014347574207931757 Engine time: 0.073707171715796 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 107.14892241824418,
    "estimated_duration": 3600.1030935347626,
    "input_throughput": 8306.066305073511,
    "output_throughput": 7369.252854909619,
    "total_throughput": 15675.31915998313,
    "itl": 111.34482122620908,
    "ttft": 1779247.5052028745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5953934515430603,
    "arrivals": 553859,
    "finished_requests": 120636,
    "scheduler_time": 242.16562766334218
}
#Debug simulation 
Total elapsed time: 107.14908641623333. Arrivals time: 0.4754746030084789 Scheduler time: 106.48206032346934 Scheduler overhead time: 0.0746330595575273 Adapter cache time: 0.014370526652783155 Engine time: 0.07385944435372949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 107.38047508522868,
    "estimated_duration": 3600.1051278819286,
    "input_throughput": 8306.061611482115,
    "output_throughput": 7369.248690692706,
    "total_throughput": 15675.310302174821,
    "itl": 111.34484609114837,
    "ttft": 1779248.7959727298,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5967591536790157,
    "arrivals": 553859,
    "finished_requests": 120636,
    "scheduler_time": 242.1656960768829
}
#Debug simulation 
Total elapsed time: 107.38063940638676. Arrivals time: 0.47787901712581515 Scheduler time: 106.711697622668 Scheduler overhead time: 0.0747900023125112 Adapter cache time: 0.01445096218958497 Engine time: 0.07319966098293662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 112.28154914779589,
    "estimated_duration": 3600.071100665259,
    "input_throughput": 8315.060498240808,
    "output_throughput": 7388.35213423558,
    "total_throughput": 15703.412632476387,
    "itl": 111.4144371365007,
    "ttft": 1772677.0231776573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 171,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5333627476240514,
    "arrivals": 553859,
    "finished_requests": 120817,
    "scheduler_time": 241.74683350747696
}
#Debug simulation 
Total elapsed time: 112.28170777997002. Arrivals time: 0.48102467879652977 Scheduler time: 111.6074720704928 Scheduler overhead time: 0.07565906690433621 Adapter cache time: 0.014438406564295292 Engine time: 0.07420625258237123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 106.81083331396803,
    "estimated_duration": 3600.111508786255,
    "input_throughput": 8306.046889664654,
    "output_throughput": 7369.235629299819,
    "total_throughput": 15675.282518964474,
    "itl": 111.34492413990368,
    "ttft": 1779251.5194441527,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6035498581454174,
    "arrivals": 553859,
    "finished_requests": 120636,
    "scheduler_time": 242.16578646965075
}
#Debug simulation 
Total elapsed time: 106.81099811568856. Arrivals time: 0.5318758338689804 Scheduler time: 106.08750057639554 Scheduler overhead time: 0.07552777975797653 Adapter cache time: 0.014221187680959702 Engine time: 0.07331756595522165 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 110.02869126712903,
    "estimated_duration": 3600.0152785796136,
    "input_throughput": 8312.151945034651,
    "output_throughput": 7397.826658810119,
    "total_throughput": 15709.978603844771,
    "itl": 111.36324950325981,
    "ttft": 1770806.2172130074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 175,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5232588016078814,
    "arrivals": 553859,
    "finished_requests": 120796,
    "scheduler_time": 242.17147301850895
}
#Debug simulation 
Total elapsed time: 110.02885427884758. Arrivals time: 0.4746426912024617 Scheduler time: 109.36199471494183 Scheduler overhead time: 0.0751105579547584 Adapter cache time: 0.01462926296517253 Engine time: 0.07371034054085612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 66, 34560, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 66, 34560, 17280, 66, 66, 17280, 34560, 66, 17280, 66, 66, 17280, 17280, 17280, 66, 66, 34560, 17280, 17280, 66, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 66, 34560, 17280, 17280, 17280, 34560, 34560, 66, 66, 17280, 66, 34560, 66, 66, 34560, 66, 17280, 17280, 66, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 66, 66, 34560, 17280, 34560, 66, 17280, 34560, 66, 34560, 17280, 66, 34560, 66, 66, 34560, 66, 66, 17280]
Prompts retrieved: 1660992 . Total input tokens: 370572591 . Total output tokens: 332033415
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 107.20489153219387,
    "estimated_duration": 3600.1201810969455,
    "input_throughput": 8306.026881271708,
    "output_throughput": 7369.217877586622,
    "total_throughput": 15675.24475885833,
    "itl": 111.34504855449069,
    "ttft": 1779255.5778056523,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 183,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6115981004759681,
    "arrivals": 553859,
    "finished_requests": 120636,
    "scheduler_time": 242.16591034511515
}
#Debug simulation 
Total elapsed time: 107.2050620620139. Arrivals time: 0.47992815310135484 Scheduler time: 106.53436205396429 Scheduler overhead time: 0.07419109018519521 Adapter cache time: 0.014110775664448738 Engine time: 0.07387110078707337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 104.20905423583463,
    "estimated_duration": 3600.0184684791034,
    "input_throughput": 8366.545134065562,
    "output_throughput": 7384.306561969047,
    "total_throughput": 15750.85169603461,
    "itl": 110.41461955353908,
    "ttft": 1777840.7256699598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.550887793907895,
    "arrivals": 553508,
    "finished_requests": 121469,
    "scheduler_time": 241.6995388140549
}
#Debug simulation 
Total elapsed time: 104.20918783219531. Arrivals time: 0.4912670128978789 Scheduler time: 103.52745185699314 Scheduler overhead time: 0.07435297919437289 Adapter cache time: 0.014248174149543047 Engine time: 0.07357226544991136 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 104.58394593186677,
    "estimated_duration": 3600.0542316557803,
    "input_throughput": 8366.462020253228,
    "output_throughput": 7384.233205779607,
    "total_throughput": 15750.695226032834,
    "itl": 110.41548533769004,
    "ttft": 1777855.661895131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.585606110021473,
    "arrivals": 553508,
    "finished_requests": 121469,
    "scheduler_time": 241.69988340454373
}
#Debug simulation 
Total elapsed time: 104.58408147701994. Arrivals time: 0.4961767219938338 Scheduler time: 103.89580450253561 Scheduler overhead time: 0.0750154578126967 Adapter cache time: 0.014052041340619326 Engine time: 0.07426161644980311 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 104.63121665176004,
    "estimated_duration": 3600.0561575636884,
    "input_throughput": 8366.457544479888,
    "output_throughput": 7384.22925546536,
    "total_throughput": 15750.686799945248,
    "itl": 110.41549626584532,
    "ttft": 1777856.8176583939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5869541021436476,
    "arrivals": 553508,
    "finished_requests": 121469,
    "scheduler_time": 241.69996112741978
}
#Debug simulation 
Total elapsed time: 104.63135508168489. Arrivals time: 0.4930436545982957 Scheduler time: 103.94729922711849 Scheduler overhead time: 0.07466153427958488 Adapter cache time: 0.014486391562968493 Engine time: 0.07342793326824903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 104.27601310564205,
    "estimated_duration": 3600.031832071524,
    "input_throughput": 8366.514076812638,
    "output_throughput": 7384.279150860532,
    "total_throughput": 15750.79322767317,
    "itl": 110.41490691382823,
    "ttft": 1777846.0888473243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5639505581441343,
    "arrivals": 553508,
    "finished_requests": 121469,
    "scheduler_time": 241.6997396036404
}
#Debug simulation 
Total elapsed time: 104.27614532969892. Arrivals time: 0.4903161213733256 Scheduler time: 103.59468258125708 Scheduler overhead time: 0.07539508258923888 Adapter cache time: 0.013816990423947573 Engine time: 0.07364727696403861 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 104.50793093908578,
    "estimated_duration": 3600.0620719594326,
    "input_throughput": 8366.443799566632,
    "output_throughput": 7384.2171242150625,
    "total_throughput": 15750.660923781696,
    "itl": 110.41562077255324,
    "ttft": 1777858.9624157308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5936190528236346,
    "arrivals": 553508,
    "finished_requests": 121469,
    "scheduler_time": 241.70001088113318
}
#Debug simulation 
Total elapsed time: 104.50806514685974. Arrivals time: 0.49299193918704987 Scheduler time: 103.82485398976132 Scheduler overhead time: 0.07419977756217122 Adapter cache time: 0.014135058503597975 Engine time: 0.07331552868708968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 104.75101441005245,
    "estimated_duration": 3600.005991035606,
    "input_throughput": 8366.574132099022,
    "output_throughput": 7384.332155611981,
    "total_throughput": 15750.906287711003,
    "itl": 110.41434249817486,
    "ttft": 1777835.4528065138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5382090530823923,
    "arrivals": 553508,
    "finished_requests": 121469,
    "scheduler_time": 241.69943999561536
}
#Debug simulation 
Total elapsed time: 104.75114991841838. Arrivals time: 0.49916212260723114 Scheduler time: 104.06074283597991 Scheduler overhead time: 0.07472398644313216 Adapter cache time: 0.014147386886179447 Engine time: 0.07356557296589017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_96_slots_16_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 17280, 34560, 17280, 17280, 17280, 17280, 34560, 17280, 34560, 17280, 33, 34560, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 17280, 33, 34560, 17280, 33, 33, 17280, 34560, 33, 17280, 33, 33, 17280, 17280, 17280, 33, 33, 34560, 17280, 17280, 33, 34560, 34560, 17280, 34560, 34560, 17280, 34560, 33, 34560, 17280, 17280, 17280, 34560, 34560, 33, 33, 17280, 33, 34560, 33, 33, 34560, 33, 17280, 17280, 33, 17280, 34560, 34560, 34560, 17280, 34560, 34560, 33, 33, 34560, 17280, 34560, 33, 17280, 34560, 33, 34560, 17280, 33, 34560, 33, 33, 34560, 33, 33, 17280]
Prompts retrieved: 1659936 . Total input tokens: 370337047 . Total output tokens: 331827132
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 104.62089818716049,
    "estimated_duration": 3600.069645287658,
    "input_throughput": 8366.426199400186,
    "output_throughput": 7384.201590321143,
    "total_throughput": 15750.62778972133,
    "itl": 110.41577092606877,
    "ttft": 1777861.9414247617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6015415413677702,
    "arrivals": 553508,
    "finished_requests": 121469,
    "scheduler_time": 241.70006187514417
}
#Debug simulation 
Total elapsed time: 104.62103454302996. Arrivals time: 0.5496715204790235 Scheduler time: 103.88142881216481 Scheduler overhead time: 0.07451905636116862 Adapter cache time: 0.01414634520187974 Engine time: 0.07331364555284381 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 112.97160309879109,
    "estimated_duration": 3600.0489777150433,
    "input_throughput": 8226.97085049056,
    "output_throughput": 7268.386947504239,
    "total_throughput": 15495.357797994799,
    "itl": 106.99306650597504,
    "ttft": 1763414.9499042756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.661065352689474,
    "arrivals": 507133,
    "finished_requests": 119675,
    "scheduler_time": 245.92444448402983
}
#Debug simulation 
Total elapsed time: 112.97173289116472. Arrivals time: 0.511608088389039 Scheduler time: 112.26061980705708 Scheduler overhead time: 0.07828084100037813 Adapter cache time: 0.014915500301867723 Engine time: 0.07607709849253297 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 123.11621866934001,
    "estimated_duration": 3600.0793353848967,
    "input_throughput": 8238.832324740672,
    "output_throughput": 7293.853983135241,
    "total_throughput": 15532.686307875912,
    "itl": 107.22481918895276,
    "ttft": 1752952.8169872481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6595591228781287,
    "arrivals": 507133,
    "finished_requests": 119984,
    "scheduler_time": 244.8014856979232
}
#Debug simulation 
Total elapsed time: 123.11635001422837. Arrivals time: 0.5688798646442592 Scheduler time: 122.34516215603799 Scheduler overhead time: 0.07992231100797653 Adapter cache time: 0.015601437538862228 Engine time: 0.07694475119933486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 123.21230621216819,
    "estimated_duration": 3600.081124584846,
    "input_throughput": 8238.828230133393,
    "output_throughput": 7293.850358171601,
    "total_throughput": 15532.678588304994,
    "itl": 107.22485769432863,
    "ttft": 1752953.9291217348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.66065646670759,
    "arrivals": 507133,
    "finished_requests": 119984,
    "scheduler_time": 244.8015773225506
}
#Debug simulation 
Total elapsed time: 123.2124319979921. Arrivals time: 0.5751340277493 Scheduler time: 122.4354269397445 Scheduler overhead time: 0.07958900462836027 Adapter cache time: 0.015180089510977268 Engine time: 0.07754385424777865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 113.50378292193636,
    "estimated_duration": 3600.062056918252,
    "input_throughput": 8226.940961499247,
    "output_throughput": 7268.360541095576,
    "total_throughput": 15495.301502594823,
    "itl": 106.99350984515941,
    "ttft": 1763419.4002211893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6740439406712556,
    "arrivals": 507133,
    "finished_requests": 119675,
    "scheduler_time": 245.9244450606541
}
#Debug simulation 
Total elapsed time: 113.50391238881275. Arrivals time: 0.5526711507700384 Scheduler time: 112.74903015512973 Scheduler overhead time: 0.07891865773126483 Adapter cache time: 0.016036806628108025 Engine time: 0.07715371530503035 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 122.86162805231288,
    "estimated_duration": 3600.0008728232315,
    "input_throughput": 8238.782446944244,
    "output_throughput": 7293.841009379478,
    "total_throughput": 15532.623456323723,
    "itl": 107.22479409055606,
    "ttft": 1752970.4060676792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6694592317566298,
    "arrivals": 507133,
    "finished_requests": 119982,
    "scheduler_time": 244.79484586469582
}
#Debug simulation 
Total elapsed time: 122.86175574827939. Arrivals time: 0.563823277130723 Scheduler time: 122.09396043466404 Scheduler overhead time: 0.08001224976032972 Adapter cache time: 0.015416927170008421 Engine time: 0.07833239389583468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 112.64066945808008,
    "estimated_duration": 3600.0326214422885,
    "input_throughput": 8227.008228646073,
    "output_throughput": 7268.419970460391,
    "total_throughput": 15495.428199106464,
    "itl": 106.99270415277287,
    "ttft": 1763407.8489367426,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6458508636988708,
    "arrivals": 507133,
    "finished_requests": 119675,
    "scheduler_time": 245.92410300887605
}
#Debug simulation 
Total elapsed time: 112.64080700464547. Arrivals time: 0.5447567766532302 Scheduler time: 111.89531082194299 Scheduler overhead time: 0.07901796326041222 Adapter cache time: 0.015602658037096262 Engine time: 0.076586389914155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [4320, 4320, 4320, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 4320, 34560, 8640, 4320, 4320, 8640, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 4320, 4320, 34560, 8640, 8640, 4320, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 4320, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 4320, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 4320, 8640, 34560, 4320, 34560, 8640, 4320, 34560, 4320, 4320, 34560, 4320, 4320, 8640]
Prompts retrieved: 1520640 . Total input tokens: 339170557 . Total output tokens: 304105255
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 123.59476380608976,
    "estimated_duration": 3600.0089229037885,
    "input_throughput": 8238.764023972577,
    "output_throughput": 7293.824699417766,
    "total_throughput": 15532.588723390343,
    "itl": 107.22499151586494,
    "ttft": 1752973.3356321836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 202,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6777589816600103,
    "arrivals": 507133,
    "finished_requests": 119982,
    "scheduler_time": 244.79489631109885
}
#Debug simulation 
Total elapsed time: 123.59489013720304. Arrivals time: 0.560608312021941 Scheduler time: 122.83180060843006 Scheduler overhead time: 0.0801096954382956 Adapter cache time: 0.015311697963625193 Engine time: 0.07723456854000688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 111.90813291911036,
    "estimated_duration": 3600.038810965109,
    "input_throughput": 8302.291605569491,
    "output_throughput": 7364.925877810757,
    "total_throughput": 15667.21748338025,
    "itl": 109.74223327375752,
    "ttft": 1718620.9142255683,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5661902326275587,
    "arrivals": 472666,
    "finished_requests": 120635,
    "scheduler_time": 243.35268636119613
}
#Debug simulation 
Total elapsed time: 111.90826033893973. Arrivals time: 0.5003899782896042 Scheduler time: 111.21154853934422 Scheduler overhead time: 0.07682170206680894 Adapter cache time: 0.01465570880100131 Engine time: 0.07573862466961145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 115.58832737104967,
    "estimated_duration": 3600.0119100518514,
    "input_throughput": 8332.475488829134,
    "output_throughput": 7378.456978387446,
    "total_throughput": 15710.932467216579,
    "itl": 110.66704793384174,
    "ttft": 1721581.8933237093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5788088187947878,
    "arrivals": 472666,
    "finished_requests": 121068,
    "scheduler_time": 241.49612494339118
}
#Debug simulation 
Total elapsed time: 115.58846083795652. Arrivals time: 0.5064629022963345 Scheduler time: 114.88654998457059 Scheduler overhead time: 0.0761545761488378 Adapter cache time: 0.015332470647990704 Engine time: 0.07481691846624017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 114.77498160302639,
    "estimated_duration": 3600.0132054172245,
    "input_throughput": 8332.472490617847,
    "output_throughput": 7378.454323453385,
    "total_throughput": 15710.926814071232,
    "itl": 110.66706957846229,
    "ttft": 1721582.4780354355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5801925694569967,
    "arrivals": 472666,
    "finished_requests": 121068,
    "scheduler_time": 241.496136596678
}
#Debug simulation 
Total elapsed time: 114.77511838916689. Arrivals time: 0.5551992473192513 Scheduler time: 114.02323124790564 Scheduler overhead time: 0.0773932277224958 Adapter cache time: 0.015355963725596666 Engine time: 0.07464702241122723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 115.30679376097396,
    "estimated_duration": 3600.114340780729,
    "input_throughput": 8332.490626810088,
    "output_throughput": 7378.541758826293,
    "total_throughput": 15711.03238563638,
    "itl": 110.66656737801074,
    "ttft": 1721614.0434676337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5555188856436876,
    "arrivals": 472666,
    "finished_requests": 121073,
    "scheduler_time": 241.50430895632968
}
#Debug simulation 
Total elapsed time: 115.30693246098235. Arrivals time: 0.5051592662930489 Scheduler time: 114.60501120099798 Scheduler overhead time: 0.07776716817170382 Adapter cache time: 0.015490602236241102 Engine time: 0.07446108106523752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 115.21070944191888,
    "estimated_duration": 3600.021154719665,
    "input_throughput": 8332.454091463771,
    "output_throughput": 7378.438030892192,
    "total_throughput": 15710.892122355963,
    "itl": 110.66727148465931,
    "ttft": 1721585.8993453376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5873605352826433,
    "arrivals": 472666,
    "finished_requests": 121068,
    "scheduler_time": 241.49621766323452
}
#Debug simulation 
Total elapsed time: 115.21084962412715. Arrivals time: 0.5142310704104602 Scheduler time: 114.49991339677945 Scheduler overhead time: 0.07779402751475573 Adapter cache time: 0.014884319622069597 Engine time: 0.07494288962334394 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 112.0504442602396,
    "estimated_duration": 3600.026270203137,
    "input_throughput": 8302.320526764794,
    "output_throughput": 7364.9515336742,
    "total_throughput": 15667.272060438992,
    "itl": 109.7419819229168,
    "ttft": 1718615.8058038603,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 185,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5531593045569032,
    "arrivals": 472666,
    "finished_requests": 120635,
    "scheduler_time": 243.35257629578132
}
#Debug simulation 
Total elapsed time: 112.05057146400213. Arrivals time: 0.49413042794913054 Scheduler time: 111.36076856125146 Scheduler overhead time: 0.07706161309033632 Adapter cache time: 0.014635205268859863 Engine time: 0.07494393549859524 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 1080, 34560, 8640, 1080, 1080, 8640, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 1080, 1080, 34560, 8640, 8640, 1080, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 1080, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 1080, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 1080, 8640, 34560, 1080, 34560, 8640, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 8640]
Prompts retrieved: 1416960 . Total input tokens: 316002805 . Total output tokens: 283393833
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 115.1316089630127,
    "estimated_duration": 3600.027804574621,
    "input_throughput": 8332.438700023997,
    "output_throughput": 7378.4244016800385,
    "total_throughput": 15710.863101704037,
    "itl": 110.66736137460911,
    "ttft": 1721588.658917317,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 178,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5945285011082897,
    "arrivals": 472666,
    "finished_requests": 121068,
    "scheduler_time": 241.4962997838502
}
#Debug simulation 
Total elapsed time: 115.13174695475027. Arrivals time: 0.5023681079037488 Scheduler time: 114.4348514568992 Scheduler overhead time: 0.07635459117591381 Adapter cache time: 0.015275026205927134 Engine time: 0.07424729783087969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 116.90009285276756,
    "estimated_duration": 3600.0147142950923,
    "input_throughput": 8255.043203571751,
    "output_throughput": 7352.314671075644,
    "total_throughput": 15607.357874647394,
    "itl": 109.40369687766376,
    "ttft": 1706864.2846268294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4957990145171055,
    "arrivals": 466828,
    "finished_requests": 120209,
    "scheduler_time": 243.62565365941913
}
#Debug simulation 
Total elapsed time: 116.90023440308869. Arrivals time: 0.5061301970854402 Scheduler time: 116.1976415598765 Scheduler overhead time: 0.0774235688149929 Adapter cache time: 0.014951382298022509 Engine time: 0.07492289412766695 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 119.24853104911745,
    "estimated_duration": 3600.02393364267,
    "input_throughput": 8279.887731146027,
    "output_throughput": 7359.846903348364,
    "total_throughput": 15639.73463449439,
    "itl": 110.04708204107466,
    "ttft": 1709633.640677806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5162775287334808,
    "arrivals": 466828,
    "finished_requests": 120593,
    "scheduler_time": 242.30684021329552
}
#Debug simulation 
Total elapsed time: 119.24865717301145. Arrivals time: 0.5101488591171801 Scheduler time: 118.54280304396525 Scheduler overhead time: 0.07681401632726192 Adapter cache time: 0.014823023695498705 Engine time: 0.07493182038888335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 119.42736615100875,
    "estimated_duration": 3600.0248144427046,
    "input_throughput": 8279.885705347378,
    "output_throughput": 7359.845102651496,
    "total_throughput": 15639.730807998874,
    "itl": 110.04708785619472,
    "ttft": 1709633.72191547,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5176442464068549,
    "arrivals": 466828,
    "finished_requests": 120593,
    "scheduler_time": 242.30685448855684
}
#Debug simulation 
Total elapsed time: 119.42749120201916. Arrivals time: 0.5154695841483772 Scheduler time: 118.71438286919147 Scheduler overhead time: 0.07736939750611782 Adapter cache time: 0.014711725059896708 Engine time: 0.07558700535446405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 117.34025585092604,
    "estimated_duration": 3600.0813326858397,
    "input_throughput": 8245.983147789779,
    "output_throughput": 7339.278632432416,
    "total_throughput": 15585.261780222194,
    "itl": 109.09940877269985,
    "ttft": 1707979.2074111677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 161,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5046880306303505,
    "arrivals": 466828,
    "finished_requests": 120075,
    "scheduler_time": 244.19393420364895
}
#Debug simulation 
Total elapsed time: 117.34039747202769. Arrivals time: 0.5080351452343166 Scheduler time: 116.63518902938813 Scheduler overhead time: 0.07734735263511539 Adapter cache time: 0.01447708485648036 Engine time: 0.07516985852271318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 118.80720338784158,
    "estimated_duration": 3600.0312459792403,
    "input_throughput": 8279.870913145927,
    "output_throughput": 7359.831954123208,
    "total_throughput": 15639.702867269134,
    "itl": 110.04721771552926,
    "ttft": 1709636.7148646212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.523931935727597,
    "arrivals": 466828,
    "finished_requests": 120593,
    "scheduler_time": 242.30689829719367
}
#Debug simulation 
Total elapsed time: 118.80733502283692. Arrivals time: 0.518668198492378 Scheduler time: 118.09024719148874 Scheduler overhead time: 0.07839969452470541 Adapter cache time: 0.015186951030045748 Engine time: 0.07532183872535825 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 117.35839725239202,
    "estimated_duration": 3600.002965151313,
    "input_throughput": 8255.070145129977,
    "output_throughput": 7352.338666445375,
    "total_throughput": 15607.408811575351,
    "itl": 109.40403312347269,
    "ttft": 1706859.5972408361,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 162,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48438814777415307,
    "arrivals": 466828,
    "finished_requests": 120209,
    "scheduler_time": 243.6254154209399
}
#Debug simulation 
Total elapsed time: 117.35853375634179. Arrivals time: 0.49980983044952154 Scheduler time: 116.6620853706263 Scheduler overhead time: 0.07713039731606841 Adapter cache time: 0.015130573883652687 Engine time: 0.07426344091072679 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 540, 34560, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 540, 34560, 8640, 540, 540, 8640, 34560, 540, 8640, 540, 540, 8640, 8640, 8640, 540, 540, 34560, 8640, 8640, 540, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 540, 34560, 8640, 8640, 8640, 34560, 34560, 540, 540, 8640, 540, 34560, 540, 540, 34560, 540, 8640, 8640, 540, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 540, 540, 34560, 8640, 34560, 540, 8640, 34560, 540, 34560, 8640, 540, 34560, 540, 540, 34560, 540, 540, 8640]
Prompts retrieved: 1399680 . Total input tokens: 312160527 . Total output tokens: 279955315
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 119.00198736414313,
    "estimated_duration": 3600.0367202833754,
    "input_throughput": 8279.858322571135,
    "output_throughput": 7359.820762582224,
    "total_throughput": 15639.679085153359,
    "itl": 110.04727057139175,
    "ttft": 1709638.9101935977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 159,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5302196250483393,
    "arrivals": 466828,
    "finished_requests": 120593,
    "scheduler_time": 242.306985259232
}
#Debug simulation 
Total elapsed time: 119.0021234578453. Arrivals time: 0.5190448267385364 Scheduler time: 118.28514861362055 Scheduler overhead time: 0.07835469953715801 Adapter cache time: 0.015181981958448887 Engine time: 0.07531549921259284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 115.23412784188986,
    "estimated_duration": 3600.0541513762955,
    "input_throughput": 8329.639982925244,
    "output_throughput": 7383.600602184826,
    "total_throughput": 15713.24058511007,
    "itl": 111.06733144862127,
    "ttft": 1712310.1756612994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.49885950226103826,
    "arrivals": 463915,
    "finished_requests": 121326,
    "scheduler_time": 241.1072687904938
}
#Debug simulation 
Total elapsed time: 115.23425559699535. Arrivals time: 0.5369197796098888 Scheduler time: 114.5024745836854 Scheduler overhead time: 0.07644253922626376 Adapter cache time: 0.014567838050425053 Engine time: 0.07416774798184633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 111.70531194191426,
    "estimated_duration": 3600.061168208716,
    "input_throughput": 8290.393858738364,
    "output_throughput": 7372.307791427304,
    "total_throughput": 15662.701650165669,
    "itl": 110.90823157602922,
    "ttft": 1708589.0202344013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5392508573899982,
    "arrivals": 463915,
    "finished_requests": 120829,
    "scheduler_time": 243.00306984661572
}
#Debug simulation 
Total elapsed time: 111.70544250309467. Arrivals time: 0.5024432125501335 Scheduler time: 111.00722133507952 Scheduler overhead time: 0.07655174052342772 Adapter cache time: 0.014828072860836983 Engine time: 0.07487817481160164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 111.97370123676956,
    "estimated_duration": 3600.0630106014437,
    "input_throughput": 8290.389615990027,
    "output_throughput": 7372.304018524936,
    "total_throughput": 15662.69363451496,
    "itl": 110.90825479092813,
    "ttft": 1708589.9623948103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5406351158209164,
    "arrivals": 463915,
    "finished_requests": 120829,
    "scheduler_time": 243.00312782658887
}
#Debug simulation 
Total elapsed time: 111.97383352508768. Arrivals time: 0.4956243201158941 Scheduler time: 111.2844855915755 Scheduler overhead time: 0.07624026294797659 Adapter cache time: 0.014988525304943323 Engine time: 0.07364765368402004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 115.54939689068124,
    "estimated_duration": 3600.067356355181,
    "input_throughput": 8329.609429963533,
    "output_throughput": 7383.573519277647,
    "total_throughput": 15713.18294924118,
    "itl": 111.06755589922676,
    "ttft": 1712316.2225151705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5102595359017145,
    "arrivals": 463915,
    "finished_requests": 121326,
    "scheduler_time": 241.1074731184361
}
#Debug simulation 
Total elapsed time: 115.54953332198784. Arrivals time: 0.4975693840533495 Scheduler time: 114.8571857814677 Scheduler overhead time: 0.07682341290637851 Adapter cache time: 0.014876625034958124 Engine time: 0.0743422880768776 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 111.27634067507461,
    "estimated_duration": 3600.030292888778,
    "input_throughput": 8272.790387022478,
    "output_throughput": 7340.1426794095,
    "total_throughput": 15612.933066431977,
    "itl": 110.74366677048367,
    "ttft": 1708079.025306263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5741347035393131,
    "arrivals": 463915,
    "finished_requests": 120518,
    "scheduler_time": 243.16892751803317
}
#Debug simulation 
Total elapsed time: 111.27646392770112. Arrivals time: 0.4999760687351227 Scheduler time: 110.57912183832377 Scheduler overhead time: 0.0774549376219511 Adapter cache time: 0.015022092498838902 Engine time: 0.0752949551679194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 115.35737378103659,
    "estimated_duration": 3600.042283854996,
    "input_throughput": 8329.667441541593,
    "output_throughput": 7383.624942187111,
    "total_throughput": 15713.292383728703,
    "itl": 111.0667545033215,
    "ttft": 1712304.9292636975,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 163,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48737819806905525,
    "arrivals": 463915,
    "finished_requests": 121326,
    "scheduler_time": 241.10688257336184
}
#Debug simulation 
Total elapsed time: 115.3575030057691. Arrivals time: 0.5452177571132779 Scheduler time: 114.61664007557556 Scheduler overhead time: 0.07659588241949677 Adapter cache time: 0.014511295594274998 Engine time: 0.07509486610069871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 270, 34560, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 270, 34560, 8640, 270, 270, 8640, 34560, 270, 8640, 270, 270, 8640, 8640, 8640, 270, 270, 34560, 8640, 8640, 270, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 270, 34560, 8640, 8640, 8640, 34560, 34560, 270, 270, 8640, 270, 34560, 270, 270, 34560, 270, 8640, 8640, 270, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 270, 270, 34560, 8640, 34560, 270, 8640, 34560, 270, 34560, 8640, 270, 34560, 270, 270, 34560, 270, 270, 8640]
Prompts retrieved: 1391040 . Total input tokens: 310246563 . Total output tokens: 278256734
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 111.35438491171226,
    "estimated_duration": 3600.0374802966885,
    "input_throughput": 8272.773870550249,
    "output_throughput": 7340.128024951082,
    "total_throughput": 15612.90189550133,
    "itl": 110.74373278025101,
    "ttft": 1708081.9200581955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5814284231513744,
    "arrivals": 463915,
    "finished_requests": 120518,
    "scheduler_time": 243.16902128349773
}
#Debug simulation 
Total elapsed time: 111.3545163529925. Arrivals time: 0.5028433045372367 Scheduler time: 110.65487280953676 Scheduler overhead time: 0.07764001190662384 Adapter cache time: 0.014923295937478542 Engine time: 0.07511807465925813 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 112.66327184205875,
    "estimated_duration": 3600.0920430488245,
    "input_throughput": 8347.512963737976,
    "output_throughput": 7396.449224517472,
    "total_throughput": 15743.96218825545,
    "itl": 110.64457970300171,
    "ttft": 1706553.1015277097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5294643797003658,
    "arrivals": 462529,
    "finished_requests": 121621,
    "scheduler_time": 241.07701515561945
}
#Debug simulation 
Total elapsed time: 112.66340305004269. Arrivals time: 0.5059333043172956 Scheduler time: 111.96047991607338 Scheduler overhead time: 0.07780394703149796 Adapter cache time: 0.014711538795381784 Engine time: 0.07567843608558178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 113.41742673283443,
    "estimated_duration": 3600.1028183112644,
    "input_throughput": 8259.13550267642,
    "output_throughput": 7319.052074284908,
    "total_throughput": 15578.187576961327,
    "itl": 109.75177867393438,
    "ttft": 1706183.051099721,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5052644012565725,
    "arrivals": 462529,
    "finished_requests": 120376,
    "scheduler_time": 244.17845033553388
}
#Debug simulation 
Total elapsed time: 113.41756996512413. Arrivals time: 0.49933281587436795 Scheduler time: 112.72105180332437 Scheduler overhead time: 0.07782323425635695 Adapter cache time: 0.014978935942053795 Engine time: 0.07522654579952359 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 113.23409967124462,
    "estimated_duration": 3600.10479053917,
    "input_throughput": 8259.130978114368,
    "output_throughput": 7319.04806472419,
    "total_throughput": 15578.17904283856,
    "itl": 109.75183370260889,
    "ttft": 1706184.0327238245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5068274523876624,
    "arrivals": 462529,
    "finished_requests": 120376,
    "scheduler_time": 244.17855939656698
}
#Debug simulation 
Total elapsed time: 113.23422994604334. Arrivals time: 0.4967302647419274 Scheduler time: 112.53878633212298 Scheduler overhead time: 0.07846140721812844 Adapter cache time: 0.015190073754638433 Engine time: 0.07594837062060833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 119.26265827007592,
    "estimated_duration": 3600.0029055567443,
    "input_throughput": 8290.31664222627,
    "output_throughput": 7342.614351560375,
    "total_throughput": 15632.930993786644,
    "itl": 110.1291548005455,
    "ttft": 1706154.3670972337,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 170,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5295555066922685,
    "arrivals": 462529,
    "finished_requests": 120776,
    "scheduler_time": 242.94010398377864
}
#Debug simulation 
Total elapsed time: 119.26278938585892. Arrivals time: 0.5078848912380636 Scheduler time: 118.55554928258061 Scheduler overhead time: 0.07838871143758297 Adapter cache time: 0.015429996885359287 Engine time: 0.07547389343380928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 112.7233890676871,
    "estimated_duration": 3600.1099392396304,
    "input_throughput": 8259.11916631079,
    "output_throughput": 7319.037597381032,
    "total_throughput": 15578.15676369182,
    "itl": 109.75190494617623,
    "ttft": 1706185.9799960952,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.51273788034916,
    "arrivals": 462529,
    "finished_requests": 120376,
    "scheduler_time": 244.17869801628964
}
#Debug simulation 
Total elapsed time: 112.72352851508185. Arrivals time: 0.4945172453299165 Scheduler time: 112.0312719438225 Scheduler overhead time: 0.07822533790022135 Adapter cache time: 0.014649424701929092 Engine time: 0.07575961574912071 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 112.53285201732069,
    "estimated_duration": 3600.0787178512082,
    "input_throughput": 8347.543860912334,
    "output_throughput": 7396.476601459839,
    "total_throughput": 15744.020462372173,
    "itl": 110.64447464297588,
    "ttft": 1706546.6908796134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 173,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.517278701018077,
    "arrivals": 462529,
    "finished_requests": 121621,
    "scheduler_time": 241.07677598388202
}
#Debug simulation 
Total elapsed time: 112.53299311921. Arrivals time: 0.5057110856287181 Scheduler time: 111.83120061270893 Scheduler overhead time: 0.0766881718300283 Adapter cache time: 0.014953282661736012 Engine time: 0.07573171146214008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 135, 34560, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 135, 34560, 8640, 135, 135, 8640, 34560, 135, 8640, 135, 135, 8640, 8640, 8640, 135, 135, 34560, 8640, 8640, 135, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 135, 34560, 8640, 8640, 8640, 34560, 34560, 135, 135, 8640, 135, 34560, 135, 135, 34560, 135, 8640, 8640, 135, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 135, 135, 34560, 8640, 34560, 135, 8640, 34560, 135, 34560, 8640, 135, 34560, 135, 135, 34560, 135, 135, 8640]
Prompts retrieved: 1386720 . Total input tokens: 309283426 . Total output tokens: 277385822
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 113.27738156355917,
    "estimated_duration": 3600.116259676644,
    "input_throughput": 8259.10466643392,
    "output_throughput": 7319.024747930404,
    "total_throughput": 15578.129414364324,
    "itl": 109.75199803178744,
    "ttft": 1706188.9767558908,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5187740620970726,
    "arrivals": 462529,
    "finished_requests": 120376,
    "scheduler_time": 244.17878219439592
}
#Debug simulation 
Total elapsed time: 113.27751309378073. Arrivals time: 0.4916891953907907 Scheduler time: 112.58874305896461 Scheduler overhead time: 0.07795706810429692 Adapter cache time: 0.014623348135501146 Engine time: 0.07556983921676874 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 108.8302508671768,
    "estimated_duration": 3600.0218521670527,
    "input_throughput": 8338.062443129611,
    "output_throughput": 7368.996936513315,
    "total_throughput": 15707.059379642926,
    "itl": 109.68676057137715,
    "ttft": 1709392.2918655672,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5814926713472225,
    "arrivals": 461810,
    "finished_requests": 121323,
    "scheduler_time": 241.70786961157668
}
#Debug simulation 
Total elapsed time: 108.83037952985615. Arrivals time: 0.5400244942866266 Scheduler time: 108.0964427436702 Scheduler overhead time: 0.07600919902324677 Adapter cache time: 0.014667484909296036 Engine time: 0.0742249502800405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 113.93648580787703,
    "estimated_duration": 3600.0185454772227,
    "input_throughput": 8361.58803621098,
    "output_throughput": 7391.588866515844,
    "total_throughput": 15753.176902726824,
    "itl": 110.72551364776517,
    "ttft": 1705790.144917498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.532453566163313,
    "arrivals": 461810,
    "finished_requests": 121615,
    "scheduler_time": 240.61566002787814
}
#Debug simulation 
Total elapsed time: 113.9366281949915. Arrivals time: 0.5130543722771108 Scheduler time: 113.22778677893803 Scheduler overhead time: 0.07642596028745174 Adapter cache time: 0.015046129003167152 Engine time: 0.07488442724570632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 114.50076547916979,
    "estimated_duration": 3600.019792345314,
    "input_throughput": 8361.585140172094,
    "output_throughput": 7391.586306436502,
    "total_throughput": 15753.171446608594,
    "itl": 110.72553098939065,
    "ttft": 1705790.7419043232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5338735831342656,
    "arrivals": 461810,
    "finished_requests": 121615,
    "scheduler_time": 240.61568695615517
}
#Debug simulation 
Total elapsed time: 114.50090336380526. Arrivals time: 0.5132279517129064 Scheduler time: 113.79098607599735 Scheduler overhead time: 0.07673691492527723 Adapter cache time: 0.014937588013708591 Engine time: 0.07501096511259675 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 109.30502694612369,
    "estimated_duration": 3600.0338442381253,
    "input_throughput": 8338.034668213664,
    "output_throughput": 7368.9723896510295,
    "total_throughput": 15707.007057864694,
    "itl": 109.68708337690197,
    "ttft": 1709397.1728591034,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5938510610931561,
    "arrivals": 461810,
    "finished_requests": 121323,
    "scheduler_time": 241.70790344720493
}
#Debug simulation 
Total elapsed time: 109.30515814293176. Arrivals time: 0.49983656918630004 Scheduler time: 108.61142539046705 Scheduler overhead time: 0.076098564080894 Adapter cache time: 0.014611676335334778 Engine time: 0.07464390434324741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 113.91106668300927,
    "estimated_duration": 3600.0271171285335,
    "input_throughput": 8361.568127300652,
    "output_throughput": 7391.5712671699675,
    "total_throughput": 15753.13939447062,
    "itl": 110.72566549926796,
    "ttft": 1705794.252681357,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5402870262414226,
    "arrivals": 461810,
    "finished_requests": 121615,
    "scheduler_time": 240.61579798762983
}
#Debug simulation 
Total elapsed time: 113.91120368381962. Arrivals time: 0.5183799476362765 Scheduler time: 113.19354141317308 Scheduler overhead time: 0.07882607448846102 Adapter cache time: 0.015110095962882042 Engine time: 0.07584118144586682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 108.96796131972224,
    "estimated_duration": 3600.0083539384477,
    "input_throughput": 8338.093706688445,
    "output_throughput": 7369.024566561764,
    "total_throughput": 15707.11827325021,
    "itl": 109.68654825140858,
    "ttft": 1709386.6270087783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 190,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5681095560314141,
    "arrivals": 461810,
    "finished_requests": 121323,
    "scheduler_time": 241.70765445968092
}
#Debug simulation 
Total elapsed time: 108.96808621380478. Arrivals time: 0.5133421602658927 Scheduler time: 108.25973895657808 Scheduler overhead time: 0.07651073997840285 Adapter cache time: 0.014602439943701029 Engine time: 0.07437971141189337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 66, 34560, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 66, 34560, 8640, 66, 66, 8640, 34560, 66, 8640, 66, 66, 8640, 8640, 8640, 66, 66, 34560, 8640, 8640, 66, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 66, 34560, 8640, 8640, 8640, 34560, 34560, 66, 66, 8640, 66, 34560, 66, 66, 34560, 66, 8640, 8640, 66, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 66, 66, 34560, 8640, 34560, 66, 8640, 34560, 66, 34560, 8640, 66, 34560, 66, 66, 34560, 66, 66, 8640]
Prompts retrieved: 1384512 . Total input tokens: 308764717 . Total output tokens: 276957540
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 114.16210496006534,
    "estimated_duration": 3600.0336558845993,
    "input_throughput": 8361.552940149772,
    "output_throughput": 7391.557841828408,
    "total_throughput": 15753.11078197818,
    "itl": 110.72588776133112,
    "ttft": 1705796.9928924006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5468262231349946,
    "arrivals": 461810,
    "finished_requests": 121615,
    "scheduler_time": 240.61599762396688
}
#Debug simulation 
Total elapsed time: 114.16224247263744. Arrivals time: 0.5119445808231831 Scheduler time: 113.45468137739226 Scheduler overhead time: 0.0764842894859612 Adapter cache time: 0.014504193793982267 Engine time: 0.07524558110162616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-8/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 107.70589231234044,
    "estimated_duration": 3600.0829832927493,
    "input_throughput": 8357.043195843878,
    "output_throughput": 7383.089813026848,
    "total_throughput": 15740.133008870725,
    "itl": 110.47328879601237,
    "ttft": 1713994.9737293206,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5539482816518277,
    "arrivals": 461464,
    "finished_requests": 121329,
    "scheduler_time": 240.61450160587137
}
#Debug simulation 
Total elapsed time: 107.70602747704834. Arrivals time: 0.5036431350745261 Scheduler time: 107.0077697574161 Scheduler overhead time: 0.07575000962242484 Adapter cache time: 0.01495321560651064 Engine time: 0.07450060825794935 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-16/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 107.47457927884534,
    "estimated_duration": 3600.1182117490703,
    "input_throughput": 8356.961419159368,
    "output_throughput": 7383.01756682778,
    "total_throughput": 15739.978985987149,
    "itl": 110.47393563121598,
    "ttft": 1714010.3334937843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5885961603163751,
    "arrivals": 461464,
    "finished_requests": 121329,
    "scheduler_time": 240.61488210635497
}
#Debug simulation 
Total elapsed time: 107.4747169520706. Arrivals time: 0.5170623664744198 Scheduler time: 106.7605902645737 Scheduler overhead time: 0.07678305124863982 Adapter cache time: 0.015257964842021465 Engine time: 0.07549379859119654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-8-32/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 107.8049734919332,
    "estimated_duration": 3600.119444835821,
    "input_throughput": 8356.958556793672,
    "output_throughput": 7383.015038050255,
    "total_throughput": 15739.973594843927,
    "itl": 110.47391039822801,
    "ttft": 1714010.934682338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5899976209923647,
    "arrivals": 461464,
    "finished_requests": 121329,
    "scheduler_time": 240.61491380958398
}
#Debug simulation 
Total elapsed time: 107.80511163407937. Arrivals time: 0.5117686302401125 Scheduler time: 107.09663457004353 Scheduler overhead time: 0.07716892147436738 Adapter cache time: 0.015635565854609013 Engine time: 0.07454356597736478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-16/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 107.4658463736996,
    "estimated_duration": 3600.0959739525465,
    "input_throughput": 8357.013040118627,
    "output_throughput": 7383.063171734863,
    "total_throughput": 15740.076211853491,
    "itl": 110.473517102159,
    "ttft": 1714000.1661278415,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5665320131205962,
    "arrivals": 461464,
    "finished_requests": 121329,
    "scheduler_time": 240.61460841844
}
#Debug simulation 
Total elapsed time: 107.46598543273285. Arrivals time: 0.5124350781552494 Scheduler time: 106.7595126228407 Scheduler overhead time: 0.07635315787047148 Adapter cache time: 0.014709702227264643 Engine time: 0.07444503158330917 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_8-16-32/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 107.59739608317614,
    "estimated_duration": 3600.126101358192,
    "input_throughput": 8356.943105034477,
    "output_throughput": 7383.001387082654,
    "total_throughput": 15739.944492117133,
    "itl": 110.4740645205342,
    "ttft": 1714013.9020926447,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5967883254587665,
    "arrivals": 461464,
    "finished_requests": 121329,
    "scheduler_time": 240.61507974323402
}
#Debug simulation 
Total elapsed time: 107.59752906113863. Arrivals time: 0.5192956835962832 Scheduler time: 106.88131639920175 Scheduler overhead time: 0.07718020910397172 Adapter cache time: 0.01462967460975051 Engine time: 0.07586069218814373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-16/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 107.67208304721862,
    "estimated_duration": 3600.095607762191,
    "input_throughput": 8357.0138901676,
    "output_throughput": 7383.063922716732,
    "total_throughput": 15740.077812884334,
    "itl": 110.47296063984525,
    "ttft": 1714009.0281673577,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5411991033772945,
    "arrivals": 461464,
    "finished_requests": 121329,
    "scheduler_time": 240.61822231653542
}
#Debug simulation 
Total elapsed time: 107.67222121637315. Arrivals time: 0.5156581150367856 Scheduler time: 106.96084682270885 Scheduler overhead time: 0.07753356220200658 Adapter cache time: 0.015149601735174656 Engine time: 0.07484873477369547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.003125_size_16-16-32/adapters_96_slots_16_rate_3.2-0.8-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 8.000e-01 3.200e+00]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 8640, 34560, 8640, 8640, 8640, 8640, 34560, 8640, 34560, 8640, 33, 34560, 33, 33, 34560, 8640, 34560, 8640, 34560, 34560, 8640, 33, 34560, 8640, 33, 33, 8640, 34560, 33, 8640, 33, 33, 8640, 8640, 8640, 33, 33, 34560, 8640, 8640, 33, 34560, 34560, 8640, 34560, 34560, 8640, 34560, 33, 34560, 8640, 8640, 8640, 34560, 34560, 33, 33, 8640, 33, 34560, 33, 33, 34560, 33, 8640, 8640, 33, 8640, 34560, 34560, 34560, 8640, 34560, 34560, 33, 33, 34560, 8640, 34560, 33, 8640, 34560, 33, 34560, 8640, 33, 34560, 33, 33, 34560, 33, 33, 8640]
Prompts retrieved: 1383456 . Total input tokens: 308511644 . Total output tokens: 276741490
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 107.78045267425478,
    "estimated_duration": 3600.007989899572,
    "input_throughput": 8356.477564606523,
    "output_throughput": 7382.729170204268,
    "total_throughput": 15739.206734810792,
    "itl": 110.4741732728854,
    "ttft": 1714036.0890429262,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 181,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.6045850602164873,
    "arrivals": 461464,
    "finished_requests": 121320,
    "scheduler_time": 240.60680823752517
}
#Debug simulation 
Total elapsed time: 107.78058857889846. Arrivals time: 0.5572996130213141 Scheduler time: 107.02713507553563 Scheduler overhead time: 0.07694070925936103 Adapter cache time: 0.01522717671468854 Engine time: 0.07448587054386735 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-8/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 119.58812445541844,
    "estimated_duration": 3600.060820611649,
    "input_throughput": 8259.735732727966,
    "output_throughput": 7308.824575783018,
    "total_throughput": 15568.560308510983,
    "itl": 107.42022100033677,
    "ttft": 1677584.1526394922,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.48049657579744176,
    "arrivals": 426676,
    "finished_requests": 119834,
    "scheduler_time": 244.8334211791594
}
#Debug simulation 
Total elapsed time: 119.58826142828912. Arrivals time: 0.5324777006171644 Scheduler time: 118.85373745532706 Scheduler overhead time: 0.07905297493562102 Adapter cache time: 0.01552145415917039 Engine time: 0.0776735171675682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-16/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 117.5922300410457,
    "estimated_duration": 3600.0386445254367,
    "input_throughput": 8333.306100927892,
    "output_throughput": 7354.816604611845,
    "total_throughput": 15688.122705539738,
    "itl": 108.91281634167478,
    "ttft": 1676989.6584733983,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5102974281436765,
    "arrivals": 426676,
    "finished_requests": 120941,
    "scheduler_time": 240.70911244096996
}
#Debug simulation 
Total elapsed time: 117.59236259292811. Arrivals time: 0.5150840007700026 Scheduler time: 116.87731746258214 Scheduler overhead time: 0.07867913460358977 Adapter cache time: 0.015024444088339806 Engine time: 0.07621065946295857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-8-32/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 117.8993915328756,
    "estimated_duration": 3600.0402295162244,
    "input_throughput": 8333.302432020724,
    "output_throughput": 7354.813366504541,
    "total_throughput": 15688.115798525265,
    "itl": 108.91286232690881,
    "ttft": 1676990.3329492053,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5115572087094205,
    "arrivals": 426676,
    "finished_requests": 120941,
    "scheduler_time": 240.70913753544914
}
#Debug simulation 
Total elapsed time: 117.89952347101644. Arrivals time: 0.5242256945930421 Scheduler time: 117.17567461077124 Scheduler overhead time: 0.07860001130029559 Adapter cache time: 0.015269335824996233 Engine time: 0.07601048285141587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-16/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 117.9007046148181,
    "estimated_duration": 3600.0152987370984,
    "input_throughput": 8333.360141698346,
    "output_throughput": 7354.864299962411,
    "total_throughput": 15688.224441660757,
    "itl": 108.91245167606053,
    "ttft": 1676978.0204024145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4902762575400996,
    "arrivals": 426676,
    "finished_requests": 120941,
    "scheduler_time": 240.70858890347904
}
#Debug simulation 
Total elapsed time: 117.9008379150182. Arrivals time: 0.5202819588594139 Scheduler time: 117.18063357938081 Scheduler overhead time: 0.07856670254841447 Adapter cache time: 0.01574717229232192 Engine time: 0.07599913887679577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_8-16-32/adapters_96_slots_16_rate_3.2-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 117.56896147225052,
    "estimated_duration": 3600.0458735524444,
    "input_throughput": 8333.289367336993,
    "output_throughput": 7354.801835864518,
    "total_throughput": 15688.091203201511,
    "itl": 108.91307022186659,
    "ttft": 1676992.3235833363,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5177191442437479,
    "arrivals": 426676,
    "finished_requests": 120941,
    "scheduler_time": 240.70921986761724
}
#Debug simulation 
Total elapsed time: 117.56909521389753. Arrivals time: 0.5253108483739197 Scheduler time: 116.84228506451473 Scheduler overhead time: 0.08004958229139447 Adapter cache time: 0.015682621859014034 Engine time: 0.07636019308120012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_96_slots_16_rate_3.2-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-16/adapters_96_slots_16_rate_3.2-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 119.46084744529799,
    "estimated_duration": 3600.0494220993414,
    "input_throughput": 8259.761884785443,
    "output_throughput": 7308.847717056126,
    "total_throughput": 15568.60960184157,
    "itl": 107.42005340372795,
    "ttft": 1677578.971715747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.46943789629964217,
    "arrivals": 426676,
    "finished_requests": 119834,
    "scheduler_time": 244.83318138490534
}
#Debug simulation 
Total elapsed time: 119.46098043117672. Arrivals time: 0.5165607198141515 Scheduler time: 118.74123564176261 Scheduler overhead time: 0.07965302374213934 Adapter cache time: 0.015438130125403404 Engine time: 0.07758071646094322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_96_slots_16_rate_3.2-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 96,
    "served_adapters_rates": [
        3.2,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.4-0.1_size_16-16-32/adapters_96_slots_16_rate_3.2-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 3.2]. Counts: [32 32 32]
Adapter prompts. [1080, 1080, 1080, 4320, 34560, 4320, 4320, 4320, 4320, 34560, 4320, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 4320, 34560, 4320, 34560, 34560, 4320, 1080, 34560, 4320, 1080, 1080, 4320, 34560, 1080, 4320, 1080, 1080, 4320, 4320, 4320, 1080, 1080, 34560, 4320, 4320, 1080, 34560, 34560, 4320, 34560, 34560, 4320, 34560, 1080, 34560, 4320, 4320, 4320, 34560, 34560, 1080, 1080, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 4320, 4320, 1080, 4320, 34560, 34560, 34560, 4320, 34560, 34560, 1080, 1080, 34560, 4320, 34560, 1080, 4320, 34560, 1080, 34560, 4320, 1080, 34560, 1080, 1080, 34560, 1080, 1080, 4320]
Prompts retrieved: 1278720 . Total input tokens: 285237011 . Total output tokens: 255753449
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 117.86136051919311,
    "estimated_duration": 3600.0526058456057,
    "input_throughput": 8333.273783634986,
    "output_throughput": 7354.788081987138,
    "total_throughput": 15688.061865622123,
    "itl": 108.9131095585144,
    "ttft": 1676995.5896727382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 157,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.5241325873509048,
    "arrivals": 426676,
    "finished_requests": 120941,
    "scheduler_time": 240.709338640512
}
#Debug simulation 
Total elapsed time: 117.86150004109368. Arrivals time: 0.5246425322256982 Scheduler time: 117.13740857131779 Scheduler overhead time: 0.07877666922286153 Adapter cache time: 0.014918860513716936 Engine time: 0.07581772888079286 
