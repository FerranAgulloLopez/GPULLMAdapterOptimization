INFO 06-01 00:47:13 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:14 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 75.56647642003372,
    "estimated_duration": 3600.074244067064,
    "input_throughput": 6193.163665094864,
    "output_throughput": 5437.640635401111,
    "total_throughput": 11630.804300495975,
    "itl": 147.84098965472387,
    "ttft": 1485848.3339518213,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 488,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5265627714549135,
    "arrivals": 177727,
    "finished_requests": 89678,
    "scheduler_time": 158.85720751667193
}
#Debug simulation 
Total elapsed time: 75.56668553687632. Arrivals time: 0.40953645342960954 Scheduler time: 75.00544552970678 Scheduler overhead time: 0.05723900627344847 Adapter cache time: 0.01625345926731825 Engine time: 0.056942849420011044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 70.44292339216918,
    "estimated_duration": 3600.14021173454,
    "input_throughput": 6225.135878583532,
    "output_throughput": 5469.62058194748,
    "total_throughput": 11694.756460531013,
    "itl": 149.8391674300709,
    "ttft": 1480414.005029471,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 494,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6320868565700988,
    "arrivals": 177727,
    "finished_requests": 90124,
    "scheduler_time": 157.09438336469776
}
#Debug simulation 
Total elapsed time: 70.44312234595418. Arrivals time: 0.4212648319080472 Scheduler time: 69.8697236389853 Scheduler overhead time: 0.057956304401159286 Adapter cache time: 0.01618308573961258 Engine time: 0.05646113585680723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 74.40329628996551,
    "estimated_duration": 3600.1153412051813,
    "input_throughput": 6197.289776980074,
    "output_throughput": 5439.7832135689505,
    "total_throughput": 11637.072990549024,
    "itl": 147.96045056537565,
    "ttft": 1487276.9452890386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 501,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4980151977459737,
    "arrivals": 177727,
    "finished_requests": 89683,
    "scheduler_time": 158.70112040515374
}
#Debug simulation 
Total elapsed time: 74.403455815278. Arrivals time: 0.41586033534258604 Scheduler time: 73.83594325836748 Scheduler overhead time: 0.05793899763375521 Adapter cache time: 0.01622468838468194 Engine time: 0.05573889147490263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 135, 4320, 4320, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 4320, 540, 4320, 4320, 135, 4320, 540, 540, 4320, 4320, 540, 135, 135, 540, 4320, 4320, 540, 540, 135, 135, 540, 4320, 4320, 135, 4320, 540, 135, 540, 4320, 135, 540, 4320, 4320, 540, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 540, 540, 540, 135, 540, 135, 4320, 135, 4320, 540, 4320, 4320, 135, 4320, 135, 4320, 540, 135, 135, 540, 540, 4320, 540, 4320, 4320, 4320, 135, 540, 540, 135, 4320, 540, 4320, 4320, 540, 135, 540, 540, 540, 135, 4320, 540, 4320, 135, 4320, 135, 135, 540, 4320, 4320, 540, 135, 540, 135, 540, 4320, 4320, 540, 135, 540, 135, 4320, 135, 135, 135, 135, 4320, 540, 540, 4320, 540, 540, 135, 540, 4320, 540, 135, 135, 540, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 540, 4320, 540, 540, 540, 135, 4320, 135, 4320, 540, 135, 540, 135, 135, 540, 135, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 540, 135, 540, 135, 135, 135, 4320, 4320, 540, 540, 135, 135, 540, 135, 4320, 135, 135, 540, 135, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 135, 540, 4320, 540, 540, 4320, 540, 135, 540, 135, 4320, 540, 540, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 540, 135, 540, 135, 540, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 540, 540, 4320, 135, 4320, 135, 135, 135, 4320, 540, 4320, 4320, 135, 540, 540, 540, 135, 540, 135, 540, 540, 4320, 135, 135, 540, 135, 540, 540, 135, 4320, 4320, 4320, 135, 540, 540, 540, 540, 135, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 540, 540, 540, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 540, 4320, 540, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 534330 . Total input tokens: 119088970 . Total output tokens: 106911388
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 74.7341511468403,
    "estimated_duration": 3600.101449243256,
    "input_throughput": 6204.244606688799,
    "output_throughput": 5447.758424730659,
    "total_throughput": 11652.003031419457,
    "itl": 148.45053189525487,
    "ttft": 1486322.4909621046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 493,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6509302087500672,
    "arrivals": 177727,
    "finished_requests": 89817,
    "scheduler_time": 158.27011903510115
}
#Debug simulation 
Total elapsed time: 74.73431971902028. Arrivals time: 0.42931421753019094 Scheduler time: 74.15305322734639 Scheduler overhead time: 0.05729749146848917 Adapter cache time: 0.016294244211167097 Engine time: 0.05705381417647004 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.18802483100444,
    "estimated_duration": 3600.063003408269,
    "input_throughput": 6165.620984684408,
    "output_throughput": 5459.332789840934,
    "total_throughput": 11624.953774525342,
    "itl": 149.38587769707718,
    "ttft": 1470444.19739039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0413453252031815,
    "arrivals": 175481,
    "finished_requests": 89746,
    "scheduler_time": 157.13989356379128
}
#Debug simulation 
Total elapsed time: 75.18818760523573. Arrivals time: 0.4189936937764287 Scheduler time: 74.61416923627257 Scheduler overhead time: 0.05783700570464134 Adapter cache time: 0.018366930074989796 Engine time: 0.05723552033305168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 71.6241840920411,
    "estimated_duration": 3600.055438527775,
    "input_throughput": 6165.831993153275,
    "output_throughput": 5460.7895171857435,
    "total_throughput": 11626.621510339019,
    "itl": 149.4242514431875,
    "ttft": 1473988.6729576322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.937763738208457,
    "arrivals": 175481,
    "finished_requests": 89757,
    "scheduler_time": 157.11668405262364
}
#Debug simulation 
Total elapsed time: 71.6243525701575. Arrivals time: 0.4210801520384848 Scheduler time: 71.05064036836848 Scheduler overhead time: 0.05746864667162299 Adapter cache time: 0.017512591555714607 Engine time: 0.056271234061568975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 71.62748668016866,
    "estimated_duration": 3600.0557203219455,
    "input_throughput": 6165.831510523103,
    "output_throughput": 5460.789089742734,
    "total_throughput": 11626.620600265838,
    "itl": 149.42408754177373,
    "ttft": 1473987.9469013796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9407174176164093,
    "arrivals": 175481,
    "finished_requests": 89757,
    "scheduler_time": 157.11666143245748
}
#Debug simulation 
Total elapsed time: 71.62774595292285. Arrivals time: 0.4295844454318285 Scheduler time: 71.04353452147916 Scheduler overhead time: 0.05850706063210964 Adapter cache time: 0.01752445986494422 Engine time: 0.056990304030478 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 71.7550192438066,
    "estimated_duration": 3600.1323344635703,
    "input_throughput": 6165.841401857118,
    "output_throughput": 5460.796763441568,
    "total_throughput": 11626.638165298686,
    "itl": 149.42262598145703,
    "ttft": 1474036.2463640945,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8501944569963844,
    "arrivals": 175481,
    "finished_requests": 89761,
    "scheduler_time": 157.12262139704106
}
#Debug simulation 
Total elapsed time: 71.75518630584702. Arrivals time: 0.42089573945850134 Scheduler time: 71.18081109318882 Scheduler overhead time: 0.05820745090022683 Adapter cache time: 0.01763880718499422 Engine time: 0.056444934103637934 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 75.1795092690736,
    "estimated_duration": 3600.1108468529296,
    "input_throughput": 6163.772712553511,
    "output_throughput": 5458.225270251725,
    "total_throughput": 11621.997982805236,
    "itl": 149.39338273541324,
    "ttft": 1470343.1499201497,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 670,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.218413354381921,
    "arrivals": 175481,
    "finished_requests": 89744,
    "scheduler_time": 157.14529081707283
}
#Debug simulation 
Total elapsed time: 75.1796825141646. Arrivals time: 0.42898294515907764 Scheduler time: 74.59423914644867 Scheduler overhead time: 0.058781038504093885 Adapter cache time: 0.01883900398388505 Engine time: 0.05711742304265499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 73.52553682168946,
    "estimated_duration": 3600.075856531807,
    "input_throughput": 6161.590723082592,
    "output_throughput": 5457.130566944882,
    "total_throughput": 11618.721290027474,
    "itl": 149.2637242545139,
    "ttft": 1471944.7964008136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.024264049648738,
    "arrivals": 175481,
    "finished_requests": 89745,
    "scheduler_time": 157.26741806698087
}
#Debug simulation 
Total elapsed time: 73.52570664184168. Arrivals time: 0.4284967458806932 Scheduler time: 72.94171509100124 Scheduler overhead time: 0.05796315195038915 Adapter cache time: 0.019068571738898754 Engine time: 0.05712491786107421 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 66, 4320, 4320, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 4320, 540, 4320, 4320, 66, 4320, 540, 540, 4320, 4320, 540, 66, 66, 540, 4320, 4320, 540, 540, 66, 66, 540, 4320, 4320, 66, 4320, 540, 66, 540, 4320, 66, 540, 4320, 4320, 540, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 540, 540, 540, 66, 540, 66, 4320, 66, 4320, 540, 4320, 4320, 66, 4320, 66, 4320, 540, 66, 66, 540, 540, 4320, 540, 4320, 4320, 4320, 66, 540, 540, 66, 4320, 540, 4320, 4320, 540, 66, 540, 540, 540, 66, 4320, 540, 4320, 66, 4320, 66, 66, 540, 4320, 4320, 540, 66, 540, 66, 540, 4320, 4320, 540, 66, 540, 66, 4320, 66, 66, 66, 66, 4320, 540, 540, 4320, 540, 540, 66, 540, 4320, 540, 66, 66, 540, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 540, 4320, 540, 540, 540, 66, 4320, 66, 4320, 540, 66, 540, 66, 66, 540, 66, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 540, 66, 540, 66, 66, 66, 4320, 4320, 540, 540, 66, 66, 540, 66, 4320, 66, 66, 540, 66, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 66, 540, 4320, 540, 540, 4320, 540, 66, 540, 66, 4320, 540, 540, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 540, 66, 540, 66, 540, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 540, 540, 4320, 66, 4320, 66, 66, 66, 4320, 540, 4320, 4320, 66, 540, 540, 540, 66, 540, 66, 540, 540, 4320, 66, 66, 540, 66, 540, 540, 66, 4320, 4320, 4320, 66, 540, 540, 540, 540, 66, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 540, 540, 540, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 540, 4320, 540, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 527016 . Total input tokens: 117464930 . Total output tokens: 105442026
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.63028320809826,
    "estimated_duration": 3600.066744269898,
    "input_throughput": 6165.420414865498,
    "output_throughput": 5459.002678569957,
    "total_throughput": 11624.423093435456,
    "itl": 149.39294694751234,
    "ttft": 1470524.8552887214,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.236988644711676,
    "arrivals": 175481,
    "finished_requests": 89741,
    "scheduler_time": 157.13245878520257
}
#Debug simulation 
Total elapsed time: 75.63045581104234. Arrivals time: 0.4205638552084565 Scheduler time: 75.05260046990588 Scheduler overhead time: 0.05870211776345968 Adapter cache time: 0.018928139470517635 Engine time: 0.05784759530797601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.76551780384034,
    "estimated_duration": 3600.0175202616256,
    "input_throughput": 6150.021736113939,
    "output_throughput": 5461.508975814965,
    "total_throughput": 11611.530711928905,
    "itl": 149.7803725175225,
    "ttft": 1469692.7223775275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 496,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5180019209906626,
    "arrivals": 174302,
    "finished_requests": 89858,
    "scheduler_time": 157.71030022432652
}
#Debug simulation 
Total elapsed time: 76.76568181579933. Arrivals time: 0.4247906347736716 Scheduler time: 76.18994107982144 Scheduler overhead time: 0.05674968147650361 Adapter cache time: 0.016541498713195324 Engine time: 0.05637905839830637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.79325145157054,
    "estimated_duration": 3600.0759927700383,
    "input_throughput": 6154.352587138642,
    "output_throughput": 5466.853488516671,
    "total_throughput": 11621.206075655313,
    "itl": 150.41604422659856,
    "ttft": 1468671.723303708,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.720677960393957,
    "arrivals": 174302,
    "finished_requests": 89909,
    "scheduler_time": 157.25078214133157
}
#Debug simulation 
Total elapsed time: 76.79341508075595. Arrivals time: 0.42056598979979753 Scheduler time: 76.22205529687926 Scheduler overhead time: 0.05746129807084799 Adapter cache time: 0.016557910479605198 Engine time: 0.05581501452252269 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.85162879200652,
    "estimated_duration": 3600.0770008502936,
    "input_throughput": 6154.350863819578,
    "output_throughput": 5466.851957708563,
    "total_throughput": 11621.20282152814,
    "itl": 150.4168328754351,
    "ttft": 1468670.9791692342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 526,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7229745074734197,
    "arrivals": 174302,
    "finished_requests": 89909,
    "scheduler_time": 157.25088768710893
}
#Debug simulation 
Total elapsed time: 76.85179185960442. Arrivals time: 0.42086102068424225 Scheduler time: 76.27899443358183 Scheduler overhead time: 0.057242341339588165 Adapter cache time: 0.016768803820014 Engine time: 0.05621546879410744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 74.07365522300825,
    "estimated_duration": 3600.121030667899,
    "input_throughput": 6161.795064952175,
    "output_throughput": 5467.664790244053,
    "total_throughput": 11629.459855196228,
    "itl": 150.34172695459344,
    "ttft": 1470559.6693144112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 491,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.5375758989318218,
    "arrivals": 174302,
    "finished_requests": 89979,
    "scheduler_time": 157.24799111937256
}
#Debug simulation 
Total elapsed time: 74.07381962658837. Arrivals time: 0.4149340125732124 Scheduler time: 73.50797234335914 Scheduler overhead time: 0.056638287380337715 Adapter cache time: 0.01642810134217143 Engine time: 0.056198952719569206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 75.51943136239424,
    "estimated_duration": 3600.046090963703,
    "input_throughput": 6158.410875807737,
    "output_throughput": 5466.64751026334,
    "total_throughput": 11625.058386071078,
    "itl": 150.42358574604117,
    "ttft": 1466826.4783187958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 486,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.6120771971531254,
    "arrivals": 174302,
    "finished_requests": 89980,
    "scheduler_time": 157.2694661314133
}
#Debug simulation 
Total elapsed time: 75.51966821309179. Arrivals time: 0.41558438166975975 Scheduler time: 74.95316118048504 Scheduler overhead time: 0.056891316547989845 Adapter cache time: 0.01631417917087674 Engine time: 0.05632326751947403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 76.54209701297805,
    "estimated_duration": 3600.1116707126457,
    "input_throughput": 6151.826950305663,
    "output_throughput": 5463.112480648895,
    "total_throughput": 11614.939430954559,
    "itl": 149.81813530473033,
    "ttft": 1469455.0591211782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 500,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.4950251474510716,
    "arrivals": 174302,
    "finished_requests": 89877,
    "scheduler_time": 157.65044669717318
}
#Debug simulation 
Total elapsed time: 76.54225606285036. Arrivals time: 0.4076519780792296 Scheduler time: 75.98416517861187 Scheduler overhead time: 0.05706895608454943 Adapter cache time: 0.01623473223298788 Engine time: 0.05555440112948418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [106 107 107]
Adapter prompts. [540, 4320, 4320, 33, 4320, 4320, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 4320, 540, 4320, 4320, 33, 4320, 540, 540, 4320, 4320, 540, 33, 33, 540, 4320, 4320, 540, 540, 33, 33, 540, 4320, 4320, 33, 4320, 540, 33, 540, 4320, 33, 540, 4320, 4320, 540, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 540, 540, 540, 33, 540, 33, 4320, 33, 4320, 540, 4320, 4320, 33, 4320, 33, 4320, 540, 33, 33, 540, 540, 4320, 540, 4320, 4320, 4320, 33, 540, 540, 33, 4320, 540, 4320, 4320, 540, 33, 540, 540, 540, 33, 4320, 540, 4320, 33, 4320, 33, 33, 540, 4320, 4320, 540, 33, 540, 33, 540, 4320, 4320, 540, 33, 540, 33, 4320, 33, 33, 33, 33, 4320, 540, 540, 4320, 540, 540, 33, 540, 4320, 540, 33, 33, 540, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 540, 4320, 540, 540, 540, 33, 4320, 33, 4320, 540, 33, 540, 33, 33, 540, 33, 540, 4320, 4320, 4320, 4320, 540, 540, 4320, 4320, 4320, 540, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 540, 33, 540, 33, 33, 33, 4320, 4320, 540, 540, 33, 33, 540, 33, 4320, 33, 33, 540, 33, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 33, 540, 4320, 540, 540, 4320, 540, 33, 540, 33, 4320, 540, 540, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 540, 33, 540, 33, 540, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 540, 540, 4320, 33, 4320, 33, 33, 33, 4320, 540, 4320, 4320, 33, 540, 540, 540, 33, 540, 33, 540, 540, 4320, 33, 33, 540, 33, 540, 540, 33, 4320, 4320, 4320, 33, 540, 540, 540, 540, 33, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 540, 540, 540, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 540, 4320, 540, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 523518 . Total input tokens: 116684838 . Total output tokens: 104734129
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.81271208589897,
    "estimated_duration": 3600.0179501943735,
    "input_throughput": 6157.0976330279755,
    "output_throughput": 5466.675242254673,
    "total_throughput": 11623.772875282648,
    "itl": 150.4367731627586,
    "ttft": 1467074.9112442138,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 487,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.636836107186971,
    "arrivals": 174302,
    "finished_requests": 89969,
    "scheduler_time": 157.2621679537093
}
#Debug simulation 
Total elapsed time: 75.81288186088204. Arrivals time: 0.4173297784291208 Scheduler time: 75.2445515152067 Scheduler overhead time: 0.057536966633051634 Adapter cache time: 0.01614268869161606 Engine time: 0.05600796127691865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 77.93152231024578,
    "estimated_duration": 3600.1536519500614,
    "input_throughput": 6200.586185511409,
    "output_throughput": 5449.817951345638,
    "total_throughput": 11650.404136857047,
    "itl": 148.67795352386068,
    "ttft": 1434556.1584184791,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.75059898952956,
    "arrivals": 168141,
    "finished_requests": 89577,
    "scheduler_time": 156.01721954731676
}
#Debug simulation 
Total elapsed time: 77.93169025331736. Arrivals time: 0.40610224241390824 Scheduler time: 77.37251358944923 Scheduler overhead time: 0.056913810316473246 Adapter cache time: 0.017476046457886696 Engine time: 0.05711828451603651 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.40626869676635,
    "estimated_duration": 3600.0571923615453,
    "input_throughput": 6201.742585471067,
    "output_throughput": 5451.680334868683,
    "total_throughput": 11653.42292033975,
    "itl": 148.8606029435593,
    "ttft": 1434823.3209761644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8668007756467038,
    "arrivals": 168141,
    "finished_requests": 89589,
    "scheduler_time": 155.93603511491185
}
#Debug simulation 
Total elapsed time: 78.40643025701866. Arrivals time: 0.4157216213643551 Scheduler time: 77.83861020905897 Scheduler overhead time: 0.0567888249643147 Adapter cache time: 0.01723260758444667 Engine time: 0.05643096147105098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.9113567750901,
    "estimated_duration": 3600.0590596421684,
    "input_throughput": 6201.739368747794,
    "output_throughput": 5451.677507188113,
    "total_throughput": 11653.416875935907,
    "itl": 148.86045311414645,
    "ttft": 1434823.7789082916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.870058571901184,
    "arrivals": 168141,
    "finished_requests": 89589,
    "scheduler_time": 155.93605025193648
}
#Debug simulation 
Total elapsed time: 77.91151332994923. Arrivals time: 0.41136829601600766 Scheduler time: 77.34759546397254 Scheduler overhead time: 0.057691697496920824 Adapter cache time: 0.017348297871649265 Engine time: 0.055970686953514814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 78.08006881689653,
    "estimated_duration": 3600.0728811655317,
    "input_throughput": 6203.928291798672,
    "output_throughput": 5453.436540885763,
    "total_throughput": 11657.364832684434,
    "itl": 149.06264282829372,
    "ttft": 1434253.3377960392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.80071927100419,
    "arrivals": 168141,
    "finished_requests": 89599,
    "scheduler_time": 155.84519745368655
}
#Debug simulation 
Total elapsed time: 78.08023137087002. Arrivals time: 0.40653207153081894 Scheduler time: 77.52061716513708 Scheduler overhead time: 0.057798527646809816 Adapter cache time: 0.017367856577038765 Engine time: 0.05624891119077802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 78.63341379212216,
    "estimated_duration": 3600.083638481231,
    "input_throughput": 6201.6970276332095,
    "output_throughput": 5451.640286968383,
    "total_throughput": 11653.337314601593,
    "itl": 148.8608055797792,
    "ttft": 1434831.9799307792,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8942032988928295,
    "arrivals": 168141,
    "finished_requests": 89589,
    "scheduler_time": 155.93625849690523
}
#Debug simulation 
Total elapsed time: 78.63356844894588. Arrivals time: 0.4126958232372999 Scheduler time: 78.06751064024866 Scheduler overhead time: 0.057727362494915724 Adapter cache time: 0.017326943576335907 Engine time: 0.05662812804803252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.06388424895704,
    "estimated_duration": 3600.1036171429523,
    "input_throughput": 6201.903993452037,
    "output_throughput": 5451.826693692813,
    "total_throughput": 11653.73068714485,
    "itl": 148.85512121376604,
    "ttft": 1434853.4517545302,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7103087686840206,
    "arrivals": 168141,
    "finished_requests": 89592,
    "scheduler_time": 155.9442989007969
}
#Debug simulation 
Total elapsed time: 78.06405214173719. Arrivals time: 0.4288780987262726 Scheduler time: 77.4818319734186 Scheduler overhead time: 0.05730346031486988 Adapter cache time: 0.017486010678112507 Engine time: 0.056619320064783096 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 135, 4320, 4320, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 4320, 270, 4320, 4320, 135, 4320, 270, 270, 4320, 4320, 270, 135, 135, 270, 4320, 4320, 270, 270, 135, 135, 270, 4320, 4320, 135, 4320, 270, 135, 270, 4320, 135, 270, 4320, 4320, 270, 135, 135, 4320, 135, 135, 4320, 4320, 135, 135, 270, 270, 270, 135, 270, 135, 4320, 135, 4320, 270, 4320, 4320, 135, 4320, 135, 4320, 270, 135, 135, 270, 270, 4320, 270, 4320, 4320, 4320, 135, 270, 270, 135, 4320, 270, 4320, 4320, 270, 135, 270, 270, 270, 135, 4320, 270, 4320, 135, 4320, 135, 135, 270, 4320, 4320, 270, 135, 270, 135, 270, 4320, 4320, 270, 135, 270, 135, 4320, 135, 135, 135, 135, 4320, 270, 270, 4320, 270, 270, 135, 270, 4320, 270, 135, 135, 270, 4320, 135, 135, 135, 4320, 4320, 4320, 135, 270, 4320, 270, 270, 270, 135, 4320, 135, 4320, 270, 135, 270, 135, 135, 270, 135, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 270, 135, 270, 135, 135, 135, 4320, 4320, 270, 270, 135, 135, 270, 135, 4320, 135, 135, 270, 135, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 135, 270, 4320, 270, 270, 4320, 270, 135, 270, 135, 4320, 270, 270, 4320, 4320, 135, 135, 135, 4320, 4320, 135, 135, 4320, 270, 135, 270, 135, 270, 4320, 4320, 4320, 135, 4320, 4320, 4320, 4320, 135, 270, 270, 4320, 135, 4320, 135, 135, 135, 4320, 270, 4320, 4320, 135, 270, 270, 270, 135, 270, 135, 270, 270, 4320, 135, 135, 270, 135, 270, 270, 135, 4320, 4320, 4320, 135, 270, 270, 270, 270, 135, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 270, 270, 270, 135, 135, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 4320, 270, 4320, 270, 135, 4320, 135, 4320, 4320, 135, 135, 135]
Prompts retrieved: 505440 . Total input tokens: 112700817 . Total output tokens: 101087654
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.96444448782131,
    "estimated_duration": 3600.128950996014,
    "input_throughput": 6203.603621981686,
    "output_throughput": 5453.050506584962,
    "total_throughput": 11656.654128566648,
    "itl": 149.06538331258255,
    "ttft": 1434289.4500313036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 576,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.930396347492929,
    "arrivals": 168141,
    "finished_requests": 89596,
    "scheduler_time": 155.84262704948085
}
#Debug simulation 
Total elapsed time: 77.96467279270291. Arrivals time: 0.4167304923757911 Scheduler time: 77.39504528604448 Scheduler overhead time: 0.05736130056902766 Adapter cache time: 0.01752221630886197 Engine time: 0.05670534074306488 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 79.4898092309013,
    "estimated_duration": 3600.0731996741883,
    "input_throughput": 6227.1292156028585,
    "output_throughput": 5443.0676581169,
    "total_throughput": 11670.196873719759,
    "itl": 147.5433419156937,
    "ttft": 1421655.4085694463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7597804527613585,
    "arrivals": 165887,
    "finished_requests": 90000,
    "scheduler_time": 155.86516972940754
}
#Debug simulation 
Total elapsed time: 79.48996876180172. Arrivals time: 0.41261660400778055 Scheduler time: 78.92397070629522 Scheduler overhead time: 0.05795254511758685 Adapter cache time: 0.017306094989180565 Engine time: 0.056573791429400444 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.29309756029397,
    "estimated_duration": 3600.1102077670303,
    "input_throughput": 6236.777682960583,
    "output_throughput": 5447.779892317443,
    "total_throughput": 11684.557575278026,
    "itl": 147.79359037207013,
    "ttft": 1422898.5539786373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 590,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9259334200946678,
    "arrivals": 165887,
    "finished_requests": 90146,
    "scheduler_time": 155.54538472985124
}
#Debug simulation 
Total elapsed time: 78.29325963836163. Arrivals time: 0.41444303980097175 Scheduler time: 77.72622155118734 Scheduler overhead time: 0.05748420208692551 Adapter cache time: 0.01782795460894704 Engine time: 0.05591866094619036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 78.3562793219462,
    "estimated_duration": 3600.0653306490694,
    "input_throughput": 6239.511213522929,
    "output_throughput": 5448.3755705798885,
    "total_throughput": 11687.886784102819,
    "itl": 147.76489405345262,
    "ttft": 1423407.235246749,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9052235167101144,
    "arrivals": 165887,
    "finished_requests": 90158,
    "scheduler_time": 155.55130197235604
}
#Debug simulation 
Total elapsed time: 78.35643643606454. Arrivals time: 0.41985323233529925 Scheduler time: 77.7824774030596 Scheduler overhead time: 0.05775885749608278 Adapter cache time: 0.017686991952359676 Engine time: 0.05694848718121648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 78.21522898878902,
    "estimated_duration": 3600.0101112202096,
    "input_throughput": 6234.2549900208205,
    "output_throughput": 5446.393869531177,
    "total_throughput": 11680.648859551997,
    "itl": 147.6780017424964,
    "ttft": 1423084.4984025243,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 587,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.837695777432517,
    "arrivals": 165887,
    "finished_requests": 90094,
    "scheduler_time": 155.67664586231197
}
#Debug simulation 
Total elapsed time: 78.21539081213996. Arrivals time: 0.4145284378901124 Scheduler time: 77.64847047673538 Scheduler overhead time: 0.057242135517299175 Adapter cache time: 0.01771405152976513 Engine time: 0.055767740588635206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 78.13602813100442,
    "estimated_duration": 3600.0852071979975,
    "input_throughput": 6239.4767643522055,
    "output_throughput": 5448.345489374202,
    "total_throughput": 11687.822253726408,
    "itl": 147.76505965940015,
    "ttft": 1423412.458078397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 583,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.92911673612893,
    "arrivals": 165887,
    "finished_requests": 90158,
    "scheduler_time": 155.55122942572893
}
#Debug simulation 
Total elapsed time: 78.1361835966818. Arrivals time: 0.42341688740998507 Scheduler time: 77.55876145791262 Scheduler overhead time: 0.05761835165321827 Adapter cache time: 0.01791019504889846 Engine time: 0.05665205977857113 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 80.0497618704103,
    "estimated_duration": 3600.1114915664734,
    "input_throughput": 6224.366121019684,
    "output_throughput": 5441.47397820618,
    "total_throughput": 11665.840099225863,
    "itl": 147.47214586468309,
    "ttft": 1421456.7388097404,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7162888692738247,
    "arrivals": 165887,
    "finished_requests": 89988,
    "scheduler_time": 155.9575203303201
}
#Debug simulation 
Total elapsed time: 80.04992646723986. Arrivals time: 0.4171490645967424 Scheduler time: 79.4793565873988 Scheduler overhead time: 0.05787016078829765 Adapter cache time: 0.017659772653132677 Engine time: 0.056154504884034395 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 66, 4320, 4320, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 4320, 270, 4320, 4320, 66, 4320, 270, 270, 4320, 4320, 270, 66, 66, 270, 4320, 4320, 270, 270, 66, 66, 270, 4320, 4320, 66, 4320, 270, 66, 270, 4320, 66, 270, 4320, 4320, 270, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 270, 270, 270, 66, 270, 66, 4320, 66, 4320, 270, 4320, 4320, 66, 4320, 66, 4320, 270, 66, 66, 270, 270, 4320, 270, 4320, 4320, 4320, 66, 270, 270, 66, 4320, 270, 4320, 4320, 270, 66, 270, 270, 270, 66, 4320, 270, 4320, 66, 4320, 66, 66, 270, 4320, 4320, 270, 66, 270, 66, 270, 4320, 4320, 270, 66, 270, 66, 4320, 66, 66, 66, 66, 4320, 270, 270, 4320, 270, 270, 66, 270, 4320, 270, 66, 66, 270, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 270, 4320, 270, 270, 270, 66, 4320, 66, 4320, 270, 66, 270, 66, 66, 270, 66, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 270, 66, 270, 66, 66, 66, 4320, 4320, 270, 270, 66, 66, 270, 66, 4320, 66, 66, 270, 66, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 66, 270, 4320, 270, 270, 4320, 270, 66, 270, 66, 4320, 270, 270, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 270, 66, 270, 66, 270, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 270, 270, 4320, 66, 4320, 66, 66, 66, 4320, 270, 4320, 4320, 66, 270, 270, 270, 66, 270, 66, 270, 270, 4320, 66, 66, 270, 66, 270, 270, 66, 4320, 4320, 4320, 66, 270, 270, 270, 270, 66, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 270, 270, 270, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 270, 4320, 270, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 498126 . Total input tokens: 111065075 . Total output tokens: 99648594
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.36835409095511,
    "estimated_duration": 3600.1151948259953,
    "input_throughput": 6242.965234085046,
    "output_throughput": 5456.814834212412,
    "total_throughput": 11699.780068297458,
    "itl": 148.14392788627194,
    "ttft": 1425408.7617254322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 574,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9243093097954946,
    "arrivals": 165887,
    "finished_requests": 90279,
    "scheduler_time": 155.1040489500967
}
#Debug simulation 
Total elapsed time: 76.36859682202339. Arrivals time: 0.4165234682150185 Scheduler time: 75.79903509095311 Scheduler overhead time: 0.0570029579102993 Adapter cache time: 0.017720235977321863 Engine time: 0.05671674758195877 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.89155210927129,
    "estimated_duration": 3600.0953406092735,
    "input_throughput": 6169.578274624538,
    "output_throughput": 5463.408643136459,
    "total_throughput": 11632.986917760996,
    "itl": 149.0485990548056,
    "ttft": 1410673.4690762437,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8118087444082172,
    "arrivals": 164660,
    "finished_requests": 90178,
    "scheduler_time": 154.49678955961005
}
#Debug simulation 
Total elapsed time: 75.89170745993033. Arrivals time: 0.4156413138844073 Scheduler time: 75.32346801040694 Scheduler overhead time: 0.05774528346955776 Adapter cache time: 0.017395400442183018 Engine time: 0.05582236452028155 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.49247421883047,
    "estimated_duration": 3600.0510199157575,
    "input_throughput": 6170.987543537608,
    "output_throughput": 5465.184212989404,
    "total_throughput": 11636.171756527012,
    "itl": 149.17881946743938,
    "ttft": 1411053.3869414064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.949036631817003,
    "arrivals": 164660,
    "finished_requests": 90201,
    "scheduler_time": 154.37323016013164
}
#Debug simulation 
Total elapsed time: 75.4926351881586. Arrivals time: 0.4193774424493313 Scheduler time: 74.92276753066108 Scheduler overhead time: 0.05622209468856454 Adapter cache time: 0.017387343104928732 Engine time: 0.05543618043884635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.19731592712924,
    "estimated_duration": 3600.0228220945314,
    "input_throughput": 6170.905879722964,
    "output_throughput": 5465.345630379271,
    "total_throughput": 11636.251510102235,
    "itl": 149.17528058557158,
    "ttft": 1410816.6756287422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.95323703190313,
    "arrivals": 164660,
    "finished_requests": 90217,
    "scheduler_time": 154.37250434983923
}
#Debug simulation 
Total elapsed time: 75.19747373089194. Arrivals time: 0.414080829359591 Scheduler time: 74.63180727884173 Scheduler overhead time: 0.057226819451898336 Adapter cache time: 0.017258730717003345 Engine time: 0.05542883649468422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 75.28639181517065,
    "estimated_duration": 3600.1470346444553,
    "input_throughput": 6171.022957175991,
    "output_throughput": 5465.100400251594,
    "total_throughput": 11636.123357427585,
    "itl": 149.17723398805987,
    "ttft": 1411055.9289760801,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.8722207119502017,
    "arrivals": 164660,
    "finished_requests": 90204,
    "scheduler_time": 154.38014162046125
}
#Debug simulation 
Total elapsed time: 75.28655382525176. Arrivals time: 0.4205043241381645 Scheduler time: 74.71508636558428 Scheduler overhead time: 0.05680426396429539 Adapter cache time: 0.017164230812340975 Engine time: 0.05565921775996685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 75.55883387103677,
    "estimated_duration": 3600.160551594912,
    "input_throughput": 6170.554529896871,
    "output_throughput": 5462.608602632352,
    "total_throughput": 11633.163132529224,
    "itl": 149.03463023415475,
    "ttft": 1411094.5932944966,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 593,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9615754095837514,
    "arrivals": 164660,
    "finished_requests": 90185,
    "scheduler_time": 154.49734917674414
}
#Debug simulation 
Total elapsed time: 75.55899375164881. Arrivals time: 0.41430458100512624 Scheduler time: 74.99344489816576 Scheduler overhead time: 0.05673884693533182 Adapter cache time: 0.0173064605332911 Engine time: 0.05544917564839125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.45585987903178,
    "estimated_duration": 3600.0505310909048,
    "input_throughput": 6171.122824008777,
    "output_throughput": 5465.479395378843,
    "total_throughput": 11636.60221938762,
    "itl": 149.16840686239485,
    "ttft": 1410807.384665847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.7880500763514744,
    "arrivals": 164660,
    "finished_requests": 90221,
    "scheduler_time": 154.38044073207607
}
#Debug simulation 
Total elapsed time: 75.45601973636076. Arrivals time: 0.41647743713110685 Scheduler time: 74.88777252985165 Scheduler overhead time: 0.056590884923934937 Adapter cache time: 0.017279659397900105 Engine time: 0.05629716953262687 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [106 107 107]
Adapter prompts. [270, 4320, 4320, 33, 4320, 4320, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 4320, 270, 4320, 4320, 33, 4320, 270, 270, 4320, 4320, 270, 33, 33, 270, 4320, 4320, 270, 270, 33, 33, 270, 4320, 4320, 33, 4320, 270, 33, 270, 4320, 33, 270, 4320, 4320, 270, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 270, 270, 270, 33, 270, 33, 4320, 33, 4320, 270, 4320, 4320, 33, 4320, 33, 4320, 270, 33, 33, 270, 270, 4320, 270, 4320, 4320, 4320, 33, 270, 270, 33, 4320, 270, 4320, 4320, 270, 33, 270, 270, 270, 33, 4320, 270, 4320, 33, 4320, 33, 33, 270, 4320, 4320, 270, 33, 270, 33, 270, 4320, 4320, 270, 33, 270, 33, 4320, 33, 33, 33, 33, 4320, 270, 270, 4320, 270, 270, 33, 270, 4320, 270, 33, 33, 270, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 270, 4320, 270, 270, 270, 33, 4320, 33, 4320, 270, 33, 270, 33, 33, 270, 33, 270, 4320, 4320, 4320, 4320, 270, 270, 4320, 4320, 4320, 270, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 270, 33, 270, 33, 33, 33, 4320, 4320, 270, 270, 33, 33, 270, 33, 4320, 33, 33, 270, 33, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 33, 270, 4320, 270, 270, 4320, 270, 33, 270, 33, 4320, 270, 270, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 270, 33, 270, 33, 270, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 270, 270, 4320, 33, 4320, 33, 33, 33, 4320, 270, 4320, 4320, 33, 270, 270, 270, 33, 270, 33, 270, 270, 4320, 33, 33, 270, 33, 270, 270, 33, 4320, 4320, 4320, 33, 270, 270, 270, 270, 33, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 270, 270, 270, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 270, 4320, 270, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 494628 . Total input tokens: 110245784 . Total output tokens: 98947582
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.5342949507758,
    "estimated_duration": 3600.079060220149,
    "input_throughput": 6169.251460450384,
    "output_throughput": 5463.217243567223,
    "total_throughput": 11632.468704017607,
    "itl": 149.0556293909015,
    "ttft": 1410705.4759176646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.9837226618826345,
    "arrivals": 164660,
    "finished_requests": 90174,
    "scheduler_time": 154.48934740454015
}
#Debug simulation 
Total elapsed time: 75.53445584699512. Arrivals time: 0.4089295621961355 Scheduler time: 74.97570323618129 Scheduler overhead time: 0.05616237688809633 Adapter cache time: 0.01708229724317789 Engine time: 0.055112381000071764 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.47955191507936,
    "estimated_duration": 3600.07876523715,
    "input_throughput": 6184.758848889597,
    "output_throughput": 5460.345531830351,
    "total_throughput": 11645.10438071995,
    "itl": 149.3258991581513,
    "ttft": 1398015.3214069288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.032163861971383,
    "arrivals": 161177,
    "finished_requests": 89631,
    "scheduler_time": 153.9346572885398
}
#Debug simulation 
Total elapsed time: 75.47971531515941. Arrivals time: 0.40158649254590273 Scheduler time: 74.92810157267377 Scheduler overhead time: 0.05594991659745574 Adapter cache time: 0.01818138500675559 Engine time: 0.05470402352511883 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.15163602819666,
    "estimated_duration": 3600.0159045530054,
    "input_throughput": 6184.58045472565,
    "output_throughput": 5460.261988048274,
    "total_throughput": 11644.842442773925,
    "itl": 149.33162094954955,
    "ttft": 1397994.2349656173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1688526937947676,
    "arrivals": 161177,
    "finished_requests": 89628,
    "scheduler_time": 153.9251064336909
}
#Debug simulation 
Total elapsed time: 76.151877427008. Arrivals time: 0.40431262739002705 Scheduler time: 75.5963622983545 Scheduler overhead time: 0.05639935750514269 Adapter cache time: 0.01808001147583127 Engine time: 0.05524317128583789 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.5987846958451,
    "estimated_duration": 3600.017236483307,
    "input_throughput": 6184.578166561575,
    "output_throughput": 5460.259967866726,
    "total_throughput": 11644.8381344283,
    "itl": 149.33151134949327,
    "ttft": 1397994.0798923306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.1723206406273,
    "arrivals": 161177,
    "finished_requests": 89628,
    "scheduler_time": 153.92513917324095
}
#Debug simulation 
Total elapsed time: 75.5989497168921. Arrivals time: 0.41085682436823845 Scheduler time: 75.03692086972296 Scheduler overhead time: 0.056263144593685865 Adapter cache time: 0.01815614802762866 Engine time: 0.055395728908479214 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 75.1599674387835,
    "estimated_duration": 3600.1205476555397,
    "input_throughput": 6184.687069575977,
    "output_throughput": 5460.282159940843,
    "total_throughput": 11644.969229516819,
    "itl": 149.32565108177232,
    "ttft": 1398026.1306439238,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.07814453310099,
    "arrivals": 161177,
    "finished_requests": 89631,
    "scheduler_time": 153.93503374772007
}
#Debug simulation 
Total elapsed time: 75.16013148380443. Arrivals time: 0.40392028307542205 Scheduler time: 74.60609463974833 Scheduler overhead time: 0.056116778403520584 Adapter cache time: 0.017892247065901756 Engine time: 0.0548400953412056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 75.29007209278643,
    "estimated_duration": 3600.044248583835,
    "input_throughput": 6184.531762007736,
    "output_throughput": 5460.2189980671965,
    "total_throughput": 11644.750760074932,
    "itl": 149.33224552844305,
    "ttft": 1398002.9258285589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.200237981211396,
    "arrivals": 161177,
    "finished_requests": 89628,
    "scheduler_time": 153.9253466023419
}
#Debug simulation 
Total elapsed time: 75.29023256385699. Arrivals time: 0.414937196765095 Scheduler time: 74.72443897323683 Scheduler overhead time: 0.05593885760754347 Adapter cache time: 0.018143039662390947 Engine time: 0.05525887990370393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 75.34874312905595,
    "estimated_duration": 3600.029168718134,
    "input_throughput": 6184.844054451965,
    "output_throughput": 5460.420757368343,
    "total_throughput": 11645.264811820309,
    "itl": 149.32457518985785,
    "ttft": 1398000.596788051,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.985393395815011,
    "arrivals": 161177,
    "finished_requests": 89631,
    "scheduler_time": 153.93355509585993
}
#Debug simulation 
Total elapsed time: 75.34890822786838. Arrivals time: 0.41033408511430025 Scheduler time: 74.78731427807361 Scheduler overhead time: 0.05587548715993762 Adapter cache time: 0.018208286724984646 Engine time: 0.05532305454835296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 66, 4320, 4320, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 4320, 135, 4320, 4320, 66, 4320, 135, 135, 4320, 4320, 135, 66, 66, 135, 4320, 4320, 135, 135, 66, 66, 135, 4320, 4320, 66, 4320, 135, 66, 135, 4320, 66, 135, 4320, 4320, 135, 66, 66, 4320, 66, 66, 4320, 4320, 66, 66, 135, 135, 135, 66, 135, 66, 4320, 66, 4320, 135, 4320, 4320, 66, 4320, 66, 4320, 135, 66, 66, 135, 135, 4320, 135, 4320, 4320, 4320, 66, 135, 135, 66, 4320, 135, 4320, 4320, 135, 66, 135, 135, 135, 66, 4320, 135, 4320, 66, 4320, 66, 66, 135, 4320, 4320, 135, 66, 135, 66, 135, 4320, 4320, 135, 66, 135, 66, 4320, 66, 66, 66, 66, 4320, 135, 135, 4320, 135, 135, 66, 135, 4320, 135, 66, 66, 135, 4320, 66, 66, 66, 4320, 4320, 4320, 66, 135, 4320, 135, 135, 135, 66, 4320, 66, 4320, 135, 66, 135, 66, 66, 135, 66, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 135, 66, 135, 66, 66, 66, 4320, 4320, 135, 135, 66, 66, 135, 66, 4320, 66, 66, 135, 66, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 66, 135, 4320, 135, 135, 4320, 135, 66, 135, 66, 4320, 135, 135, 4320, 4320, 66, 66, 66, 4320, 4320, 66, 66, 4320, 135, 66, 135, 66, 135, 4320, 4320, 4320, 66, 4320, 4320, 4320, 4320, 66, 135, 135, 4320, 66, 4320, 66, 66, 66, 4320, 135, 4320, 4320, 66, 135, 135, 135, 66, 135, 66, 135, 135, 4320, 66, 66, 135, 66, 135, 135, 66, 4320, 4320, 4320, 66, 135, 135, 135, 135, 66, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 135, 135, 135, 66, 66, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 4320, 135, 4320, 135, 66, 4320, 66, 4320, 4320, 66, 66, 66]
Prompts retrieved: 483681 . Total input tokens: 107784951 . Total output tokens: 96806238
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 75.48027087794617,
    "estimated_duration": 3600.0718089554684,
    "input_throughput": 6184.48441628721,
    "output_throughput": 5460.177197327441,
    "total_throughput": 11644.661613614651,
    "itl": 149.33250105136938,
    "ttft": 1398011.7352711335,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2287840907275704,
    "arrivals": 161177,
    "finished_requests": 89628,
    "scheduler_time": 153.92601940595162
}
#Debug simulation 
Total elapsed time: 75.48042931361124. Arrivals time: 0.40435640001669526 Scheduler time: 74.92534319637343 Scheduler overhead time: 0.05562207894399762 Adapter cache time: 0.01801963336765766 Engine time: 0.055596462450921535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 77.77916750079021,
    "estimated_duration": 3600.0312354077905,
    "input_throughput": 6221.1063003355,
    "output_throughput": 5501.418378042648,
    "total_throughput": 11722.52467837815,
    "itl": 151.46012071882348,
    "ttft": 1387222.2199337736,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 676,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.068889714898577,
    "arrivals": 159905,
    "finished_requests": 90302,
    "scheduler_time": 152.49042253949526
}
#Debug simulation 
Total elapsed time: 77.779337503016. Arrivals time: 0.40887233428657055 Scheduler time: 77.22015532944351 Scheduler overhead time: 0.05565403262153268 Adapter cache time: 0.01835993491113186 Engine time: 0.05517603503540158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 77.2554090982303,
    "estimated_duration": 3600.076676279433,
    "input_throughput": 6213.529324913672,
    "output_throughput": 5497.057085031914,
    "total_throughput": 11710.586409945587,
    "itl": 151.11316857921793,
    "ttft": 1387886.0775350046,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0549331242148825,
    "arrivals": 159905,
    "finished_requests": 90245,
    "scheduler_time": 152.72308792717544
}
#Debug simulation 
Total elapsed time: 77.25556743424386. Arrivals time: 0.40681192511692643 Scheduler time: 76.70027298852801 Scheduler overhead time: 0.05487734451889992 Adapter cache time: 0.0180359473451972 Engine time: 0.05443237256258726 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.71350234095007,
    "estimated_duration": 3600.0778933392253,
    "input_throughput": 6213.527224337814,
    "output_throughput": 5497.055226670136,
    "total_throughput": 11710.58245100795,
    "itl": 151.11234605175437,
    "ttft": 1387888.1381041477,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0587235749326744,
    "arrivals": 159905,
    "finished_requests": 90245,
    "scheduler_time": 152.72277793699809
}
#Debug simulation 
Total elapsed time: 76.71366211213171. Arrivals time: 0.4069129005074501 Scheduler time: 76.15911698481068 Scheduler overhead time: 0.05469114612787962 Adapter cache time: 0.017692620866000652 Engine time: 0.05434187455102801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 76.06679332396016,
    "estimated_duration": 3600.0419850920866,
    "input_throughput": 6218.918582814062,
    "output_throughput": 5500.292519364464,
    "total_throughput": 11719.211102178526,
    "itl": 151.40818096228364,
    "ttft": 1388120.2152226693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 672,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0996133635495626,
    "arrivals": 159905,
    "finished_requests": 90319,
    "scheduler_time": 152.51722447395977
}
#Debug simulation 
Total elapsed time: 76.06705903680995. Arrivals time: 0.41027934988960624 Scheduler time: 75.50793518824503 Scheduler overhead time: 0.05515566002577543 Adapter cache time: 0.01792525267228484 Engine time: 0.054474151227623224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 76.71993494499475,
    "estimated_duration": 3600.106834319127,
    "input_throughput": 6213.477274273887,
    "output_throughput": 5497.011036269086,
    "total_throughput": 11710.488310542973,
    "itl": 151.1137788424293,
    "ttft": 1387894.8869301693,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.0850061162933726,
    "arrivals": 159905,
    "finished_requests": 90245,
    "scheduler_time": 152.7236486750156
}
#Debug simulation 
Total elapsed time: 76.72009488660842. Arrivals time: 0.4060180024243891 Scheduler time: 76.16545113734901 Scheduler overhead time: 0.05531837046146393 Adapter cache time: 0.01784129673615098 Engine time: 0.0545650995336473 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 78.0072766430676,
    "estimated_duration": 3600.1563544874307,
    "input_throughput": 6213.3206998407595,
    "output_throughput": 5492.712552706727,
    "total_throughput": 11706.033252547486,
    "itl": 150.92798926254474,
    "ttft": 1386528.6435574244,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.904662037852655,
    "arrivals": 159905,
    "finished_requests": 90177,
    "scheduler_time": 152.89831307556605
}
#Debug simulation 
Total elapsed time: 78.00744096795097. Arrivals time: 0.4069100646302104 Scheduler time: 77.45081067597494 Scheduler overhead time: 0.05556519841775298 Adapter cache time: 0.017955146729946136 Engine time: 0.05459875147789717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [106 107 107]
Adapter prompts. [135, 4320, 4320, 33, 4320, 4320, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 4320, 135, 4320, 4320, 33, 4320, 135, 135, 4320, 4320, 135, 33, 33, 135, 4320, 4320, 135, 135, 33, 33, 135, 4320, 4320, 33, 4320, 135, 33, 135, 4320, 33, 135, 4320, 4320, 135, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 135, 135, 135, 33, 135, 33, 4320, 33, 4320, 135, 4320, 4320, 33, 4320, 33, 4320, 135, 33, 33, 135, 135, 4320, 135, 4320, 4320, 4320, 33, 135, 135, 33, 4320, 135, 4320, 4320, 135, 33, 135, 135, 135, 33, 4320, 135, 4320, 33, 4320, 33, 33, 135, 4320, 4320, 135, 33, 135, 33, 135, 4320, 4320, 135, 33, 135, 33, 4320, 33, 33, 33, 33, 4320, 135, 135, 4320, 135, 135, 33, 135, 4320, 135, 33, 33, 135, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 135, 4320, 135, 135, 135, 33, 4320, 33, 4320, 135, 33, 135, 33, 33, 135, 33, 135, 4320, 4320, 4320, 4320, 135, 135, 4320, 4320, 4320, 135, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 135, 33, 135, 33, 33, 33, 4320, 4320, 135, 135, 33, 33, 135, 33, 4320, 33, 33, 135, 33, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 33, 135, 4320, 135, 135, 4320, 135, 33, 135, 33, 4320, 135, 135, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 135, 33, 135, 33, 135, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 135, 135, 4320, 33, 4320, 33, 33, 33, 4320, 135, 4320, 4320, 33, 135, 135, 135, 33, 135, 33, 135, 135, 4320, 33, 33, 135, 33, 135, 135, 33, 4320, 4320, 4320, 33, 135, 135, 135, 135, 33, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 135, 135, 135, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 135, 4320, 135, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 480183 . Total input tokens: 107014508 . Total output tokens: 96108185
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 76.68663350585848,
    "estimated_duration": 3600.1308751045904,
    "input_throughput": 6213.435782206149,
    "output_throughput": 5496.9743285860595,
    "total_throughput": 11710.410110792209,
    "itl": 151.11421610547234,
    "ttft": 1387901.8995166973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 630,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.111414411440491,
    "arrivals": 159905,
    "finished_requests": 90245,
    "scheduler_time": 152.72381405883087
}
#Debug simulation 
Total elapsed time: 76.6867982740514. Arrivals time: 0.411744749173522 Scheduler time: 76.12337696785107 Scheduler overhead time: 0.05669307196512818 Adapter cache time: 0.018423620611429214 Engine time: 0.055502633564174175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 64.41380755510181,
    "estimated_duration": 3600.0282508660225,
    "input_throughput": 6209.770435724275,
    "output_throughput": 5490.18830484049,
    "total_throughput": 11699.958740564764,
    "itl": 150.45837167949207,
    "ttft": 1393589.9050960545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 779,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.384119952523662,
    "arrivals": 157567,
    "finished_requests": 90221,
    "scheduler_time": 151.73811721697493
}
#Debug simulation 
Total elapsed time: 64.4139727409929. Arrivals time: 0.3946117786690593 Scheduler time: 63.873792953789234 Scheduler overhead time: 0.0536146555095911 Adapter cache time: 0.01834761630743742 Engine time: 0.052825499791651964 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 64.53055121563375,
    "estimated_duration": 3600.076903634316,
    "input_throughput": 6209.60318304099,
    "output_throughput": 5491.3685260563825,
    "total_throughput": 11700.971709097374,
    "itl": 150.47060601970102,
    "ttft": 1392718.6873473385,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4095991078368457,
    "arrivals": 157567,
    "finished_requests": 90218,
    "scheduler_time": 151.75280146842113
}
#Debug simulation 
Total elapsed time: 64.5307194776833. Arrivals time: 0.39700826769694686 Scheduler time: 63.98862987011671 Scheduler overhead time: 0.05341933574527502 Adapter cache time: 0.0178991686552763 Engine time: 0.05285225808620453 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 64.83250824129209,
    "estimated_duration": 3600.08003516446,
    "input_throughput": 6209.597781616755,
    "output_throughput": 5491.363749388669,
    "total_throughput": 11700.961531005425,
    "itl": 150.4707861021708,
    "ttft": 1392719.536320108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 737,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.4130461287870966,
    "arrivals": 157567,
    "finished_requests": 90218,
    "scheduler_time": 151.7528067805084
}
#Debug simulation 
Total elapsed time: 64.8326732153073. Arrivals time: 0.39386358205229044 Scheduler time: 64.29346874682233 Scheduler overhead time: 0.05287067871540785 Adapter cache time: 0.018206015694886446 Engine time: 0.05336757097393274 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 65.99283844511956,
    "estimated_duration": 3600.147032307185,
    "input_throughput": 6203.949949701454,
    "output_throughput": 5491.211281815554,
    "total_throughput": 11695.161231517008,
    "itl": 150.52030530375967,
    "ttft": 1392607.0402054973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.2991484887921065,
    "arrivals": 157567,
    "finished_requests": 90231,
    "scheduler_time": 151.72228122230516
}
#Debug simulation 
Total elapsed time: 65.99301422107965. Arrivals time: 0.3883421537466347 Scheduler time: 65.45799807365984 Scheduler overhead time: 0.05366058088839054 Adapter cache time: 0.018231992609798908 Engine time: 0.05365727888420224 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 64.29587894212455,
    "estimated_duration": 3600.143579430258,
    "input_throughput": 6208.595437056791,
    "output_throughput": 5492.515107725042,
    "total_throughput": 11701.110544781832,
    "itl": 150.61567823760763,
    "ttft": 1392831.7737383745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 745,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.472153762876989,
    "arrivals": 157567,
    "finished_requests": 90224,
    "scheduler_time": 151.73334335047147
}
#Debug simulation 
Total elapsed time: 64.2960395491682. Arrivals time: 0.38787442445755005 Scheduler time: 63.76245510857552 Scheduler overhead time: 0.054578949231654406 Adapter cache time: 0.017855643294751644 Engine time: 0.05253922985866666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 65.11145250871778,
    "estimated_duration": 3600.0245158373727,
    "input_throughput": 6207.580504434965,
    "output_throughput": 5489.443450471417,
    "total_throughput": 11697.023954906383,
    "itl": 150.46067552927144,
    "ttft": 1393942.5193264417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 776,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.320279028844043,
    "arrivals": 157567,
    "finished_requests": 90208,
    "scheduler_time": 151.7354699764964
}
#Debug simulation 
Total elapsed time: 65.11170729296282. Arrivals time: 0.3868531258776784 Scheduler time: 64.57772574201226 Scheduler overhead time: 0.05448094103485346 Adapter cache time: 0.018375585786998272 Engine time: 0.05309835495427251 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [106 107 107]
Adapter prompts. [66, 4320, 4320, 33, 4320, 4320, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 4320, 66, 4320, 4320, 33, 4320, 66, 66, 4320, 4320, 66, 33, 33, 66, 4320, 4320, 66, 66, 33, 33, 66, 4320, 4320, 33, 4320, 66, 33, 66, 4320, 33, 66, 4320, 4320, 66, 33, 33, 4320, 33, 33, 4320, 4320, 33, 33, 66, 66, 66, 33, 66, 33, 4320, 33, 4320, 66, 4320, 4320, 33, 4320, 33, 4320, 66, 33, 33, 66, 66, 4320, 66, 4320, 4320, 4320, 33, 66, 66, 33, 4320, 66, 4320, 4320, 66, 33, 66, 66, 66, 33, 4320, 66, 4320, 33, 4320, 33, 33, 66, 4320, 4320, 66, 33, 66, 33, 66, 4320, 4320, 66, 33, 66, 33, 4320, 33, 33, 33, 33, 4320, 66, 66, 4320, 66, 66, 33, 66, 4320, 66, 33, 33, 66, 4320, 33, 33, 33, 4320, 4320, 4320, 33, 66, 4320, 66, 66, 66, 33, 4320, 33, 4320, 66, 33, 66, 33, 33, 66, 33, 66, 4320, 4320, 4320, 4320, 66, 66, 4320, 4320, 4320, 66, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 66, 33, 66, 33, 33, 33, 4320, 4320, 66, 66, 33, 33, 66, 33, 4320, 33, 33, 66, 33, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 33, 66, 4320, 66, 66, 4320, 66, 33, 66, 33, 4320, 66, 66, 4320, 4320, 33, 33, 33, 4320, 4320, 33, 33, 4320, 66, 33, 66, 33, 66, 4320, 4320, 4320, 33, 4320, 4320, 4320, 4320, 33, 66, 66, 4320, 33, 4320, 33, 33, 33, 4320, 66, 4320, 4320, 33, 66, 66, 66, 33, 66, 33, 66, 66, 4320, 33, 33, 66, 33, 66, 66, 33, 4320, 4320, 4320, 33, 66, 66, 66, 66, 33, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 66, 66, 66, 33, 33, 4320, 33, 33, 4320, 4320, 4320, 33, 4320, 4320, 66, 4320, 66, 33, 4320, 33, 4320, 4320, 33, 33, 33]
Prompts retrieved: 472800 . Total input tokens: 105331521 . Total output tokens: 94640994
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 65.0317472871393,
    "estimated_duration": 3600.071057141337,
    "input_throughput": 6209.3249397555965,
    "output_throughput": 5492.683807108444,
    "total_throughput": 11702.008746864041,
    "itl": 150.4669691877036,
    "ttft": 1392782.29762052,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 753,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 2.530215352810932,
    "arrivals": 157567,
    "finished_requests": 90218,
    "scheduler_time": 151.74225736735838
}
#Debug simulation 
Total elapsed time: 65.0319045833312. Arrivals time: 0.3897747341543436 Scheduler time: 64.49403508100659 Scheduler overhead time: 0.05508876405656338 Adapter cache time: 0.018193709198385477 Engine time: 0.05397358210757375 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 13.950262003112584,
    "estimated_duration": 3600.063198039379,
    "input_throughput": 4551.437877236056,
    "output_throughput": 4015.5950617403214,
    "total_throughput": 8567.032938976377,
    "itl": 66.92393604346427,
    "ttft": 195042.53620433024,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4219,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.912197791651275,
    "arrivals": 67679,
    "finished_requests": 65546,
    "scheduler_time": 62.39314534670158
}
#Debug simulation 
Total elapsed time: 13.95035828417167. Arrivals time: 0.1955405669286847 Scheduler time: 13.515967129264027 Scheduler overhead time: 0.0758637860417366 Adapter cache time: 0.05598399182781577 Engine time: 0.07331086462363601 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.093833439983428,
    "estimated_duration": 3600.044641879722,
    "input_throughput": 4551.371893945373,
    "output_throughput": 4015.1674320495654,
    "total_throughput": 8566.539325994938,
    "itl": 66.97815893529308,
    "ttft": 196291.63225169067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4194,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.687197995682455,
    "arrivals": 67679,
    "finished_requests": 65533,
    "scheduler_time": 62.47282426235586
}
#Debug simulation 
Total elapsed time: 14.093977401033044. Arrivals time: 0.19047917099669576 Scheduler time: 13.662728347349912 Scheduler overhead time: 0.07714739441871643 Adapter cache time: 0.05554834706708789 Engine time: 0.07382498588413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.123692518100142,
    "estimated_duration": 3600.0323284322562,
    "input_throughput": 4550.502191499491,
    "output_throughput": 4014.5792263742896,
    "total_throughput": 8565.081417873782,
    "itl": 66.93728244170146,
    "ttft": 196391.49643031656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4193,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.708465497529971,
    "arrivals": 67679,
    "finished_requests": 65531,
    "scheduler_time": 62.476328037012955
}
#Debug simulation 
Total elapsed time: 14.123784291092306. Arrivals time: 0.1915779714472592 Scheduler time: 13.69136890117079 Scheduler overhead time: 0.0766337332315743 Adapter cache time: 0.055996797513216734 Engine time: 0.07429460436105728 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 14.12777430191636,
    "estimated_duration": 3600.0388893661902,
    "input_throughput": 4551.3275004883835,
    "output_throughput": 4014.4599667211937,
    "total_throughput": 8565.787467209579,
    "itl": 66.87891478846848,
    "ttft": 195576.49908121838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.154443799018292,
    "arrivals": 67679,
    "finished_requests": 65544,
    "scheduler_time": 62.46260366768975
}
#Debug simulation 
Total elapsed time: 14.127897861879319. Arrivals time: 0.19795555481687188 Scheduler time: 13.687052499037236 Scheduler overhead time: 0.07755689695477486 Adapter cache time: 0.056632482912391424 Engine time: 0.074679059907794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_320_slots_64_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 14.191353652160615,
    "estimated_duration": 3600.005076986654,
    "input_throughput": 4549.920527809501,
    "output_throughput": 4014.346005338585,
    "total_throughput": 8564.266533148086,
    "itl": 66.98676031402135,
    "ttft": 196990.7389442602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4180,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 13.83935331204808,
    "arrivals": 67679,
    "finished_requests": 65522,
    "scheduler_time": 62.487159375246335
}
#Debug simulation 
Total elapsed time: 14.19145464291796. Arrivals time: 0.19966636784374714 Scheduler time: 13.751233916264027 Scheduler overhead time: 0.07691545551642776 Adapter cache time: 0.05561460088938475 Engine time: 0.0740081719122827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_320_slots_64_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 14.117065061815083,
    "estimated_duration": 3600.0573139419785,
    "input_throughput": 4553.201121693082,
    "output_throughput": 4017.029657832018,
    "total_throughput": 8570.2307795251,
    "itl": 66.91664880760922,
    "ttft": 194695.34159039636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4198,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 12.552231138000275,
    "arrivals": 67679,
    "finished_requests": 65564,
    "scheduler_time": 62.47422501122052
}
#Debug simulation 
Total elapsed time: 14.11721710069105. Arrivals time: 0.19437987357378006 Scheduler time: 13.680475739296526 Scheduler overhead time: 0.07698634406551719 Adapter cache time: 0.0563705712556839 Engine time: 0.07502489816397429 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_320_slots_64_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 270, 1080, 1080, 540, 540, 540, 540, 270, 540, 270, 540, 270, 540, 540, 1080, 540, 1080, 1080, 270, 1080, 540, 540, 1080, 1080, 540, 270, 270, 540, 1080, 1080, 540, 540, 270, 270, 540, 1080, 1080, 270, 1080, 540, 270, 540, 1080, 270, 540, 1080, 1080, 540, 270, 270, 1080, 270, 270, 1080, 1080, 270, 270, 540, 540, 540, 270, 540, 270, 1080, 270, 1080, 540, 1080, 1080, 270, 1080, 270, 1080, 540, 270, 270, 540, 540, 1080, 540, 1080, 1080, 1080, 270, 540, 540, 270, 1080, 540, 1080, 1080, 540, 270, 540, 540, 540, 270, 1080, 540, 1080, 270, 1080, 270, 270, 540, 1080, 1080, 540, 270, 540, 270, 540, 1080, 1080, 540, 270, 540, 270, 1080, 270, 270, 270, 270, 1080, 540, 540, 1080, 540, 540, 270, 540, 1080, 540, 270, 270, 540, 1080, 270, 270, 270, 1080, 1080, 1080, 270, 540, 1080, 540, 540, 540, 270, 1080, 270, 1080, 540, 270, 540, 270, 270, 540, 270, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 540, 270, 540, 270, 270, 270, 1080, 1080, 540, 540, 270, 270, 540, 270, 1080, 270, 270, 540, 270, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 270, 540, 1080, 540, 540, 1080, 540, 270, 540, 270, 1080, 540, 540, 1080, 1080, 270, 270, 270, 1080, 1080, 270, 270, 1080, 540, 270, 540, 270, 540, 1080, 1080, 1080, 270, 1080, 1080, 1080, 1080, 270, 540, 540, 1080, 270, 1080, 270, 270, 270, 1080, 540, 1080, 1080, 270, 540, 540, 540, 270, 540, 270, 540, 540, 1080, 270, 270, 540, 270, 540, 540, 270, 1080, 1080, 1080, 270, 540, 540, 540, 540, 270, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 540, 540, 540, 270, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 1080, 540, 1080, 540, 270, 1080, 270, 1080, 1080, 270, 270, 270]
Prompts retrieved: 201960 . Total input tokens: 44943431 . Total output tokens: 40351513
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 14.09589670272544,
    "estimated_duration": 3600.0778132893943,
    "input_throughput": 4550.792746624176,
    "output_throughput": 4014.9084963231344,
    "total_throughput": 8565.70124294731,
    "itl": 66.96582323467344,
    "ttft": 196823.60334752407,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 4197,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 14.07144119877275,
    "arrivals": 67679,
    "finished_requests": 65524,
    "scheduler_time": 62.496965660069705
}
#Debug simulation 
Total elapsed time: 14.09601269196719. Arrivals time: 0.19924179930239916 Scheduler time: 13.656814262736589 Scheduler overhead time: 0.07682469673454762 Adapter cache time: 0.05605460423976183 Engine time: 0.07348352391272783 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.193980283103883,
    "estimated_duration": 3600.0205224405704,
    "input_throughput": 4252.855478062833,
    "output_throughput": 3740.3475663720433,
    "total_throughput": 7993.203044434876,
    "itl": 60.75705625419839,
    "ttft": 142349.9848385538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5147,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.752330418020145,
    "arrivals": 62899,
    "finished_requests": 61455,
    "scheduler_time": 53.94720691075805
}
#Debug simulation 
Total elapsed time: 11.1940708020702. Arrivals time: 0.1817999007180333 Scheduler time: 10.755074262153357 Scheduler overhead time: 0.08137671742588282 Adapter cache time: 0.06445851316675544 Engine time: 0.07594389794394374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.089441690128297,
    "estimated_duration": 3600.010887504109,
    "input_throughput": 4252.680194146365,
    "output_throughput": 3742.744514126034,
    "total_throughput": 7995.424708272399,
    "itl": 60.78672006613469,
    "ttft": 142006.86926495263,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5146,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.794818284912843,
    "arrivals": 62899,
    "finished_requests": 61463,
    "scheduler_time": 53.95479110987187
}
#Debug simulation 
Total elapsed time: 11.089561786968261. Arrivals time: 0.17005930375307798 Scheduler time: 10.664744100999087 Scheduler overhead time: 0.08047671522945166 Adapter cache time: 0.06381349405273795 Engine time: 0.07529865996912122 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.09739467734471,
    "estimated_duration": 3600.051310902011,
    "input_throughput": 4254.473249761103,
    "output_throughput": 3741.029179005104,
    "total_throughput": 7995.502428766207,
    "itl": 60.8431520172538,
    "ttft": 141309.91687784012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5166,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.8893574563215,
    "arrivals": 62899,
    "finished_requests": 61474,
    "scheduler_time": 53.9658247023275
}
#Debug simulation 
Total elapsed time: 11.097486232407391. Arrivals time: 0.1815488701686263 Scheduler time: 10.657650770619512 Scheduler overhead time: 0.08156612096354365 Adapter cache time: 0.06465431023389101 Engine time: 0.07675191620364785 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 11.133151005022228,
    "estimated_duration": 3600.0403620703805,
    "input_throughput": 4255.287013279467,
    "output_throughput": 3744.0488562323767,
    "total_throughput": 7999.335869511844,
    "itl": 60.884138731627,
    "ttft": 140088.07664070785,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.11662310100535,
    "arrivals": 62899,
    "finished_requests": 61494,
    "scheduler_time": 53.97545131299626
}
#Debug simulation 
Total elapsed time: 11.133260309230536. Arrivals time: 0.18662272952497005 Scheduler time: 10.690528334584087 Scheduler overhead time: 0.08087009331211448 Adapter cache time: 0.06461803102865815 Engine time: 0.0754788713529706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 11.09354643104598,
    "estimated_duration": 3600.006492859478,
    "input_throughput": 4253.3503843315675,
    "output_throughput": 3743.575192636758,
    "total_throughput": 7996.925576968326,
    "itl": 60.841834062937686,
    "ttft": 140958.00292283882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.134540680440786,
    "arrivals": 62899,
    "finished_requests": 61476,
    "scheduler_time": 53.918939742208835
}
#Debug simulation 
Total elapsed time: 11.093635611236095. Arrivals time: 0.1699906070716679 Scheduler time: 10.665449841413647 Scheduler overhead time: 0.0815023216418922 Adapter cache time: 0.06485251570120454 Engine time: 0.076541050337255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 11.119935269001871,
    "estimated_duration": 3600.0137970979317,
    "input_throughput": 4252.316202882475,
    "output_throughput": 3739.2609469584786,
    "total_throughput": 7991.577149840954,
    "itl": 60.780810768144015,
    "ttft": 142235.65319694066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5164,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 15.440619722876532,
    "arrivals": 62899,
    "finished_requests": 61456,
    "scheduler_time": 53.94853116584731
}
#Debug simulation 
Total elapsed time: 11.12002952490002. Arrivals time: 0.1807630555704236 Scheduler time: 10.683236979879439 Scheduler overhead time: 0.08080865675583482 Adapter cache time: 0.06412711273878813 Engine time: 0.07590814307332039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 135, 1080, 1080, 540, 540, 540, 540, 135, 540, 135, 540, 135, 540, 540, 1080, 540, 1080, 1080, 135, 1080, 540, 540, 1080, 1080, 540, 135, 135, 540, 1080, 1080, 540, 540, 135, 135, 540, 1080, 1080, 135, 1080, 540, 135, 540, 1080, 135, 540, 1080, 1080, 540, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 540, 540, 540, 135, 540, 135, 1080, 135, 1080, 540, 1080, 1080, 135, 1080, 135, 1080, 540, 135, 135, 540, 540, 1080, 540, 1080, 1080, 1080, 135, 540, 540, 135, 1080, 540, 1080, 1080, 540, 135, 540, 540, 540, 135, 1080, 540, 1080, 135, 1080, 135, 135, 540, 1080, 1080, 540, 135, 540, 135, 540, 1080, 1080, 540, 135, 540, 135, 1080, 135, 135, 135, 135, 1080, 540, 540, 1080, 540, 540, 135, 540, 1080, 540, 135, 135, 540, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 540, 1080, 540, 540, 540, 135, 1080, 135, 1080, 540, 135, 540, 135, 135, 540, 135, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 540, 135, 540, 135, 135, 135, 1080, 1080, 540, 540, 135, 135, 540, 135, 1080, 135, 135, 540, 135, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 135, 540, 1080, 540, 540, 1080, 540, 135, 540, 135, 1080, 540, 540, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 540, 135, 540, 135, 540, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 540, 540, 1080, 135, 1080, 135, 135, 135, 1080, 540, 1080, 1080, 135, 540, 540, 540, 135, 540, 135, 540, 540, 1080, 135, 135, 540, 135, 540, 540, 135, 1080, 1080, 1080, 135, 540, 540, 540, 540, 135, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 540, 540, 540, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 540, 1080, 540, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 187650 . Total input tokens: 41734352 . Total output tokens: 37529193
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 11.162056325003505,
    "estimated_duration": 3600.000780528202,
    "input_throughput": 4255.773521735762,
    "output_throughput": 3742.3927997102437,
    "total_throughput": 7998.166321446006,
    "itl": 60.90790365174532,
    "ttft": 140260.90007597065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5149,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.267969970292096,
    "arrivals": 62899,
    "finished_requests": 61493,
    "scheduler_time": 53.9854699855149
}
#Debug simulation 
Total elapsed time: 11.16216036817059. Arrivals time: 0.1837770394049585 Scheduler time: 10.720982886385173 Scheduler overhead time: 0.08081283792853355 Adapter cache time: 0.06479036714881659 Engine time: 0.07663203356787562 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.8904796121642,
    "estimated_duration": 3600.018679902914,
    "input_throughput": 4079.564387259254,
    "output_throughput": 3653.1402110265353,
    "total_throughput": 7732.70459828579,
    "itl": 59.023863832232166,
    "ttft": 125380.37864039472,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5454,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.691900155407662,
    "arrivals": 60544,
    "finished_requests": 59270,
    "scheduler_time": 50.555856895030914
}
#Debug simulation 
Total elapsed time: 9.890644099097699. Arrivals time: 0.17055958835408092 Scheduler time: 9.458862246014178 Scheduler overhead time: 0.08248424110934138 Adapter cache time: 0.06715438514947891 Engine time: 0.0760443527251482 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.88818705221638,
    "estimated_duration": 3600.0330718598934,
    "input_throughput": 4078.913361874661,
    "output_throughput": 3654.2022635374215,
    "total_throughput": 7733.115625412082,
    "itl": 59.06850120271878,
    "ttft": 126238.29146619128,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5448,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.78075832361633,
    "arrivals": 60544,
    "finished_requests": 59255,
    "scheduler_time": 50.555325005544006
}
#Debug simulation 
Total elapsed time: 9.888284276239574. Arrivals time: 0.170952164568007 Scheduler time: 9.455638511572033 Scheduler overhead time: 0.08277119603008032 Adapter cache time: 0.06717495806515217 Engine time: 0.07639391720294952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.917204742785543,
    "estimated_duration": 3600.0328914783718,
    "input_throughput": 4079.266063030143,
    "output_throughput": 3652.498851086955,
    "total_throughput": 7731.764914117098,
    "itl": 59.05144057700585,
    "ttft": 125980.35730466987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5456,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.83942742137131,
    "arrivals": 60544,
    "finished_requests": 59264,
    "scheduler_time": 50.58827845624602
}
#Debug simulation 
Total elapsed time: 9.917297801934183. Arrivals time: 0.16516464203596115 Scheduler time: 9.491293374914676 Scheduler overhead time: 0.08231130288913846 Adapter cache time: 0.06715232180431485 Engine time: 0.07589443773031235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 9.872292350046337,
    "estimated_duration": 3600.021326632012,
    "input_throughput": 4078.1130632176105,
    "output_throughput": 3652.5486398442367,
    "total_throughput": 7730.661703061847,
    "itl": 59.04052768307009,
    "ttft": 126531.240537188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5465,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.091623056934825,
    "arrivals": 60544,
    "finished_requests": 59250,
    "scheduler_time": 50.55449312094539
}
#Debug simulation 
Total elapsed time: 9.872437953017652. Arrivals time: 0.17284209793433547 Scheduler time: 9.438133971299976 Scheduler overhead time: 0.08216663636267185 Adapter cache time: 0.0675606345757842 Engine time: 0.07626798609271646 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 9.998924043029547,
    "estimated_duration": 3600.0430243982737,
    "input_throughput": 4079.6223546397246,
    "output_throughput": 3653.8421654554013,
    "total_throughput": 7733.464520095125,
    "itl": 59.07928322066944,
    "ttft": 125784.73192086615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5421,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.953179197924893,
    "arrivals": 60544,
    "finished_requests": 59268,
    "scheduler_time": 50.61363873770452
}
#Debug simulation 
Total elapsed time: 9.999019457027316. Arrivals time: 0.16828390257433057 Scheduler time: 9.56675619399175 Scheduler overhead time: 0.08270908985286951 Adapter cache time: 0.06717681651934981 Engine time: 0.07847176166251302 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 9.929092360194772,
    "estimated_duration": 3600.048504532827,
    "input_throughput": 4079.525034595567,
    "output_throughput": 3652.3863451962843,
    "total_throughput": 7731.911379791851,
    "itl": 59.00745959856836,
    "ttft": 126463.81907652227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5452,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.301754207808404,
    "arrivals": 60544,
    "finished_requests": 59252,
    "scheduler_time": 50.558985651302336
}
#Debug simulation 
Total elapsed time: 9.92919636098668. Arrivals time: 0.16723543871194124 Scheduler time: 9.500864524394274 Scheduler overhead time: 0.0830524330958724 Adapter cache time: 0.06663361052051187 Engine time: 0.07576284324750304 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 66, 1080, 1080, 540, 540, 540, 540, 66, 540, 66, 540, 66, 540, 540, 1080, 540, 1080, 1080, 66, 1080, 540, 540, 1080, 1080, 540, 66, 66, 540, 1080, 1080, 540, 540, 66, 66, 540, 1080, 1080, 66, 1080, 540, 66, 540, 1080, 66, 540, 1080, 1080, 540, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 540, 540, 540, 66, 540, 66, 1080, 66, 1080, 540, 1080, 1080, 66, 1080, 66, 1080, 540, 66, 66, 540, 540, 1080, 540, 1080, 1080, 1080, 66, 540, 540, 66, 1080, 540, 1080, 1080, 540, 66, 540, 540, 540, 66, 1080, 540, 1080, 66, 1080, 66, 66, 540, 1080, 1080, 540, 66, 540, 66, 540, 1080, 1080, 540, 66, 540, 66, 1080, 66, 66, 66, 66, 1080, 540, 540, 1080, 540, 540, 66, 540, 1080, 540, 66, 66, 540, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 540, 1080, 540, 540, 540, 66, 1080, 66, 1080, 540, 66, 540, 66, 66, 540, 66, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 540, 66, 540, 66, 66, 66, 1080, 1080, 540, 540, 66, 66, 540, 66, 1080, 66, 66, 540, 66, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 66, 540, 1080, 540, 540, 1080, 540, 66, 540, 66, 1080, 540, 540, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 540, 66, 540, 66, 540, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 540, 540, 1080, 66, 1080, 66, 66, 66, 1080, 540, 1080, 1080, 66, 540, 540, 540, 66, 540, 66, 540, 540, 1080, 66, 66, 540, 66, 540, 540, 66, 1080, 1080, 1080, 66, 540, 540, 540, 540, 66, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 540, 540, 540, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 540, 1080, 540, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 180336 . Total input tokens: 40127028 . Total output tokens: 36039199
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 9.980803825892508,
    "estimated_duration": 3600.0605982294137,
    "input_throughput": 4078.6563446242026,
    "output_throughput": 3654.5454280604854,
    "total_throughput": 7733.201772684688,
    "itl": 59.114209285961266,
    "ttft": 125963.93926087345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5446,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.266347329689708,
    "arrivals": 60544,
    "finished_requests": 59263,
    "scheduler_time": 50.588367960853965
}
#Debug simulation 
Total elapsed time: 9.980920263100415. Arrivals time: 0.17316214507445693 Scheduler time: 9.543181191664189 Scheduler overhead time: 0.08310017874464393 Adapter cache time: 0.0678008277900517 Engine time: 0.07801205990836024 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.838239768985659,
    "estimated_duration": 3600.0099255803857,
    "input_throughput": 4053.422990951185,
    "output_throughput": 3537.613857535912,
    "total_throughput": 7591.036848487097,
    "itl": 56.58582000364873,
    "ttft": 97235.08326034242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5628,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.224425022852135,
    "arrivals": 59315,
    "finished_requests": 58375,
    "scheduler_time": 46.96452281669066
}
#Debug simulation 
Total elapsed time: 8.83840305916965. Arrivals time: 0.1686536706984043 Scheduler time: 8.400901653803885 Scheduler overhead time: 0.0855983910150826 Adapter cache time: 0.06965076457709074 Engine time: 0.0775166661478579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.943087044171989,
    "estimated_duration": 3600.0315830222844,
    "input_throughput": 4052.727500726953,
    "output_throughput": 3536.0670334211345,
    "total_throughput": 7588.794534148088,
    "itl": 56.62266212560105,
    "ttft": 99395.1110164245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5549,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.11380664760279,
    "arrivals": 59315,
    "finished_requests": 58354,
    "scheduler_time": 47.09237218274965
}
#Debug simulation 
Total elapsed time: 8.943189406767488. Arrivals time: 0.16386850457638502 Scheduler time: 8.513351627625525 Scheduler overhead time: 0.08445894625037909 Adapter cache time: 0.06820054352283478 Engine time: 0.0774737261235714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.835682284086943,
    "estimated_duration": 3600.0328482258856,
    "input_throughput": 4054.0610642462243,
    "output_throughput": 3536.7810619491024,
    "total_throughput": 7590.842126195327,
    "itl": 56.63218359696727,
    "ttft": 98254.51549991356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5539,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.112274335491364,
    "arrivals": 59315,
    "finished_requests": 58373,
    "scheduler_time": 47.10022482061245
}
#Debug simulation 
Total elapsed time: 8.835779127199203. Arrivals time: 0.16077200463041663 Scheduler time: 8.410129234660417 Scheduler overhead time: 0.08408382022753358 Adapter cache time: 0.06807372579351068 Engine time: 0.07706321682780981 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 8.956557645928115,
    "estimated_duration": 3600.0484490151093,
    "input_throughput": 4053.5121142584253,
    "output_throughput": 3537.735722274594,
    "total_throughput": 7591.247836533019,
    "itl": 56.57898028057296,
    "ttft": 97077.36923956689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5619,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 17.568026019768762,
    "arrivals": 59315,
    "finished_requests": 58380,
    "scheduler_time": 46.9836494339402
}
#Debug simulation 
Total elapsed time: 8.956648136954755. Arrivals time: 0.16510196588933468 Scheduler time: 8.522628786042333 Scheduler overhead time: 0.08526897244155407 Adapter cache time: 0.0694580851122737 Engine time: 0.07819232298061252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 8.968209637794644,
    "estimated_duration": 3600.0200158823086,
    "input_throughput": 4054.3116248265765,
    "output_throughput": 3538.371437881593,
    "total_throughput": 7592.68306270817,
    "itl": 56.63527827540811,
    "ttft": 98014.94953180538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.455103999542782,
    "arrivals": 59315,
    "finished_requests": 58373,
    "scheduler_time": 47.06257643431781
}
#Debug simulation 
Total elapsed time: 8.968312535900623. Arrivals time: 0.16571925906464458 Scheduler time: 8.53495736606419 Scheduler overhead time: 0.08478263998404145 Adapter cache time: 0.06893572444096208 Engine time: 0.07801800360903144 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 8.849449139088392,
    "estimated_duration": 3600.0351940241662,
    "input_throughput": 4054.2959202809457,
    "output_throughput": 3538.0276340472074,
    "total_throughput": 7592.3235543281535,
    "itl": 56.586262389053886,
    "ttft": 96992.02954849036,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5612,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 16.780162254992593,
    "arrivals": 59315,
    "finished_requests": 58384,
    "scheduler_time": 47.01065364743938
}
#Debug simulation 
Total elapsed time: 8.849565126001835. Arrivals time: 0.16896320367231965 Scheduler time: 8.414772067219019 Scheduler overhead time: 0.08461670391261578 Adapter cache time: 0.06861024256795645 Engine time: 0.07689964957535267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [106 107 107]
Adapter prompts. [540, 1080, 1080, 33, 1080, 1080, 540, 540, 540, 540, 33, 540, 33, 540, 33, 540, 540, 1080, 540, 1080, 1080, 33, 1080, 540, 540, 1080, 1080, 540, 33, 33, 540, 1080, 1080, 540, 540, 33, 33, 540, 1080, 1080, 33, 1080, 540, 33, 540, 1080, 33, 540, 1080, 1080, 540, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 540, 540, 540, 33, 540, 33, 1080, 33, 1080, 540, 1080, 1080, 33, 1080, 33, 1080, 540, 33, 33, 540, 540, 1080, 540, 1080, 1080, 1080, 33, 540, 540, 33, 1080, 540, 1080, 1080, 540, 33, 540, 540, 540, 33, 1080, 540, 1080, 33, 1080, 33, 33, 540, 1080, 1080, 540, 33, 540, 33, 540, 1080, 1080, 540, 33, 540, 33, 1080, 33, 33, 33, 33, 1080, 540, 540, 1080, 540, 540, 33, 540, 1080, 540, 33, 33, 540, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 540, 1080, 540, 540, 540, 33, 1080, 33, 1080, 540, 33, 540, 33, 33, 540, 33, 540, 1080, 1080, 1080, 1080, 540, 540, 1080, 1080, 1080, 540, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 540, 33, 540, 33, 33, 33, 1080, 1080, 540, 540, 33, 33, 540, 33, 1080, 33, 33, 540, 33, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 33, 540, 1080, 540, 540, 1080, 540, 33, 540, 33, 1080, 540, 540, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 540, 33, 540, 33, 540, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 540, 540, 1080, 33, 1080, 33, 33, 33, 1080, 540, 1080, 1080, 33, 540, 540, 540, 33, 540, 33, 540, 540, 1080, 33, 33, 540, 33, 540, 540, 33, 1080, 1080, 1080, 33, 540, 540, 540, 540, 33, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 540, 540, 540, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 540, 1080, 540, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 176838 . Total input tokens: 39355514 . Total output tokens: 35329103
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 8.948615450877696,
    "estimated_duration": 3600.019783750617,
    "input_throughput": 4053.7121673248357,
    "output_throughput": 3536.3775103303465,
    "total_throughput": 7590.089677655183,
    "itl": 56.62285101825017,
    "ttft": 98435.77681023694,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5543,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.594904750248904,
    "arrivals": 59315,
    "finished_requests": 58370,
    "scheduler_time": 47.10019401573104
}
#Debug simulation 
Total elapsed time: 8.948707398027182. Arrivals time: 0.16296416288241744 Scheduler time: 8.520393469836563 Scheduler overhead time: 0.08427188219502568 Adapter cache time: 0.06825635815039277 Engine time: 0.07698196964338422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.5020559430122375,
    "estimated_duration": 3600.0043692351314,
    "input_throughput": 3627.0067090985735,
    "output_throughput": 3183.8980802224037,
    "total_throughput": 6810.904789320977,
    "itl": 51.31605218915729,
    "ttft": 85566.72988090977,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7642,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.388247339134704,
    "arrivals": 53129,
    "finished_requests": 52383,
    "scheduler_time": 39.67213460155718
}
#Debug simulation 
Total elapsed time: 7.502147836145014. Arrivals time: 0.14933508588001132 Scheduler time: 7.055972017347813 Scheduler overhead time: 0.09008492855355144 Adapter cache time: 0.0874929167330265 Engine time: 0.08119858615100384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.621727152727544,
    "estimated_duration": 3600.004184560236,
    "input_throughput": 3628.990226186612,
    "output_throughput": 3184.5493539059457,
    "total_throughput": 6813.539580092558,
    "itl": 51.3704684799605,
    "ttft": 85975.1613202979,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7489,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.45098987282289,
    "arrivals": 53129,
    "finished_requests": 52389,
    "scheduler_time": 39.811555274345636
}
#Debug simulation 
Total elapsed time: 7.621839080005884. Arrivals time: 0.1537980162538588 Scheduler time: 7.169494004454464 Scheduler overhead time: 0.09049654379487038 Adapter cache time: 0.08692906005308032 Engine time: 0.08275019098073244 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.851382550783455,
    "estimated_duration": 3600.020365417836,
    "input_throughput": 3628.4897511916956,
    "output_throughput": 3184.901427264352,
    "total_throughput": 6813.391178456048,
    "itl": 51.39525648835457,
    "ttft": 85598.4426637929,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7498,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.521717937980068,
    "arrivals": 53129,
    "finished_requests": 52393,
    "scheduler_time": 39.80408887452295
}
#Debug simulation 
Total elapsed time: 7.851558436173946. Arrivals time: 0.1525498814880848 Scheduler time: 7.401998969260603 Scheduler overhead time: 0.09063552040606737 Adapter cache time: 0.08645070157945156 Engine time: 0.08144104154780507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 7.463775283657014,
    "estimated_duration": 3600.0363358603545,
    "input_throughput": 3627.216167216631,
    "output_throughput": 3184.2836934201073,
    "total_throughput": 6811.499860636739,
    "itl": 51.32863262331639,
    "ttft": 85442.20403765616,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7648,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.920854791031307,
    "arrivals": 53129,
    "finished_requests": 52381,
    "scheduler_time": 39.640561535229914
}
#Debug simulation 
Total elapsed time: 7.463867945596576. Arrivals time: 0.14835541928187013 Scheduler time: 7.019452264066786 Scheduler overhead time: 0.08950124401599169 Adapter cache time: 0.087789093144238 Engine time: 0.08082725433632731 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 7.565308935008943,
    "estimated_duration": 3600.0025122600337,
    "input_throughput": 3628.6369122001415,
    "output_throughput": 3184.794444157834,
    "total_throughput": 6813.431356357975,
    "itl": 51.39043951267005,
    "ttft": 85786.56487707015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7503,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.85232602855103,
    "arrivals": 53129,
    "finished_requests": 52390,
    "scheduler_time": 39.80083053594864
}
#Debug simulation 
Total elapsed time: 7.56541177816689. Arrivals time: 0.15246637305244803 Scheduler time: 7.116572978440672 Scheduler overhead time: 0.09010260784998536 Adapter cache time: 0.0869533596560359 Engine time: 0.0812827660702169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 7.477844411041588,
    "estimated_duration": 3600.041894512621,
    "input_throughput": 3628.1072228378225,
    "output_throughput": 3185.0551565740398,
    "total_throughput": 6813.162379411862,
    "itl": 51.29572958583452,
    "ttft": 85649.13469647327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.77222304597456,
    "arrivals": 53129,
    "finished_requests": 52383,
    "scheduler_time": 39.69052364888014
}
#Debug simulation 
Total elapsed time: 7.477936374023557. Arrivals time: 0.15321052493527532 Scheduler time: 7.026486239861697 Scheduler overhead time: 0.09003370208665729 Adapter cache time: 0.08769728802144527 Engine time: 0.08278163941577077 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 135, 1080, 1080, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 1080, 270, 1080, 1080, 135, 1080, 270, 270, 1080, 1080, 270, 135, 135, 270, 1080, 1080, 270, 270, 135, 135, 270, 1080, 1080, 135, 1080, 270, 135, 270, 1080, 135, 270, 1080, 1080, 270, 135, 135, 1080, 135, 135, 1080, 1080, 135, 135, 270, 270, 270, 135, 270, 135, 1080, 135, 1080, 270, 1080, 1080, 135, 1080, 135, 1080, 270, 135, 135, 270, 270, 1080, 270, 1080, 1080, 1080, 135, 270, 270, 135, 1080, 270, 1080, 1080, 270, 135, 270, 270, 270, 135, 1080, 270, 1080, 135, 1080, 135, 135, 270, 1080, 1080, 270, 135, 270, 135, 270, 1080, 1080, 270, 135, 270, 135, 1080, 135, 135, 135, 135, 1080, 270, 270, 1080, 270, 270, 135, 270, 1080, 270, 135, 135, 270, 1080, 135, 135, 135, 1080, 1080, 1080, 135, 270, 1080, 270, 270, 270, 135, 1080, 135, 1080, 270, 135, 270, 135, 135, 270, 135, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 270, 135, 270, 135, 135, 135, 1080, 1080, 270, 270, 135, 135, 270, 135, 1080, 135, 135, 270, 135, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 135, 270, 1080, 270, 270, 1080, 270, 135, 270, 135, 1080, 270, 270, 1080, 1080, 135, 135, 135, 1080, 1080, 135, 135, 1080, 270, 135, 270, 135, 270, 1080, 1080, 1080, 135, 1080, 1080, 1080, 1080, 135, 270, 270, 1080, 135, 1080, 135, 135, 135, 1080, 270, 1080, 1080, 135, 270, 270, 270, 135, 270, 135, 270, 270, 1080, 135, 135, 270, 135, 270, 270, 135, 1080, 1080, 1080, 135, 270, 270, 270, 270, 135, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 270, 270, 270, 135, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 1080, 270, 1080, 270, 135, 1080, 135, 1080, 1080, 135, 135, 135]
Prompts retrieved: 158760 . Total input tokens: 35347864 . Total output tokens: 31749041
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 7.554738816805184,
    "estimated_duration": 3600.0443840276776,
    "input_throughput": 3626.0952942461386,
    "output_throughput": 3182.8290925626284,
    "total_throughput": 6808.924386808767,
    "itl": 51.372513418015444,
    "ttft": 87398.10607677948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7495,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.144237226208514,
    "arrivals": 53129,
    "finished_requests": 52367,
    "scheduler_time": 39.79316883713721
}
#Debug simulation 
Total elapsed time: 7.5548591036349535. Arrivals time: 0.14873989950865507 Scheduler time: 7.109185891225934 Scheduler overhead time: 0.09008861472830176 Adapter cache time: 0.08700260752812028 Engine time: 0.08167448686435819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.521263281349093,
    "estimated_duration": 3599.9963313971252,
    "input_throughput": 3466.7485328121206,
    "output_throughput": 3062.533954228019,
    "total_throughput": 6529.282487040139,
    "itl": 49.601393805279116,
    "ttft": 69489.51547548907,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.84503950524717,
    "arrivals": 50759,
    "finished_requests": 50146,
    "scheduler_time": 35.90241497806956
}
#Debug simulation 
Total elapsed time: 6.521357344929129. Arrivals time: 0.1424486986361444 Scheduler time: 6.06895126728341 Scheduler overhead time: 0.09333282755687833 Adapter cache time: 0.09190105367451906 Engine time: 0.08554352354258299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.460876594763249,
    "estimated_duration": 3600.0219334828494,
    "input_throughput": 3466.065826973508,
    "output_throughput": 3062.170787758207,
    "total_throughput": 6528.236614731715,
    "itl": 49.632345688934016,
    "ttft": 69930.7703041645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8088,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.39198448133619,
    "arrivals": 50759,
    "finished_requests": 50140,
    "scheduler_time": 35.90547376693117
}
#Debug simulation 
Total elapsed time: 6.460967240855098. Arrivals time: 0.1445498699322343 Scheduler time: 6.0139118623919785 Scheduler overhead time: 0.09091952256858349 Adapter cache time: 0.09115908062085509 Engine time: 0.08174122171476483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.477243390865624,
    "estimated_duration": 3599.9948056747558,
    "input_throughput": 3466.037501035025,
    "output_throughput": 3062.106362660106,
    "total_throughput": 6528.143863695131,
    "itl": 49.62807050206194,
    "ttft": 70271.56586554252,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8107,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.502025974821887,
    "arrivals": 50759,
    "finished_requests": 50135,
    "scheduler_time": 35.90781269197336
}
#Debug simulation 
Total elapsed time: 6.477366213221103. Arrivals time: 0.14420793764293194 Scheduler time: 6.028958125039935 Scheduler overhead time: 0.09172612149268389 Adapter cache time: 0.09146353043615818 Engine time: 0.08219266124069691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.4319552863016725,
    "estimated_duration": 3599.986771073807,
    "input_throughput": 3465.6041239503247,
    "output_throughput": 3061.668750719425,
    "total_throughput": 6527.272874669749,
    "itl": 49.597069089430775,
    "ttft": 70188.84531612691,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8125,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.41003246073893,
    "arrivals": 50759,
    "finished_requests": 50136,
    "scheduler_time": 35.905242437996954
}
#Debug simulation 
Total elapsed time: 6.432047131005675. Arrivals time: 0.1433777566999197 Scheduler time: 5.984423136338592 Scheduler overhead time: 0.09144232701510191 Adapter cache time: 0.09192350134253502 Engine time: 0.08200752967968583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.451159263029695,
    "estimated_duration": 3599.9866811041584,
    "input_throughput": 3466.1825460345276,
    "output_throughput": 3061.701049577049,
    "total_throughput": 6527.883595611576,
    "itl": 49.631632443472675,
    "ttft": 70194.83216608294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8084,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.766215742956078,
    "arrivals": 50759,
    "finished_requests": 50137,
    "scheduler_time": 35.9193411944349
}
#Debug simulation 
Total elapsed time: 6.451316884253174. Arrivals time: 0.1470973021350801 Scheduler time: 6.000546684954315 Scheduler overhead time: 0.09125994751229882 Adapter cache time: 0.09073882456868887 Engine time: 0.0826946864835918 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.473524238914251,
    "estimated_duration": 3600.0178326185896,
    "input_throughput": 3466.74393857711,
    "output_throughput": 3062.321497441316,
    "total_throughput": 6529.065436018425,
    "itl": 49.5729214448109,
    "ttft": 69409.34399207692,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8131,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.312098947848668,
    "arrivals": 50759,
    "finished_requests": 50146,
    "scheduler_time": 35.88517040670963
}
#Debug simulation 
Total elapsed time: 6.473639322910458. Arrivals time: 0.14611196611076593 Scheduler time: 6.022942137904465 Scheduler overhead time: 0.09176055388525128 Adapter cache time: 0.0913769700564444 Engine time: 0.08259042631834745 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 66, 1080, 1080, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 1080, 270, 1080, 1080, 66, 1080, 270, 270, 1080, 1080, 270, 66, 66, 270, 1080, 1080, 270, 270, 66, 66, 270, 1080, 1080, 66, 1080, 270, 66, 270, 1080, 66, 270, 1080, 1080, 270, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 270, 270, 270, 66, 270, 66, 1080, 66, 1080, 270, 1080, 1080, 66, 1080, 66, 1080, 270, 66, 66, 270, 270, 1080, 270, 1080, 1080, 1080, 66, 270, 270, 66, 1080, 270, 1080, 1080, 270, 66, 270, 270, 270, 66, 1080, 270, 1080, 66, 1080, 66, 66, 270, 1080, 1080, 270, 66, 270, 66, 270, 1080, 1080, 270, 66, 270, 66, 1080, 66, 66, 66, 66, 1080, 270, 270, 1080, 270, 270, 66, 270, 1080, 270, 66, 66, 270, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 270, 1080, 270, 270, 270, 66, 1080, 66, 1080, 270, 66, 270, 66, 66, 270, 66, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 270, 66, 270, 66, 66, 66, 1080, 1080, 270, 270, 66, 66, 270, 66, 1080, 66, 66, 270, 66, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 66, 270, 1080, 270, 270, 1080, 270, 66, 270, 66, 1080, 270, 270, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 270, 66, 270, 66, 270, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 270, 270, 1080, 66, 1080, 66, 66, 66, 1080, 270, 1080, 1080, 66, 270, 270, 270, 66, 270, 66, 270, 270, 1080, 66, 66, 270, 66, 270, 270, 66, 1080, 1080, 1080, 66, 270, 270, 270, 270, 66, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 270, 270, 270, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 270, 1080, 270, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 151446 . Total input tokens: 33701223 . Total output tokens: 30293712
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.4944211561232805,
    "estimated_duration": 3599.999117399241,
    "input_throughput": 3465.845016377067,
    "output_throughput": 3061.99352847717,
    "total_throughput": 6527.838544854237,
    "itl": 49.63853786957171,
    "ttft": 70248.06311835388,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8101,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.165013136600717,
    "arrivals": 50759,
    "finished_requests": 50136,
    "scheduler_time": 35.92420418361888
}
#Debug simulation 
Total elapsed time: 6.494517066050321. Arrivals time: 0.14612166630104184 Scheduler time: 6.039017813745886 Scheduler overhead time: 0.093719189055264 Adapter cache time: 0.09161634556949139 Engine time: 0.08473572367802262 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.062810502015054,
    "estimated_duration": 3600.0326176664976,
    "input_throughput": 3377.2280118619506,
    "output_throughput": 3010.575500570099,
    "total_throughput": 6387.8035124320495,
    "itl": 48.87881711643249,
    "ttft": 58913.842777703074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8040,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.606321461220336,
    "arrivals": 49552,
    "finished_requests": 49045,
    "scheduler_time": 34.27698285758577
}
#Debug simulation 
Total elapsed time: 6.062906137201935. Arrivals time: 0.14335712604224682 Scheduler time: 5.612150105647743 Scheduler overhead time: 0.09361662529408932 Adapter cache time: 0.09098710166290402 Engine time: 0.08309494936838746 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.045133162289858,
    "estimated_duration": 3600.0515589114,
    "input_throughput": 3376.574418749641,
    "output_throughput": 3009.267179294479,
    "total_throughput": 6385.84159804412,
    "itl": 48.90510634603169,
    "ttft": 59766.207820758216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8071,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.340336435685998,
    "arrivals": 49552,
    "finished_requests": 49032,
    "scheduler_time": 34.27047760655142
}
#Debug simulation 
Total elapsed time: 6.045252894982696. Arrivals time: 0.1433160756714642 Scheduler time: 5.592607928905636 Scheduler overhead time: 0.09373197285458446 Adapter cache time: 0.09174356609582901 Engine time: 0.08439883170649409 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 6.022578589618206,
    "estimated_duration": 3600.034066990486,
    "input_throughput": 3375.222226760143,
    "output_throughput": 3009.2973561932217,
    "total_throughput": 6384.519582953364,
    "itl": 48.90102105396917,
    "ttft": 60853.631802727345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8020,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.220714707747625,
    "arrivals": 49552,
    "finished_requests": 49019,
    "scheduler_time": 34.27865386663079
}
#Debug simulation 
Total elapsed time: 6.022674972657114. Arrivals time: 0.14008369529619813 Scheduler time: 5.5766220930963755 Scheduler overhead time: 0.09365132451057434 Adapter cache time: 0.09035610780119896 Engine time: 0.08254464343190193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 6.083450410980731,
    "estimated_duration": 3600.02642904607,
    "input_throughput": 3375.4152197210146,
    "output_throughput": 3009.466239632807,
    "total_throughput": 6384.881459353822,
    "itl": 48.86908933700857,
    "ttft": 60620.65885308734,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.129338436094713,
    "arrivals": 49552,
    "finished_requests": 49020,
    "scheduler_time": 34.260257477364505
}
#Debug simulation 
Total elapsed time: 6.083542976062745. Arrivals time: 0.13910904340445995 Scheduler time: 5.638607400469482 Scheduler overhead time: 0.09223016072064638 Adapter cache time: 0.09127305448055267 Engine time: 0.08290886506438255 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 6.093189333099872,
    "estimated_duration": 3600.0232050283025,
    "input_throughput": 3375.47546444342,
    "output_throughput": 3009.0831039281693,
    "total_throughput": 6384.558568371589,
    "itl": 48.90876398484848,
    "ttft": 60616.02588431277,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8024,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.572006731237387,
    "arrivals": 49552,
    "finished_requests": 49021,
    "scheduler_time": 34.281087272788376
}
#Debug simulation 
Total elapsed time: 6.093295575119555. Arrivals time: 0.1437038742005825 Scheduler time: 5.6427519572898746 Scheduler overhead time: 0.09294402226805687 Adapter cache time: 0.09066990204155445 Engine time: 0.0839330367743969 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 6.061000633053482,
    "estimated_duration": 3600.0303963354163,
    "input_throughput": 3376.201493290827,
    "output_throughput": 3010.058751456824,
    "total_throughput": 6386.260244747651,
    "itl": 48.8689427389656,
    "ttft": 59857.88469950989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8065,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.11475562838519,
    "arrivals": 49552,
    "finished_requests": 49030,
    "scheduler_time": 34.25930305095828
}
#Debug simulation 
Total elapsed time: 6.061100271064788. Arrivals time: 0.13845549942925572 Scheduler time: 5.616465685423464 Scheduler overhead time: 0.09231260837987065 Adapter cache time: 0.09132355218753219 Engine time: 0.08336016070097685 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [106 107 107]
Adapter prompts. [270, 1080, 1080, 33, 1080, 1080, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 1080, 270, 1080, 1080, 33, 1080, 270, 270, 1080, 1080, 270, 33, 33, 270, 1080, 1080, 270, 270, 33, 33, 270, 1080, 1080, 33, 1080, 270, 33, 270, 1080, 33, 270, 1080, 1080, 270, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 270, 270, 270, 33, 270, 33, 1080, 33, 1080, 270, 1080, 1080, 33, 1080, 33, 1080, 270, 33, 33, 270, 270, 1080, 270, 1080, 1080, 1080, 33, 270, 270, 33, 1080, 270, 1080, 1080, 270, 33, 270, 270, 270, 33, 1080, 270, 1080, 33, 1080, 33, 33, 270, 1080, 1080, 270, 33, 270, 33, 270, 1080, 1080, 270, 33, 270, 33, 1080, 33, 33, 33, 33, 1080, 270, 270, 1080, 270, 270, 33, 270, 1080, 270, 33, 33, 270, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 270, 1080, 270, 270, 270, 33, 1080, 33, 1080, 270, 33, 270, 33, 33, 270, 33, 270, 1080, 1080, 1080, 1080, 270, 270, 1080, 1080, 1080, 270, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 270, 33, 270, 33, 33, 33, 1080, 1080, 270, 270, 33, 33, 270, 33, 1080, 33, 33, 270, 33, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 33, 270, 1080, 270, 270, 1080, 270, 33, 270, 33, 1080, 270, 270, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 270, 33, 270, 33, 270, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 270, 270, 1080, 33, 1080, 33, 33, 33, 1080, 270, 1080, 1080, 33, 270, 270, 270, 33, 270, 33, 270, 270, 1080, 33, 33, 270, 33, 270, 270, 33, 1080, 1080, 1080, 33, 270, 270, 270, 270, 33, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 270, 270, 270, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 270, 1080, 270, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 147948 . Total input tokens: 32945481 . Total output tokens: 29592250
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.989054556004703,
    "estimated_duration": 3600.039937952388,
    "input_throughput": 3375.7575497654734,
    "output_throughput": 3009.525779361865,
    "total_throughput": 6385.283329127338,
    "itl": 48.91985747427928,
    "ttft": 60175.141324319644,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8043,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.973673002382398,
    "arrivals": 49552,
    "finished_requests": 49028,
    "scheduler_time": 34.28100934998774
}
#Debug simulation 
Total elapsed time: 5.989199316129088. Arrivals time: 0.1384317330084741 Scheduler time: 5.546869293786585 Scheduler overhead time: 0.09195059537887573 Adapter cache time: 0.09064765926450491 Engine time: 0.08220526715740561 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.114352717995644,
    "estimated_duration": 3600.0335072831126,
    "input_throughput": 3144.040458818397,
    "output_throughput": 2798.075623357755,
    "total_throughput": 5942.116082176151,
    "itl": 46.30625502432703,
    "ttft": 43319.18576347401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9429,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.857338937544313,
    "arrivals": 45990,
    "finished_requests": 45638,
    "scheduler_time": 29.398805521905558
}
#Debug simulation 
Total elapsed time: 5.114445789717138. Arrivals time: 0.12471445044502616 Scheduler time: 4.674473376479 Scheduler overhead time: 0.08956403145566583 Adapter cache time: 0.10130480863153934 Engine time: 0.08458985202014446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.171515014953911,
    "estimated_duration": 3600.0033018059,
    "input_throughput": 3144.1860051411386,
    "output_throughput": 2797.9513226966155,
    "total_throughput": 5942.137327837754,
    "itl": 46.3422069055166,
    "ttft": 43596.96242671794,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9402,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.70090421498561,
    "arrivals": 45990,
    "finished_requests": 45635,
    "scheduler_time": 29.41324809507578
}
#Debug simulation 
Total elapsed time: 5.171619447879493. Arrivals time: 0.13011183589696884 Scheduler time: 4.724752357695252 Scheduler overhead time: 0.08912702882662416 Adapter cache time: 0.10216865921393037 Engine time: 0.08513173181563616 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.21463046874851,
    "estimated_duration": 3600.0157283081276,
    "input_throughput": 3144.007097246561,
    "output_throughput": 2797.2844454023116,
    "total_throughput": 5941.291542648873,
    "itl": 46.33841168062222,
    "ttft": 44321.14146923871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9408,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.772586187032523,
    "arrivals": 45990,
    "finished_requests": 45625,
    "scheduler_time": 29.396166724921624
}
#Debug simulation 
Total elapsed time: 5.214739080984145. Arrivals time: 0.12968791276216507 Scheduler time: 4.7639667061157525 Scheduler overhead time: 0.09087828174233437 Adapter cache time: 0.10341444099321961 Engine time: 0.08594005880877376 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 5.1472420282661915,
    "estimated_duration": 3600.0170260205823,
    "input_throughput": 3144.6484608751616,
    "output_throughput": 2797.953989438274,
    "total_throughput": 5942.602450313436,
    "itl": 46.3290044829563,
    "ttft": 43125.612686399676,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9430,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.522066089263166,
    "arrivals": 45990,
    "finished_requests": 45641,
    "scheduler_time": 29.40769414653559
}
#Debug simulation 
Total elapsed time: 5.14733623014763. Arrivals time: 0.12872493639588356 Scheduler time: 4.702162731438875 Scheduler overhead time: 0.08903499972075224 Adapter cache time: 0.10192056559026241 Engine time: 0.08540756162256002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 5.1579519947990775,
    "estimated_duration": 3600.0053801971467,
    "input_throughput": 3143.7083572859074,
    "output_throughput": 2797.85720749351,
    "total_throughput": 5941.565564779417,
    "itl": 46.35368427837337,
    "ttft": 43861.99549600256,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9390,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.102495133298827,
    "arrivals": 45990,
    "finished_requests": 45632,
    "scheduler_time": 29.4206117379322
}
#Debug simulation 
Total elapsed time: 5.158048781100661. Arrivals time: 0.1283730980940163 Scheduler time: 4.712380998302251 Scheduler overhead time: 0.08973930263891816 Adapter cache time: 0.10211732797324657 Engine time: 0.08515443373471498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 5.145209880545735,
    "estimated_duration": 3599.9928726609146,
    "input_throughput": 3144.251780596836,
    "output_throughput": 2798.5024849655947,
    "total_throughput": 5942.754265562431,
    "itl": 46.29167384933635,
    "ttft": 43205.34677635468,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.14235337561708,
    "arrivals": 45990,
    "finished_requests": 45640,
    "scheduler_time": 29.403860240995133
}
#Debug simulation 
Total elapsed time: 5.145318522583693. Arrivals time: 0.1271784952841699 Scheduler time: 4.7020752602256835 Scheduler overhead time: 0.08932370133697987 Adapter cache time: 0.1019030106253922 Engine time: 0.0846207938157022 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 66, 1080, 1080, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 1080, 135, 1080, 1080, 66, 1080, 135, 135, 1080, 1080, 135, 66, 66, 135, 1080, 1080, 135, 135, 66, 66, 135, 1080, 1080, 66, 1080, 135, 66, 135, 1080, 66, 135, 1080, 1080, 135, 66, 66, 1080, 66, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 135, 66, 1080, 66, 1080, 135, 1080, 1080, 66, 1080, 66, 1080, 135, 66, 66, 135, 135, 1080, 135, 1080, 1080, 1080, 66, 135, 135, 66, 1080, 135, 1080, 1080, 135, 66, 135, 135, 135, 66, 1080, 135, 1080, 66, 1080, 66, 66, 135, 1080, 1080, 135, 66, 135, 66, 135, 1080, 1080, 135, 66, 135, 66, 1080, 66, 66, 66, 66, 1080, 135, 135, 1080, 135, 135, 66, 135, 1080, 135, 66, 66, 135, 1080, 66, 66, 66, 1080, 1080, 1080, 66, 135, 1080, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 135, 66, 66, 135, 66, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 66, 66, 1080, 135, 1080, 135, 1080, 135, 66, 135, 66, 66, 66, 1080, 1080, 135, 135, 66, 66, 135, 66, 1080, 66, 66, 135, 66, 1080, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 66, 135, 1080, 135, 135, 1080, 135, 66, 135, 66, 1080, 135, 135, 1080, 1080, 66, 66, 66, 1080, 1080, 66, 66, 1080, 135, 66, 135, 66, 135, 1080, 1080, 1080, 66, 1080, 1080, 1080, 1080, 66, 135, 135, 1080, 66, 1080, 66, 66, 66, 1080, 135, 1080, 1080, 66, 135, 135, 135, 66, 135, 66, 135, 135, 1080, 66, 66, 135, 66, 135, 135, 66, 1080, 1080, 1080, 66, 135, 135, 135, 135, 66, 135, 66, 1080, 66, 66, 1080, 135, 1080, 135, 135, 135, 135, 66, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 1080, 135, 1080, 135, 66, 1080, 66, 1080, 1080, 66, 66, 66]
Prompts retrieved: 137001 . Total input tokens: 30496485 . Total output tokens: 27423595
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 5.117860635742545,
    "estimated_duration": 3600.033911747012,
    "input_throughput": 3144.17871539079,
    "output_throughput": 2797.7292011430895,
    "total_throughput": 5941.907916533879,
    "itl": 46.36471168222104,
    "ttft": 43702.66286131559,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9398,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.533788249117464,
    "arrivals": 45990,
    "finished_requests": 45634,
    "scheduler_time": 29.421848180321867
}
#Debug simulation 
Total elapsed time: 5.118026923853904. Arrivals time: 0.12843286525458097 Scheduler time: 4.674476214684546 Scheduler overhead time: 0.08897615363821387 Adapter cache time: 0.10135937621816993 Engine time: 0.084307792596519 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.679613307118416,
    "estimated_duration": 3600.033092077657,
    "input_throughput": 3083.131936877366,
    "output_throughput": 2705.2223551588177,
    "total_throughput": 5788.354292036184,
    "itl": 45.22027830797099,
    "ttft": 36968.560844431144,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9626,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.46025502309926,
    "arrivals": 44803,
    "finished_requests": 44493,
    "scheduler_time": 27.099225949384316
}
#Debug simulation 
Total elapsed time: 4.679691514931619. Arrivals time: 0.12027624109759927 Scheduler time: 4.240395477041602 Scheduler overhead time: 0.0901078823953867 Adapter cache time: 0.1028954810462892 Engine time: 0.08520025294274092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.701179306022823,
    "estimated_duration": 3600.0487861949914,
    "input_throughput": 3082.237674819941,
    "output_throughput": 2704.6622360613237,
    "total_throughput": 5786.899910881264,
    "itl": 45.252246538445455,
    "ttft": 38434.99896764548,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.056349497002362,
    "arrivals": 44803,
    "finished_requests": 44480,
    "scheduler_time": 27.16667406661229
}
#Debug simulation 
Total elapsed time: 4.70126907993108. Arrivals time: 0.12456663278862834 Scheduler time: 4.260036848951131 Scheduler overhead time: 0.0890813497826457 Adapter cache time: 0.1026480938307941 Engine time: 0.08445653924718499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.705349030904472,
    "estimated_duration": 3600.0360899326097,
    "input_throughput": 3082.2485449604796,
    "output_throughput": 2704.6717746049785,
    "total_throughput": 5786.920319565458,
    "itl": 45.254683949260055,
    "ttft": 38432.72644754803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9515,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.10970911866198,
    "arrivals": 44803,
    "finished_requests": 44480,
    "scheduler_time": 27.16655958016247
}
#Debug simulation 
Total elapsed time: 4.705441285856068. Arrivals time: 0.12202138779684901 Scheduler time: 4.263999360147864 Scheduler overhead time: 0.0902106361463666 Adapter cache time: 0.10306160477921367 Engine time: 0.08548430865630507 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.698510559741408,
    "estimated_duration": 3600.036952862388,
    "input_throughput": 3083.0194648905485,
    "output_throughput": 2705.066400014881,
    "total_throughput": 5788.085864905429,
    "itl": 45.23949894158989,
    "ttft": 36647.470336185645,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9788,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.612525265441356,
    "arrivals": 44803,
    "finished_requests": 44493,
    "scheduler_time": 27.06129543438008
}
#Debug simulation 
Total elapsed time: 4.698606607038528. Arrivals time: 0.12446046061813831 Scheduler time: 4.25189330521971 Scheduler overhead time: 0.08996729040518403 Adapter cache time: 0.10525450017303228 Engine time: 0.08602358587086201 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.701889345888048,
    "estimated_duration": 3600.0091859649133,
    "input_throughput": 3082.271579544838,
    "output_throughput": 2704.691987442862,
    "total_throughput": 5786.9635669877,
    "itl": 45.26026086389811,
    "ttft": 38352.46878606631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.5409076208615,
    "arrivals": 44803,
    "finished_requests": 44480,
    "scheduler_time": 27.168632651837104
}
#Debug simulation 
Total elapsed time: 4.701980370562524. Arrivals time: 0.12383076269179583 Scheduler time: 4.2590997270308435 Scheduler overhead time: 0.08973131654784083 Adapter cache time: 0.10282643279060721 Engine time: 0.08566768141463399 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.603802425786853,
    "estimated_duration": 3600.020414913351,
    "input_throughput": 3083.540847161331,
    "output_throughput": 2705.5396574006463,
    "total_throughput": 5789.080504561977,
    "itl": 45.2055672525145,
    "ttft": 35881.50293380203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9783,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.25166203502542,
    "arrivals": 44803,
    "finished_requests": 44502,
    "scheduler_time": 27.054746212961597
}
#Debug simulation 
Total elapsed time: 4.603881170041859. Arrivals time: 0.11975665157660842 Scheduler time: 4.164106979966164 Scheduler overhead time: 0.09004966262727976 Adapter cache time: 0.1044807224534452 Engine time: 0.08475485444068909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [106 107 107]
Adapter prompts. [135, 1080, 1080, 33, 1080, 1080, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 1080, 135, 1080, 1080, 33, 1080, 135, 135, 1080, 1080, 135, 33, 33, 135, 1080, 1080, 135, 135, 33, 33, 135, 1080, 1080, 33, 1080, 135, 33, 135, 1080, 33, 135, 1080, 1080, 135, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 135, 33, 1080, 33, 1080, 135, 1080, 1080, 33, 1080, 33, 1080, 135, 33, 33, 135, 135, 1080, 135, 1080, 1080, 1080, 33, 135, 135, 33, 1080, 135, 1080, 1080, 135, 33, 135, 135, 135, 33, 1080, 135, 1080, 33, 1080, 33, 33, 135, 1080, 1080, 135, 33, 135, 33, 135, 1080, 1080, 135, 33, 135, 33, 1080, 33, 33, 33, 33, 1080, 135, 135, 1080, 135, 135, 33, 135, 1080, 135, 33, 33, 135, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 135, 1080, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 135, 33, 33, 135, 33, 135, 1080, 1080, 1080, 1080, 135, 135, 1080, 1080, 1080, 135, 1080, 33, 33, 1080, 135, 1080, 135, 1080, 135, 33, 135, 33, 33, 33, 1080, 1080, 135, 135, 33, 33, 135, 33, 1080, 33, 33, 135, 33, 1080, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 33, 135, 1080, 135, 135, 1080, 135, 33, 135, 33, 1080, 135, 135, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 135, 33, 135, 33, 135, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 135, 135, 1080, 33, 1080, 33, 33, 33, 1080, 135, 1080, 1080, 33, 135, 135, 135, 33, 135, 33, 135, 135, 1080, 33, 33, 135, 33, 135, 135, 33, 1080, 1080, 1080, 33, 135, 135, 135, 135, 33, 135, 33, 1080, 33, 33, 1080, 135, 1080, 135, 135, 135, 135, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 135, 1080, 135, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 133503 . Total input tokens: 29742321 . Total output tokens: 26714906
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.7134569571353495,
    "estimated_duration": 3600.0213800233573,
    "input_throughput": 3082.261139218014,
    "output_throughput": 2704.6828260605566,
    "total_throughput": 5786.94396527857,
    "itl": 45.270956060007,
    "ttft": 38355.55728360958,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9524,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.942273693231034,
    "arrivals": 44803,
    "finished_requests": 44480,
    "scheduler_time": 27.17144294855483
}
#Debug simulation 
Total elapsed time: 4.713548757135868. Arrivals time: 0.12558082677423954 Scheduler time: 4.268057490233332 Scheduler overhead time: 0.09139670291915536 Adapter cache time: 0.10271483333781362 Engine time: 0.08533661253750324 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.0070892120711505,
    "estimated_duration": 3600.014455784782,
    "input_throughput": 2930.8573978211753,
    "output_throughput": 2579.2654763037162,
    "total_throughput": 5510.1228741248915,
    "itl": 43.84885330959747,
    "ttft": 22029.753433820188,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.990498895066136,
    "arrivals": 42341,
    "finished_requests": 42161,
    "scheduler_time": 23.978375528700568
}
#Debug simulation 
Total elapsed time: 4.007179222069681. Arrivals time: 0.1133977766148746 Scheduler time: 3.568554111290723 Scheduler overhead time: 0.09035746566951275 Adapter cache time: 0.10702219139784575 Engine time: 0.08645038679242134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.081670794636011,
    "estimated_duration": 3600.043016738097,
    "input_throughput": 2930.7830353538193,
    "output_throughput": 2579.515010466216,
    "total_throughput": 5510.298045820035,
    "itl": 43.885144669673245,
    "ttft": 22083.08362173583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.88015577338927,
    "arrivals": 42341,
    "finished_requests": 42162,
    "scheduler_time": 23.997293272246928
}
#Debug simulation 
Total elapsed time: 4.081827074754983. Arrivals time: 0.11679623881354928 Scheduler time: 3.631011638790369 Scheduler overhead time: 0.094578942283988 Adapter cache time: 0.10851885518059134 Engine time: 0.08784180227667093 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.06545164482668,
    "estimated_duration": 3600.0118941487935,
    "input_throughput": 2930.8567055428475,
    "output_throughput": 2579.3000892835985,
    "total_throughput": 5510.1567948264465,
    "itl": 43.88934127176688,
    "ttft": 21975.781386412677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10106,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.02646538136737,
    "arrivals": 42341,
    "finished_requests": 42162,
    "scheduler_time": 23.995228359462736
}
#Debug simulation 
Total elapsed time: 4.065541566815227. Arrivals time: 0.11579205375164747 Scheduler time: 3.6216996517032385 Scheduler overhead time: 0.09097073413431644 Adapter cache time: 0.10769538814201951 Engine time: 0.08723855251446366 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 4.070807229261845,
    "estimated_duration": 3600.0188214732125,
    "input_throughput": 2930.663289055392,
    "output_throughput": 2579.17846001714,
    "total_throughput": 5509.8417490725315,
    "itl": 43.856855507431355,
    "ttft": 22463.18935855201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9920,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.061146486402393,
    "arrivals": 42341,
    "finished_requests": 42159,
    "scheduler_time": 24.016953392976514
}
#Debug simulation 
Total elapsed time: 4.0708855423145. Arrivals time: 0.11386227142065763 Scheduler time: 3.628517779055983 Scheduler overhead time: 0.0926426318474114 Adapter cache time: 0.10647926153615117 Engine time: 0.08706602733582258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 4.0782795418053865,
    "estimated_duration": 3600.0328154961717,
    "input_throughput": 2930.8396730672025,
    "output_throughput": 2579.285099855467,
    "total_throughput": 5510.124772922669,
    "itl": 43.89769971454363,
    "ttft": 22051.521919965555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10104,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.43054718108851,
    "arrivals": 42341,
    "finished_requests": 42162,
    "scheduler_time": 23.996504351769094
}
#Debug simulation 
Total elapsed time: 4.078367537818849. Arrivals time: 0.1173356669023633 Scheduler time: 3.63467321684584 Scheduler overhead time: 0.09068358922377229 Adapter cache time: 0.1077825571410358 Engine time: 0.08645290648564696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 4.063684086315334,
    "estimated_duration": 3600.0369918558613,
    "input_throughput": 2930.8390507845224,
    "output_throughput": 2579.2493302168186,
    "total_throughput": 5510.088381001341,
    "itl": 43.83680016077447,
    "ttft": 22105.423366308893,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.283229386766326,
    "arrivals": 42341,
    "finished_requests": 42161,
    "scheduler_time": 23.97303706688006
}
#Debug simulation 
Total elapsed time: 4.063774392940104. Arrivals time: 0.11463735904544592 Scheduler time: 3.6207107761874795 Scheduler overhead time: 0.09094599541276693 Adapter cache time: 0.10826546465978026 Engine time: 0.08767043892294168 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [106 107 107]
Adapter prompts. [66, 1080, 1080, 33, 1080, 1080, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 1080, 66, 1080, 1080, 33, 1080, 66, 66, 1080, 1080, 66, 33, 33, 66, 1080, 1080, 66, 66, 33, 33, 66, 1080, 1080, 33, 1080, 66, 33, 66, 1080, 33, 66, 1080, 1080, 66, 33, 33, 1080, 33, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 66, 33, 1080, 33, 1080, 66, 1080, 1080, 33, 1080, 33, 1080, 66, 33, 33, 66, 66, 1080, 66, 1080, 1080, 1080, 33, 66, 66, 33, 1080, 66, 1080, 1080, 66, 33, 66, 66, 66, 33, 1080, 66, 1080, 33, 1080, 33, 33, 66, 1080, 1080, 66, 33, 66, 33, 66, 1080, 1080, 66, 33, 66, 33, 1080, 33, 33, 33, 33, 1080, 66, 66, 1080, 66, 66, 33, 66, 1080, 66, 33, 33, 66, 1080, 33, 33, 33, 1080, 1080, 1080, 33, 66, 1080, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 66, 33, 33, 66, 33, 66, 1080, 1080, 1080, 1080, 66, 66, 1080, 1080, 1080, 66, 1080, 33, 33, 1080, 66, 1080, 66, 1080, 66, 33, 66, 33, 33, 33, 1080, 1080, 66, 66, 33, 33, 66, 33, 1080, 33, 33, 66, 33, 1080, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 33, 66, 1080, 66, 66, 1080, 66, 33, 66, 33, 1080, 66, 66, 1080, 1080, 33, 33, 33, 1080, 1080, 33, 33, 1080, 66, 33, 66, 33, 66, 1080, 1080, 1080, 33, 1080, 1080, 1080, 1080, 33, 66, 66, 1080, 33, 1080, 33, 33, 33, 1080, 66, 1080, 1080, 33, 66, 66, 66, 33, 66, 33, 66, 66, 1080, 33, 33, 66, 33, 66, 66, 33, 1080, 1080, 1080, 33, 66, 66, 66, 66, 33, 66, 33, 1080, 33, 33, 1080, 66, 1080, 66, 66, 66, 66, 33, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 1080, 1080, 66, 1080, 66, 33, 1080, 33, 1080, 1080, 33, 33, 33]
Prompts retrieved: 126120 . Total input tokens: 28098161 . Total output tokens: 25213446
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 4.0910799079574645,
    "estimated_duration": 3600.004555272631,
    "input_throughput": 2930.862402534087,
    "output_throughput": 2579.2628474318176,
    "total_throughput": 5510.125249965904,
    "itl": 43.904181340864376,
    "ttft": 22077.80285512805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10093,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.830530351137355,
    "arrivals": 42341,
    "finished_requests": 42161,
    "scheduler_time": 24.002583330269005
}
#Debug simulation 
Total elapsed time: 4.091173272114247. Arrivals time: 0.11465991893783212 Scheduler time: 3.649575716815889 Scheduler overhead time: 0.0903205145150423 Adapter cache time: 0.10794718423858285 Engine time: 0.08705825405195355 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.5420236266218126,
    "estimated_duration": 3600.018659328017,
    "input_throughput": 2314.8938348990587,
    "output_throughput": 2067.7173382733163,
    "total_throughput": 4382.611173172375,
    "itl": 39.51865976361582,
    "ttft": 26038.97292004719,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.29071410055629,
    "arrivals": 33871,
    "finished_requests": 33717,
    "scheduler_time": 15.189560551713141
}
#Debug simulation 
Total elapsed time: 3.5421406608074903. Arrivals time: 0.0958159975707531 Scheduler time: 3.0510845500975847 Scheduler overhead time: 0.09645070787519217 Adapter cache time: 0.16253650467842817 Engine time: 0.09185830131173134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.52306573279202,
    "estimated_duration": 3600.0060129295684,
    "input_throughput": 2314.9019668493097,
    "output_throughput": 2067.724601921556,
    "total_throughput": 4382.626568770866,
    "itl": 39.56803907019153,
    "ttft": 26120.114752651552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16712,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.55456859663593,
    "arrivals": 33871,
    "finished_requests": 33717,
    "scheduler_time": 15.219493996095272
}
#Debug simulation 
Total elapsed time: 3.523196836002171. Arrivals time: 0.09461312089115381 Scheduler time: 3.0348031274043024 Scheduler overhead time: 0.09628502978011966 Adapter cache time: 0.1611801697872579 Engine time: 0.09202424995601177 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.544745151884854,
    "estimated_duration": 3600.0267486068865,
    "input_throughput": 2314.8886333205446,
    "output_throughput": 2067.7126921016793,
    "total_throughput": 4382.601325422224,
    "itl": 39.569758689186756,
    "ttft": 26120.956020706348,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.65463991695548,
    "arrivals": 33871,
    "finished_requests": 33717,
    "scheduler_time": 15.220360242843949
}
#Debug simulation 
Total elapsed time: 3.544834330212325. Arrivals time: 0.09528953628614545 Scheduler time: 3.0532481060363352 Scheduler overhead time: 0.09721311926841736 Adapter cache time: 0.16261177835986018 Engine time: 0.09206287004053593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.5202253311872482,
    "estimated_duration": 3600.0108329500076,
    "input_throughput": 2314.898867448971,
    "output_throughput": 2067.7218334646523,
    "total_throughput": 4382.620700913623,
    "itl": 39.536990986700474,
    "ttft": 26073.082919260174,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16733,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.33372041806602,
    "arrivals": 33871,
    "finished_requests": 33717,
    "scheduler_time": 15.200220542975776
}
#Debug simulation 
Total elapsed time: 3.5203201388940215. Arrivals time: 0.09527423558756709 Scheduler time: 3.0322637064382434 Scheduler overhead time: 0.09566581482067704 Adapter cache time: 0.16212235065177083 Engine time: 0.09076371183618903 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.6121208532713354,
    "estimated_duration": 3600.038218127119,
    "input_throughput": 2314.8812582149467,
    "output_throughput": 2067.706104484793,
    "total_throughput": 4382.58736269974,
    "itl": 39.58249476322625,
    "ttft": 26246.675500087964,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16695,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.293877749824176,
    "arrivals": 33871,
    "finished_requests": 33717,
    "scheduler_time": 15.226847108949615
}
#Debug simulation 
Total elapsed time: 3.612211499363184. Arrivals time: 0.09835569793358445 Scheduler time: 3.1147483638487756 Scheduler overhead time: 0.09709019260481 Adapter cache time: 0.16390525037422776 Engine time: 0.09360473742708564 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.552211272995919,
    "estimated_duration": 3600.0404294620107,
    "input_throughput": 2314.892336152288,
    "output_throughput": 2067.769833660573,
    "total_throughput": 4382.662169812861,
    "itl": 39.49985330175368,
    "ttft": 26023.70463359381,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16778,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 50.16706384788076,
    "arrivals": 33871,
    "finished_requests": 33718,
    "scheduler_time": 15.180951693908272
}
#Debug simulation 
Total elapsed time: 3.5523005169816315. Arrivals time: 0.09407691285014153 Scheduler time: 3.060445639770478 Scheduler overhead time: 0.0965823857113719 Adapter cache time: 0.16319151362404227 Engine time: 0.09321212768554688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_320_slots_64_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 135, 540, 540, 270, 270, 270, 270, 135, 270, 135, 270, 135, 270, 270, 540, 270, 540, 540, 135, 540, 270, 270, 540, 540, 270, 135, 135, 270, 540, 540, 270, 270, 135, 135, 270, 540, 540, 135, 540, 270, 135, 270, 540, 135, 270, 540, 540, 270, 135, 135, 540, 135, 135, 540, 540, 135, 135, 270, 270, 270, 135, 270, 135, 540, 135, 540, 270, 540, 540, 135, 540, 135, 540, 270, 135, 135, 270, 270, 540, 270, 540, 540, 540, 135, 270, 270, 135, 540, 270, 540, 540, 270, 135, 270, 270, 270, 135, 540, 270, 540, 135, 540, 135, 135, 270, 540, 540, 270, 135, 270, 135, 270, 540, 540, 270, 135, 270, 135, 540, 135, 135, 135, 135, 540, 270, 270, 540, 270, 270, 135, 270, 540, 270, 135, 135, 270, 540, 135, 135, 135, 540, 540, 540, 135, 270, 540, 270, 270, 270, 135, 540, 135, 540, 270, 135, 270, 135, 135, 270, 135, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 135, 135, 540, 270, 540, 270, 540, 270, 135, 270, 135, 135, 135, 540, 540, 270, 270, 135, 135, 270, 135, 540, 135, 135, 270, 135, 540, 270, 135, 540, 135, 135, 540, 270, 540, 270, 135, 270, 540, 270, 270, 540, 270, 135, 270, 135, 540, 270, 270, 540, 540, 135, 135, 135, 540, 540, 135, 135, 540, 270, 135, 270, 135, 270, 540, 540, 540, 135, 540, 540, 540, 540, 135, 270, 270, 540, 135, 540, 135, 135, 135, 540, 270, 540, 540, 135, 270, 270, 270, 135, 270, 135, 270, 270, 540, 135, 135, 270, 135, 270, 270, 135, 540, 540, 540, 135, 270, 270, 270, 270, 135, 270, 135, 540, 135, 135, 540, 270, 540, 270, 270, 270, 270, 135, 135, 540, 135, 135, 540, 540, 540, 135, 540, 540, 270, 540, 270, 135, 540, 135, 540, 540, 135, 135, 135]
Prompts retrieved: 100980 . Total input tokens: 22497641 . Total output tokens: 20173181
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.5407721218653023,
    "estimated_duration": 3600.01883753482,
    "input_throughput": 2314.8937203080386,
    "output_throughput": 2067.7172359179363,
    "total_throughput": 4382.610956225975,
    "itl": 39.59248842654803,
    "ttft": 26163.452145174604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16677,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.94052618239394,
    "arrivals": 33871,
    "finished_requests": 33717,
    "scheduler_time": 15.233528417310817
}
#Debug simulation 
Total elapsed time: 3.540857085958123. Arrivals time: 0.0948538207449019 Scheduler time: 3.0519770178943872 Scheduler overhead time: 0.09628227911889553 Adapter cache time: 0.16111320909112692 Engine time: 0.09208237053826451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.9956720070913434,
    "estimated_duration": 3599.958057169847,
    "input_throughput": 2154.0984302734983,
    "output_throughput": 1927.814682778835,
    "total_throughput": 4081.9131130523333,
    "itl": 38.35638132262705,
    "ttft": 13655.421848190123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18810,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.567774463357125,
    "arrivals": 31462,
    "finished_requests": 31378,
    "scheduler_time": 11.857138413581708
}
#Debug simulation 
Total elapsed time: 2.9957619942724705. Arrivals time: 0.08879997814074159 Scheduler time: 2.4955812892876565 Scheduler overhead time: 0.0962621783837676 Adapter cache time: 0.17788468906655908 Engine time: 0.09229169739410281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.017534771002829,
    "estimated_duration": 3599.9665828241177,
    "input_throughput": 2154.0933288098986,
    "output_throughput": 1927.8101172138206,
    "total_throughput": 4081.9034460237194,
    "itl": 38.41701627605501,
    "ttft": 13700.777196680274,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18770,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.28094274000285,
    "arrivals": 31462,
    "finished_requests": 31378,
    "scheduler_time": 11.888736524070783
}
#Debug simulation 
Total elapsed time: 3.01760908216238. Arrivals time: 0.08785954024642706 Scheduler time: 2.5166410114616156 Scheduler overhead time: 0.09666805854067206 Adapter cache time: 0.17800714261829853 Engine time: 0.0935422838665545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 3.0111002889461815,
    "estimated_duration": 3599.948731350061,
    "input_throughput": 2154.1040105567918,
    "output_throughput": 1927.8196768644887,
    "total_throughput": 4081.92368742128,
    "itl": 38.41750267971173,
    "ttft": 13703.929372717912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18768,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.3771623821919,
    "arrivals": 31462,
    "finished_requests": 31378,
    "scheduler_time": 11.88989819389232
}
#Debug simulation 
Total elapsed time: 3.011191790923476. Arrivals time: 0.09041806543245912 Scheduler time: 2.508702709339559 Scheduler overhead time: 0.09669519262388349 Adapter cache time: 0.17805455019697547 Engine time: 0.09249583492055535 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 3.0402231039479375,
    "estimated_duration": 3599.9838315723227,
    "input_throughput": 2154.083007815367,
    "output_throughput": 1927.8008804191975,
    "total_throughput": 4081.883888234565,
    "itl": 38.37956191446263,
    "ttft": 13669.977827037164,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18803,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.8205819203432,
    "arrivals": 31462,
    "finished_requests": 31378,
    "scheduler_time": 11.867933682474366
}
#Debug simulation 
Total elapsed time: 3.040375283919275. Arrivals time: 0.08906103391200304 Scheduler time: 2.536688338033855 Scheduler overhead time: 0.09661385277286172 Adapter cache time: 0.17763775447383523 Engine time: 0.09494892600923777 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 3.0396224069409072,
    "estimated_duration": 3599.970686519765,
    "input_throughput": 2154.090873305622,
    "output_throughput": 1927.807919655375,
    "total_throughput": 4081.898792960997,
    "itl": 38.43061184561868,
    "ttft": 13712.798473002566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.139181247327606,
    "arrivals": 31462,
    "finished_requests": 31378,
    "scheduler_time": 11.896221712778441
}
#Debug simulation 
Total elapsed time: 3.0397120881825686. Arrivals time: 0.08845946751534939 Scheduler time: 2.53405821043998 Scheduler overhead time: 0.09653359279036522 Adapter cache time: 0.17796584963798523 Engine time: 0.09775708802044392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 3.0248681590892375,
    "estimated_duration": 3599.9716030392524,
    "input_throughput": 2154.09060267397,
    "output_throughput": 1927.8279845710017,
    "total_throughput": 4081.918587244971,
    "itl": 38.33475204534288,
    "ttft": 13522.110489764926,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 56.263776399191514,
    "arrivals": 31462,
    "finished_requests": 31379,
    "scheduler_time": 11.845768092541507
}
#Debug simulation 
Total elapsed time: 3.024954654276371. Arrivals time: 0.08798756916075945 Scheduler time: 2.518774133641273 Scheduler overhead time: 0.10076518449932337 Adapter cache time: 0.1783951073884964 Engine time: 0.09340097894892097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 66, 540, 540, 270, 270, 270, 270, 66, 270, 66, 270, 66, 270, 270, 540, 270, 540, 540, 66, 540, 270, 270, 540, 540, 270, 66, 66, 270, 540, 540, 270, 270, 66, 66, 270, 540, 540, 66, 540, 270, 66, 270, 540, 66, 270, 540, 540, 270, 66, 66, 540, 66, 66, 540, 540, 66, 66, 270, 270, 270, 66, 270, 66, 540, 66, 540, 270, 540, 540, 66, 540, 66, 540, 270, 66, 66, 270, 270, 540, 270, 540, 540, 540, 66, 270, 270, 66, 540, 270, 540, 540, 270, 66, 270, 270, 270, 66, 540, 270, 540, 66, 540, 66, 66, 270, 540, 540, 270, 66, 270, 66, 270, 540, 540, 270, 66, 270, 66, 540, 66, 66, 66, 66, 540, 270, 270, 540, 270, 270, 66, 270, 540, 270, 66, 66, 270, 540, 66, 66, 66, 540, 540, 540, 66, 270, 540, 270, 270, 270, 66, 540, 66, 540, 270, 66, 270, 66, 66, 270, 66, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 66, 66, 540, 270, 540, 270, 540, 270, 66, 270, 66, 66, 66, 540, 540, 270, 270, 66, 66, 270, 66, 540, 66, 66, 270, 66, 540, 270, 66, 540, 66, 66, 540, 270, 540, 270, 66, 270, 540, 270, 270, 540, 270, 66, 270, 66, 540, 270, 270, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 270, 66, 270, 66, 270, 540, 540, 540, 66, 540, 540, 540, 540, 66, 270, 270, 540, 66, 540, 66, 66, 66, 540, 270, 540, 540, 66, 270, 270, 270, 66, 270, 66, 270, 270, 540, 66, 66, 270, 66, 270, 270, 66, 540, 540, 540, 66, 270, 270, 270, 270, 66, 270, 66, 540, 66, 66, 540, 270, 540, 270, 270, 270, 270, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 270, 540, 270, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 93666 . Total input tokens: 20908649 . Total output tokens: 18710898
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.99634049506858,
    "estimated_duration": 3599.9541281455463,
    "input_throughput": 2154.100781277088,
    "output_throughput": 1927.816786814183,
    "total_throughput": 4081.917568091271,
    "itl": 38.44563485176322,
    "ttft": 13724.407614114712,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 18759,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 62.93366824191554,
    "arrivals": 31462,
    "finished_requests": 31378,
    "scheduler_time": 11.903279731775195
}
#Debug simulation 
Total elapsed time: 2.996426932979375. Arrivals time: 0.08748854510486126 Scheduler time: 2.499975469429046 Scheduler overhead time: 0.09611456468701363 Adapter cache time: 0.1763219186104834 Engine time: 0.09157284628599882 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.7053564111702144,
    "estimated_duration": 3600.027175487048,
    "input_throughput": 2060.1302819322796,
    "output_throughput": 1829.170914274864,
    "total_throughput": 3889.301196207143,
    "itl": 37.137427190229985,
    "ttft": 17420.991599575813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.98862026880591,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 9.485568493161734
}
#Debug simulation 
Total elapsed time: 2.705474239308387. Arrivals time: 0.08592513343319297 Scheduler time: 2.1990047306753695 Scheduler overhead time: 0.09787835506722331 Adapter cache time: 0.18322712928056717 Engine time: 0.09358033072203398 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.752287751995027,
    "estimated_duration": 3600.0393982184737,
    "input_throughput": 2060.123287447955,
    "output_throughput": 1829.1647039359361,
    "total_throughput": 3889.287991383891,
    "itl": 37.20779712140956,
    "ttft": 17448.712331718398,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19578,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.90487839537185,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 9.522691363545766
}
#Debug simulation 
Total elapsed time: 2.7523973318748176. Arrivals time: 0.08568532904610038 Scheduler time: 2.241984034422785 Scheduler overhead time: 0.09841140499338508 Adapter cache time: 0.184627593960613 Engine time: 0.09577012527734041 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7276868000626564,
    "estimated_duration": 3600.01499421133,
    "input_throughput": 2060.1372527407398,
    "output_throughput": 1829.1771035922081,
    "total_throughput": 3889.314356332948,
    "itl": 37.21186103631846,
    "ttft": 17449.576089406324,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19572,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 63.99614775881218,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 9.52348864204454
}
#Debug simulation 
Total elapsed time: 2.7277766610495746. Arrivals time: 0.08568011922761798 Scheduler time: 2.2183984452858567 Scheduler overhead time: 0.09824900375679135 Adapter cache time: 0.18422170635312796 Engine time: 0.09531336557120085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.7184333889745176,
    "estimated_duration": 3600.0250320993073,
    "input_throughput": 2060.131508495415,
    "output_throughput": 1829.1720033291008,
    "total_throughput": 3889.3035118245157,
    "itl": 37.16186405030611,
    "ttft": 17431.31515627452,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 61.33904588497272,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 9.498568416659312
}
#Debug simulation 
Total elapsed time: 2.718561197631061. Arrivals time: 0.08468884881585836 Scheduler time: 2.212488283868879 Scheduler overhead time: 0.09820320829749107 Adapter cache time: 0.18393068155273795 Engine time: 0.09325902163982391 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7015425791032612,
    "estimated_duration": 3600.024613823346,
    "input_throughput": 2060.131747855858,
    "output_throughput": 1829.172215855058,
    "total_throughput": 3889.3039637109164,
    "itl": 37.22492689962051,
    "ttft": 17454.638345464013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19575,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 64.81484117842615,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 9.53139088700724
}
#Debug simulation 
Total elapsed time: 2.7016284288838506. Arrivals time: 0.08479312667623162 Scheduler time: 2.1970857810229063 Scheduler overhead time: 0.09807001473382115 Adapter cache time: 0.18170676799491048 Engine time: 0.09410472773015499 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.7074630251154304,
    "estimated_duration": 3600.020047785169,
    "input_throughput": 2060.134360796921,
    "output_throughput": 1829.1745358616301,
    "total_throughput": 3889.308896658551,
    "itl": 37.11287674777714,
    "ttft": 17411.318805412844,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.652826584820396,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 9.472798296376036
}
#Debug simulation 
Total elapsed time: 2.7075809370726347. Arrivals time: 0.08507980266585946 Scheduler time: 2.201394663192332 Scheduler overhead time: 0.09896922810003161 Adapter cache time: 0.18198267836123705 Engine time: 0.09369931695982814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [106 107 107]
Adapter prompts. [270, 540, 540, 33, 540, 540, 270, 270, 270, 270, 33, 270, 33, 270, 33, 270, 270, 540, 270, 540, 540, 33, 540, 270, 270, 540, 540, 270, 33, 33, 270, 540, 540, 270, 270, 33, 33, 270, 540, 540, 33, 540, 270, 33, 270, 540, 33, 270, 540, 540, 270, 33, 33, 540, 33, 33, 540, 540, 33, 33, 270, 270, 270, 33, 270, 33, 540, 33, 540, 270, 540, 540, 33, 540, 33, 540, 270, 33, 33, 270, 270, 540, 270, 540, 540, 540, 33, 270, 270, 33, 540, 270, 540, 540, 270, 33, 270, 270, 270, 33, 540, 270, 540, 33, 540, 33, 33, 270, 540, 540, 270, 33, 270, 33, 270, 540, 540, 270, 33, 270, 33, 540, 33, 33, 33, 33, 540, 270, 270, 540, 270, 270, 33, 270, 540, 270, 33, 33, 270, 540, 33, 33, 33, 540, 540, 540, 33, 270, 540, 270, 270, 270, 33, 540, 33, 540, 270, 33, 270, 33, 33, 270, 33, 270, 540, 540, 540, 540, 270, 270, 540, 540, 540, 270, 540, 33, 33, 540, 270, 540, 270, 540, 270, 33, 270, 33, 33, 33, 540, 540, 270, 270, 33, 33, 270, 33, 540, 33, 33, 270, 33, 540, 270, 33, 540, 33, 33, 540, 270, 540, 270, 33, 270, 540, 270, 270, 540, 270, 33, 270, 33, 540, 270, 270, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 270, 33, 270, 33, 270, 540, 540, 540, 33, 540, 540, 540, 540, 33, 270, 270, 540, 33, 540, 33, 33, 33, 540, 270, 540, 540, 33, 270, 270, 270, 33, 270, 33, 270, 270, 540, 33, 33, 270, 33, 270, 270, 33, 540, 540, 540, 33, 270, 270, 270, 270, 33, 270, 33, 540, 33, 33, 540, 270, 540, 270, 270, 270, 270, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 270, 540, 270, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 90168 . Total input tokens: 20108351 . Total output tokens: 18015308
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.7278870111331344,
    "estimated_duration": 3600.029324156369,
    "input_throughput": 2060.1290523482025,
    "output_throughput": 1829.1698225383607,
    "total_throughput": 3889.298874886563,
    "itl": 37.238274115298594,
    "ttft": 17460.87561714074,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 19567,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 65.63035112884576,
    "arrivals": 30252,
    "finished_requests": 30117,
    "scheduler_time": 9.538882160269724
}
#Debug simulation 
Total elapsed time: 2.72798022814095. Arrivals time: 0.0864904816262424 Scheduler time: 2.2166755576618016 Scheduler overhead time: 0.09813757752999663 Adapter cache time: 0.18329928815364838 Engine time: 0.09752791794016957 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.3422651439905167,
    "estimated_duration": 3600.021073697848,
    "input_throughput": 1837.8375749906254,
    "output_throughput": 1596.659542355344,
    "total_throughput": 3434.4971173459694,
    "itl": 32.43371192819577,
    "ttft": 9450.294643135496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17685,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.124725751435655,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.736218149938448
}
#Debug simulation 
Total elapsed time: 2.342340241651982. Arrivals time: 0.07612634776160121 Scheduler time: 1.8374254191294312 Scheduler overhead time: 0.10791321750730276 Adapter cache time: 0.1686876155436039 Engine time: 0.10183372255414724 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3542756610549986,
    "estimated_duration": 3600.000667396743,
    "input_throughput": 1837.8479926183986,
    "output_throughput": 1596.668592885717,
    "total_throughput": 3434.5165855041155,
    "itl": 32.49597944198646,
    "ttft": 9451.835851272852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17678,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.650523603281435,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.76519797142793
}
#Debug simulation 
Total elapsed time: 2.354366689454764. Arrivals time: 0.07707583392038941 Scheduler time: 1.8447001283057034 Scheduler overhead time: 0.1068913615308702 Adapter cache time: 0.16895141499117017 Engine time: 0.10615326184779406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3484367709606886,
    "estimated_duration": 3600.0244258018897,
    "input_throughput": 1837.8358637181352,
    "output_throughput": 1596.6580556518463,
    "total_throughput": 3434.4939193699815,
    "itl": 32.497172227678185,
    "ttft": 9451.7144244989,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17674,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 57.74672799650302,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.765974714175653
}
#Debug simulation 
Total elapsed time: 2.348514620680362. Arrivals time: 0.07660150621086359 Scheduler time: 1.8390897121280432 Scheduler overhead time: 0.10783875780180097 Adapter cache time: 0.17030069883912802 Engine time: 0.10365437064319849 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.3367875567637384,
    "estimated_duration": 3600.012897525524,
    "input_throughput": 1837.8417489969816,
    "output_throughput": 1596.6631686100084,
    "total_throughput": 3434.5049176069897,
    "itl": 32.455849496858235,
    "ttft": 9450.898913042061,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17683,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 55.341383683467534,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.746341156777115
}
#Debug simulation 
Total elapsed time: 2.3369224946945906. Arrivals time: 0.07643247721716762 Scheduler time: 1.8327704011462629 Scheduler overhead time: 0.10696827387437224 Adapter cache time: 0.16854635486379266 Engine time: 0.10206977184861898 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3579342062585056,
    "estimated_duration": 3600.0267715904406,
    "input_throughput": 1837.8346661786165,
    "output_throughput": 1596.6570152645315,
    "total_throughput": 3434.491681443148,
    "itl": 32.51061376715886,
    "ttft": 9452.23361932122,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 58.4830686579935,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.772011136300995
}
#Debug simulation 
Total elapsed time: 2.35802595410496. Arrivals time: 0.07910714438185096 Scheduler time: 1.8461611378006637 Scheduler overhead time: 0.10774772008880973 Adapter cache time: 0.16983390087261796 Engine time: 0.10471669211983681 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.327419017907232,
    "estimated_duration": 3600.014768031333,
    "input_throughput": 1837.840794085991,
    "output_throughput": 1596.6623390112636,
    "total_throughput": 3434.5031330972547,
    "itl": 32.410427030818575,
    "ttft": 9449.72673564196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17681,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 52.867079264179736,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.72609517206335
}
#Debug simulation 
Total elapsed time: 2.3275072360411286. Arrivals time: 0.07722829468548298 Scheduler time: 1.8197335223667324 Scheduler overhead time: 0.10812132759019732 Adapter cache time: 0.16844849567860365 Engine time: 0.10332566825672984 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 66, 540, 540, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 540, 135, 540, 540, 66, 540, 135, 135, 540, 540, 135, 66, 66, 135, 540, 540, 135, 135, 66, 66, 135, 540, 540, 66, 540, 135, 66, 135, 540, 66, 135, 540, 540, 135, 66, 66, 540, 66, 66, 540, 540, 66, 66, 135, 135, 135, 66, 135, 66, 540, 66, 540, 135, 540, 540, 66, 540, 66, 540, 135, 66, 66, 135, 135, 540, 135, 540, 540, 540, 66, 135, 135, 66, 540, 135, 540, 540, 135, 66, 135, 135, 135, 66, 540, 135, 540, 66, 540, 66, 66, 135, 540, 540, 135, 66, 135, 66, 135, 540, 540, 135, 66, 135, 66, 540, 66, 66, 66, 66, 540, 135, 135, 540, 135, 135, 66, 135, 540, 135, 66, 66, 135, 540, 66, 66, 66, 540, 540, 540, 66, 135, 540, 135, 135, 135, 66, 540, 66, 540, 135, 66, 135, 66, 66, 135, 66, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 66, 66, 540, 135, 540, 135, 540, 135, 66, 135, 66, 66, 66, 540, 540, 135, 135, 66, 66, 135, 66, 540, 66, 66, 135, 66, 540, 135, 66, 540, 66, 66, 540, 135, 540, 135, 66, 135, 540, 135, 135, 540, 135, 66, 135, 66, 540, 135, 135, 540, 540, 66, 66, 66, 540, 540, 66, 66, 540, 135, 66, 135, 66, 135, 540, 540, 540, 66, 540, 540, 540, 540, 66, 135, 135, 540, 66, 540, 66, 66, 66, 540, 135, 540, 540, 66, 135, 135, 135, 66, 135, 66, 135, 135, 540, 66, 66, 135, 66, 135, 135, 66, 540, 540, 540, 66, 135, 135, 135, 135, 66, 135, 66, 540, 66, 66, 540, 135, 540, 135, 135, 135, 135, 66, 66, 540, 66, 66, 540, 540, 540, 66, 540, 540, 135, 540, 135, 66, 540, 66, 540, 540, 66, 66, 66]
Prompts retrieved: 79221 . Total input tokens: 17627711 . Total output tokens: 15832351
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.32229718612507,
    "estimated_duration": 3599.9992887367994,
    "input_throughput": 1837.8486964428184,
    "output_throughput": 1596.6692043477913,
    "total_throughput": 3434.5179007906095,
    "itl": 32.524451789775846,
    "ttft": 9452.475614303883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 17675,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 59.22242266979513,
    "arrivals": 26579,
    "finished_requests": 26510,
    "scheduler_time": 3.778205493414714
}
#Debug simulation 
Total elapsed time: 2.3223852664232254. Arrivals time: 0.07657037861645222 Scheduler time: 1.8180074524134398 Scheduler overhead time: 0.10716920485720038 Adapter cache time: 0.16818387946113944 Engine time: 0.10208040289580822 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.287920847069472,
    "estimated_duration": 3599.937638980514,
    "input_throughput": 1731.4536042255424,
    "output_throughput": 1563.1868005340357,
    "total_throughput": 3294.640404759578,
    "itl": 31.5526888108461,
    "ttft": 5736.510016914991,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16313,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 49.925736566763426,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.910826769908409
}
#Debug simulation 
Total elapsed time: 2.288005503360182. Arrivals time: 0.07302078604698181 Scheduler time: 1.7897249041125178 Scheduler overhead time: 0.10965057043358684 Adapter cache time: 0.15993708977475762 Engine time: 0.10387432016432285 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.3093733401037753,
    "estimated_duration": 3599.9415877496826,
    "input_throughput": 1731.4517049973347,
    "output_throughput": 1563.1850858773691,
    "total_throughput": 3294.636790874704,
    "itl": 31.604893882062154,
    "ttft": 5737.1634995935065,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.2061803171378,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.9343467658719
}
#Debug simulation 
Total elapsed time: 2.3094737199135125. Arrivals time: 0.07563198171555996 Scheduler time: 1.8029679604806006 Scheduler overhead time: 0.1094200205989182 Adapter cache time: 0.16147343767806888 Engine time: 0.10748818144202232 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2755167530849576,
    "estimated_duration": 3599.924316728606,
    "input_throughput": 1731.460011821662,
    "output_throughput": 1563.1925854246344,
    "total_throughput": 3294.6525972462964,
    "itl": 31.60700159828951,
    "ttft": 5737.109473459097,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.31376662885233,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.934869636156077
}
#Debug simulation 
Total elapsed time: 2.2756088031455874. Arrivals time: 0.07382361404597759 Scheduler time: 1.7765541994012892 Scheduler overhead time: 0.10862834099680185 Adapter cache time: 0.16331283282488585 Engine time: 0.10224489495158195 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.2734057107008994,
    "estimated_duration": 3599.94169130449,
    "input_throughput": 1731.4516551909312,
    "output_throughput": 1563.185040911271,
    "total_throughput": 3294.636696102202,
    "itl": 31.57009848723297,
    "ttft": 5736.812697160395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 51.076432688240075,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.9191706350257105
}
#Debug simulation 
Total elapsed time: 2.2735391408205032. Arrivals time: 0.07326309708878398 Scheduler time: 1.7739442754536867 Scheduler overhead time: 0.10985360946506262 Adapter cache time: 0.1600035186856985 Engine time: 0.10441927518695593 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.268476163968444,
    "estimated_duration": 3599.94741438253,
    "input_throughput": 1731.4489025860166,
    "output_throughput": 1563.1825558110877,
    "total_throughput": 3294.6314583971043,
    "itl": 31.61821613850784,
    "ttft": 5737.203225235818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 53.976957214427166,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.940137701938929
}
#Debug simulation 
Total elapsed time: 2.268558130133897. Arrivals time: 0.07385119376704097 Scheduler time: 1.769792609848082 Scheduler overhead time: 0.10978437727317214 Adapter cache time: 0.1600581957027316 Engine time: 0.10389190027490258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.289367615710944,
    "estimated_duration": 3599.9346771426463,
    "input_throughput": 1731.455028774961,
    "output_throughput": 1563.1880866423335,
    "total_throughput": 3294.643115417294,
    "itl": 31.53065397701415,
    "ttft": 5736.1753731809695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16300,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 48.7378198069163,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.902162631553778
}
#Debug simulation 
Total elapsed time: 2.289449878036976. Arrivals time: 0.073285355232656 Scheduler time: 1.7880808296613395 Scheduler overhead time: 0.10977368103340268 Adapter cache time: 0.1603216757066548 Engine time: 0.1064950474537909 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [106 107 107]
Adapter prompts. [135, 540, 540, 33, 540, 540, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 540, 135, 540, 540, 33, 540, 135, 135, 540, 540, 135, 33, 33, 135, 540, 540, 135, 135, 33, 33, 135, 540, 540, 33, 540, 135, 33, 135, 540, 33, 135, 540, 540, 135, 33, 33, 540, 33, 33, 540, 540, 33, 33, 135, 135, 135, 33, 135, 33, 540, 33, 540, 135, 540, 540, 33, 540, 33, 540, 135, 33, 33, 135, 135, 540, 135, 540, 540, 540, 33, 135, 135, 33, 540, 135, 540, 540, 135, 33, 135, 135, 135, 33, 540, 135, 540, 33, 540, 33, 33, 135, 540, 540, 135, 33, 135, 33, 135, 540, 540, 135, 33, 135, 33, 540, 33, 33, 33, 33, 540, 135, 135, 540, 135, 135, 33, 135, 540, 135, 33, 33, 135, 540, 33, 33, 33, 540, 540, 540, 33, 135, 540, 135, 135, 135, 33, 540, 33, 540, 135, 33, 135, 33, 33, 135, 33, 135, 540, 540, 540, 540, 135, 135, 540, 540, 540, 135, 540, 33, 33, 540, 135, 540, 135, 540, 135, 33, 135, 33, 33, 33, 540, 540, 135, 135, 33, 33, 135, 33, 540, 33, 33, 135, 33, 540, 135, 33, 540, 33, 33, 540, 135, 540, 135, 33, 135, 540, 135, 135, 540, 135, 33, 135, 33, 540, 135, 135, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 135, 33, 135, 33, 135, 540, 540, 540, 33, 540, 540, 540, 540, 33, 135, 135, 540, 33, 540, 33, 33, 33, 540, 135, 540, 540, 33, 135, 135, 135, 33, 135, 33, 135, 135, 540, 33, 33, 135, 33, 135, 135, 33, 540, 540, 540, 33, 135, 135, 135, 135, 33, 135, 33, 540, 33, 33, 540, 135, 540, 135, 135, 135, 135, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 135, 540, 135, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 75723 . Total input tokens: 16854799 . Total output tokens: 15128237
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.2741135037504137,
    "estimated_duration": 3599.9242386470114,
    "input_throughput": 1731.460049376663,
    "output_throughput": 1563.1926193299505,
    "total_throughput": 3294.6526687066134,
    "itl": 31.628935231603595,
    "ttft": 5737.355842971847,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16297,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 54.638143616358896,
    "arrivals": 25398,
    "finished_requests": 25358,
    "scheduler_time": 2.944774855707129
}
#Debug simulation 
Total elapsed time: 2.274201275780797. Arrivals time: 0.07418360421434045 Scheduler time: 1.7764402921311557 Scheduler overhead time: 0.10850476985797286 Adapter cache time: 0.15944378962740302 Engine time: 0.1043013483285904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.1096611032262444,
    "estimated_duration": 3599.95065767192,
    "input_throughput": 1576.9193913538788,
    "output_throughput": 1406.78705948573,
    "total_throughput": 2983.706450839609,
    "itl": 28.657145004466077,
    "ttft": 4905.057590673703,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 40.74121284722891,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.695986740199084
}
#Debug simulation 
Total elapsed time: 2.10974945127964. Arrivals time: 0.06802696455270052 Scheduler time: 1.6152553581632674 Scheduler overhead time: 0.11711300304159522 Adapter cache time: 0.1409180643968284 Engine time: 0.11302654445171356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.102074970025569,
    "estimated_duration": 3599.9687102212865,
    "input_throughput": 1576.9114836698263,
    "output_throughput": 1406.7800049541815,
    "total_throughput": 2983.691488624008,
    "itl": 28.69369557401958,
    "ttft": 4905.323177246677,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.405206320848166,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.7040070117669833
}
#Debug simulation 
Total elapsed time: 2.102172230836004. Arrivals time: 0.06849383329972625 Scheduler time: 1.6089236671105027 Scheduler overhead time: 0.11695614410564303 Adapter cache time: 0.14047186076641083 Engine time: 0.11177442455664277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1108873831108212,
    "estimated_duration": 3599.947872581972,
    "input_throughput": 1576.9206113333066,
    "output_throughput": 1406.7881478427387,
    "total_throughput": 2983.708759176045,
    "itl": 28.695600769461908,
    "ttft": 4905.0626162970575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 43.47257986317246,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.704264711997621
}
#Debug simulation 
Total elapsed time: 2.110974739305675. Arrivals time: 0.06778363417834044 Scheduler time: 1.617242624051869 Scheduler overhead time: 0.11730993166565895 Adapter cache time: 0.14187672128900886 Engine time: 0.11144453473389149 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 2.093294563703239,
    "estimated_duration": 3599.9509944598217,
    "input_throughput": 1576.9192438276004,
    "output_throughput": 1406.7869278759213,
    "total_throughput": 2983.7061717035217,
    "itl": 28.6703696352471,
    "ttft": 4904.984342598467,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13312,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.69902320798599,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.698856969672388
}
#Debug simulation 
Total elapsed time: 2.0934152519330382. Arrivals time: 0.06865772930905223 Scheduler time: 1.5992371425963938 Scheduler overhead time: 0.1161608500406146 Adapter cache time: 0.14070614334195852 Engine time: 0.1132308361120522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 2.130884785670787,
    "estimated_duration": 3599.9600748859,
    "input_throughput": 1576.9152662560919,
    "output_throughput": 1406.7833794408161,
    "total_throughput": 2983.698645696908,
    "itl": 28.702555862165184,
    "ttft": 4905.27055942568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.01130534036527,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.7059179961244939
}
#Debug simulation 
Total elapsed time: 2.1309978240169585. Arrivals time: 0.06787246884778142 Scheduler time: 1.6365589164197445 Scheduler overhead time: 0.11752866208553314 Adapter cache time: 0.14205018943175673 Engine time: 0.1114340447820723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 2.128033557906747,
    "estimated_duration": 3599.947193125596,
    "input_throughput": 1576.920908962329,
    "output_throughput": 1406.7884133608493,
    "total_throughput": 2983.709322323178,
    "itl": 28.644942861957897,
    "ttft": 4904.949867355328,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13310,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.797569425151146,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.6932900621055366
}
#Debug simulation 
Total elapsed time: 2.1281400825828314. Arrivals time: 0.0708917398005724 Scheduler time: 1.629909000825137 Scheduler overhead time: 0.11655877064913511 Adapter cache time: 0.14134776080027223 Engine time: 0.11369634559378028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_320_slots_64_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [106 107 107]
Adapter prompts. [66, 540, 540, 33, 540, 540, 66, 66, 66, 66, 33, 66, 33, 66, 33, 66, 66, 540, 66, 540, 540, 33, 540, 66, 66, 540, 540, 66, 33, 33, 66, 540, 540, 66, 66, 33, 33, 66, 540, 540, 33, 540, 66, 33, 66, 540, 33, 66, 540, 540, 66, 33, 33, 540, 33, 33, 540, 540, 33, 33, 66, 66, 66, 33, 66, 33, 540, 33, 540, 66, 540, 540, 33, 540, 33, 540, 66, 33, 33, 66, 66, 540, 66, 540, 540, 540, 33, 66, 66, 33, 540, 66, 540, 540, 66, 33, 66, 66, 66, 33, 540, 66, 540, 33, 540, 33, 33, 66, 540, 540, 66, 33, 66, 33, 66, 540, 540, 66, 33, 66, 33, 540, 33, 33, 33, 33, 540, 66, 66, 540, 66, 66, 33, 66, 540, 66, 33, 33, 66, 540, 33, 33, 33, 540, 540, 540, 33, 66, 540, 66, 66, 66, 33, 540, 33, 540, 66, 33, 66, 33, 33, 66, 33, 66, 540, 540, 540, 540, 66, 66, 540, 540, 540, 66, 540, 33, 33, 540, 66, 540, 66, 540, 66, 33, 66, 33, 33, 33, 540, 540, 66, 66, 33, 33, 66, 33, 540, 33, 33, 66, 33, 540, 66, 33, 540, 33, 33, 540, 66, 540, 66, 33, 66, 540, 66, 66, 540, 66, 33, 66, 33, 540, 66, 66, 540, 540, 33, 33, 33, 540, 540, 33, 33, 540, 66, 33, 66, 33, 66, 540, 540, 540, 33, 540, 540, 540, 540, 33, 66, 66, 540, 33, 540, 33, 33, 33, 540, 66, 540, 540, 33, 66, 66, 66, 33, 66, 33, 66, 66, 540, 33, 33, 66, 33, 66, 66, 33, 540, 540, 540, 33, 66, 66, 66, 66, 33, 66, 33, 540, 33, 33, 540, 66, 540, 66, 66, 66, 66, 33, 33, 540, 33, 33, 540, 540, 540, 33, 540, 540, 66, 540, 66, 33, 540, 33, 540, 540, 33, 33, 33]
Prompts retrieved: 68340 . Total input tokens: 15202698 . Total output tokens: 13659282
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 2.1288795340806246,
    "estimated_duration": 3599.952518634409,
    "input_throughput": 1576.9185761798396,
    "output_throughput": 1406.7863322600417,
    "total_throughput": 2983.7049084398814,
    "itl": 28.710465048379817,
    "ttft": 4905.289610449081,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 13307,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 44.594888649248034,
    "arrivals": 22982,
    "finished_requests": 22951,
    "scheduler_time": 0.7076398336120804
}
#Debug simulation 
Total elapsed time: 2.1289707021787763. Arrivals time: 0.06783198053017259 Scheduler time: 1.63450166862458 Scheduler overhead time: 0.11705953860655427 Adapter cache time: 0.1410299027338624 Engine time: 0.11326187057420611 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.7284248457290232,
    "estimated_duration": 3599.8134634416774,
    "input_throughput": 1180.7275691269615,
    "output_throughput": 1042.564576779995,
    "total_throughput": 2223.2921459069566,
    "itl": 24.82827764055022,
    "ttft": 8060.885934730246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.76107727690607,
    "arrivals": 17062,
    "finished_requests": 17024,
    "scheduler_time": 0.000562270667802381
}
#Debug simulation 
Total elapsed time: 1.7285394719801843. Arrivals time: 0.05613291310146451 Scheduler time: 1.2326869298703969 Scheduler overhead time: 0.12890280317515135 Adapter cache time: 0.12358004180714488 Engine time: 0.12487647216767073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7221438316628337,
    "estimated_duration": 3599.8125437122535,
    "input_throughput": 1180.727870795416,
    "output_throughput": 1042.5648431486754,
    "total_throughput": 2223.2927139440917,
    "itl": 24.857271759866887,
    "ttft": 8061.163871457049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12665,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.34327297763639,
    "arrivals": 17062,
    "finished_requests": 17024,
    "scheduler_time": 0.0005883326100718121
}
#Debug simulation 
Total elapsed time: 1.7222203370183706. Arrivals time: 0.05457139341160655 Scheduler time: 1.226399754639715 Scheduler overhead time: 0.12861280981451273 Adapter cache time: 0.12386155175045133 Engine time: 0.12699728924781084 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7302382993511856,
    "estimated_duration": 3599.8098019951726,
    "input_throughput": 1180.7287700711972,
    "output_throughput": 1042.5656371955822,
    "total_throughput": 2223.2944072667797,
    "itl": 24.85806896700448,
    "ttft": 8061.050199923059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.41682518451221,
    "arrivals": 17062,
    "finished_requests": 17024,
    "scheduler_time": 0.0005858306520447328
}
#Debug simulation 
Total elapsed time: 1.7303307461552322. Arrivals time: 0.05463396990671754 Scheduler time: 1.23399109672755 Scheduler overhead time: 0.12897886568680406 Adapter cache time: 0.12371739139780402 Engine time: 0.12669802457094193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.7033561849966645,
    "estimated_duration": 3599.8129153798864,
    "input_throughput": 1180.727748889544,
    "output_throughput": 1042.564735507635,
    "total_throughput": 2223.292484397179,
    "itl": 24.83878925326501,
    "ttft": 8060.906983772096,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 39.65399110201702,
    "arrivals": 17062,
    "finished_requests": 17024,
    "scheduler_time": 0.0005679834478616831
}
#Debug simulation 
Total elapsed time: 1.7034873887896538. Arrivals time: 0.05437821662053466 Scheduler time: 1.21147146448493 Scheduler overhead time: 0.12882672902196646 Adapter cache time: 0.12348012998700142 Engine time: 0.1233518929220736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7116810558363795,
    "estimated_duration": 3599.8134966784014,
    "input_throughput": 1180.72755822542,
    "output_throughput": 1042.5645671540988,
    "total_throughput": 2223.292125379519,
    "itl": 24.86291921013173,
    "ttft": 8061.1079313602595,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12666,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 41.93857764434407,
    "arrivals": 17062,
    "finished_requests": 17024,
    "scheduler_time": 0.0005923774181130614
}
#Debug simulation 
Total elapsed time: 1.711768789216876. Arrivals time: 0.05426116520538926 Scheduler time: 1.2199786566197872 Scheduler overhead time: 0.12912657717242837 Adapter cache time: 0.1234205225482583 Engine time: 0.12306311912834644 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [16]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.7288645491935313,
    "estimated_duration": 3599.804460289617,
    "input_throughput": 1180.7305221400943,
    "output_throughput": 1042.5671842459062,
    "total_throughput": 2223.2977063860003,
    "itl": 24.820170276662704,
    "ttft": 8060.868404190698,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12664,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.86599693464269,
    "arrivals": 17062,
    "finished_requests": 17024,
    "scheduler_time": 0.0005420466275961346
}
#Debug simulation 
Total elapsed time: 1.7289575221948326. Arrivals time: 0.05488865030929446 Scheduler time: 1.2338338023982942 Scheduler overhead time: 0.12922467617318034 Adapter cache time: 0.12356134178116918 Engine time: 0.12509097019210458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_320_slots_64_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 66, 270, 270, 135, 135, 135, 135, 66, 135, 66, 135, 66, 135, 135, 270, 135, 270, 270, 66, 270, 135, 135, 270, 270, 135, 66, 66, 135, 270, 270, 135, 135, 66, 66, 135, 270, 270, 66, 270, 135, 66, 135, 270, 66, 135, 270, 270, 135, 66, 66, 270, 66, 66, 270, 270, 66, 66, 135, 135, 135, 66, 135, 66, 270, 66, 270, 135, 270, 270, 66, 270, 66, 270, 135, 66, 66, 135, 135, 270, 135, 270, 270, 270, 66, 135, 135, 66, 270, 135, 270, 270, 135, 66, 135, 135, 135, 66, 270, 135, 270, 66, 270, 66, 66, 135, 270, 270, 135, 66, 135, 66, 135, 270, 270, 135, 66, 135, 66, 270, 66, 66, 66, 66, 270, 135, 135, 270, 135, 135, 66, 135, 270, 135, 66, 66, 135, 270, 66, 66, 66, 270, 270, 270, 66, 135, 270, 135, 135, 135, 66, 270, 66, 270, 135, 66, 135, 66, 66, 135, 66, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 66, 66, 270, 135, 270, 135, 270, 135, 66, 135, 66, 66, 66, 270, 270, 135, 135, 66, 66, 135, 66, 270, 66, 66, 135, 66, 270, 135, 66, 270, 66, 66, 270, 135, 270, 135, 66, 135, 270, 135, 135, 270, 135, 66, 135, 66, 270, 135, 135, 270, 270, 66, 66, 66, 270, 270, 66, 66, 270, 135, 66, 135, 66, 135, 270, 270, 270, 66, 270, 270, 270, 270, 66, 135, 135, 270, 66, 270, 66, 66, 66, 270, 135, 270, 270, 66, 135, 135, 135, 66, 135, 66, 135, 135, 270, 66, 66, 135, 66, 135, 135, 66, 270, 270, 270, 66, 135, 135, 135, 135, 66, 135, 66, 270, 66, 66, 270, 135, 270, 135, 135, 135, 135, 66, 66, 270, 66, 66, 270, 270, 270, 66, 270, 270, 135, 270, 135, 66, 270, 66, 270, 270, 66, 66, 66]
Prompts retrieved: 50331 . Total input tokens: 11166485 . Total output tokens: 10087733
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.7055933983065188,
    "estimated_duration": 3599.803248551581,
    "input_throughput": 1180.7309195885061,
    "output_throughput": 1042.5675351868397,
    "total_throughput": 2223.298454775346,
    "itl": 24.869355414824906,
    "ttft": 8061.136592760948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 12667,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 42.48961615052056,
    "arrivals": 17062,
    "finished_requests": 17024,
    "scheduler_time": 0.0005947542541362579
}
#Debug simulation 
Total elapsed time: 1.7056719912216067. Arrivals time: 0.05368148349225521 Scheduler time: 1.2120056990534067 Scheduler overhead time: 0.12939692242071033 Adapter cache time: 0.12299289088696241 Engine time: 0.1258953372016549 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [8]. Counts: [320]
---Simulation End---
#Simulation results
{
    "duration": 1.6678516217507422,
    "estimated_duration": 3599.8505467945506,
    "input_throughput": 1091.030849460471,
    "output_throughput": 973.7037564298769,
    "total_throughput": 2064.734605890348,
    "itl": 24.045015592073522,
    "ttft": 6379.707883397464,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11395,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.87425784211472,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.0002534889146247241
}
#Debug simulation 
Total elapsed time: 1.667950448114425. Arrivals time: 0.052032040897756815 Scheduler time: 1.1756791714578867 Scheduler overhead time: 0.13344619469717145 Adapter cache time: 0.11456392705440521 Engine time: 0.1286329599097371 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.6260017156600952,
    "estimated_duration": 3599.870434001484,
    "input_throughput": 1091.0248221445797,
    "output_throughput": 973.6983772784737,
    "total_throughput": 2064.7231994230533,
    "itl": 24.06589390036347,
    "ttft": 6379.949957736022,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.18445107547471,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.0002615785307072227
}
#Debug simulation 
Total elapsed time: 1.6260939138010144. Arrivals time: 0.0513149444013834 Scheduler time: 1.1398217575624585 Scheduler overhead time: 0.13177450746297836 Adapter cache time: 0.1139230439439416 Engine time: 0.12604439072310925 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [214 106]
---Simulation End---
#Simulation results
{
    "duration": 1.652929691132158,
    "estimated_duration": 3599.864014398034,
    "input_throughput": 1091.0267677588263,
    "output_throughput": 973.7001136655808,
    "total_throughput": 2064.726881424407,
    "itl": 24.06740321615557,
    "ttft": 6380.117682609084,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11393,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.24935761727843,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00026003568069305253
}
#Debug simulation 
Total elapsed time: 1.6530030257999897. Arrivals time: 0.0514244744554162 Scheduler time: 1.1642205365933478 Scheduler overhead time: 0.13151905126869678 Adapter cache time: 0.11492822971194983 Engine time: 0.12732608523219824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107 213]
---Simulation End---
#Simulation results
{
    "duration": 1.6261399667710066,
    "estimated_duration": 3599.8677301966204,
    "input_throughput": 1091.0256415964157,
    "output_throughput": 973.6991086082352,
    "total_throughput": 2064.7247502046507,
    "itl": 24.052582628160597,
    "ttft": 6379.809848648625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11392,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.64881998570975,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.0002543229006337505
}
#Debug simulation 
Total elapsed time: 1.6262638038024306. Arrivals time: 0.051737939938902855 Scheduler time: 1.1390364957042038 Scheduler overhead time: 0.13100274512544274 Adapter cache time: 0.11404906027019024 Engine time: 0.12721992144361138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 64,
    "served_adapters": 320,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_320_slots_64_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [106 107 107]
Adapter prompts. [135, 270, 270, 33, 270, 270, 135, 135, 135, 135, 33, 135, 33, 135, 33, 135, 135, 270, 135, 270, 270, 33, 270, 135, 135, 270, 270, 135, 33, 33, 135, 270, 270, 135, 135, 33, 33, 135, 270, 270, 33, 270, 135, 33, 135, 270, 33, 135, 270, 270, 135, 33, 33, 270, 33, 33, 270, 270, 33, 33, 135, 135, 135, 33, 135, 33, 270, 33, 270, 135, 270, 270, 33, 270, 33, 270, 135, 33, 33, 135, 135, 270, 135, 270, 270, 270, 33, 135, 135, 33, 270, 135, 270, 270, 135, 33, 135, 135, 135, 33, 270, 135, 270, 33, 270, 33, 33, 135, 270, 270, 135, 33, 135, 33, 135, 270, 270, 135, 33, 135, 33, 270, 33, 33, 33, 33, 270, 135, 135, 270, 135, 135, 33, 135, 270, 135, 33, 33, 135, 270, 33, 33, 33, 270, 270, 270, 33, 135, 270, 135, 135, 135, 33, 270, 33, 270, 135, 33, 135, 33, 33, 135, 33, 135, 270, 270, 270, 270, 135, 135, 270, 270, 270, 135, 270, 33, 33, 270, 135, 270, 135, 270, 135, 33, 135, 33, 33, 33, 270, 270, 135, 135, 33, 33, 135, 33, 270, 33, 33, 135, 33, 270, 135, 33, 270, 33, 33, 270, 135, 270, 135, 33, 135, 270, 135, 135, 270, 135, 33, 135, 33, 270, 135, 135, 270, 270, 33, 33, 33, 270, 270, 33, 33, 270, 135, 33, 135, 33, 135, 270, 270, 270, 33, 270, 270, 270, 270, 33, 135, 135, 270, 33, 270, 33, 33, 33, 270, 135, 270, 270, 33, 135, 135, 135, 33, 135, 33, 135, 135, 270, 33, 33, 135, 33, 135, 135, 33, 270, 270, 270, 33, 135, 135, 135, 135, 33, 135, 33, 270, 33, 33, 270, 135, 270, 135, 135, 135, 135, 33, 33, 270, 33, 33, 270, 270, 270, 33, 270, 270, 135, 270, 135, 33, 270, 33, 270, 270, 33, 33, 33]
Prompts retrieved: 46833 . Total input tokens: 10357816 . Total output tokens: 9396702
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [107 107 106]
---Simulation End---
#Simulation results
{
    "duration": 1.631032387726009,
    "estimated_duration": 3599.8534075172574,
    "input_throughput": 1091.0299824427425,
    "output_throughput": 973.7029826493557,
    "total_throughput": 2064.7329650920983,
    "itl": 24.071436886039837,
    "ttft": 6379.854917886445,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11391,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.71370978236374,
    "arrivals": 15904,
    "finished_requests": 15876,
    "scheduler_time": 0.00026241251671624906
}
#Debug simulation 
Total elapsed time: 1.6311308480799198. Arrivals time: 0.05370431300252676 Scheduler time: 1.1410143706016243 Scheduler overhead time: 0.13193439645692706 Adapter cache time: 0.1136714480817318 Engine time: 0.12740181433036923 
