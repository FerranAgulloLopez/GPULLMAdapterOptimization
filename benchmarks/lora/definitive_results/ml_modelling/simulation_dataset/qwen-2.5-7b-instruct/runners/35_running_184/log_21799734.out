INFO 06-01 00:47:02 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:02 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 33.92118960572407,
    "estimated_duration": 3600.0421838911257,
    "input_throughput": 6327.979183670853,
    "output_throughput": 5615.534754137033,
    "total_throughput": 11943.513937807886,
    "itl": 66.03679108016644,
    "ttft": 155711.56579624064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14996389945270483,
    "arrivals": 95912,
    "finished_requests": 91766,
    "scheduler_time": 84.96096446772805
}
#Debug simulation 
Total elapsed time: 33.92143217287958. Arrivals time: 0.30218768771737814 Scheduler time: 33.39801032003015 Scheduler overhead time: 0.08566927909851074 Adapter cache time: 0.013495106250047684 Engine time: 0.0848516202531755 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 33.86168035399169,
    "estimated_duration": 3600.0793080184308,
    "input_throughput": 6328.062537194352,
    "output_throughput": 5615.605454849746,
    "total_throughput": 11943.667992044098,
    "itl": 66.03718695250394,
    "ttft": 155710.00478361102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1583617286849767,
    "arrivals": 95912,
    "finished_requests": 91767,
    "scheduler_time": 84.96209674773144
}
#Debug simulation 
Total elapsed time: 33.86190143274143. Arrivals time: 0.3071060939691961 Scheduler time: 33.33539818553254 Scheduler overhead time: 0.08469945704564452 Adapter cache time: 0.013116777408868074 Engine time: 0.08431848883628845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 33.85953572113067,
    "estimated_duration": 3600.0792772764944,
    "input_throughput": 6328.062591231189,
    "output_throughput": 5615.605502802742,
    "total_throughput": 11943.668094033932,
    "itl": 66.03720670843883,
    "ttft": 155709.97812252498,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15891260093078013,
    "arrivals": 95912,
    "finished_requests": 91767,
    "scheduler_time": 84.96208065870533
}
#Debug simulation 
Total elapsed time: 33.85971388500184. Arrivals time: 0.29500548588111997 Scheduler time: 33.343815156724304 Scheduler overhead time: 0.08466511638835073 Adapter cache time: 0.013318244833499193 Engine time: 0.08554101875051856 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 34.008690271060914,
    "estimated_duration": 3600.0578694131877,
    "input_throughput": 6327.951612542639,
    "output_throughput": 5615.510287143037,
    "total_throughput": 11943.461899685677,
    "itl": 66.03679859266745,
    "ttft": 155747.608280242,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15223279890837152,
    "arrivals": 95912,
    "finished_requests": 91766,
    "scheduler_time": 84.96147867938927
}
#Debug simulation 
Total elapsed time: 34.00887185987085. Arrivals time: 0.3082857448607683 Scheduler time: 33.478844253346324 Scheduler overhead time: 0.08650743355974555 Adapter cache time: 0.013179184403270483 Engine time: 0.08469748916104436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 34.01940310932696,
    "estimated_duration": 3600.016626897947,
    "input_throughput": 6328.024106830269,
    "output_throughput": 5615.574619559413,
    "total_throughput": 11943.598726389682,
    "itl": 66.0372449598433,
    "ttft": 155639.7725253903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.160798907727003,
    "arrivals": 95912,
    "finished_requests": 91766,
    "scheduler_time": 84.96045573786891
}
#Debug simulation 
Total elapsed time: 34.019573946949095. Arrivals time: 0.30405719112604856 Scheduler time: 33.49310721596703 Scheduler overhead time: 0.0861793328076601 Adapter cache time: 0.013395529240369797 Engine time: 0.08569184504449368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 34.06732245720923,
    "estimated_duration": 3600.0377027483596,
    "input_throughput": 6327.987060415622,
    "output_throughput": 5615.541744067423,
    "total_throughput": 11943.528804483045,
    "itl": 66.03700024120566,
    "ttft": 155675.7146298589,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.14651246445020671,
    "arrivals": 95912,
    "finished_requests": 91766,
    "scheduler_time": 84.96093120021881
}
#Debug simulation 
Total elapsed time: 34.06749125616625. Arrivals time: 0.30849412735551596 Scheduler time: 33.538343575783074 Scheduler overhead time: 0.08575773844495416 Adapter cache time: 0.013315837364643812 Engine time: 0.08441159827634692 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 66, 8640, 66, 66, 8640, 270, 8640, 270, 8640, 8640, 270, 66, 8640, 270, 66, 66, 270, 8640, 66, 270, 66, 66, 270, 270, 270, 66, 66, 8640, 270, 270, 66, 8640, 8640, 270, 8640, 8640, 270, 8640, 66, 8640, 270, 270, 270, 8640, 8640, 66, 66, 270, 66, 8640, 66, 66, 8640, 66, 270, 270, 66, 270, 8640, 8640, 8640, 270, 8640, 8640, 66, 66, 8640, 270, 8640, 66, 270, 8640, 66, 8640, 270, 66, 8640, 66, 66, 8640, 66, 66, 270]
Prompts retrieved: 287232 . Total input tokens: 64093852 . Total output tokens: 57509602
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 34.30088662635535,
    "estimated_duration": 3600.0165892375744,
    "input_throughput": 6328.024173028783,
    "output_throughput": 5615.5746783048735,
    "total_throughput": 11943.598851333656,
    "itl": 66.03715595829117,
    "ttft": 155639.7457585796,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 49,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16255946073681102,
    "arrivals": 95912,
    "finished_requests": 91766,
    "scheduler_time": 84.96036941351277
}
#Debug simulation 
Total elapsed time: 34.3010213309899. Arrivals time: 0.3153887987136841 Scheduler time: 33.75992998108268 Scheduler overhead time: 0.08681784570217133 Adapter cache time: 0.013481592759490013 Engine time: 0.08830079669132829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 32.114846034906805,
    "estimated_duration": 3600.0493943223055,
    "input_throughput": 6329.693152526758,
    "output_throughput": 5596.799041640072,
    "total_throughput": 11926.492194166829,
    "itl": 65.51384801467277,
    "ttft": 141520.71486399678,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15608487494057033,
    "arrivals": 95515,
    "finished_requests": 91766,
    "scheduler_time": 83.54493795730775
}
#Debug simulation 
Total elapsed time: 32.11498059891164. Arrivals time: 0.3124047755263746 Scheduler time: 31.574207445140928 Scheduler overhead time: 0.08887332957237959 Adapter cache time: 0.01333374297246337 Engine time: 0.08816505642607808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 31.81141112325713,
    "estimated_duration": 3600.0706009742726,
    "input_throughput": 6329.6558667025,
    "output_throughput": 5596.766073017353,
    "total_throughput": 11926.421939719852,
    "itl": 65.51378738347175,
    "ttft": 141520.7765744295,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16515901991166174,
    "arrivals": 95515,
    "finished_requests": 91766,
    "scheduler_time": 83.54546563123853
}
#Debug simulation 
Total elapsed time: 31.8115305993706. Arrivals time: 0.3047787914983928 Scheduler time: 31.285781984217465 Scheduler overhead time: 0.08515828102827072 Adapter cache time: 0.013136563822627068 Engine time: 0.08530883677303791 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 31.88052270002663,
    "estimated_duration": 3600.0708874394854,
    "input_throughput": 6329.655363038469,
    "output_throughput": 5596.765627670904,
    "total_throughput": 11926.420990709374,
    "itl": 65.51380624753678,
    "ttft": 141520.78017614904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16567413361743086,
    "arrivals": 95515,
    "finished_requests": 91766,
    "scheduler_time": 83.54546319280867
}
#Debug simulation 
Total elapsed time: 31.88067119428888. Arrivals time: 0.31235389364883304 Scheduler time: 31.343664379790425 Scheduler overhead time: 0.08700639940798283 Adapter cache time: 0.013872034847736359 Engine time: 0.08650765242055058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 32.182400714140385,
    "estimated_duration": 3600.059885943965,
    "input_throughput": 6329.674705959789,
    "output_throughput": 5596.78273093972,
    "total_throughput": 11926.457436899509,
    "itl": 65.51391920184157,
    "ttft": 141520.82976321824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15862149481661625,
    "arrivals": 95515,
    "finished_requests": 91766,
    "scheduler_time": 83.54526646862323
}
#Debug simulation 
Total elapsed time: 32.18254037108272. Arrivals time: 0.31580077297985554 Scheduler time: 31.643683397676796 Scheduler overhead time: 0.08588196616619825 Adapter cache time: 0.013730961829423904 Engine time: 0.08560002455487847 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 32.48374160705134,
    "estimated_duration": 3600.0714941737115,
    "input_throughput": 6329.654296276724,
    "output_throughput": 5596.7646844259525,
    "total_throughput": 11926.418980702678,
    "itl": 65.5136456170258,
    "ttft": 141520.77138782156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16768619420006858,
    "arrivals": 95515,
    "finished_requests": 91766,
    "scheduler_time": 83.54543642780375
}
#Debug simulation 
Total elapsed time: 32.48388102790341. Arrivals time: 0.3201109799556434 Scheduler time: 31.93416568962857 Scheduler overhead time: 0.08928658673539758 Adapter cache time: 0.013480355963110924 Engine time: 0.0893808794207871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 32.25973034836352,
    "estimated_duration": 3600.0149186251942,
    "input_throughput": 6329.75376910443,
    "output_throughput": 5596.852639625889,
    "total_throughput": 11926.606408730318,
    "itl": 65.51332656813058,
    "ttft": 141412.05990758308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.15249256504001107,
    "arrivals": 95515,
    "finished_requests": 91766,
    "scheduler_time": 83.54375940797412
}
#Debug simulation 
Total elapsed time: 32.259860125370324. Arrivals time: 0.3147760587744415 Scheduler time: 31.71730515640229 Scheduler overhead time: 0.08964286558330059 Adapter cache time: 0.013805708847939968 Engine time: 0.08668166073039174 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 8640, 270, 270, 270, 270, 8640, 270, 8640, 270, 33, 8640, 33, 33, 8640, 270, 8640, 270, 8640, 8640, 270, 33, 8640, 270, 33, 33, 270, 8640, 33, 270, 33, 33, 270, 270, 270, 33, 33, 8640, 270, 270, 33, 8640, 8640, 270, 8640, 8640, 270, 8640, 33, 8640, 270, 270, 270, 8640, 8640, 33, 33, 270, 33, 8640, 33, 33, 8640, 33, 270, 270, 33, 270, 8640, 8640, 8640, 270, 8640, 8640, 33, 33, 8640, 270, 8640, 33, 270, 8640, 33, 8640, 270, 33, 8640, 33, 33, 8640, 33, 33, 270]
Prompts retrieved: 286176 . Total input tokens: 63855893 . Total output tokens: 57307226
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 32.27332306606695,
    "estimated_duration": 3600.002580853192,
    "input_throughput": 6329.775462160776,
    "output_throughput": 5596.871820915416,
    "total_throughput": 11926.647283076192,
    "itl": 65.51359366082366,
    "ttft": 141412.13180388967,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 51,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.16957250099629148,
    "arrivals": 95515,
    "finished_requests": 91766,
    "scheduler_time": 83.54360315425113
}
#Debug simulation 
Total elapsed time: 32.2734870002605. Arrivals time: 0.32143963407725096 Scheduler time: 31.725733822211623 Scheduler overhead time: 0.0879490110091865 Adapter cache time: 0.014138288795948029 Engine time: 0.08640829008072615 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 23.40596191585064,
    "estimated_duration": 3600.070469527595,
    "input_throughput": 6339.779232986776,
    "output_throughput": 5596.750722116818,
    "total_throughput": 11936.529955103595,
    "itl": 65.21022215243579,
    "ttft": 97515.95550856901,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10099609554978084,
    "arrivals": 94463,
    "finished_requests": 91907,
    "scheduler_time": 79.46749843818263
}
#Debug simulation 
Total elapsed time: 23.406113632954657. Arrivals time: 0.2941460693255067 Scheduler time: 22.89157591573894 Scheduler overhead time: 0.08440800616517663 Adapter cache time: 0.013318263925611973 Engine time: 0.08543176157400012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 23.35521725891158,
    "estimated_duration": 3600.0113871355684,
    "input_throughput": 6339.879390814969,
    "output_throughput": 5596.8225745062755,
    "total_throughput": 11936.701965321245,
    "itl": 65.21042092399423,
    "ttft": 97480.84422269156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10684356610057875,
    "arrivals": 94463,
    "finished_requests": 91905,
    "scheduler_time": 79.46602735720705
}
#Debug simulation 
Total elapsed time: 23.355379262939095. Arrivals time: 0.2882017269730568 Scheduler time: 22.84823010629043 Scheduler overhead time: 0.08420077804476023 Adapter cache time: 0.012947426177561283 Engine time: 0.0847735651768744 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 23.36182904103771,
    "estimated_duration": 3600.0218192377897,
    "input_throughput": 6339.861019184686,
    "output_throughput": 5596.806356097571,
    "total_throughput": 11936.667375282255,
    "itl": 65.21063790596371,
    "ttft": 97517.979713751,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1071810718998313,
    "arrivals": 94463,
    "finished_requests": 91905,
    "scheduler_time": 79.46639492093325
}
#Debug simulation 
Total elapsed time: 23.362011164892465. Arrivals time: 0.2968849712051451 Scheduler time: 22.845829810015857 Scheduler overhead time: 0.0845298026688397 Adapter cache time: 0.013236604165285826 Engine time: 0.08447311073541641 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 23.241451516747475,
    "estimated_duration": 3600.0015981520755,
    "input_throughput": 6339.896352189302,
    "output_throughput": 5596.774182084368,
    "total_throughput": 11936.67053427367,
    "itl": 65.21030805256612,
    "ttft": 97519.07742983571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10316620823461566,
    "arrivals": 94463,
    "finished_requests": 91904,
    "scheduler_time": 79.46578276429672
}
#Debug simulation 
Total elapsed time: 23.241609388031065. Arrivals time: 0.2900765500962734 Scheduler time: 22.733952744398266 Scheduler overhead time: 0.08417718997225165 Adapter cache time: 0.012986039277166128 Engine time: 0.08340955339372158 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 23.4532053116709,
    "estimated_duration": 3600.0215394211364,
    "input_throughput": 6339.861511959152,
    "output_throughput": 5596.806791117086,
    "total_throughput": 11936.668303076238,
    "itl": 65.21064656597734,
    "ttft": 97517.99587902124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10831285597756504,
    "arrivals": 94463,
    "finished_requests": 91905,
    "scheduler_time": 79.46635038041686
}
#Debug simulation 
Total elapsed time: 23.453369830735028. Arrivals time: 0.2967805960215628 Scheduler time: 22.936388995032758 Scheduler overhead time: 0.0851255189627409 Adapter cache time: 0.013206514064222574 Engine time: 0.08474471606314182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 23.290472690947354,
    "estimated_duration": 3600.0694685481926,
    "input_throughput": 6339.780995727325,
    "output_throughput": 5596.752278262399,
    "total_throughput": 11936.533273989724,
    "itl": 65.21035183460933,
    "ttft": 97515.94966136725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.09867165973177183,
    "arrivals": 94463,
    "finished_requests": 91907,
    "scheduler_time": 79.467543439828
}
#Debug simulation 
Total elapsed time: 23.290599811822176. Arrivals time: 0.29113405710086226 Scheduler time: 22.781512796878815 Scheduler overhead time: 0.08373165782541037 Adapter cache time: 0.012960916850715876 Engine time: 0.08420311752706766 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.8-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.8    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 66, 8640, 66, 66, 8640, 135, 8640, 135, 8640, 8640, 135, 66, 8640, 135, 66, 66, 135, 8640, 66, 135, 66, 66, 135, 135, 135, 66, 66, 8640, 135, 135, 66, 8640, 8640, 135, 8640, 8640, 135, 8640, 66, 8640, 135, 135, 135, 8640, 8640, 66, 66, 135, 66, 8640, 66, 66, 8640, 66, 135, 135, 66, 135, 8640, 8640, 8640, 135, 8640, 8640, 66, 66, 8640, 135, 8640, 66, 135, 8640, 66, 8640, 135, 66, 8640, 66, 66, 8640, 66, 66, 135]
Prompts retrieved: 282912 . Total input tokens: 63134280 . Total output tokens: 56635556
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 23.356511081103235,
    "estimated_duration": 3600.03145167819,
    "input_throughput": 6339.844333682289,
    "output_throughput": 5596.791936528088,
    "total_throughput": 11936.636270210378,
    "itl": 65.21037289473416,
    "ttft": 97479.9172178156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 33,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.1096961476281285,
    "arrivals": 94463,
    "finished_requests": 91906,
    "scheduler_time": 79.46666847913836
}
#Debug simulation 
Total elapsed time: 23.356624789070338. Arrivals time: 0.29248794773593545 Scheduler time: 22.846955525688827 Scheduler overhead time: 0.0837595690973103 Adapter cache time: 0.012958339415490627 Engine time: 0.08351593045517802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 19.977259060833603,
    "estimated_duration": 3600.027511823483,
    "input_throughput": 6341.580980984291,
    "output_throughput": 5608.307140345532,
    "total_throughput": 11949.888121329823,
    "itl": 65.42363071366171,
    "ttft": 84450.04494458079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 36,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11017755878157909,
    "arrivals": 94079,
    "finished_requests": 91872,
    "scheduler_time": 78.10659662484983
}
#Debug simulation 
Total elapsed time: 19.977365299127996. Arrivals time: 0.27881113067269325 Scheduler time: 19.479932196903974 Scheduler overhead time: 0.08344906149432063 Adapter cache time: 0.015264676418155432 Engine time: 0.08310422394424677 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.018017990048975,
    "estimated_duration": 3600.042232022681,
    "input_throughput": 6341.710326873788,
    "output_throughput": 5608.395318367142,
    "total_throughput": 11950.10564524093,
    "itl": 65.42379348042257,
    "ttft": 84373.55399502753,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 36,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11663090762216598,
    "arrivals": 94079,
    "finished_requests": 91874,
    "scheduler_time": 78.10688433230963
}
#Debug simulation 
Total elapsed time: 20.018150712829083. Arrivals time: 0.2863265383057296 Scheduler time: 19.515761393588036 Scheduler overhead time: 0.08337430143728852 Adapter cache time: 0.012922071386128664 Engine time: 0.08287032507359982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 20.097640540916473,
    "estimated_duration": 3600.0422364781452,
    "input_throughput": 6341.710319025196,
    "output_throughput": 5608.395311426111,
    "total_throughput": 11950.105630451308,
    "itl": 65.42376544384645,
    "ttft": 84373.56356121776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 36,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11698612343519926,
    "arrivals": 94079,
    "finished_requests": 91874,
    "scheduler_time": 78.10687288705451
}
#Debug simulation 
Total elapsed time: 20.097833013162017. Arrivals time: 0.28335349867120385 Scheduler time: 19.599248117301613 Scheduler overhead time: 0.08330926485359669 Adapter cache time: 0.012802362442016602 Engine time: 0.08221610030159354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 20.083292479161173,
    "estimated_duration": 3600.0313751852286,
    "input_throughput": 6341.668619159004,
    "output_throughput": 5608.316121678573,
    "total_throughput": 11949.984740837577,
    "itl": 65.42368047553427,
    "ttft": 84411.83113326094,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 36,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11213635911932218,
    "arrivals": 94079,
    "finished_requests": 91873,
    "scheduler_time": 78.10666183538768
}
#Debug simulation 
Total elapsed time: 20.08345077279955. Arrivals time: 0.2906053685583174 Scheduler time: 19.575732732657343 Scheduler overhead time: 0.08376056980341673 Adapter cache time: 0.013276731129735708 Engine time: 0.08299307432025671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 20.043742809910327,
    "estimated_duration": 3600.043627901991,
    "input_throughput": 6341.707867941856,
    "output_throughput": 5608.393143770443,
    "total_throughput": 11950.1010117123,
    "itl": 65.42369707197379,
    "ttft": 84373.44821027333,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 36,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11836941508576271,
    "arrivals": 94079,
    "finished_requests": 91874,
    "scheduler_time": 78.10688101924883
}
#Debug simulation 
Total elapsed time: 20.043851913884282. Arrivals time: 0.28841972071677446 Scheduler time: 19.540127182379365 Scheduler overhead time: 0.08292694762349129 Adapter cache time: 0.01306571764871478 Engine time: 0.08257011137902737 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 20.047388737089932,
    "estimated_duration": 3600.027308431707,
    "input_throughput": 6341.581339266412,
    "output_throughput": 5608.30745719967,
    "total_throughput": 11949.888796466083,
    "itl": 65.42377649644229,
    "ttft": 84450.07502452093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 36,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.10764181061647837,
    "arrivals": 94079,
    "finished_requests": 91872,
    "scheduler_time": 78.1066998176071
}
#Debug simulation 
Total elapsed time: 20.04750498617068. Arrivals time: 0.28646478382870555 Scheduler time: 19.545644762460142 Scheduler overhead time: 0.08303618477657437 Adapter cache time: 0.012853193562477827 Engine time: 0.082507258746773 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 8640, 135, 135, 135, 135, 8640, 135, 8640, 135, 33, 8640, 33, 33, 8640, 135, 8640, 135, 8640, 8640, 135, 33, 8640, 135, 33, 33, 135, 8640, 33, 135, 33, 33, 135, 135, 135, 33, 33, 8640, 135, 135, 33, 8640, 8640, 135, 8640, 8640, 135, 8640, 33, 8640, 135, 135, 135, 8640, 8640, 33, 33, 135, 33, 8640, 33, 33, 8640, 33, 135, 135, 33, 135, 8640, 8640, 8640, 135, 8640, 8640, 33, 33, 8640, 135, 8640, 33, 135, 8640, 33, 8640, 135, 33, 8640, 33, 33, 8640, 33, 33, 135]
Prompts retrieved: 281856 . Total input tokens: 62899814 . Total output tokens: 56427192
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 19.996068053878844,
    "estimated_duration": 3600.052734871219,
    "input_throughput": 6341.691825471743,
    "output_throughput": 5608.378956349442,
    "total_throughput": 11950.070781821185,
    "itl": 65.42391797829727,
    "ttft": 84410.8331256584,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 36,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11975270673632617,
    "arrivals": 94079,
    "finished_requests": 91874,
    "scheduler_time": 78.1071610657419
}
#Debug simulation 
Total elapsed time: 19.996222521644086. Arrivals time: 0.287978142965585 Scheduler time: 19.493131295777857 Scheduler overhead time: 0.08302595466375351 Adapter cache time: 0.01302160695195198 Engine time: 0.0819786274805665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.626579958945513,
    "estimated_duration": 3600.0651573228893,
    "input_throughput": 6372.50327354072,
    "output_throughput": 5621.303814136757,
    "total_throughput": 11993.807087677476,
    "itl": 65.47075852852997,
    "ttft": 54498.250546891904,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11323804652551184,
    "arrivals": 93393,
    "finished_requests": 91982,
    "scheduler_time": 75.79686945026756
}
#Debug simulation 
Total elapsed time: 14.6267295232974. Arrivals time: 0.27273306297138333 Scheduler time: 14.141382369212806 Scheduler overhead time: 0.08184723183512688 Adapter cache time: 0.012650592718273401 Engine time: 0.08178699854761362 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.626022573094815,
    "estimated_duration": 3600.006012053124,
    "input_throughput": 6372.607968761765,
    "output_throughput": 5621.3961677410025,
    "total_throughput": 11994.004136502768,
    "itl": 65.47052364640236,
    "ttft": 54460.12301416207,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12002955323550848,
    "arrivals": 93393,
    "finished_requests": 91982,
    "scheduler_time": 75.79544621807025
}
#Debug simulation 
Total elapsed time: 14.626129511743784. Arrivals time: 0.27897045388817787 Scheduler time: 14.134830930735916 Scheduler overhead time: 0.0818878747522831 Adapter cache time: 0.012689970433712006 Engine time: 0.08138907002285123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.62072913814336,
    "estimated_duration": 3600.005851851655,
    "input_throughput": 6372.6082523449595,
    "output_throughput": 5621.396417895019,
    "total_throughput": 11994.004670239978,
    "itl": 65.4704925057991,
    "ttft": 54460.113287934066,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12036688977852462,
    "arrivals": 93393,
    "finished_requests": 91982,
    "scheduler_time": 75.79541831791535
}
#Debug simulation 
Total elapsed time: 14.620862434152514. Arrivals time: 0.2736080400645733 Scheduler time: 14.134945313446224 Scheduler overhead time: 0.08175934990867972 Adapter cache time: 0.012661977205425501 Engine time: 0.08158491319045424 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 14.602131706662476,
    "estimated_duration": 3600.0023443724886,
    "input_throughput": 6372.553627877943,
    "output_throughput": 5621.400228151099,
    "total_throughput": 11993.953856029042,
    "itl": 65.4708288564137,
    "ttft": 54498.750550453035,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11594360005110503,
    "arrivals": 93393,
    "finished_requests": 91981,
    "scheduler_time": 75.79548372906262
}
#Debug simulation 
Total elapsed time: 14.602267620619386. Arrivals time: 0.27296056132763624 Scheduler time: 14.114371152129024 Scheduler overhead time: 0.08246785728260875 Adapter cache time: 0.012867904268205166 Engine time: 0.08319136034697294 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 14.687410701997578,
    "estimated_duration": 3600.00694396098,
    "input_throughput": 6372.60631913066,
    "output_throughput": 5621.394712570684,
    "total_throughput": 11994.001031701344,
    "itl": 65.47036159318658,
    "ttft": 54498.124242669226,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12162442764267321,
    "arrivals": 93393,
    "finished_requests": 91982,
    "scheduler_time": 75.7953861398632
}
#Debug simulation 
Total elapsed time: 14.687514491379261. Arrivals time: 0.2797033288516104 Scheduler time: 14.194586448837072 Scheduler overhead time: 0.08190900646150112 Adapter cache time: 0.012908830307424068 Engine time: 0.08201322425156832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 14.567428194917738,
    "estimated_duration": 3600.0570609549845,
    "input_throughput": 6372.517605016612,
    "output_throughput": 5621.316456198539,
    "total_throughput": 11993.83406121515,
    "itl": 65.4707650097834,
    "ttft": 54498.31816552266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.11063186091138055,
    "arrivals": 93393,
    "finished_requests": 91982,
    "scheduler_time": 75.79669295735557
}
#Debug simulation 
Total elapsed time: 14.567535810172558. Arrivals time: 0.27442899951711297 Scheduler time: 14.079474782571197 Scheduler overhead time: 0.08233784232288599 Adapter cache time: 0.01270462479442358 Engine time: 0.08212827984243631 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.8,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.8-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.8     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 8640, 66, 66, 66, 66, 8640, 66, 8640, 66, 33, 8640, 33, 33, 8640, 66, 8640, 66, 8640, 8640, 66, 33, 8640, 66, 33, 33, 66, 8640, 33, 66, 33, 33, 66, 66, 66, 33, 33, 8640, 66, 66, 33, 8640, 8640, 66, 8640, 8640, 66, 8640, 33, 8640, 66, 66, 66, 8640, 8640, 33, 33, 66, 33, 8640, 33, 33, 8640, 33, 66, 66, 33, 66, 8640, 8640, 8640, 66, 8640, 8640, 33, 33, 8640, 66, 8640, 33, 66, 8640, 33, 8640, 66, 33, 8640, 33, 33, 8640, 33, 33, 66]
Prompts retrieved: 279648 . Total input tokens: 62397649 . Total output tokens: 55965424
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 14.571178243029863,
    "estimated_duration": 3600.023812390127,
    "input_throughput": 6372.576459367565,
    "output_throughput": 5621.368372717572,
    "total_throughput": 11993.944832085137,
    "itl": 65.47067005320817,
    "ttft": 54498.195321245636,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 37,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.12325922686606638,
    "arrivals": 93393,
    "finished_requests": 91982,
    "scheduler_time": 75.79589467989051
}
#Debug simulation 
Total elapsed time: 14.57134280493483. Arrivals time: 0.2734735789708793 Scheduler time: 14.084795298054814 Scheduler overhead time: 0.08203275594860315 Adapter cache time: 0.012824688572436571 Engine time: 0.08173001976683736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 9.734438571613282,
    "estimated_duration": 3600.007634376398,
    "input_throughput": 4371.729895713463,
    "output_throughput": 3836.9010299037045,
    "total_throughput": 8208.630925617166,
    "itl": 41.24439116624708,
    "ttft": 70245.86513814566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1886,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.772079885057338,
    "arrivals": 63713,
    "finished_requests": 62977,
    "scheduler_time": 45.80543211364289
}
#Debug simulation 
Total elapsed time: 9.734534947667271. Arrivals time: 0.201972468290478 Scheduler time: 9.247568605002016 Scheduler overhead time: 0.10886324942111969 Adapter cache time: 0.029196518007665873 Engine time: 0.10029025096446276 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 9.621199657674879,
    "estimated_duration": 3600.0310417212227,
    "input_throughput": 4369.193714640762,
    "output_throughput": 3835.858313432107,
    "total_throughput": 8205.052028072869,
    "itl": 41.17677363122606,
    "ttft": 70493.97796989973,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1922,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.278050580774233,
    "arrivals": 63713,
    "finished_requests": 62960,
    "scheduler_time": 45.613980382996175
}
#Debug simulation 
Total elapsed time: 9.621304641012102. Arrivals time: 0.20920004649087787 Scheduler time: 9.124809424392879 Scheduler overhead time: 0.10939004179090261 Adapter cache time: 0.029596973210573196 Engine time: 0.10142525844275951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 9.767959834076464,
    "estimated_duration": 3600.026264096572,
    "input_throughput": 4368.990070117466,
    "output_throughput": 3833.687308796193,
    "total_throughput": 8202.677378913659,
    "itl": 41.23330881712318,
    "ttft": 71542.9050380397,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1869,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.113605818953321,
    "arrivals": 63713,
    "finished_requests": 62957,
    "scheduler_time": 45.7961712246718
}
#Debug simulation 
Total elapsed time: 9.768096277024597. Arrivals time: 0.20386813208460808 Scheduler time: 9.278207893949002 Scheduler overhead time: 0.10851432522758842 Adapter cache time: 0.02913411660119891 Engine time: 0.10165591677650809 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 9.693630640860647,
    "estimated_duration": 3600.003164967548,
    "input_throughput": 4374.104487805901,
    "output_throughput": 3835.2807948502077,
    "total_throughput": 8209.385282656109,
    "itl": 41.2044287667821,
    "ttft": 68500.66206061513,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1893,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.914720091637983,
    "arrivals": 63713,
    "finished_requests": 63005,
    "scheduler_time": 45.75347896204525
}
#Debug simulation 
Total elapsed time: 9.693730308674276. Arrivals time: 0.20366775849834085 Scheduler time: 9.199228310026228 Scheduler overhead time: 0.11155808297917247 Adapter cache time: 0.029805027414113283 Engine time: 0.10258326726034284 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 9.8467834321782,
    "estimated_duration": 3600.0379651344133,
    "input_throughput": 4365.638960536128,
    "output_throughput": 3832.977911243999,
    "total_throughput": 8198.616871780128,
    "itl": 41.2468817852064,
    "ttft": 74569.6486553688,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1817,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.027274033166376,
    "arrivals": 63713,
    "finished_requests": 62909,
    "scheduler_time": 45.819132060418355
}
#Debug simulation 
Total elapsed time: 9.846932357177138. Arrivals time: 0.20363347651436925 Scheduler time: 9.356957608368248 Scheduler overhead time: 0.10933996783569455 Adapter cache time: 0.02885559108108282 Engine time: 0.10117159318178892 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 9.634941873140633,
    "estimated_duration": 3600.016875623727,
    "input_throughput": 4371.452563614276,
    "output_throughput": 3836.993680094003,
    "total_throughput": 8208.44624370828,
    "itl": 41.29717210134197,
    "ttft": 68875.88305203072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1925,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.75584681768652,
    "arrivals": 63713,
    "finished_requests": 62989,
    "scheduler_time": 45.66879188567536
}
#Debug simulation 
Total elapsed time: 9.635054709855467. Arrivals time: 0.20368720311671495 Scheduler time: 9.141146060544997 Scheduler overhead time: 0.11145109916105866 Adapter cache time: 0.02999746147543192 Engine time: 0.10183594049885869 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.05_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.4 ]. Counts: [32 32 32]
Adapter prompts. [540, 540, 540, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 540, 4320, 540, 540, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 540, 4320, 1080, 540, 540, 1080, 4320, 540, 1080, 540, 540, 1080, 1080, 1080, 540, 540, 4320, 1080, 1080, 540, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 540, 4320, 1080, 1080, 1080, 4320, 4320, 540, 540, 1080, 540, 4320, 540, 540, 4320, 540, 1080, 1080, 540, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 540, 540, 4320, 1080, 4320, 540, 1080, 4320, 540, 4320, 1080, 540, 4320, 540, 540, 4320, 540, 540, 1080]
Prompts retrieved: 190080 . Total input tokens: 42454870 . Total output tokens: 37943171
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 9.78014175966382,
    "estimated_duration": 3600.0346292298564,
    "input_throughput": 4372.015166800515,
    "output_throughput": 3835.5683825613473,
    "total_throughput": 8207.583549361862,
    "itl": 41.175671053695325,
    "ttft": 69596.33846240643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1873,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.2889854318274425,
    "arrivals": 63713,
    "finished_requests": 62992,
    "scheduler_time": 45.82909102719917
}
#Debug simulation 
Total elapsed time: 9.780249597970396. Arrivals time: 0.2097079516388476 Scheduler time: 9.281322144437581 Scheduler overhead time: 0.11014936957508326 Adapter cache time: 0.029396490193903446 Engine time: 0.1020801910199225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.552622684743255,
    "estimated_duration": 3600.0436198498205,
    "input_throughput": 4173.052770018022,
    "output_throughput": 3684.466190038367,
    "total_throughput": 7857.518960056389,
    "itl": 39.806056440135244,
    "ttft": 61251.44392725842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1993,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.099552073658154,
    "arrivals": 60841,
    "finished_requests": 60193,
    "scheduler_time": 41.889440655765576
}
#Debug simulation 
Total elapsed time: 8.552746972069144. Arrivals time: 0.1904164431616664 Scheduler time: 8.071520405355841 Scheduler overhead time: 0.10974903218448162 Adapter cache time: 0.029776670038700104 Engine time: 0.10328739695250988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.508299278095365,
    "estimated_duration": 3600.0056846135562,
    "input_throughput": 4174.482852688385,
    "output_throughput": 3688.42584242346,
    "total_throughput": 7862.908695111844,
    "itl": 39.81071519011975,
    "ttft": 59262.628196181315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.5446115445809045,
    "arrivals": 60841,
    "finished_requests": 60226,
    "scheduler_time": 41.899234968796016
}
#Debug simulation 
Total elapsed time: 8.508401977829635. Arrivals time: 0.18957276036962867 Scheduler time: 8.029459650628269 Scheduler overhead time: 0.10911197913810611 Adapter cache time: 0.03009093552827835 Engine time: 0.10229238634929061 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.48906769324094,
    "estimated_duration": 3600.007396079573,
    "input_throughput": 4173.261426174004,
    "output_throughput": 3687.5907573014797,
    "total_throughput": 7860.852183475483,
    "itl": 39.843009051175166,
    "ttft": 60513.55944353986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.564646480977494,
    "arrivals": 60841,
    "finished_requests": 60203,
    "scheduler_time": 41.8810671885703
}
#Debug simulation 
Total elapsed time: 8.489210006315261. Arrivals time: 0.18686527339741588 Scheduler time: 8.01400886848569 Scheduler overhead time: 0.10898154880851507 Adapter cache time: 0.029897199012339115 Engine time: 0.10205532610416412 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 8.578211230691522,
    "estimated_duration": 3599.9949685178394,
    "input_throughput": 4174.087778291165,
    "output_throughput": 3689.185156130361,
    "total_throughput": 7863.272934421526,
    "itl": 39.86201852763224,
    "ttft": 58632.58151912782,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1978,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.186852560716027,
    "arrivals": 60841,
    "finished_requests": 60241,
    "scheduler_time": 41.974965965632904
}
#Debug simulation 
Total elapsed time: 8.578311901073903. Arrivals time: 0.18967542285099626 Scheduler time: 8.099864741321653 Scheduler overhead time: 0.10981454886496067 Adapter cache time: 0.02966834232211113 Engine time: 0.10186390485614538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 8.46872279420495,
    "estimated_duration": 3600.033167642322,
    "input_throughput": 4174.7765368069595,
    "output_throughput": 3686.2893706868495,
    "total_throughput": 7861.0659074938085,
    "itl": 39.82972008731865,
    "ttft": 59356.76176727384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.632169166002305,
    "arrivals": 60841,
    "finished_requests": 60224,
    "scheduler_time": 41.909284131614555
}
#Debug simulation 
Total elapsed time: 8.46882847789675. Arrivals time: 0.19187294226139784 Scheduler time: 7.986967847216874 Scheduler overhead time: 0.10921095963567495 Adapter cache time: 0.02992788702249527 Engine time: 0.10341851552948356 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 8.52705680578947,
    "estimated_duration": 3600.002515290985,
    "input_throughput": 4175.558471459839,
    "output_throughput": 3689.4196444544527,
    "total_throughput": 7864.978115914291,
    "itl": 39.810851558768654,
    "ttft": 58414.278506558556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1995,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.965150338329665,
    "arrivals": 60841,
    "finished_requests": 60242,
    "scheduler_time": 41.93562644646608
}
#Debug simulation 
Total elapsed time: 8.527166116982698. Arrivals time: 0.19059190852567554 Scheduler time: 8.04739237157628 Scheduler overhead time: 0.10935192229226232 Adapter cache time: 0.029785677790641785 Engine time: 0.10264999326318502 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.025_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 270, 4320, 270, 270, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 270, 4320, 1080, 270, 270, 1080, 4320, 270, 1080, 270, 270, 1080, 1080, 1080, 270, 270, 4320, 1080, 1080, 270, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 270, 4320, 1080, 1080, 1080, 4320, 4320, 270, 270, 1080, 270, 4320, 270, 270, 4320, 270, 1080, 1080, 270, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 270, 270, 4320, 1080, 4320, 270, 1080, 4320, 270, 4320, 1080, 270, 4320, 270, 270, 4320, 270, 270, 1080]
Prompts retrieved: 181440 . Total input tokens: 40530424 . Total output tokens: 36179951
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 8.463987389579415,
    "estimated_duration": 3599.9973984707594,
    "input_throughput": 4173.145515711134,
    "output_throughput": 3687.5279425588246,
    "total_throughput": 7860.673458269959,
    "itl": 39.84634508567423,
    "ttft": 60571.68441280289,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2008,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.733659569918902,
    "arrivals": 60841,
    "finished_requests": 60202,
    "scheduler_time": 41.88165586375075
}
#Debug simulation 
Total elapsed time: 8.464100851677358. Arrivals time: 0.19141152128577232 Scheduler time: 7.983822997659445 Scheduler overhead time: 0.10914994589984417 Adapter cache time: 0.030083313584327698 Engine time: 0.10219577606767416 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.479493828024715,
    "estimated_duration": 3600.016567185503,
    "input_throughput": 4097.609476151025,
    "output_throughput": 3576.6527069253125,
    "total_throughput": 7674.262183076337,
    "itl": 38.72649138511322,
    "ttft": 46989.46964354271,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2126,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.506596943601225,
    "arrivals": 59397,
    "finished_requests": 58914,
    "scheduler_time": 38.84218354040122
}
#Debug simulation 
Total elapsed time: 7.47962529072538. Arrivals time: 0.18093740660697222 Scheduler time: 7.00633200770244 Scheduler overhead time: 0.10930331004783511 Adapter cache time: 0.03070771601051092 Engine time: 0.10419496428221464 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.527075907681137,
    "estimated_duration": 3600.015326449728,
    "input_throughput": 4096.52311523456,
    "output_throughput": 3577.397269777941,
    "total_throughput": 7673.9203850125,
    "itl": 38.75233726818104,
    "ttft": 46964.570008017996,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2123,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.913781292116944,
    "arrivals": 59397,
    "finished_requests": 58913,
    "scheduler_time": 38.85462851479977
}
#Debug simulation 
Total elapsed time: 7.527176879812032. Arrivals time: 0.18903741892427206 Scheduler time: 7.046350683551282 Scheduler overhead time: 0.10941207921132445 Adapter cache time: 0.03087980905547738 Engine time: 0.10317821195349097 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.495979629922658,
    "estimated_duration": 3600.0149524132426,
    "input_throughput": 4096.566318457648,
    "output_throughput": 3578.358748583684,
    "total_throughput": 7674.925067041331,
    "itl": 38.764869778912754,
    "ttft": 46771.16311683959,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2150,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.0163865121826055,
    "arrivals": 59397,
    "finished_requests": 58914,
    "scheduler_time": 38.8264125006154
}
#Debug simulation 
Total elapsed time: 7.49611178971827. Arrivals time: 0.18349054688587785 Scheduler time: 7.0198131538927555 Scheduler overhead time: 0.10961029026657343 Adapter cache time: 0.030990954488515854 Engine time: 0.10375875327736139 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.4721572659909725,
    "estimated_duration": 3600.015637633506,
    "input_throughput": 4096.747204602402,
    "output_throughput": 3575.861411663827,
    "total_throughput": 7672.60861626623,
    "itl": 38.73892028663374,
    "ttft": 47769.447359377344,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2156,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.729296396169588,
    "arrivals": 59397,
    "finished_requests": 58896,
    "scheduler_time": 38.79369784442401
}
#Debug simulation 
Total elapsed time: 7.472273955121636. Arrivals time: 0.1880710911937058 Scheduler time: 6.990492940414697 Scheduler overhead time: 0.10973537433892488 Adapter cache time: 0.03106226772069931 Engine time: 0.10447112657129765 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.471605534199625,
    "estimated_duration": 3600.004993827492,
    "input_throughput": 4095.881262743207,
    "output_throughput": 3576.3133723633227,
    "total_throughput": 7672.19463510653,
    "itl": 38.763858063804854,
    "ttft": 47741.62126821502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2153,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.114973736926765,
    "arrivals": 59397,
    "finished_requests": 58899,
    "scheduler_time": 38.814223572108425
}
#Debug simulation 
Total elapsed time: 7.4717107131145895. Arrivals time: 0.18163908505812287 Scheduler time: 6.998360861558467 Scheduler overhead time: 0.10893605137243867 Adapter cache time: 0.030912688467651606 Engine time: 0.10391158331185579 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.46888728113845,
    "estimated_duration": 3600.016108714915,
    "input_throughput": 4095.8686168944782,
    "output_throughput": 3576.3023306570294,
    "total_throughput": 7672.170947551507,
    "itl": 38.752004096112,
    "ttft": 47738.15866307251,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2153,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.437578284924192,
    "arrivals": 59397,
    "finished_requests": 58899,
    "scheduler_time": 38.80947602112061
}
#Debug simulation 
Total elapsed time: 7.46902135387063. Arrivals time: 0.18365608574822545 Scheduler time: 6.992642426397651 Scheduler overhead time: 0.11030874960124493 Adapter cache time: 0.03101291134953499 Engine time: 0.10287279961630702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 135, 4320, 135, 135, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 135, 4320, 1080, 135, 135, 1080, 4320, 135, 1080, 135, 135, 1080, 1080, 1080, 135, 135, 4320, 1080, 1080, 135, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 135, 4320, 1080, 1080, 1080, 4320, 4320, 135, 135, 1080, 135, 4320, 135, 135, 4320, 135, 1080, 1080, 135, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 135, 135, 4320, 1080, 4320, 135, 1080, 4320, 135, 4320, 1080, 135, 4320, 135, 135, 4320, 135, 135, 1080]
Prompts retrieved: 177120 . Total input tokens: 39571502 . Total output tokens: 35335486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.528410889208317,
    "estimated_duration": 3600.0063337119122,
    "input_throughput": 4095.905293809958,
    "output_throughput": 3577.2409285518106,
    "total_throughput": 7673.146222361768,
    "itl": 38.80055666928,
    "ttft": 47692.93639181673,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2124,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.104301805048931,
    "arrivals": 59397,
    "finished_requests": 58901,
    "scheduler_time": 38.85263429980281
}
#Debug simulation 
Total elapsed time: 7.528513182420284. Arrivals time: 0.1878920355811715 Scheduler time: 7.045722997747362 Scheduler overhead time: 0.1110369530506432 Adapter cache time: 0.030922831036150455 Engine time: 0.10432588309049606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.139861625153571,
    "estimated_duration": 3599.9949297383264,
    "input_throughput": 4071.776290269797,
    "output_throughput": 3554.491672834138,
    "total_throughput": 7626.267963103935,
    "itl": 38.49824637186647,
    "ttft": 40687.20565435625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.2342135343912,
    "arrivals": 58689,
    "finished_requests": 58280,
    "scheduler_time": 37.98155566372533
}
#Debug simulation 
Total elapsed time: 7.13999700313434. Arrivals time: 0.18184808688238263 Scheduler time: 6.6677709692157805 Scheduler overhead time: 0.10793669847771525 Adapter cache time: 0.030413351953029633 Engine time: 0.10357825690880418 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.06188203766942,
    "estimated_duration": 3599.9986717266074,
    "input_throughput": 4072.4915026061403,
    "output_throughput": 3555.2285339765185,
    "total_throughput": 7627.720036582658,
    "itl": 38.504926723665996,
    "ttft": 39916.4582152254,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2085,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.773192089893609,
    "arrivals": 58689,
    "finished_requests": 58288,
    "scheduler_time": 37.94186210869922
}
#Debug simulation 
Total elapsed time: 7.06198739586398. Arrivals time: 0.1839130837470293 Scheduler time: 6.58765029348433 Scheduler overhead time: 0.10736432112753391 Adapter cache time: 0.03073488874360919 Engine time: 0.10394988721236587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.077734608203173,
    "estimated_duration": 3599.9845770009697,
    "input_throughput": 4072.6663368691566,
    "output_throughput": 3555.0655082699686,
    "total_throughput": 7627.731845139126,
    "itl": 38.505272764197834,
    "ttft": 40043.19345051946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2089,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.8010540828853285,
    "arrivals": 58689,
    "finished_requests": 58286,
    "scheduler_time": 37.943770508303324
}
#Debug simulation 
Total elapsed time: 7.077870862092823. Arrivals time: 0.1838402934372425 Scheduler time: 6.603782941587269 Scheduler overhead time: 0.10705033037811518 Adapter cache time: 0.030572019517421722 Engine time: 0.10424093483015895 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 7.127144121099263,
    "estimated_duration": 3599.998761916214,
    "input_throughput": 4070.9294555977094,
    "output_throughput": 3553.2842775732365,
    "total_throughput": 7624.2137331709455,
    "itl": 38.47321609584348,
    "ttft": 41619.62575520345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2037,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.349373287288271,
    "arrivals": 58689,
    "finished_requests": 58265,
    "scheduler_time": 37.98133004831819
}
#Debug simulation 
Total elapsed time: 7.127255052793771. Arrivals time: 0.17943832650780678 Scheduler time: 6.656934179365635 Scheduler overhead time: 0.10805955529212952 Adapter cache time: 0.030275790486484766 Engine time: 0.10424929205328226 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 7.1216801488772035,
    "estimated_duration": 3599.9764479103683,
    "input_throughput": 4071.499414533096,
    "output_throughput": 3552.736020654777,
    "total_throughput": 7624.235435187873,
    "itl": 38.4659652157714,
    "ttft": 41164.74770469378,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2080,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.856111171077794,
    "arrivals": 58689,
    "finished_requests": 58267,
    "scheduler_time": 37.916445518906336
}
#Debug simulation 
Total elapsed time: 7.121787779033184. Arrivals time: 0.18744912324473262 Scheduler time: 6.640790218487382 Scheduler overhead time: 0.10882376926019788 Adapter cache time: 0.030841877683997154 Engine time: 0.10499149095267057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 7.296979513019323,
    "estimated_duration": 3599.985051668876,
    "input_throughput": 4069.025229204577,
    "output_throughput": 3551.478913522994,
    "total_throughput": 7620.504142727571,
    "itl": 38.55341499329268,
    "ttft": 43819.446055678076,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1984,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.932259785085742,
    "arrivals": 58689,
    "finished_requests": 58251,
    "scheduler_time": 38.219661873535074
}
#Debug simulation 
Total elapsed time: 7.297098388895392. Arrivals time: 0.18474479811266065 Scheduler time: 6.8206078531220555 Scheduler overhead time: 0.1089045163244009 Adapter cache time: 0.030019850004464388 Engine time: 0.10443246364593506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 66, 4320, 66, 66, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 66, 4320, 1080, 66, 66, 1080, 4320, 66, 1080, 66, 66, 1080, 1080, 1080, 66, 66, 4320, 1080, 1080, 66, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 66, 4320, 1080, 1080, 1080, 4320, 4320, 66, 66, 1080, 66, 4320, 66, 66, 4320, 66, 1080, 1080, 66, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 66, 66, 4320, 1080, 4320, 66, 1080, 4320, 66, 4320, 1080, 66, 4320, 66, 66, 4320, 66, 66, 1080]
Prompts retrieved: 174912 . Total input tokens: 39078046 . Total output tokens: 34889352
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 7.075814317911863,
    "estimated_duration": 3600.0149842653645,
    "input_throughput": 4072.1377727797253,
    "output_throughput": 3554.3610390308304,
    "total_throughput": 7626.498811810556,
    "itl": 38.50048657108675,
    "ttft": 40438.85233482269,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2061,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.875057013816902,
    "arrivals": 58689,
    "finished_requests": 58281,
    "scheduler_time": 37.95024308001713
}
#Debug simulation 
Total elapsed time: 7.075932882260531. Arrivals time: 0.18458853336051106 Scheduler time: 6.600047373678535 Scheduler overhead time: 0.10929809510707855 Adapter cache time: 0.030463657807558775 Engine time: 0.10344556113705039 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.877310670912266,
    "estimated_duration": 3599.2446968690515,
    "input_throughput": 4024.4362970376264,
    "output_throughput": 3553.164921274949,
    "total_throughput": 7577.601218312575,
    "itl": 38.44539849072888,
    "ttft": 37717.563352484874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.931225247741847,
    "arrivals": 58348,
    "finished_requests": 57966,
    "scheduler_time": 37.65674609135256
}
#Debug simulation 
Total elapsed time: 6.877450963016599. Arrivals time: 0.17525651585310698 Scheduler time: 6.414244963321835 Scheduler overhead time: 0.10668576927855611 Adapter cache time: 0.029452496208250523 Engine time: 0.10338867548853159 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.910201631952077,
    "estimated_duration": 3599.2634935351844,
    "input_throughput": 4023.8690571039247,
    "output_throughput": 3552.06697785907,
    "total_throughput": 7575.936034962994,
    "itl": 38.470729918036035,
    "ttft": 38487.05148338852,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1925,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.228591601121975,
    "arrivals": 58348,
    "finished_requests": 57958,
    "scheduler_time": 37.69936151903662
}
#Debug simulation 
Total elapsed time: 6.910306250210851. Arrivals time: 0.17735674744471908 Scheduler time: 6.443649337161332 Scheduler overhead time: 0.10721172066405416 Adapter cache time: 0.029612448532134295 Engine time: 0.10397736262530088 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.865958936046809,
    "estimated_duration": 3599.261027087253,
    "input_throughput": 4023.6262085497606,
    "output_throughput": 3551.3125899468523,
    "total_throughput": 7574.938798496613,
    "itl": 38.46276523950571,
    "ttft": 38326.823768488786,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1941,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.300026169083939,
    "arrivals": 58348,
    "finished_requests": 57959,
    "scheduler_time": 37.68813562595484
}
#Debug simulation 
Total elapsed time: 6.866093523800373. Arrivals time: 0.17780981492251158 Scheduler time: 6.402246001176536 Scheduler overhead time: 0.1054454525001347 Adapter cache time: 0.02963593229651451 Engine time: 0.10284197935834527 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.873708825092763,
    "estimated_duration": 3599.264163928016,
    "input_throughput": 4024.4145303833534,
    "output_throughput": 3553.1457035493577,
    "total_throughput": 7577.560233932711,
    "itl": 38.44949507320224,
    "ttft": 37718.96835854103,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1938,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.040283257902887,
    "arrivals": 58348,
    "finished_requests": 57966,
    "scheduler_time": 37.65805803394245
}
#Debug simulation 
Total elapsed time: 6.873810108751059. Arrivals time: 0.18206811975687742 Scheduler time: 6.404019339010119 Scheduler overhead time: 0.10649366909638047 Adapter cache time: 0.02966191340237856 Engine time: 0.10299340495839715 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.890223812777549,
    "estimated_duration": 3599.237702865204,
    "input_throughput": 4025.181773481377,
    "output_throughput": 3554.028118180965,
    "total_throughput": 7579.209891662342,
    "itl": 38.47948176549508,
    "ttft": 36953.923692338394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1936,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.356533959153915,
    "arrivals": 58348,
    "finished_requests": 57979,
    "scheduler_time": 37.66570941827158
}
#Debug simulation 
Total elapsed time: 6.8903374588117. Arrivals time: 0.1780817937105894 Scheduler time: 6.4260131334885955 Scheduler overhead time: 0.10576407564803958 Adapter cache time: 0.029504382517188787 Engine time: 0.102936290204525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.881940416991711,
    "estimated_duration": 3599.230387946776,
    "input_throughput": 4024.3519971676214,
    "output_throughput": 3552.973725389958,
    "total_throughput": 7577.325722557579,
    "itl": 38.472074221119975,
    "ttft": 37882.202208051196,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1946,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 5.818637873879464,
    "arrivals": 58348,
    "finished_requests": 57964,
    "scheduler_time": 37.657206743145146
}
#Debug simulation 
Total elapsed time: 6.882036502938718. Arrivals time: 0.17485381988808513 Scheduler time: 6.4197919042780995 Scheduler overhead time: 0.10581954102963209 Adapter cache time: 0.029852756299078465 Engine time: 0.10356814879924059 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.1-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 1080, 4320, 1080, 1080, 1080, 1080, 4320, 1080, 4320, 1080, 33, 4320, 33, 33, 4320, 1080, 4320, 1080, 4320, 4320, 1080, 33, 4320, 1080, 33, 33, 1080, 4320, 33, 1080, 33, 33, 1080, 1080, 1080, 33, 33, 4320, 1080, 1080, 33, 4320, 4320, 1080, 4320, 4320, 1080, 4320, 33, 4320, 1080, 1080, 1080, 4320, 4320, 33, 33, 1080, 33, 4320, 33, 33, 4320, 33, 1080, 1080, 33, 1080, 4320, 4320, 4320, 1080, 4320, 4320, 33, 33, 4320, 1080, 4320, 33, 1080, 4320, 33, 4320, 1080, 33, 4320, 33, 33, 4320, 33, 33, 1080]
Prompts retrieved: 173856 . Total input tokens: 38837193 . Total output tokens: 34681657
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.903653208166361,
    "estimated_duration": 3599.2598310151056,
    "input_throughput": 4024.4593833379204,
    "output_throughput": 3553.4330947129456,
    "total_throughput": 7577.892478050866,
    "itl": 38.46691562914545,
    "ttft": 37718.176868359325,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 1931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.4159683879835505,
    "arrivals": 58348,
    "finished_requests": 57969,
    "scheduler_time": 37.692857236652024
}
#Debug simulation 
Total elapsed time: 6.90378334838897. Arrivals time: 0.18124082405120134 Scheduler time: 6.434584224130958 Scheduler overhead time: 0.1068003005348146 Adapter cache time: 0.029465326108038425 Engine time: 0.1033231457695365 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.383654152974486,
    "estimated_duration": 3599.9992104310227,
    "input_throughput": 3787.8738863299195,
    "output_throughput": 3327.131563055518,
    "total_throughput": 7115.005449385438,
    "itl": 36.83346008307621,
    "ttft": 36690.9448838633,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2714,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.306163737033657,
    "arrivals": 55037,
    "finished_requests": 54688,
    "scheduler_time": 33.4865421623907
}
#Debug simulation 
Total elapsed time: 6.383759350981563. Arrivals time: 0.17086297599598765 Scheduler time: 5.915055296383798 Scheduler overhead time: 0.10761727206408978 Adapter cache time: 0.034692393615841866 Engine time: 0.10584109462797642 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.302754541859031,
    "estimated_duration": 3599.989685488117,
    "input_throughput": 3787.4891850283902,
    "output_throughput": 3327.001754555314,
    "total_throughput": 7114.490939583705,
    "itl": 36.86513189654611,
    "ttft": 36185.9497796232,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2812,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.17904079516171,
    "arrivals": 55037,
    "finished_requests": 54690,
    "scheduler_time": 33.42805179898633
}
#Debug simulation 
Total elapsed time: 6.302862343844026. Arrivals time: 0.17326797731220722 Scheduler time: 5.831939234863967 Scheduler overhead time: 0.10672440100461245 Adapter cache time: 0.035258383490145206 Engine time: 0.10628957394510508 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.285958144348115,
    "estimated_duration": 3600.00130652085,
    "input_throughput": 3789.0216804344927,
    "output_throughput": 3327.9482366572893,
    "total_throughput": 7116.969917091782,
    "itl": 36.84568594678608,
    "ttft": 35129.972782146986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2831,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.254948615506043,
    "arrivals": 55037,
    "finished_requests": 54704,
    "scheduler_time": 33.41552314994855
}
#Debug simulation 
Total elapsed time: 6.286068581044674. Arrivals time: 0.17500044917687774 Scheduler time: 5.812836220487952 Scheduler overhead time: 0.10734230279922485 Adapter cache time: 0.03530298080295324 Engine time: 0.1059113685041666 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 6.2907349918968976,
    "estimated_duration": 3599.9885470945105,
    "input_throughput": 3786.903158623326,
    "output_throughput": 3326.800305980413,
    "total_throughput": 7113.703464603739,
    "itl": 36.83363892797744,
    "ttft": 36454.99994954519,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2820,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.818881598187021,
    "arrivals": 55037,
    "finished_requests": 54685,
    "scheduler_time": 33.41568874661288
}
#Debug simulation 
Total elapsed time: 6.290840175002813. Arrivals time: 0.1729817441664636 Scheduler time: 5.818673320580274 Scheduler overhead time: 0.10789657710120082 Adapter cache time: 0.035336973145604134 Engine time: 0.1064128722064197 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_0.4-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 6.332620033994317,
    "estimated_duration": 3600.013285580098,
    "input_throughput": 3789.0168501980957,
    "output_throughput": 3327.3557761523116,
    "total_throughput": 7116.372626350407,
    "itl": 36.81682553627283,
    "ttft": 35537.360714747134,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2795,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.256171051300703,
    "arrivals": 55037,
    "finished_requests": 54701,
    "scheduler_time": 33.452975827425966
}
#Debug simulation 
Total elapsed time: 6.332722713239491. Arrivals time: 0.1722543784417212 Scheduler time: 5.863304053898901 Scheduler overhead time: 0.1070815334096551 Adapter cache time: 0.035179953556507826 Engine time: 0.10555639211088419 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_0.4-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_0.4-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 6.310866890009493,
    "estimated_duration": 3600.0132669599534,
    "input_throughput": 3787.2696540125467,
    "output_throughput": 3326.3599636987697,
    "total_throughput": 7113.629617711316,
    "itl": 36.83373758074063,
    "ttft": 36440.72759819699,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2800,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.37214082572594,
    "arrivals": 55037,
    "finished_requests": 54686,
    "scheduler_time": 33.422323128528234
}
#Debug simulation 
Total elapsed time: 6.310970684979111. Arrivals time: 0.16742900619283319 Scheduler time: 5.846136998850852 Scheduler overhead time: 0.10702397441491485 Adapter cache time: 0.03515319945290685 Engine time: 0.10573161114007235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_0.4-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_0.4-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.4  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 270, 4320, 270, 270, 4320, 540, 4320, 540, 4320, 4320, 540, 270, 4320, 540, 270, 270, 540, 4320, 270, 540, 270, 270, 540, 540, 540, 270, 270, 4320, 540, 540, 270, 4320, 4320, 540, 4320, 4320, 540, 4320, 270, 4320, 540, 540, 540, 4320, 4320, 270, 270, 540, 270, 4320, 270, 270, 4320, 270, 540, 540, 270, 540, 4320, 4320, 4320, 540, 4320, 4320, 270, 270, 4320, 540, 4320, 270, 540, 4320, 270, 4320, 540, 270, 4320, 270, 270, 4320, 270, 270, 540]
Prompts retrieved: 164160 . Total input tokens: 36683917 . Total output tokens: 32750485
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 6.267075149808079,
    "estimated_duration": 3599.9938543365865,
    "input_throughput": 3787.4045211426105,
    "output_throughput": 3327.2365133543635,
    "total_throughput": 7114.641034496974,
    "itl": 36.843297973306235,
    "ttft": 35974.88677545315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2828,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.483532729148388,
    "arrivals": 55037,
    "finished_requests": 54691,
    "scheduler_time": 33.40073067351076
}
#Debug simulation 
Total elapsed time: 6.267214649822563. Arrivals time: 0.173625192604959 Scheduler time: 5.793762871064246 Scheduler overhead time: 0.1078312168829143 Adapter cache time: 0.035495500545948744 Engine time: 0.10674887988716364 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.578870894853026,
    "estimated_duration": 3600.010219616545,
    "input_throughput": 3690.9520221904577,
    "output_throughput": 3233.713042414636,
    "total_throughput": 6924.665064605094,
    "itl": 35.993969495131886,
    "ttft": 25127.89456178868,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2940,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.997833967162283,
    "arrivals": 53479,
    "finished_requests": 53247,
    "scheduler_time": 30.940011885060535
}
#Debug simulation 
Total elapsed time: 5.578974700067192. Arrivals time: 0.15938773145899177 Scheduler time: 5.123348884750158 Scheduler overhead time: 0.1058412422426045 Adapter cache time: 0.03616357455030084 Engine time: 0.10462747607380152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.6154798259958625,
    "estimated_duration": 3600.0004596506287,
    "input_throughput": 3691.4823064466214,
    "output_throughput": 3234.0523648516105,
    "total_throughput": 6925.534671298232,
    "itl": 36.009198204895824,
    "ttft": 24447.447128895004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2950,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.601065428182427,
    "arrivals": 53479,
    "finished_requests": 53256,
    "scheduler_time": 30.944561693556185
}
#Debug simulation 
Total elapsed time: 5.615605415776372. Arrivals time: 0.16306684352457523 Scheduler time: 5.153169096447527 Scheduler overhead time: 0.10694759292528033 Adapter cache time: 0.0363394757732749 Engine time: 0.10603412473574281 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.606263175141066,
    "estimated_duration": 3600.0277730588405,
    "input_throughput": 3691.301522573782,
    "output_throughput": 3233.8106075521437,
    "total_throughput": 6925.112130125925,
    "itl": 35.99508932377965,
    "ttft": 25033.550390242228,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.616099033224994,
    "arrivals": 53479,
    "finished_requests": 53248,
    "scheduler_time": 30.937441466625167
}
#Debug simulation 
Total elapsed time: 5.606368137989193. Arrivals time: 0.165074085816741 Scheduler time: 5.140181742142886 Scheduler overhead time: 0.10890949191525578 Adapter cache time: 0.03608935093507171 Engine time: 0.10577890323475003 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.612426287960261,
    "estimated_duration": 3600.0105336683696,
    "input_throughput": 3691.4236432687585,
    "output_throughput": 3233.939704097675,
    "total_throughput": 6925.363347366433,
    "itl": 35.990680358950776,
    "ttft": 25077.94548076822,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2901,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.075376508219566,
    "arrivals": 53479,
    "finished_requests": 53250,
    "scheduler_time": 30.968447859303037
}
#Debug simulation 
Total elapsed time: 5.612553438637406. Arrivals time: 0.15896374871954322 Scheduler time: 5.153321140445769 Scheduler overhead time: 0.10833504516631365 Adapter cache time: 0.03585666650906205 Engine time: 0.10630383109673858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.565162395127118,
    "estimated_duration": 3600.0014089304996,
    "input_throughput": 3691.451333056008,
    "output_throughput": 3233.870401028156,
    "total_throughput": 6925.321734084164,
    "itl": 36.00256214352575,
    "ttft": 24991.26233420183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2948,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.731118021737352,
    "arrivals": 53479,
    "finished_requests": 53248,
    "scheduler_time": 30.943717069130255
}
#Debug simulation 
Total elapsed time: 5.5652640061452985. Arrivals time: 0.1626383806578815 Scheduler time: 5.102797552011907 Scheduler overhead time: 0.10759981255978346 Adapter cache time: 0.035859701223671436 Engine time: 0.10452950466424227 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.611037080641836,
    "estimated_duration": 3600.012570048711,
    "input_throughput": 3691.0004455401686,
    "output_throughput": 3233.75648653429,
    "total_throughput": 6924.756932074459,
    "itl": 36.009804897702836,
    "ttft": 25014.109306533013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2954,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.832608571140996,
    "arrivals": 53479,
    "finished_requests": 53248,
    "scheduler_time": 30.930485702217513
}
#Debug simulation 
Total elapsed time: 5.611140024848282. Arrivals time: 0.16337925428524613 Scheduler time: 5.146546456497163 Scheduler overhead time: 0.10912130074575543 Adapter cache time: 0.0361565831117332 Engine time: 0.10581913916394114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 135, 4320, 135, 135, 4320, 540, 4320, 540, 4320, 4320, 540, 135, 4320, 540, 135, 135, 540, 4320, 135, 540, 135, 135, 540, 540, 540, 135, 135, 4320, 540, 540, 135, 4320, 4320, 540, 4320, 4320, 540, 4320, 135, 4320, 540, 540, 540, 4320, 4320, 135, 135, 540, 135, 4320, 135, 135, 4320, 135, 540, 540, 135, 540, 4320, 4320, 4320, 540, 4320, 4320, 135, 135, 4320, 540, 4320, 135, 540, 4320, 135, 4320, 540, 135, 4320, 135, 135, 4320, 135, 135, 540]
Prompts retrieved: 159840 . Total input tokens: 35733207 . Total output tokens: 31891719
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.59146014181897,
    "estimated_duration": 3600.0203820309057,
    "input_throughput": 3691.471322310395,
    "output_throughput": 3233.970301421491,
    "total_throughput": 6925.441623731886,
    "itl": 36.012688757300076,
    "ttft": 24513.955889349327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2949,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.859206530339492,
    "arrivals": 53479,
    "finished_requests": 53256,
    "scheduler_time": 30.94638481818194
}
#Debug simulation 
Total elapsed time: 5.5915718781761825. Arrivals time: 0.16310941940173507 Scheduler time: 5.125884938985109 Scheduler overhead time: 0.10996122052893043 Adapter cache time: 0.03599919565021992 Engine time: 0.10638625780120492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.36764075094834,
    "estimated_duration": 3600.0355515557635,
    "input_throughput": 3665.841853783032,
    "output_throughput": 3210.0216329824757,
    "total_throughput": 6875.863486765507,
    "itl": 35.832961064793224,
    "ttft": 23961.305377441735,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2763,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.456127636486324,
    "arrivals": 52821,
    "finished_requests": 52589,
    "scheduler_time": 30.255341608569196
}
#Debug simulation 
Total elapsed time: 5.367749630007893. Arrivals time: 0.1601988789625466 Scheduler time: 4.90914774639532 Scheduler overhead time: 0.10690457094460726 Adapter cache time: 0.0349183389917016 Engine time: 0.10635706409811974 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.355614406988025,
    "estimated_duration": 3600.0392348474334,
    "input_throughput": 3665.8381031670297,
    "output_throughput": 3210.0183487277304,
    "total_throughput": 6875.85645189476,
    "itl": 35.851767083565555,
    "ttft": 24016.787888888026,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2760,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.957365738239433,
    "arrivals": 52821,
    "finished_requests": 52589,
    "scheduler_time": 30.269674766614795
}
#Debug simulation 
Total elapsed time: 5.355716268997639. Arrivals time: 0.15841118479147553 Scheduler time: 4.901050771120936 Scheduler overhead time: 0.1064664889127016 Adapter cache time: 0.03490291489288211 Engine time: 0.1051696827635169 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.345316789112985,
    "estimated_duration": 3600.040442256763,
    "input_throughput": 3665.1221594968215,
    "output_throughput": 3209.5233887863956,
    "total_throughput": 6874.645548283217,
    "itl": 35.83533421735708,
    "ttft": 24396.16041087923,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2717,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.838851730357643,
    "arrivals": 52821,
    "finished_requests": 52585,
    "scheduler_time": 30.289452288246036
}
#Debug simulation 
Total elapsed time: 5.345417550764978. Arrivals time: 0.15566417947411537 Scheduler time: 4.893787779379636 Scheduler overhead time: 0.10681874118745327 Adapter cache time: 0.03457007743418217 Engine time: 0.10485583497211337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.355700904969126,
    "estimated_duration": 3600.0004863989216,
    "input_throughput": 3665.8775602558635,
    "output_throughput": 3210.052899620481,
    "total_throughput": 6875.930459876345,
    "itl": 35.833765886978455,
    "ttft": 23779.343532799656,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2784,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.687541259100978,
    "arrivals": 52821,
    "finished_requests": 52589,
    "scheduler_time": 30.247773276860485
}
#Debug simulation 
Total elapsed time: 5.3558360962197185. Arrivals time: 0.16139252297580242 Scheduler time: 4.895355240441859 Scheduler overhead time: 0.10703604435548186 Adapter cache time: 0.03520192205905914 Engine time: 0.10695390915498137 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.378292683977634,
    "estimated_duration": 3600.0058782714023,
    "input_throughput": 3665.157348669548,
    "output_throughput": 3209.5542037136975,
    "total_throughput": 6874.711552383245,
    "itl": 35.85005537649883,
    "ttft": 24326.112404059004,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2723,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.96519249642234,
    "arrivals": 52821,
    "finished_requests": 52585,
    "scheduler_time": 30.289825544910965
}
#Debug simulation 
Total elapsed time: 5.378394447732717. Arrivals time: 0.1552139730192721 Scheduler time: 4.924302753526717 Scheduler overhead time: 0.1078752395696938 Adapter cache time: 0.03476199600845575 Engine time: 0.10583627270534635 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.372835313901305,
    "estimated_duration": 3600.019458181267,
    "input_throughput": 3665.1307453393306,
    "output_throughput": 3209.3537643924174,
    "total_throughput": 6874.4845097317475,
    "itl": 35.83475961021527,
    "ttft": 24512.658032008843,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2736,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.180777606852152,
    "arrivals": 52821,
    "finished_requests": 52582,
    "scheduler_time": 30.25914338881211
}
#Debug simulation 
Total elapsed time: 5.372967446688563. Arrivals time: 0.16032731672748923 Scheduler time: 4.915943714790046 Scheduler overhead time: 0.10702882241457701 Adapter cache time: 0.03449804149568081 Engine time: 0.1048629037104547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.4-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 66, 4320, 66, 66, 4320, 540, 4320, 540, 4320, 4320, 540, 66, 4320, 540, 66, 66, 540, 4320, 66, 540, 66, 66, 540, 540, 540, 66, 66, 4320, 540, 540, 66, 4320, 4320, 540, 4320, 4320, 540, 4320, 66, 4320, 540, 540, 540, 4320, 4320, 66, 66, 540, 66, 4320, 66, 66, 4320, 66, 540, 540, 66, 540, 4320, 4320, 4320, 540, 4320, 4320, 66, 66, 4320, 540, 4320, 66, 540, 4320, 66, 4320, 540, 66, 4320, 66, 66, 4320, 66, 66, 540]
Prompts retrieved: 157632 . Total input tokens: 35246322 . Total output tokens: 31436834
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.377121650148183,
    "estimated_duration": 3600.003684601765,
    "input_throughput": 3665.4054151224273,
    "output_throughput": 3209.8589369300266,
    "total_throughput": 6875.264352052453,
    "itl": 35.86664618628206,
    "ttft": 24373.049964260896,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2706,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.014067158028034,
    "arrivals": 52821,
    "finished_requests": 52585,
    "scheduler_time": 30.29343274462328
}
#Debug simulation 
Total elapsed time: 5.37722186697647. Arrivals time: 0.15693416632711887 Scheduler time: 4.922233489342034 Scheduler overhead time: 0.1067219227552414 Adapter cache time: 0.03441623691469431 Engine time: 0.10686771059408784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.142916865181178,
    "estimated_duration": 3600.0245653897846,
    "input_throughput": 3629.609677006533,
    "output_throughput": 3204.8036868745135,
    "total_throughput": 6834.413363881046,
    "itl": 35.728922271417396,
    "ttft": 22049.168898665775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.079687643982691,
    "arrivals": 52471,
    "finished_requests": 52252,
    "scheduler_time": 29.933391249912265
}
#Debug simulation 
Total elapsed time: 5.143019414972514. Arrivals time: 0.1575271268375218 Scheduler time: 4.685933054424822 Scheduler overhead time: 0.10680466424673796 Adapter cache time: 0.0339953675866127 Engine time: 0.10856064967811108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.172583226580173,
    "estimated_duration": 3600.0125358267337,
    "input_throughput": 3629.6218054694273,
    "output_throughput": 3204.8143958338947,
    "total_throughput": 6834.4362013033215,
    "itl": 35.73959352329853,
    "ttft": 22038.07044504937,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2645,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.558758181654609,
    "arrivals": 52471,
    "finished_requests": 52252,
    "scheduler_time": 29.934918749020028
}
#Debug simulation 
Total elapsed time: 5.172686072997749. Arrivals time: 0.15765839768573642 Scheduler time: 4.716979785356671 Scheduler overhead time: 0.10807021660730243 Adapter cache time: 0.03414007043465972 Engine time: 0.10561772203072906 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.192172588314861,
    "estimated_duration": 3600.017607628594,
    "input_throughput": 3629.616691960375,
    "output_throughput": 3204.8098808049735,
    "total_throughput": 6834.426572765348,
    "itl": 35.73261775596333,
    "ttft": 22017.065746372566,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2640,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.571113277040242,
    "arrivals": 52471,
    "finished_requests": 52252,
    "scheduler_time": 29.930915501096575
}
#Debug simulation 
Total elapsed time: 5.192302477080375. Arrivals time: 0.15607796935364604 Scheduler time: 4.7374657285399735 Scheduler overhead time: 0.10842769639566541 Adapter cache time: 0.03395785391330719 Engine time: 0.10575479734688997 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 5.190147450193763,
    "estimated_duration": 3600.016539945433,
    "input_throughput": 3629.6177684222685,
    "output_throughput": 3204.810831278813,
    "total_throughput": 6834.428599701082,
    "itl": 35.72619603790322,
    "ttft": 22001.353051593982,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2643,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.231213565452245,
    "arrivals": 52471,
    "finished_requests": 52252,
    "scheduler_time": 29.925508864110515
}
#Debug simulation 
Total elapsed time: 5.19025403726846. Arrivals time: 0.15670578368008137 Scheduler time: 4.732641407288611 Scheduler overhead time: 0.10945544019341469 Adapter cache time: 0.03428184799849987 Engine time: 0.10686514154076576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 5.15479936497286,
    "estimated_duration": 3600.0162600154918,
    "input_throughput": 3629.618050653963,
    "output_throughput": 3204.811080478384,
    "total_throughput": 6834.429131132348,
    "itl": 35.72971649132683,
    "ttft": 22003.42474684509,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.71597750585495,
    "arrivals": 52471,
    "finished_requests": 52252,
    "scheduler_time": 29.92911949290305
}
#Debug simulation 
Total elapsed time: 5.15489965910092. Arrivals time: 0.1552104940637946 Scheduler time: 4.700589939951897 Scheduler overhead time: 0.10825199307873845 Adapter cache time: 0.03416406502947211 Engine time: 0.10635745106264949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 5.2015192452818155,
    "estimated_duration": 3600.0283023756374,
    "input_throughput": 3629.3070227748162,
    "output_throughput": 3204.5367511103127,
    "total_throughput": 6833.843773885129,
    "itl": 35.72926183648732,
    "ttft": 22388.405066288986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2637,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.8847626276567935,
    "arrivals": 52471,
    "finished_requests": 52247,
    "scheduler_time": 29.92801320687953
}
#Debug simulation 
Total elapsed time: 5.201619834173471. Arrivals time: 0.15034915087744594 Scheduler time: 4.752333091571927 Scheduler overhead time: 0.1087024686858058 Adapter cache time: 0.0339974663220346 Engine time: 0.10597209585830569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 4320, 540, 540, 540, 540, 4320, 540, 4320, 540, 33, 4320, 33, 33, 4320, 540, 4320, 540, 4320, 4320, 540, 33, 4320, 540, 33, 33, 540, 4320, 33, 540, 33, 33, 540, 540, 540, 33, 33, 4320, 540, 540, 33, 4320, 4320, 540, 4320, 4320, 540, 4320, 33, 4320, 540, 540, 540, 4320, 4320, 33, 33, 540, 33, 4320, 33, 33, 4320, 33, 540, 540, 33, 540, 4320, 4320, 4320, 540, 4320, 4320, 33, 33, 4320, 540, 4320, 33, 540, 4320, 33, 4320, 540, 33, 4320, 33, 33, 4320, 33, 33, 540]
Prompts retrieved: 156576 . Total input tokens: 35009874 . Total output tokens: 31239626
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 5.1642652079463005,
    "estimated_duration": 3600.020867252253,
    "input_throughput": 3629.101464062305,
    "output_throughput": 3204.4094813275087,
    "total_throughput": 6833.510945389813,
    "itl": 35.733145723634316,
    "ttft": 22623.08047495611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2627,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.727329040877093,
    "arrivals": 52471,
    "finished_requests": 52244,
    "scheduler_time": 29.94029652432652
}
#Debug simulation 
Total elapsed time: 5.164366431999952. Arrivals time: 0.15383799141272902 Scheduler time: 4.711543685756624 Scheduler overhead time: 0.10942574683576822 Adapter cache time: 0.03395537007600069 Engine time: 0.10544385807588696 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.8716638116166,
    "estimated_duration": 3599.9268641500385,
    "input_throughput": 3490.918142018184,
    "output_throughput": 3098.0751612111553,
    "total_throughput": 6588.993303229339,
    "itl": 35.09655576862363,
    "ttft": 19517.558415752745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3079,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.423241763568827,
    "arrivals": 50642,
    "finished_requests": 50449,
    "scheduler_time": 27.79419182398416
}
#Debug simulation 
Total elapsed time: 4.871795456856489. Arrivals time: 0.15007431199774146 Scheduler time: 4.417639013379812 Scheduler overhead time: 0.10882799653336406 Adapter cache time: 0.03672884590923786 Engine time: 0.1072464999742806 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.836541558150202,
    "estimated_duration": 3599.91730419889,
    "input_throughput": 3490.6535173302814,
    "output_throughput": 3098.4311742355935,
    "total_throughput": 6589.084691565875,
    "itl": 35.10714093322806,
    "ttft": 19730.478219133198,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3075,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.016498437526188,
    "arrivals": 50642,
    "finished_requests": 50446,
    "scheduler_time": 27.79552114483984
}
#Debug simulation 
Total elapsed time: 4.836636537220329. Arrivals time: 0.14578462485224009 Scheduler time: 4.38842985779047 Scheduler overhead time: 0.10804745042696595 Adapter cache time: 0.03656398691236973 Engine time: 0.10723181767389178 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.865466107148677,
    "estimated_duration": 3599.9244444689175,
    "input_throughput": 3489.9993579874917,
    "output_throughput": 3098.3605828553673,
    "total_throughput": 6588.359940842859,
    "itl": 35.104763609924966,
    "ttft": 20141.644743798934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3077,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.04446119913792,
    "arrivals": 50642,
    "finished_requests": 50440,
    "scheduler_time": 27.78740354257841
}
#Debug simulation 
Total elapsed time: 4.8655790709890425. Arrivals time: 0.14335387106984854 Scheduler time: 4.418398035224527 Scheduler overhead time: 0.10864549595862627 Adapter cache time: 0.0370861915871501 Engine time: 0.10701216012239456 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.832575112115592,
    "estimated_duration": 3599.923844323339,
    "input_throughput": 3490.921070404524,
    "output_throughput": 3098.077760057824,
    "total_throughput": 6588.998830462348,
    "itl": 35.097817335904594,
    "ttft": 19508.51686685405,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3077,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.617560577541639,
    "arrivals": 50642,
    "finished_requests": 50449,
    "scheduler_time": 27.79402410419269
}
#Debug simulation 
Total elapsed time: 4.832678000908345. Arrivals time: 0.148756992071867 Scheduler time: 4.380794537253678 Scheduler overhead time: 0.10981042869389057 Adapter cache time: 0.036659509874880314 Engine time: 0.10569406533613801 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.863253264222294,
    "estimated_duration": 3599.9178786951848,
    "input_throughput": 3490.607959244503,
    "output_throughput": 3098.374567378411,
    "total_throughput": 6588.9825266229145,
    "itl": 35.1071617736905,
    "ttft": 19875.435207081755,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3072,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.152556631117577,
    "arrivals": 50642,
    "finished_requests": 50444,
    "scheduler_time": 27.797515770711723
}
#Debug simulation 
Total elapsed time: 4.863351271953434. Arrivals time: 0.14762916089966893 Scheduler time: 4.411238077096641 Scheduler overhead time: 0.10905451886355877 Adapter cache time: 0.03675995301455259 Engine time: 0.10793012101203203 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.857289334759116,
    "estimated_duration": 3599.9056772637177,
    "input_throughput": 3490.8986864211633,
    "output_throughput": 3098.03672647254,
    "total_throughput": 6588.935412893703,
    "itl": 35.0913147765165,
    "ttft": 19588.783100445704,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3078,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.203374807708963,
    "arrivals": 50642,
    "finished_requests": 50448,
    "scheduler_time": 27.79192680181442
}
#Debug simulation 
Total elapsed time: 4.857410409022123. Arrivals time: 0.1485814661718905 Scheduler time: 4.403954014647752 Scheduler overhead time: 0.10957628721371293 Adapter cache time: 0.036800469271838665 Engine time: 0.10769518371671438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.4   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 135, 4320, 135, 135, 4320, 270, 4320, 270, 4320, 4320, 270, 135, 4320, 270, 135, 135, 270, 4320, 135, 270, 135, 135, 270, 270, 270, 135, 135, 4320, 270, 270, 135, 4320, 4320, 270, 4320, 4320, 270, 4320, 135, 4320, 270, 270, 270, 4320, 4320, 135, 135, 270, 135, 4320, 135, 135, 4320, 135, 270, 270, 135, 270, 4320, 4320, 4320, 270, 4320, 4320, 135, 135, 4320, 270, 4320, 135, 270, 4320, 135, 4320, 270, 135, 4320, 135, 135, 4320, 135, 135, 270]
Prompts retrieved: 151200 . Total input tokens: 33809263 . Total output tokens: 30204504
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.898639102000743,
    "estimated_duration": 3599.898280406297,
    "input_throughput": 3490.626962543444,
    "output_throughput": 3098.391435310537,
    "total_throughput": 6589.018397853981,
    "itl": 35.109995325079126,
    "ttft": 19887.119856099045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3073,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.28336599696371,
    "arrivals": 50642,
    "finished_requests": 50444,
    "scheduler_time": 27.800464620847848
}
#Debug simulation 
Total elapsed time: 4.898737059906125. Arrivals time: 0.14871908957138658 Scheduler time: 4.444046893157065 Scheduler overhead time: 0.1105510238558054 Adapter cache time: 0.03696296131238341 Engine time: 0.10740745672956109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.506666079163551,
    "estimated_duration": 3599.92108866298,
    "input_throughput": 3446.067203825143,
    "output_throughput": 3049.8532411102697,
    "total_throughput": 6495.920444935413,
    "itl": 34.6368373030364,
    "ttft": 15445.088289989342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3003,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.190644695029997,
    "arrivals": 49929,
    "finished_requests": 49771,
    "scheduler_time": 26.56741136197345
}
#Debug simulation 
Total elapsed time: 4.50677081104368. Arrivals time: 0.1479764971882105 Scheduler time: 4.055359001271427 Scheduler overhead time: 0.10890391143038869 Adapter cache time: 0.03628752753138542 Engine time: 0.10741611197590828 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.519395519979298,
    "estimated_duration": 3599.9252216256464,
    "input_throughput": 3446.063247502102,
    "output_throughput": 3049.8497396682096,
    "total_throughput": 6495.912987170312,
    "itl": 34.640396436892466,
    "ttft": 15450.520295741031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3013,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.777589332526523,
    "arrivals": 49929,
    "finished_requests": 49771,
    "scheduler_time": 26.572829821180598
}
#Debug simulation 
Total elapsed time: 4.519501282367855. Arrivals time: 0.14253301778808236 Scheduler time: 4.07407356845215 Scheduler overhead time: 0.10883989417925477 Adapter cache time: 0.03636006452143192 Engine time: 0.10640156734734774 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.541245419997722,
    "estimated_duration": 3599.9345290547926,
    "input_throughput": 3446.0543378985385,
    "output_throughput": 3049.8418544524843,
    "total_throughput": 6495.896192351023,
    "itl": 34.642447443256415,
    "ttft": 15454.990913369827,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.807528347391262,
    "arrivals": 49929,
    "finished_requests": 49771,
    "scheduler_time": 26.573971936087947
}
#Debug simulation 
Total elapsed time: 4.541346787009388. Arrivals time: 0.1482425993308425 Scheduler time: 4.086743647232652 Scheduler overhead time: 0.11012610048055649 Adapter cache time: 0.03668393520638347 Engine time: 0.10848163440823555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.545261032879353,
    "estimated_duration": 3599.933715459017,
    "input_throughput": 3446.0551167171147,
    "output_throughput": 3049.8425437258556,
    "total_throughput": 6495.897660442971,
    "itl": 34.63635699839635,
    "ttft": 15446.108575967733,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3016,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.417189315541188,
    "arrivals": 49929,
    "finished_requests": 49771,
    "scheduler_time": 26.569358007140295
}
#Debug simulation 
Total elapsed time: 4.545355640817434. Arrivals time: 0.14748560450971127 Scheduler time: 4.091418490279466 Scheduler overhead time: 0.11001974018290639 Adapter cache time: 0.03666729433462024 Engine time: 0.1086328481324017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.560235362034291,
    "estimated_duration": 3599.9239643815617,
    "input_throughput": 3446.0644510115862,
    "output_throughput": 3049.8508048033577,
    "total_throughput": 6495.915255814944,
    "itl": 34.643626646482836,
    "ttft": 15456.00630070393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3014,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.921461277883033,
    "arrivals": 49929,
    "finished_requests": 49771,
    "scheduler_time": 26.574984150311515
}
#Debug simulation 
Total elapsed time: 4.560336926952004. Arrivals time: 0.1480370294302702 Scheduler time: 4.105881800875068 Scheduler overhead time: 0.1105675925500691 Adapter cache time: 0.036731208208948374 Engine time: 0.1077733444981277 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.516172007191926,
    "estimated_duration": 3599.943643315648,
    "input_throughput": 3446.045613251358,
    "output_throughput": 3049.8341329276545,
    "total_throughput": 6495.879746179013,
    "itl": 34.628660430508525,
    "ttft": 15451.550342520775,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3005,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.985101136181047,
    "arrivals": 49929,
    "finished_requests": 49771,
    "scheduler_time": 26.566962568233187
}
#Debug simulation 
Total elapsed time: 4.516296884976327. Arrivals time: 0.14679612824693322 Scheduler time: 4.065556262154132 Scheduler overhead time: 0.10896671377122402 Adapter cache time: 0.0362691399641335 Engine time: 0.10745328804478049 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.4-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 66, 4320, 66, 66, 4320, 270, 4320, 270, 4320, 4320, 270, 66, 4320, 270, 66, 66, 270, 4320, 66, 270, 66, 66, 270, 270, 270, 66, 66, 4320, 270, 270, 66, 4320, 4320, 270, 4320, 4320, 270, 4320, 66, 4320, 270, 270, 270, 4320, 4320, 66, 66, 270, 66, 4320, 66, 66, 4320, 66, 270, 270, 66, 270, 4320, 4320, 4320, 270, 4320, 4320, 66, 66, 4320, 270, 4320, 66, 270, 4320, 66, 4320, 270, 66, 4320, 66, 66, 4320, 66, 66, 270]
Prompts retrieved: 148992 . Total input tokens: 33330154 . Total output tokens: 29754013
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.515107706189156,
    "estimated_duration": 3599.940876535435,
    "input_throughput": 3446.0482617534144,
    "output_throughput": 3049.836476916353,
    "total_throughput": 6495.884738669768,
    "itl": 34.646207084441805,
    "ttft": 15443.558226880476,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 3018,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 10.057634298875378,
    "arrivals": 49929,
    "finished_requests": 49771,
    "scheduler_time": 26.573897675205735
}
#Debug simulation 
Total elapsed time: 4.515202315058559. Arrivals time: 0.1435324647463858 Scheduler time: 4.0683503220789135 Scheduler overhead time: 0.10925974184647202 Adapter cache time: 0.03637667326256633 Engine time: 0.10657216003164649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.3654465628787875,
    "estimated_duration": 3599.9994258979477,
    "input_throughput": 3410.339432745241,
    "output_throughput": 3021.0840928918274,
    "total_throughput": 6431.423525637068,
    "itl": 34.50259573089844,
    "ttft": 15755.392670182739,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.648938364354038,
    "arrivals": 49606,
    "finished_requests": 49433,
    "scheduler_time": 25.906345955055688
}
#Debug simulation 
Total elapsed time: 4.365574077703059. Arrivals time: 0.14385199639946222 Scheduler time: 3.917694811709225 Scheduler overhead time: 0.10943202022463083 Adapter cache time: 0.0352804777212441 Engine time: 0.10791645292192698 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.354194620158523,
    "estimated_duration": 3600.026873707946,
    "input_throughput": 3410.313431175791,
    "output_throughput": 3021.0610591353916,
    "total_throughput": 6431.374490311182,
    "itl": 34.511423688674924,
    "ttft": 15762.490438623841,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.126256214598992,
    "arrivals": 49606,
    "finished_requests": 49433,
    "scheduler_time": 25.911712383490684
}
#Debug simulation 
Total elapsed time: 4.354298132006079. Arrivals time: 0.14152788510546088 Scheduler time: 3.9097274830564857 Scheduler overhead time: 0.10948585532605648 Adapter cache time: 0.03537539904937148 Engine time: 0.10681459819898009 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.361173557117581,
    "estimated_duration": 3600.003294175504,
    "input_throughput": 3410.335768265403,
    "output_throughput": 3021.0808466748554,
    "total_throughput": 6431.416614940259,
    "itl": 34.51049064736544,
    "ttft": 15736.270143685731,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.191570960711394,
    "arrivals": 49606,
    "finished_requests": 49433,
    "scheduler_time": 25.907169907264784
}
#Debug simulation 
Total elapsed time: 4.36128824390471. Arrivals time: 0.1488519161939621 Scheduler time: 3.9086644928902388 Scheduler overhead time: 0.109731983859092 Adapter cache time: 0.035445818677544594 Engine time: 0.10727246338501573 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.37714608758688,
    "estimated_duration": 3600.012040820748,
    "input_throughput": 3410.327482460581,
    "output_throughput": 3021.0735066098446,
    "total_throughput": 6431.400989070426,
    "itl": 34.50716442752788,
    "ttft": 15744.105118939358,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2826,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.80413427448121,
    "arrivals": 49606,
    "finished_requests": 49433,
    "scheduler_time": 25.905811036910272
}
#Debug simulation 
Total elapsed time: 4.3772495007142425. Arrivals time: 0.1468651918694377 Scheduler time: 3.9237862550653517 Scheduler overhead time: 0.10971338301897049 Adapter cache time: 0.035440018866211176 Engine time: 0.1096337023191154 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.353998553939164,
    "estimated_duration": 3600.021645033718,
    "input_throughput": 3410.3183843176616,
    "output_throughput": 3021.0654469268156,
    "total_throughput": 6431.383831244478,
    "itl": 34.511562536421216,
    "ttft": 15748.554943845866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2827,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.270652152001457,
    "arrivals": 49606,
    "finished_requests": 49433,
    "scheduler_time": 25.910276765256736
}
#Debug simulation 
Total elapsed time: 4.354096153285354. Arrivals time: 0.14363306760787964 Scheduler time: 3.9066332546062768 Scheduler overhead time: 0.1093156742863357 Adapter cache time: 0.03535356558859348 Engine time: 0.1078445753082633 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.353932762984186,
    "estimated_duration": 3600.016869033704,
    "input_throughput": 3410.2501312154436,
    "output_throughput": 3021.0580660193505,
    "total_throughput": 6431.3081972347945,
    "itl": 34.499188747670686,
    "ttft": 15806.369912459308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2839,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.488752787227156,
    "arrivals": 49606,
    "finished_requests": 49432,
    "scheduler_time": 25.9006060963713
}
#Debug simulation 
Total elapsed time: 4.354066291823983. Arrivals time: 0.14198955241590738 Scheduler time: 3.909419093746692 Scheduler overhead time: 0.1093165441416204 Adapter cache time: 0.03523000469431281 Engine time: 0.10692004999145865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.025-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 4320, 270, 270, 270, 270, 4320, 270, 4320, 270, 33, 4320, 33, 33, 4320, 270, 4320, 270, 4320, 4320, 270, 33, 4320, 270, 33, 33, 270, 4320, 33, 270, 33, 33, 270, 270, 270, 33, 33, 4320, 270, 270, 33, 4320, 4320, 270, 4320, 4320, 270, 4320, 33, 4320, 270, 270, 270, 4320, 4320, 33, 33, 270, 33, 4320, 33, 33, 4320, 33, 270, 270, 33, 270, 4320, 4320, 4320, 270, 4320, 4320, 33, 33, 4320, 270, 4320, 33, 270, 4320, 33, 4320, 270, 33, 4320, 33, 33, 4320, 33, 33, 270]
Prompts retrieved: 147936 . Total input tokens: 33097985 . Total output tokens: 29538647
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.367707523051649,
    "estimated_duration": 3599.994095753226,
    "input_throughput": 3410.344482087613,
    "output_throughput": 3021.0885659034498,
    "total_throughput": 6431.433047991063,
    "itl": 34.513599723497784,
    "ttft": 15740.754990379059,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2834,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.402248566820719,
    "arrivals": 49606,
    "finished_requests": 49433,
    "scheduler_time": 25.90955525151007
}
#Debug simulation 
Total elapsed time: 4.367800422012806. Arrivals time: 0.14284927723929286 Scheduler time: 3.9204000174067914 Scheduler overhead time: 0.1099333381280303 Adapter cache time: 0.035221705213189125 Engine time: 0.10771595221012831 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.079446198884398,
    "estimated_duration": 3599.9402725733635,
    "input_throughput": 3336.5945239457346,
    "output_throughput": 2965.9667082108253,
    "total_throughput": 6302.5612321565595,
    "itl": 34.10833051454555,
    "ttft": 13628.062516204069,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2821,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.633635925634378,
    "arrivals": 48532,
    "finished_requests": 48371,
    "scheduler_time": 24.641340608778616
}
#Debug simulation 
Total elapsed time: 4.079551396891475. Arrivals time: 0.13717475812882185 Scheduler time: 3.636290372814983 Scheduler overhead time: 0.1102659716270864 Adapter cache time: 0.03505864879116416 Engine time: 0.10912381624802947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.066160521004349,
    "estimated_duration": 3599.97022612454,
    "input_throughput": 3336.5667618120083,
    "output_throughput": 2965.9420298857276,
    "total_throughput": 6302.508791697735,
    "itl": 34.11839697690702,
    "ttft": 13697.438513292018,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2763,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.984314083135516,
    "arrivals": 48532,
    "finished_requests": 48371,
    "scheduler_time": 24.657146117354458
}
#Debug simulation 
Total elapsed time: 4.0662650861777365. Arrivals time: 0.14215886173769832 Scheduler time: 3.621203928720206 Scheduler overhead time: 0.10967276291921735 Adapter cache time: 0.03479206981137395 Engine time: 0.10724355420097709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.07397161796689,
    "estimated_duration": 3599.956621394194,
    "input_throughput": 3336.5793711559118,
    "output_throughput": 2965.9532385878824,
    "total_throughput": 6302.532609743794,
    "itl": 34.11808325207807,
    "ttft": 13689.823872781859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2769,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.025106252543392,
    "arrivals": 48532,
    "finished_requests": 48371,
    "scheduler_time": 24.656065141352684
}
#Debug simulation 
Total elapsed time: 4.074075001291931. Arrivals time: 0.1438648458570242 Scheduler time: 3.626302683260292 Scheduler overhead time: 0.10957029182463884 Adapter cache time: 0.03467344352975488 Engine time: 0.10815255111083388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 4.029694355092943,
    "estimated_duration": 3599.9646425689934,
    "input_throughput": 3336.2441558396004,
    "output_throughput": 2965.951630119481,
    "total_throughput": 6302.195785959081,
    "itl": 34.11080014977683,
    "ttft": 13920.453483716163,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2824,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.807960461533973,
    "arrivals": 48532,
    "finished_requests": 48367,
    "scheduler_time": 24.638535213558317
}
#Debug simulation 
Total elapsed time: 4.02979180496186. Arrivals time: 0.1330901854671538 Scheduler time: 3.5935426084324718 Scheduler overhead time: 0.10997916478663683 Adapter cache time: 0.034915552008897066 Engine time: 0.10658390168100595 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 4.093333932105452,
    "estimated_duration": 3599.9640697117857,
    "input_throughput": 3336.572467780671,
    "output_throughput": 2965.947102037279,
    "total_throughput": 6302.51956981795,
    "itl": 34.120850163985665,
    "ttft": 13696.517173829072,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2766,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.127016289401444,
    "arrivals": 48532,
    "finished_requests": 48371,
    "scheduler_time": 24.658114679585594
}
#Debug simulation 
Total elapsed time: 4.093432209920138. Arrivals time: 0.13937211548909545 Scheduler time: 3.6480382634326816 Scheduler overhead time: 0.11038282746449113 Adapter cache time: 0.0348564088344574 Engine time: 0.10920608369633555 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 4.059945686720312,
    "estimated_duration": 3599.9615839184657,
    "input_throughput": 3336.2469904267787,
    "output_throughput": 2965.95415009346,
    "total_throughput": 6302.201140520238,
    "itl": 34.10651734891527,
    "ttft": 13922.336911501478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2823,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.440911982508709,
    "arrivals": 48532,
    "finished_requests": 48367,
    "scheduler_time": 24.63599014042142
}
#Debug simulation 
Total elapsed time: 4.060064003802836. Arrivals time: 0.1450849212706089 Scheduler time: 3.6116264732554555 Scheduler overhead time: 0.10977742122486234 Adapter cache time: 0.03497421694919467 Engine time: 0.10685594147071242 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.4-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.4    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 66, 4320, 66, 66, 4320, 135, 4320, 135, 4320, 4320, 135, 66, 4320, 135, 66, 66, 135, 4320, 66, 135, 66, 66, 135, 135, 135, 66, 66, 4320, 135, 135, 66, 4320, 4320, 135, 4320, 4320, 135, 4320, 66, 4320, 135, 135, 135, 4320, 4320, 66, 66, 135, 66, 4320, 66, 66, 4320, 66, 135, 135, 66, 135, 4320, 4320, 4320, 135, 4320, 4320, 66, 66, 4320, 135, 4320, 66, 135, 4320, 66, 4320, 135, 66, 4320, 66, 66, 4320, 66, 66, 135]
Prompts retrieved: 144672 . Total input tokens: 32354420 . Total output tokens: 28898873
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 4.064647072926164,
    "estimated_duration": 3599.948963727537,
    "input_throughput": 3336.5864685933634,
    "output_throughput": 2965.95954764433,
    "total_throughput": 6302.546016237693,
    "itl": 34.12186412527321,
    "ttft": 13693.778813677836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2767,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 9.240928921810816,
    "arrivals": 48532,
    "finished_requests": 48371,
    "scheduler_time": 24.658246949829714
}
#Debug simulation 
Total elapsed time: 4.064744446892291. Arrivals time: 0.13458991656079888 Scheduler time: 3.627008361276239 Scheduler overhead time: 0.11007516970857978 Adapter cache time: 0.03469253471121192 Engine time: 0.1071605896577239 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.9425102109089494,
    "estimated_duration": 3600.026532734768,
    "input_throughput": 3317.014997366904,
    "output_throughput": 2944.9563506261793,
    "total_throughput": 6261.971347993083,
    "itl": 33.930808903077754,
    "ttft": 11123.267963549015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.990933499408662,
    "arrivals": 48139,
    "finished_requests": 48007,
    "scheduler_time": 24.136863984846528
}
#Debug simulation 
Total elapsed time: 3.9426062027923763. Arrivals time: 0.1436325260438025 Scheduler time: 3.4974117861129344 Scheduler overhead time: 0.1093766619451344 Adapter cache time: 0.033796037547290325 Engine time: 0.10691005503758788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9799133827909827,
    "estimated_duration": 3600.0185420727944,
    "input_throughput": 3317.0223598694283,
    "output_throughput": 2944.9628873010465,
    "total_throughput": 6261.985247170475,
    "itl": 33.93858979251309,
    "ttft": 11123.57391099878,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.462408210767641,
    "arrivals": 48139,
    "finished_requests": 48007,
    "scheduler_time": 24.140712993249394
}
#Debug simulation 
Total elapsed time: 3.9800110068172216. Arrivals time: 0.1400304827839136 Scheduler time: 3.533578193280846 Scheduler overhead time: 0.10996994189918041 Adapter cache time: 0.033837344497442245 Engine time: 0.11061969958245754 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9773458591662347,
    "estimated_duration": 3600.0268922949967,
    "input_throughput": 3317.014666073081,
    "output_throughput": 2944.9560564924936,
    "total_throughput": 6261.970722565575,
    "itl": 33.93918176167549,
    "ttft": 11124.051544715789,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2614,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.49737774688733,
    "arrivals": 48139,
    "finished_requests": 48007,
    "scheduler_time": 24.140913033610506
}
#Debug simulation 
Total elapsed time: 3.9774408359080553. Arrivals time: 0.13996461313217878 Scheduler time: 3.535956570878625 Scheduler overhead time: 0.1098633105866611 Adapter cache time: 0.03375401394441724 Engine time: 0.1064872364513576 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.974031541030854,
    "estimated_duration": 3600.033305188155,
    "input_throughput": 3317.0087573331184,
    "output_throughput": 2944.9508105164305,
    "total_throughput": 6261.959567849549,
    "itl": 33.93320198662447,
    "ttft": 11156.495999925957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2571,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.009801014442631,
    "arrivals": 48139,
    "finished_requests": 48007,
    "scheduler_time": 24.14367537292497
}
#Debug simulation 
Total elapsed time: 3.9741348400712013. Arrivals time: 0.14247155422344804 Scheduler time: 3.52552974736318 Scheduler overhead time: 0.11296491418033838 Adapter cache time: 0.033510325476527214 Engine time: 0.10780641669407487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9718693010509014,
    "estimated_duration": 3600.0016271502254,
    "input_throughput": 3317.0379451891554,
    "output_throughput": 2944.976724466794,
    "total_throughput": 6262.01466965595,
    "itl": 33.939807170050145,
    "ttft": 11049.168025659757,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2611,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.58553489496902,
    "arrivals": 48139,
    "finished_requests": 48007,
    "scheduler_time": 24.141307487389586
}
#Debug simulation 
Total elapsed time: 3.9719703630544245. Arrivals time: 0.14641017327085137 Scheduler time: 3.5241824104450643 Scheduler overhead time: 0.10863909358158708 Adapter cache time: 0.03394512785598636 Engine time: 0.10744484374299645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.9680351531133056,
    "estimated_duration": 3600.032823110597,
    "input_throughput": 3317.009201511147,
    "output_throughput": 2944.9512048724723,
    "total_throughput": 6261.960406383619,
    "itl": 33.928969074497594,
    "ttft": 11123.178479774308,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2616,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.82197157146385,
    "arrivals": 48139,
    "finished_requests": 48007,
    "scheduler_time": 24.135403396896383
}
#Debug simulation 
Total elapsed time: 3.9681319119408727. Arrivals time: 0.14224051125347614 Scheduler time: 3.522154624108225 Scheduler overhead time: 0.1097472095862031 Adapter cache time: 0.033874879125505686 Engine time: 0.1087325750850141 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.0125-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 135, 4320, 135, 135, 135, 135, 4320, 135, 4320, 135, 33, 4320, 33, 33, 4320, 135, 4320, 135, 4320, 4320, 135, 33, 4320, 135, 33, 33, 135, 4320, 33, 135, 33, 33, 135, 135, 135, 33, 33, 4320, 135, 135, 33, 4320, 4320, 135, 4320, 4320, 135, 4320, 33, 4320, 135, 135, 135, 4320, 4320, 33, 33, 135, 33, 4320, 33, 33, 4320, 33, 135, 135, 33, 135, 4320, 4320, 4320, 135, 4320, 4320, 33, 33, 4320, 135, 4320, 33, 135, 4320, 33, 4320, 135, 33, 4320, 33, 33, 4320, 33, 33, 135]
Prompts retrieved: 143616 . Total input tokens: 32121383 . Total output tokens: 28686554
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.9604748929850757,
    "estimated_duration": 3600.016288286471,
    "input_throughput": 3317.0244364877076,
    "output_throughput": 2944.964730991893,
    "total_throughput": 6261.9891674796,
    "itl": 33.94151610668231,
    "ttft": 11124.276642654031,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2615,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 8.701918845437046,
    "arrivals": 48139,
    "finished_requests": 48007,
    "scheduler_time": 24.142560162372963
}
#Debug simulation 
Total elapsed time: 3.960577388294041. Arrivals time: 0.13932064594700933 Scheduler time: 3.519933831412345 Scheduler overhead time: 0.10931376228109002 Adapter cache time: 0.033753478433936834 Engine time: 0.10678102308884263 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.779267368838191,
    "estimated_duration": 3600.0061859740435,
    "input_throughput": 3266.0954988938943,
    "output_throughput": 2916.25471114557,
    "total_throughput": 6182.350210039464,
    "itl": 33.702982308662776,
    "ttft": 7758.051777812961,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2216,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.782040840555182,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.448047748195606
}
#Debug simulation 
Total elapsed time: 3.779365629889071. Arrivals time: 0.13346492033451796 Scheduler time: 3.3487243759445846 Scheduler overhead time: 0.1084244903177023 Adapter cache time: 0.031432506162673235 Engine time: 0.10635366011410952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.796843610238284,
    "estimated_duration": 3600.0259067645397,
    "input_throughput": 3266.0776073601273,
    "output_throughput": 2916.2387360249236,
    "total_throughput": 6182.3163433850505,
    "itl": 33.708366998560535,
    "ttft": 7758.782656145965,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2215,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.185597156700406,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.451450297147204
}
#Debug simulation 
Total elapsed time: 3.796941062901169. Arrivals time: 0.13837371207773685 Scheduler time: 3.3591912197880447 Scheduler overhead time: 0.10869125043973327 Adapter cache time: 0.031550888903439045 Engine time: 0.10808883048593998 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.810391844250262,
    "estimated_duration": 3600.031216409603,
    "input_throughput": 3266.0727902594404,
    "output_throughput": 2916.234434897606,
    "total_throughput": 6182.307225157047,
    "itl": 33.70815568361061,
    "ttft": 7760.038119768582,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.17433711901299,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.451523623801684
}
#Debug simulation 
Total elapsed time: 3.810495449230075. Arrivals time: 0.13824438070878386 Scheduler time: 3.370718279387802 Scheduler overhead time: 0.10917260590940714 Adapter cache time: 0.03178459405899048 Engine time: 0.10925983404740691 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 3.772754375822842,
    "estimated_duration": 3600.0067866680683,
    "input_throughput": 3266.0949539160188,
    "output_throughput": 2916.2542245418263,
    "total_throughput": 6182.3491784578455,
    "itl": 33.704685601179015,
    "ttft": 7759.4772020851315,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.884389362307037,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.449060613128562
}
#Debug simulation 
Total elapsed time: 3.772844864986837. Arrivals time: 0.132608434651047 Scheduler time: 3.3432346023619175 Scheduler overhead time: 0.10804116539657116 Adapter cache time: 0.03148057358339429 Engine time: 0.10637135384604335 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 3.78642362030223,
    "estimated_duration": 3600.0166431497873,
    "input_throughput": 3266.086011678136,
    "output_throughput": 2916.2462401325024,
    "total_throughput": 6182.332251810638,
    "itl": 33.70981523793138,
    "ttft": 7758.75235336819,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.280028253830788,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.452120704983606
}
#Debug simulation 
Total elapsed time: 3.78652327042073. Arrivals time: 0.1351061901077628 Scheduler time: 3.3538290769793093 Scheduler overhead time: 0.10866854013875127 Adapter cache time: 0.03152210731059313 Engine time: 0.10623017093166709 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 3.781126603949815,
    "estimated_duration": 3600.00606881245,
    "input_throughput": 3266.0956051884245,
    "output_throughput": 2916.2548060545905,
    "total_throughput": 6182.3504112430155,
    "itl": 33.7020895367745,
    "ttft": 7773.004355342684,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2174,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 6.5003693411171355,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.450641965883694
}
#Debug simulation 
Total elapsed time: 3.781224459875375. Arrivals time: 0.13247934728860855 Scheduler time: 3.3508851919323206 Scheduler overhead time: 0.1089229523204267 Adapter cache time: 0.03133815806359053 Engine time: 0.10653669247403741 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.4,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.4-0.00625-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.4-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.4     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 66, 4320, 66, 66, 66, 66, 4320, 66, 4320, 66, 33, 4320, 33, 33, 4320, 66, 4320, 66, 4320, 4320, 66, 33, 4320, 66, 33, 33, 66, 4320, 33, 66, 33, 33, 66, 66, 66, 33, 33, 4320, 66, 66, 33, 4320, 4320, 66, 4320, 4320, 66, 4320, 33, 4320, 66, 66, 66, 4320, 4320, 33, 33, 66, 33, 4320, 33, 33, 4320, 33, 66, 66, 33, 66, 4320, 4320, 4320, 66, 4320, 4320, 33, 33, 4320, 66, 4320, 33, 66, 4320, 33, 4320, 66, 33, 4320, 33, 33, 4320, 33, 33, 66]
Prompts retrieved: 141408 . Total input tokens: 31614290 . Total output tokens: 28253337
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 3.768851418979466,
    "estimated_duration": 3600.013741910698,
    "input_throughput": 3266.0886438059792,
    "output_throughput": 2916.2485903256384,
    "total_throughput": 6182.337234131617,
    "itl": 33.71116226234894,
    "ttft": 7758.6173641063915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 2212,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 7.369353456049874,
    "arrivals": 47462,
    "finished_requests": 47365,
    "scheduler_time": 23.45285366193707
}
#Debug simulation 
Total elapsed time: 3.7689484520815313. Arrivals time: 0.13640057714655995 Scheduler time: 3.33418934000656 Scheduler overhead time: 0.10797473695129156 Adapter cache time: 0.03140467731282115 Engine time: 0.10809662844985723 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-8/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.9307149089872837,
    "estimated_duration": 3599.976541162353,
    "input_throughput": 1378.6614838321998,
    "output_throughput": 1256.665411086071,
    "total_throughput": 2635.3268949182707,
    "itl": 25.554906879138237,
    "ttft": 5752.344278215867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11606,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 35.520020756083994,
    "arrivals": 20310,
    "finished_requests": 20279,
    "scheduler_time": 0.004316562239088069
}
#Debug simulation 
Total elapsed time: 1.9308171248994768. Arrivals time: 0.06673586927354336 Scheduler time: 1.4660674422048032 Scheduler overhead time: 0.12477817805483937 Adapter cache time: 0.08929947065189481 Engine time: 0.12332105077803135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-16/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9439505757763982,
    "estimated_duration": 3599.9725583076715,
    "input_throughput": 1378.6630091239224,
    "output_throughput": 1256.66680140659,
    "total_throughput": 2635.3298105305125,
    "itl": 25.575819012175376,
    "ttft": 5754.556441685538,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.664896619689614,
    "arrivals": 20310,
    "finished_requests": 20279,
    "scheduler_time": 0.004384432838820604
}
#Debug simulation 
Total elapsed time: 1.9441026519052684. Arrivals time: 0.06568119581788778 Scheduler time: 1.4811983876861632 Scheduler overhead time: 0.12497795559465885 Adapter cache time: 0.08936892682686448 Engine time: 0.12183409556746483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-8-32/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9007404670119286,
    "estimated_duration": 3599.981299794428,
    "input_throughput": 1378.6596614497453,
    "output_throughput": 1256.6637499640165,
    "total_throughput": 2635.3234114137617,
    "itl": 25.575264023875334,
    "ttft": 5754.579028449596,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 37.754534697574556,
    "arrivals": 20310,
    "finished_requests": 20279,
    "scheduler_time": 0.0043717134181501145
}
#Debug simulation 
Total elapsed time: 1.9008316886611283. Arrivals time: 0.06367495702579618 Scheduler time: 1.4435094366781414 Scheduler overhead time: 0.124638213776052 Adapter cache time: 0.08829064341261983 Engine time: 0.1202430883422494 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-16/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.9398557189852,
    "estimated_duration": 3599.9728695426006,
    "input_throughput": 1378.6628899318898,
    "output_throughput": 1256.6666927617148,
    "total_throughput": 2635.3295826936046,
    "itl": 25.561820044294144,
    "ttft": 5752.924310249433,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11597,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 36.22010357368427,
    "arrivals": 20310,
    "finished_requests": 20279,
    "scheduler_time": 0.004310099950526668
}
#Debug simulation 
Total elapsed time: 1.9399528373032808. Arrivals time: 0.06486054556444287 Scheduler time: 1.4790772930718958 Scheduler overhead time: 0.12529508909210563 Adapter cache time: 0.08917616819962859 Engine time: 0.12081795744597912 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_8-16-32/adapters_96_slots_32_rate_0.1-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9544150871224701,
    "estimated_duration": 3599.9769405300444,
    "input_throughput": 1378.6613308887606,
    "output_throughput": 1256.6652716764102,
    "total_throughput": 2635.326602565171,
    "itl": 25.58161218526482,
    "ttft": 5755.209191764432,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.20612738667262,
    "arrivals": 20310,
    "finished_requests": 20279,
    "scheduler_time": 0.004400965232930551
}
#Debug simulation 
Total elapsed time: 1.9545057392679155. Arrivals time: 0.06366099929437041 Scheduler time: 1.4878700049594045 Scheduler overhead time: 0.1252311123535037 Adapter cache time: 0.08973774686455727 Engine time: 0.1270506214350462 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_0.1-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-16/adapters_96_slots_32_rate_0.1-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.9343068874441087,
    "estimated_duration": 3599.984918878116,
    "input_throughput": 1378.6582754759693,
    "output_throughput": 1256.6624866333689,
    "total_throughput": 2635.320762109338,
    "itl": 25.544739941319225,
    "ttft": 5751.671762192314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11592,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 34.66066301850481,
    "arrivals": 20310,
    "finished_requests": 20279,
    "scheduler_time": 0.0042668176996633654
}
#Debug simulation 
Total elapsed time: 1.934425616171211. Arrivals time: 0.06484768399968743 Scheduler time: 1.4704619660042226 Scheduler overhead time: 0.12541155237704515 Adapter cache time: 0.08920668438076973 Engine time: 0.12363111367449164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_0.1-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.025_size_16-16-32/adapters_96_slots_32_rate_0.1-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.1  ]. Counts: [32 32 32]
Adapter prompts. [270, 270, 270, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 270, 1080, 270, 270, 1080, 540, 1080, 540, 1080, 1080, 540, 270, 1080, 540, 270, 270, 540, 1080, 270, 540, 270, 270, 540, 540, 540, 270, 270, 1080, 540, 540, 270, 1080, 1080, 540, 1080, 1080, 540, 1080, 270, 1080, 540, 540, 540, 1080, 1080, 270, 270, 540, 270, 1080, 270, 270, 1080, 270, 540, 540, 270, 540, 1080, 1080, 1080, 540, 1080, 1080, 270, 270, 1080, 540, 1080, 270, 540, 1080, 270, 1080, 540, 270, 1080, 270, 270, 1080, 270, 270, 540]
Prompts retrieved: 60480 . Total input tokens: 13412337 . Total output tokens: 12123165
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.9661390399560332,
    "estimated_duration": 3599.977694048741,
    "input_throughput": 1378.661042318337,
    "output_throughput": 1256.665008641231,
    "total_throughput": 2635.326050959568,
    "itl": 25.585357924811245,
    "ttft": 5755.519749169246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 11596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 38.680424942969466,
    "arrivals": 20310,
    "finished_requests": 20279,
    "scheduler_time": 0.004415409170431062
}
#Debug simulation 
Total elapsed time: 1.9662508741021156. Arrivals time: 0.06779893673956394 Scheduler time: 1.4978660265915096 Scheduler overhead time: 0.12488806154578924 Adapter cache time: 0.09051628690212965 Engine time: 0.12459571473300457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.8326348098926246,
    "estimated_duration": 3599.709099027564,
    "input_throughput": 1299.9222635140409,
    "output_throughput": 1137.4455233357864,
    "total_throughput": 2437.367786849827,
    "itl": 24.464578159274208,
    "ttft": 5239.743785328435,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10114,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.95377304213893,
    "arrivals": 18897,
    "finished_requests": 18870,
    "scheduler_time": 0.002049589295071071
}
#Debug simulation 
Total elapsed time: 1.8327323757112026. Arrivals time: 0.05997536703944206 Scheduler time: 1.369832230731845 Scheduler overhead time: 0.12820898555219173 Adapter cache time: 0.08415492624044418 Engine time: 0.12743767770007253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7870937399566174,
    "estimated_duration": 3599.686474875475,
    "input_throughput": 1299.779587099139,
    "output_throughput": 1137.3357175895787,
    "total_throughput": 2437.115304688718,
    "itl": 24.47963187878895,
    "ttft": 5430.705332047631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10113,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.755325793934176,
    "arrivals": 18897,
    "finished_requests": 18869,
    "scheduler_time": 0.002066438001289736
}
#Debug simulation 
Total elapsed time: 1.7871871488168836. Arrivals time: 0.05972586991265416 Scheduler time: 1.3277824306860566 Scheduler overhead time: 0.12851811666041613 Adapter cache time: 0.0832544807344675 Engine time: 0.12512078322470188 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.78072814270854,
    "estimated_duration": 3599.693754574635,
    "input_throughput": 1299.7769585409856,
    "output_throughput": 1137.3334175433993,
    "total_throughput": 2437.110376084385,
    "itl": 24.481964349799096,
    "ttft": 5430.821186008604,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10110,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 32.84708287982431,
    "arrivals": 18897,
    "finished_requests": 18869,
    "scheduler_time": 0.0020679878344776457
}
#Debug simulation 
Total elapsed time: 1.7808244028128684. Arrivals time: 0.06007757131010294 Scheduler time: 1.3184374375268817 Scheduler overhead time: 0.12910557352006435 Adapter cache time: 0.08301759511232376 Engine time: 0.12738830409944057 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.8097616070881486,
    "estimated_duration": 3599.6956033200363,
    "input_throughput": 1299.7762909965763,
    "output_throughput": 1137.3328334273635,
    "total_throughput": 2437.10912442394,
    "itl": 24.469994271505684,
    "ttft": 5430.358025457463,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10118,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 31.561242498143823,
    "arrivals": 18897,
    "finished_requests": 18869,
    "scheduler_time": 0.0020512769620648617
}
#Debug simulation 
Total elapsed time: 1.8098897533491254. Arrivals time: 0.06046738335862756 Scheduler time: 1.3471150347031653 Scheduler overhead time: 0.12850732589140534 Adapter cache time: 0.08374829031527042 Engine time: 0.12694596126675606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.8375525986775756,
    "estimated_duration": 3599.7019149155685,
    "input_throughput": 1299.7740120128092,
    "output_throughput": 1137.330839266458,
    "total_throughput": 2437.104851279267,
    "itl": 24.485429268192366,
    "ttft": 5430.8763062999715,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10117,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.242807972170176,
    "arrivals": 18897,
    "finished_requests": 18869,
    "scheduler_time": 0.0020565159012338264
}
#Debug simulation 
Total elapsed time: 1.8376529728993773. Arrivals time: 0.06084893457591534 Scheduler time: 1.3710351851768792 Scheduler overhead time: 0.1306695849634707 Adapter cache time: 0.08485033828765154 Engine time: 0.12681116489693522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.80321115674451,
    "estimated_duration": 3599.6958961719492,
    "input_throughput": 1299.7761852537624,
    "output_throughput": 1137.3327409000765,
    "total_throughput": 2437.108926153839,
    "itl": 24.456220105113463,
    "ttft": 5429.946868426306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.235388582047907,
    "arrivals": 18897,
    "finished_requests": 18869,
    "scheduler_time": 0.002028144445587632
}
#Debug simulation 
Total elapsed time: 1.8033092408441007. Arrivals time: 0.06024951674044132 Scheduler time: 1.3408864755183458 Scheduler overhead time: 0.1294598081149161 Adapter cache time: 0.0836774636991322 Engine time: 0.1259561493061483 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 135, 1080, 135, 135, 1080, 540, 1080, 540, 1080, 1080, 540, 135, 1080, 540, 135, 135, 540, 1080, 135, 540, 135, 135, 540, 540, 540, 135, 135, 1080, 540, 540, 135, 1080, 1080, 540, 1080, 1080, 540, 1080, 135, 1080, 540, 540, 540, 1080, 1080, 135, 135, 540, 135, 1080, 135, 135, 1080, 135, 540, 540, 135, 540, 1080, 1080, 1080, 540, 1080, 1080, 135, 135, 1080, 540, 1080, 135, 540, 1080, 135, 1080, 540, 135, 1080, 135, 135, 1080, 135, 135, 540]
Prompts retrieved: 56160 . Total input tokens: 12459839 . Total output tokens: 11250841
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.8006898839958012,
    "estimated_duration": 3599.7017641753328,
    "input_throughput": 1299.7740664418295,
    "output_throughput": 1137.3308868930478,
    "total_throughput": 2437.1049533348773,
    "itl": 24.488142827654826,
    "ttft": 5431.1807112286015,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 10112,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 33.62815048932799,
    "arrivals": 18897,
    "finished_requests": 18869,
    "scheduler_time": 0.0020668445195336405
}
#Debug simulation 
Total elapsed time: 1.8007833482697606. Arrivals time: 0.060840364545583725 Scheduler time: 1.3357517290860415 Scheduler overhead time: 0.13077744841575623 Adapter cache time: 0.08338993648067117 Engine time: 0.1265288135036826 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.7649648217484355,
    "estimated_duration": 3599.6562853162604,
    "input_throughput": 1253.6438599452342,
    "output_throughput": 1098.1017871412448,
    "total_throughput": 2351.745647086479,
    "itl": 24.02916409038033,
    "ttft": 4009.4591124083427,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.174850170647087,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.0003712919933252154
}
#Debug simulation 
Total elapsed time: 1.7650852939113975. Arrivals time: 0.05819259071722627 Scheduler time: 1.3025552472099662 Scheduler overhead time: 0.13043934386223555 Adapter cache time: 0.08009104570373893 Engine time: 0.13022211520001292 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7902300311252475,
    "estimated_duration": 3599.6550029094155,
    "input_throughput": 1253.6443065662204,
    "output_throughput": 1098.102178349082,
    "total_throughput": 2351.746484915302,
    "itl": 24.04213473284678,
    "ttft": 4009.853089179784,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9206,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.74262402208611,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.00036461437662474515
}
#Debug simulation 
Total elapsed time: 1.7903269389644265. Arrivals time: 0.06073636608198285 Scheduler time: 1.3258412634022534 Scheduler overhead time: 0.1304484773427248 Adapter cache time: 0.08080120896920562 Engine time: 0.12874447740614414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7348235389217734,
    "estimated_duration": 3599.6705710197994,
    "input_throughput": 1253.638884716481,
    "output_throughput": 1098.0974291989617,
    "total_throughput": 2351.7363139154427,
    "itl": 24.042974815050428,
    "ttft": 4009.7789103330992,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 29.844146918208065,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.00036738501908984724
}
#Debug simulation 
Total elapsed time: 1.7349244058132172. Arrivals time: 0.05814795522019267 Scheduler time: 1.2758114510215819 Scheduler overhead time: 0.13148351619020104 Adapter cache time: 0.07908061239868402 Engine time: 0.12675281008705497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.7271909397095442,
    "estimated_duration": 3599.659802617978,
    "input_throughput": 1253.6426349840035,
    "output_throughput": 1098.1007141633763,
    "total_throughput": 2351.74334914738,
    "itl": 24.034215287512815,
    "ttft": 4009.7420683467108,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9209,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.698644037350874,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.00037394449696017426
}
#Debug simulation 
Total elapsed time: 1.7272910489700735. Arrivals time: 0.05839086649939418 Scheduler time: 1.2666302332654595 Scheduler overhead time: 0.13157780189067125 Adapter cache time: 0.0790754510089755 Engine time: 0.12762483162805438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7805231809616089,
    "estimated_duration": 3599.666741960336,
    "input_throughput": 1253.6402182448824,
    "output_throughput": 1098.098597273857,
    "total_throughput": 2351.7388155187396,
    "itl": 24.047734212897744,
    "ttft": 4009.8500655735406,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9207,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.175690467338118,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.0003760456653716084
}
#Debug simulation 
Total elapsed time: 1.7806228958070278. Arrivals time: 0.058458649553358555 Scheduler time: 1.3184109409339726 Scheduler overhead time: 0.13063893979415298 Adapter cache time: 0.08011054154485464 Engine time: 0.1292722662910819 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.7807527435943484,
    "estimated_duration": 3599.6567905074853,
    "input_throughput": 1253.6436840034949,
    "output_throughput": 1098.101633028945,
    "total_throughput": 2351.7453170324397,
    "itl": 24.023369689140658,
    "ttft": 4009.36512966327,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9205,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.523412964572536,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.0003727039927072437
}
#Debug simulation 
Total elapsed time: 1.7808502255938947. Arrivals time: 0.058675407897681 Scheduler time: 1.3192620584741235 Scheduler overhead time: 0.13065663492307067 Adapter cache time: 0.08046336658298969 Engine time: 0.12814501952379942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.1-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 66, 1080, 66, 66, 1080, 540, 1080, 540, 1080, 1080, 540, 66, 1080, 540, 66, 66, 540, 1080, 66, 540, 66, 66, 540, 540, 540, 66, 66, 1080, 540, 540, 66, 1080, 1080, 540, 1080, 1080, 540, 1080, 66, 1080, 540, 540, 540, 1080, 1080, 66, 66, 540, 66, 1080, 66, 66, 1080, 66, 540, 540, 66, 540, 1080, 1080, 1080, 540, 1080, 1080, 66, 66, 1080, 540, 1080, 66, 540, 1080, 66, 1080, 540, 66, 1080, 66, 66, 1080, 66, 66, 540]
Prompts retrieved: 53952 . Total input tokens: 11961062 . Total output tokens: 10808170
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7394900498911738,
    "estimated_duration": 3599.667825833651,
    "input_throughput": 1253.6398407691693,
    "output_throughput": 1098.0982666323023,
    "total_throughput": 2351.7381074014716,
    "itl": 24.051023018964276,
    "ttft": 4009.9860712955906,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 9201,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 30.51380987275124,
    "arrivals": 18219,
    "finished_requests": 18199,
    "scheduler_time": 0.000369899688918925
}
#Debug simulation 
Total elapsed time: 1.7395922802388668. Arrivals time: 0.057284228038042784 Scheduler time: 1.277490645647049 Scheduler overhead time: 0.13158857496455312 Adapter cache time: 0.07933742459863424 Engine time: 0.12711467314511538 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.7405008501373231,
    "estimated_duration": 3599.9772637982323,
    "input_throughput": 1208.091796505233,
    "output_throughput": 1096.575536656293,
    "total_throughput": 2304.667333161526,
    "itl": 23.959497165191618,
    "ttft": 6513.447401966549,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8603,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.329376061055036,
    "arrivals": 17838,
    "finished_requests": 17806,
    "scheduler_time": 7.642761763077173e-05
}
#Debug simulation 
Total elapsed time: 1.7406037459149957. Arrivals time: 0.056581614539027214 Scheduler time: 1.2825511554256082 Scheduler overhead time: 0.1321578910574317 Adapter cache time: 0.07717132475227118 Engine time: 0.12752074282616377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7851781751960516,
    "estimated_duration": 3599.9751401905874,
    "input_throughput": 1208.0925091526474,
    "output_throughput": 1096.5761835208136,
    "total_throughput": 2304.668692673461,
    "itl": 23.973284890527708,
    "ttft": 6513.548619649481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.74037800804875,
    "arrivals": 17838,
    "finished_requests": 17806,
    "scheduler_time": 8.06102594779022e-05
}
#Debug simulation 
Total elapsed time: 1.785283996257931. Arrivals time: 0.05815966613590717 Scheduler time: 1.320436836220324 Scheduler overhead time: 0.13143611559644341 Adapter cache time: 0.07839421043172479 Engine time: 0.1323145804926753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7793328720144928,
    "estimated_duration": 3599.994897557533,
    "input_throughput": 1208.0858789413035,
    "output_throughput": 1096.5701653294943,
    "total_throughput": 2304.656044270798,
    "itl": 23.97299124163919,
    "ttft": 6513.501402365671,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8596,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 27.830114131905415,
    "arrivals": 17838,
    "finished_requests": 17806,
    "scheduler_time": 8.214039769007385e-05
}
#Debug simulation 
Total elapsed time: 1.7794389352202415. Arrivals time: 0.058602264150977135 Scheduler time: 1.317470075096935 Scheduler overhead time: 0.13051041681319475 Adapter cache time: 0.07820291817188263 Engine time: 0.13100986368954182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.711795796174556,
    "estimated_duration": 3599.988873579173,
    "input_throughput": 1208.0879004706603,
    "output_throughput": 1096.572000255984,
    "total_throughput": 2304.659900726644,
    "itl": 23.962484106017484,
    "ttft": 6513.354900816805,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8598,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 26.764262738416523,
    "arrivals": 17838,
    "finished_requests": 17806,
    "scheduler_time": 7.963843966299464e-05
}
#Debug simulation 
Total elapsed time: 1.7118961052037776. Arrivals time: 0.055297781713306904 Scheduler time: 1.2603648393414915 Scheduler overhead time: 0.13025281950831413 Adapter cache time: 0.07639559172093868 Engine time: 0.1258757165633142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7423123456537724,
    "estimated_duration": 3599.986350436527,
    "input_throughput": 1208.0887471900098,
    "output_throughput": 1096.5727688165584,
    "total_throughput": 2304.6615160065685,
    "itl": 23.975379370309486,
    "ttft": 6513.631762019424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8600,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.142056644632405,
    "arrivals": 17838,
    "finished_requests": 17806,
    "scheduler_time": 7.726160363979813e-05
}
#Debug simulation 
Total elapsed time: 1.7424161257222295. Arrivals time: 0.05564914923161268 Scheduler time: 1.2875929060392082 Scheduler overhead time: 0.1309713958762586 Adapter cache time: 0.07709194766357541 Engine time: 0.12745077582076192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.7683744886890054,
    "estimated_duration": 3599.9876783613718,
    "input_throughput": 1208.0883015631896,
    "output_throughput": 1096.5723643245565,
    "total_throughput": 2304.660665887746,
    "itl": 23.953290441207564,
    "ttft": 6513.192684934451,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8601,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 25.717422586452223,
    "arrivals": 17838,
    "finished_requests": 17806,
    "scheduler_time": 7.559363162174532e-05
}
#Debug simulation 
Total elapsed time: 1.7684839670546353. Arrivals time: 0.056397957261651754 Scheduler time: 1.3093736241571605 Scheduler overhead time: 0.13078564638271928 Adapter cache time: 0.07772827800363302 Engine time: 0.130310186650604 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.05-0.003125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 540, 1080, 540, 540, 540, 540, 1080, 540, 1080, 540, 33, 1080, 33, 33, 1080, 540, 1080, 540, 1080, 1080, 540, 33, 1080, 540, 33, 33, 540, 1080, 33, 540, 33, 33, 540, 540, 540, 33, 33, 1080, 540, 540, 33, 1080, 1080, 540, 1080, 1080, 540, 1080, 33, 1080, 540, 540, 540, 1080, 1080, 33, 33, 540, 33, 1080, 33, 33, 1080, 33, 540, 540, 33, 540, 1080, 1080, 1080, 540, 1080, 1080, 33, 33, 1080, 540, 1080, 33, 540, 1080, 33, 1080, 540, 33, 1080, 33, 33, 1080, 33, 33, 540]
Prompts retrieved: 52896 . Total input tokens: 11724235 . Total output tokens: 10607449
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.7540921620093286,
    "estimated_duration": 3599.989382273594,
    "input_throughput": 1208.087729762497,
    "output_throughput": 1096.5718453055106,
    "total_throughput": 2304.6595750680076,
    "itl": 23.979980441725846,
    "ttft": 6513.634679649131,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 8594,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 28.446931324375168,
    "arrivals": 17838,
    "finished_requests": 17806,
    "scheduler_time": 8.047242567202104e-05
}
#Debug simulation 
Total elapsed time: 1.7541985996067524. Arrivals time: 0.057532682083547115 Scheduler time: 1.2967920182272792 Scheduler overhead time: 0.1300905547104776 Adapter cache time: 0.07720698276534677 Engine time: 0.12900117319077253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.6231680270284414,
    "estimated_duration": 3599.998110179176,
    "input_throughput": 1096.0802976098253,
    "output_throughput": 992.1763541765375,
    "total_throughput": 2088.256651786363,
    "itl": 23.10194598844411,
    "ttft": 5632.529687030171,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7414,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.69045613351781,
    "arrivals": 16094,
    "finished_requests": 16069,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6232630419544876. Arrivals time: 0.05235278746113181 Scheduler time: 1.1676450688391924 Scheduler overhead time: 0.13426003651693463 Adapter cache time: 0.07211140869185328 Engine time: 0.13158084964379668 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.638428460340947,
    "estimated_duration": 3600.0131608327547,
    "input_throughput": 1096.0757152030071,
    "output_throughput": 992.172206163203,
    "total_throughput": 2088.24792136621,
    "itl": 23.115698627073115,
    "ttft": 5632.59233376552,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.04561743769153,
    "arrivals": 16094,
    "finished_requests": 16069,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.638529830146581. Arrivals time: 0.05409789690747857 Scheduler time: 1.178722485434264 Scheduler overhead time: 0.13495506020262837 Adapter cache time: 0.07272214023396373 Engine time: 0.13170580798760056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-8-32/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.6573717780411243,
    "estimated_duration": 3600.0184665809243,
    "input_throughput": 1096.074099794149,
    "output_throughput": 992.1707438885187,
    "total_throughput": 2088.244843682668,
    "itl": 23.115022880821456,
    "ttft": 5632.500123036182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7410,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.110895341578797,
    "arrivals": 16094,
    "finished_requests": 16069,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6574654998257756. Arrivals time: 0.05315942084416747 Scheduler time: 1.1976553951390088 Scheduler overhead time: 0.13458684459328651 Adapter cache time: 0.07308191480115056 Engine time: 0.13282479345798492 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-16/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.6538961920887232,
    "estimated_duration": 3600.021399328322,
    "input_throughput": 1096.073206880439,
    "output_throughput": 992.169935619388,
    "total_throughput": 2088.243142499827,
    "itl": 23.107536189524108,
    "ttft": 5632.403965182392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7409,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 23.111847251990273,
    "arrivals": 16094,
    "finished_requests": 16069,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6539990869350731. Arrivals time: 0.05403127707540989 Scheduler time: 1.192635256331414 Scheduler overhead time: 0.13375786505639553 Adapter cache time: 0.07301623420789838 Engine time: 0.1351856249384582 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_8-16-32/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.6220339480787516,
    "estimated_duration": 3600.0097090035233,
    "input_throughput": 1096.0767661630043,
    "output_throughput": 992.1731574964773,
    "total_throughput": 2088.2499236594817,
    "itl": 23.116809410828953,
    "ttft": 5632.5936100442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7412,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.40479849470679,
    "arrivals": 16094,
    "finished_requests": 16069,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6221326268278062. Arrivals time: 0.05330473463982344 Scheduler time: 1.1648000008426607 Scheduler overhead time: 0.1343412846326828 Adapter cache time: 0.07244200864806771 Engine time: 0.13195291394367814 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-16/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.6447432925924659,
    "estimated_duration": 3600.018181319802,
    "input_throughput": 1096.074186645746,
    "output_throughput": 992.1708225069383,
    "total_throughput": 2088.2450091526844,
    "itl": 23.09786011195327,
    "ttft": 5632.429801998605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7413,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.16524283610962,
    "arrivals": 16094,
    "finished_requests": 16069,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.644841490779072. Arrivals time: 0.05305610550567508 Scheduler time: 1.185852896887809 Scheduler overhead time: 0.13502753991633654 Adapter cache time: 0.07315026316791773 Engine time: 0.13229536917060614 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.0125_size_16-16-32/adapters_96_slots_32_rate_0.1-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.1   ]. Counts: [32 32 32]
Adapter prompts. [135, 135, 135, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 135, 1080, 135, 135, 1080, 270, 1080, 270, 1080, 1080, 270, 135, 1080, 270, 135, 135, 270, 1080, 135, 270, 135, 135, 270, 270, 270, 135, 135, 1080, 270, 270, 135, 1080, 1080, 270, 1080, 1080, 270, 1080, 135, 1080, 270, 270, 270, 1080, 1080, 135, 135, 270, 135, 1080, 135, 135, 1080, 135, 270, 270, 135, 270, 1080, 1080, 1080, 270, 1080, 1080, 135, 135, 1080, 270, 1080, 135, 270, 1080, 135, 1080, 270, 135, 1080, 135, 135, 1080, 135, 135, 270]
Prompts retrieved: 47520 . Total input tokens: 10522237 . Total output tokens: 9530691
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.65832488425076,
    "estimated_duration": 3600.0192622218888,
    "input_throughput": 1096.073857550597,
    "output_throughput": 992.1705246086676,
    "total_throughput": 2088.2443821592647,
    "itl": 23.120011277385075,
    "ttft": 5632.616704981161,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 7415,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 24.709073187967586,
    "arrivals": 16094,
    "finished_requests": 16069,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.658424959052354. Arrivals time: 0.054512311704456806 Scheduler time: 1.1981743043288589 Scheduler overhead time: 0.1349620190449059 Adapter cache time: 0.07302104728296399 Engine time: 0.1322405063547194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-8/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5827459851279855,
    "estimated_duration": 3599.7265550613956,
    "input_throughput": 1059.586038455342,
    "output_throughput": 919.5648473203385,
    "total_throughput": 1979.1508857756805,
    "itl": 22.49875250258052,
    "ttft": 6130.404640020241,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6656,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.370606423616028,
    "arrivals": 15365,
    "finished_requests": 15339,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5828427742235363. Arrivals time: 0.051220251712948084 Scheduler time: 1.1206601061858237 Scheduler overhead time: 0.13688185065984726 Adapter cache time: 0.07063044561073184 Engine time: 0.13590190978720784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-16/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5616602138616145,
    "estimated_duration": 3599.7245526136335,
    "input_throughput": 1059.5866278797996,
    "output_throughput": 919.5653588540804,
    "total_throughput": 1979.15198673388,
    "itl": 22.507716125479607,
    "ttft": 6130.433936576473,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6652,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.509486403986,
    "arrivals": 15365,
    "finished_requests": 15339,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5617553601041436. Arrivals time: 0.051614079624414444 Scheduler time: 1.1005747374147177 Scheduler overhead time: 0.1368655883707106 Adapter cache time: 0.0699529848061502 Engine time: 0.13620527368038893 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-8-32/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.558392179198563,
    "estimated_duration": 3599.743715156859,
    "input_throughput": 1059.5809873742069,
    "output_throughput": 919.5604637247791,
    "total_throughput": 1979.141451098986,
    "itl": 22.508441958555604,
    "ttft": 6130.45937250154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6651,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.578618436455184,
    "arrivals": 15365,
    "finished_requests": 15339,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.558488239068538. Arrivals time: 0.051599277183413506 Scheduler time: 1.0994243896566331 Scheduler overhead time: 0.1367523306980729 Adapter cache time: 0.07010214170441031 Engine time: 0.13382151443511248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-16/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [32 64]
---Simulation End---
#Simulation results
{
    "duration": 1.5789505210705101,
    "estimated_duration": 3599.723956500343,
    "input_throughput": 1059.5868033470517,
    "output_throughput": 919.5655111338493,
    "total_throughput": 1979.1523144809012,
    "itl": 22.5009302780647,
    "ttft": 6130.4034529317005,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 20.75343623568519,
    "arrivals": 15365,
    "finished_requests": 15339,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5790489981882274. Arrivals time: 0.050983942579478025 Scheduler time: 1.1186796450056136 Scheduler overhead time: 0.13703260943293571 Adapter cache time: 0.07041194988414645 Engine time: 0.1347808870486915 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_8-16-32/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [32 32 32]
---Simulation End---
#Simulation results
{
    "duration": 1.58308215579018,
    "estimated_duration": 3599.7468270930735,
    "input_throughput": 1059.5800713796646,
    "output_throughput": 919.5596687762323,
    "total_throughput": 1979.139740155897,
    "itl": 22.50935724302403,
    "ttft": 6130.365857521625,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6654,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 21.82388030221573,
    "arrivals": 15365,
    "finished_requests": 15339,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5831841640174389. Arrivals time: 0.052473786752671 Scheduler time: 1.1216844446025789 Scheduler overhead time: 0.13741303235292435 Adapter cache time: 0.07057642145082355 Engine time: 0.13423309428617358 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-16/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [16]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5485768429934978,
    "estimated_duration": 3599.740628093446,
    "input_throughput": 1059.5818960490355,
    "output_throughput": 919.561252320891,
    "total_throughput": 1979.1431483699266,
    "itl": 22.494137011406398,
    "ttft": 6130.263570858156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6647,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.874864310215315,
    "arrivals": 15365,
    "finished_requests": 15339,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.548678144812584. Arrivals time: 0.05162478517740965 Scheduler time: 1.0883784820325673 Scheduler overhead time: 0.1370871840044856 Adapter cache time: 0.06961135007441044 Engine time: 0.13532623928040266 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.00625_size_16-16-32/adapters_96_slots_32_rate_0.1-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.1    ]. Counts: [32 32 32]
Adapter prompts. [66, 66, 66, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 66, 1080, 66, 66, 1080, 270, 1080, 270, 1080, 1080, 270, 66, 1080, 270, 66, 66, 270, 1080, 66, 270, 66, 66, 270, 270, 270, 66, 66, 1080, 270, 270, 66, 1080, 1080, 270, 1080, 1080, 270, 1080, 66, 1080, 270, 270, 270, 1080, 1080, 66, 66, 270, 66, 1080, 66, 66, 1080, 66, 270, 270, 66, 270, 1080, 1080, 1080, 270, 1080, 1080, 66, 66, 1080, 270, 1080, 66, 270, 1080, 66, 1080, 270, 66, 1080, 66, 66, 1080, 66, 66, 270]
Prompts retrieved: 45312 . Total input tokens: 10028328 . Total output tokens: 9089061
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.571305010933429,
    "estimated_duration": 3599.739480328547,
    "input_throughput": 1059.582233893181,
    "output_throughput": 919.5615455199221,
    "total_throughput": 1979.1437794131032,
    "itl": 22.511356671153532,
    "ttft": 6130.44818098987,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 6653,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 22.08479398105113,
    "arrivals": 15365,
    "finished_requests": 15339,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5714056589640677. Arrivals time: 0.05218694964423776 Scheduler time: 1.108309797476977 Scheduler overhead time: 0.13663123780861497 Adapter cache time: 0.07014156831428409 Engine time: 0.1377033945173025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-8/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [8]. Counts: [96]
---Simulation End---
#Simulation results
{
    "duration": 1.5720542850904167,
    "estimated_duration": 3599.750538226439,
    "input_throughput": 1021.1677061964142,
    "output_throughput": 912.4943423491686,
    "total_throughput": 1933.6620485455828,
    "itl": 22.403939220581876,
    "ttft": 6516.784922850396,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5932,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 18.154813297007994,
    "arrivals": 15003,
    "finished_requests": 14976,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5721502308733761. Arrivals time: 0.05015107477083802 Scheduler time: 1.1142129395157099 Scheduler overhead time: 0.13723868038505316 Adapter cache time: 0.06800638837739825 Engine time: 0.13560798345133662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 32,
    "served_adapters": 96,
    "served_adapters_rates": [
        0.1,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.025-0.003125_size_8-8-16/adapters_96_slots_32_rate_0.1-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.1     ]. Counts: [32 32 32]
Adapter prompts. [33, 33, 33, 270, 1080, 270, 270, 270, 270, 1080, 270, 1080, 270, 33, 1080, 33, 33, 1080, 270, 1080, 270, 1080, 1080, 270, 33, 1080, 270, 33, 33, 270, 1080, 33, 270, 33, 33, 270, 270, 270, 33, 33, 1080, 270, 270, 33, 1080, 1080, 270, 1080, 1080, 270, 1080, 33, 1080, 270, 270, 270, 1080, 1080, 33, 33, 270, 33, 1080, 33, 33, 1080, 33, 270, 270, 33, 270, 1080, 1080, 1080, 270, 1080, 1080, 33, 33, 1080, 270, 1080, 33, 270, 1080, 33, 1080, 270, 33, 1080, 33, 33, 1080, 33, 33, 270]
Prompts retrieved: 44256 . Total input tokens: 9790606 . Total output tokens: 8891185
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [64 32]
---Simulation End---
#Simulation results
{
    "duration": 1.5621181828901172,
    "estimated_duration": 3599.7665826912657,
    "input_throughput": 1021.1631547653789,
    "output_throughput": 912.4902752845286,
    "total_throughput": 1933.6534300499075,
    "itl": 22.41168065176512,
    "ttft": 6516.95180379386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 5931,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 19.14527652895781,
    "arrivals": 15003,
    "finished_requests": 14976,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5622581909410655. Arrivals time: 0.05018172785639763 Scheduler time: 1.107183972839266 Scheduler overhead time: 0.13665866618975997 Adapter cache time: 0.06709793768823147 Engine time: 0.13430937565863132 
