INFO 06-01 00:46:58 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:46:58 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 17280, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109410 . Total input tokens: 24332555 . Total output tokens: 21885352
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.868501608725637,
    "estimated_duration": 3600.0250202953544,
    "input_throughput": 2522.4671908682953,
    "output_throughput": 2226.394804151229,
    "total_throughput": 4748.861995019524,
    "itl": 23.45485376406386,
    "ttft": 6416.374981854237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 36691,
    "finished_requests": 36626,
    "scheduler_time": 5.310319943233372
}
#Debug simulation 
Total elapsed time: 2.8686169809661806. Arrivals time: 0.09809772251173854 Scheduler time: 2.399572765920311 Scheduler overhead time: 0.1397234220057726 Adapter cache time: 0.0252910228446126 Engine time: 0.13787798443809152 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 17280, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109410 . Total input tokens: 24332555 . Total output tokens: 21885352
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.850578465964645,
    "estimated_duration": 3600.014851417922,
    "input_throughput": 2522.4743160221487,
    "output_throughput": 2226.401092996363,
    "total_throughput": 4748.875409018512,
    "itl": 23.454736007803753,
    "ttft": 6318.429270466921,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 36691,
    "finished_requests": 36626,
    "scheduler_time": 5.310415768299453
}
#Debug simulation 
Total elapsed time: 2.8506934703327715. Arrivals time: 0.09844129113480449 Scheduler time: 2.386311843059957 Scheduler overhead time: 0.1403770330362022 Adapter cache time: 0.02533817756921053 Engine time: 0.13217187719419599 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     1.6    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 17280, 66, 17280, 66, 1080, 1080, 66, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109410 . Total input tokens: 24332555 . Total output tokens: 21885352
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8371935877949,
    "estimated_duration": 3600.0257778005825,
    "input_throughput": 2522.4666600992946,
    "output_throughput": 2226.3943356807767,
    "total_throughput": 4748.860995780071,
    "itl": 23.45481598712717,
    "ttft": 6416.326848151536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 36691,
    "finished_requests": 36626,
    "scheduler_time": 5.310205729500204
}
#Debug simulation 
Total elapsed time: 2.8372883261181414. Arrivals time: 0.09747075894847512 Scheduler time: 2.373715355526656 Scheduler overhead time: 0.1406840975396335 Adapter cache time: 0.025329608470201492 Engine time: 0.13244692562147975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 17280, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109245 . Total input tokens: 24298321 . Total output tokens: 21853164
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8279890441335738,
    "estimated_duration": 3599.9018134929443,
    "input_throughput": 2505.073601229673,
    "output_throughput": 2240.5847208854184,
    "total_throughput": 4745.658322115091,
    "itl": 23.48015907815181,
    "ttft": 5444.744041502997,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 36626,
    "finished_requests": 36571,
    "scheduler_time": 5.4358269705103535
}
#Debug simulation 
Total elapsed time: 2.8280802951194346. Arrivals time: 0.09706326248124242 Scheduler time: 2.365846216212958 Scheduler overhead time: 0.1391976522281766 Adapter cache time: 0.0248551438562572 Engine time: 0.13437117962166667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 17280, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109245 . Total input tokens: 24298321 . Total output tokens: 21853164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8475366663187742,
    "estimated_duration": 3599.9043933853454,
    "input_throughput": 2505.0718059541205,
    "output_throughput": 2240.583115157359,
    "total_throughput": 4745.65492111148,
    "itl": 23.480181240717396,
    "ttft": 5444.738514043813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 36626,
    "finished_requests": 36571,
    "scheduler_time": 5.435999687904096
}
#Debug simulation 
Total elapsed time: 2.8476349343545735. Arrivals time: 0.09992071380838752 Scheduler time: 2.382178342435509 Scheduler overhead time: 0.13954446790739894 Adapter cache time: 0.024966293014585972 Engine time: 0.1332854381762445 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 17280, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109245 . Total input tokens: 24298321 . Total output tokens: 21853164
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8503661691211164,
    "estimated_duration": 3599.904457694084,
    "input_throughput": 2505.071761203486,
    "output_throughput": 2240.583075131554,
    "total_throughput": 4745.65483633504,
    "itl": 23.480180909060287,
    "ttft": 5444.74758287141,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 36626,
    "finished_requests": 36571,
    "scheduler_time": 5.435984342657936
}
#Debug simulation 
Total elapsed time: 2.8504632841795683. Arrivals time: 0.09835378220304847 Scheduler time: 2.385778384283185 Scheduler overhead time: 0.13981007924303412 Adapter cache time: 0.024819208774715662 Engine time: 0.134150386787951 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 17280, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109245 . Total input tokens: 24298321 . Total output tokens: 21853164
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.841035094112158,
    "estimated_duration": 3599.902381087836,
    "input_throughput": 2505.0732062559127,
    "output_throughput": 2240.5843676134937,
    "total_throughput": 4745.657573869406,
    "itl": 23.480149186354918,
    "ttft": 5444.742947674763,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 36626,
    "finished_requests": 36571,
    "scheduler_time": 5.435863498904723
}
#Debug simulation 
Total elapsed time: 2.84114434896037. Arrivals time: 0.09756440948694944 Scheduler time: 2.377351079136133 Scheduler overhead time: 0.13905986258760095 Adapter cache time: 0.024791272822767496 Engine time: 0.13470938615500927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 17280, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109245 . Total input tokens: 24298321 . Total output tokens: 21853164
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.8377585960552096,
    "estimated_duration": 3599.9044024010004,
    "input_throughput": 2505.071799680381,
    "output_throughput": 2240.583109546009,
    "total_throughput": 4745.6549092263895,
    "itl": 23.48017837081003,
    "ttft": 5444.749590391245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 36626,
    "finished_requests": 36571,
    "scheduler_time": 5.435970540261796
}
#Debug simulation 
Total elapsed time: 2.8378492454066873. Arrivals time: 0.09841311536729336 Scheduler time: 2.3737390539608896 Scheduler overhead time: 0.13966990122571588 Adapter cache time: 0.02514123870059848 Engine time: 0.1332415617071092 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 17280, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109245 . Total input tokens: 24298321 . Total output tokens: 21853164
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.830238997004926,
    "estimated_duration": 3599.8998614066763,
    "input_throughput": 2505.0749596340634,
    "output_throughput": 2240.585935867733,
    "total_throughput": 4745.660895501796,
    "itl": 23.480102947504808,
    "ttft": 5444.7968306014545,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 36626,
    "finished_requests": 36571,
    "scheduler_time": 5.435645329514502
}
#Debug simulation 
Total elapsed time: 2.830345876980573. Arrivals time: 0.09841612912714481 Scheduler time: 2.3665802204050124 Scheduler overhead time: 0.13903366029262543 Adapter cache time: 0.025042031891644 Engine time: 0.13368770154193044 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.1-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      1.6     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 17280, 33, 17280, 33, 1080, 1080, 33, 1080, 17280, 17280, 17280, 17280]
Prompts retrieved: 109245 . Total input tokens: 24298321 . Total output tokens: 21853164
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.825493976008147,
    "estimated_duration": 3599.90562849896,
    "input_throughput": 2505.0709464737306,
    "output_throughput": 2240.58234642201,
    "total_throughput": 4745.65329289574,
    "itl": 23.48015156386682,
    "ttft": 5444.73186034392,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 36626,
    "finished_requests": 36571,
    "scheduler_time": 5.435875841704803
}
#Debug simulation 
Total elapsed time: 2.8255931166931987. Arrivals time: 0.0964950225315988 Scheduler time: 2.365647255908698 Scheduler overhead time: 0.13990712817758322 Adapter cache time: 0.024860113859176636 Engine time: 0.1314185606315732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 17280, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107730 . Total input tokens: 23963882 . Total output tokens: 21546319
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8180253417231143,
    "estimated_duration": 3599.9266270735757,
    "input_throughput": 2474.4568217050887,
    "output_throughput": 2218.252988809261,
    "total_throughput": 4692.70981051435,
    "itl": 23.32491329310301,
    "ttft": 4522.774276651799,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 36126,
    "finished_requests": 36081,
    "scheduler_time": 5.04820043919254
}
#Debug simulation 
Total elapsed time: 2.818133757915348. Arrivals time: 0.09781177062541246 Scheduler time: 2.351755395065993 Scheduler overhead time: 0.14221154432743788 Adapter cache time: 0.025279511231929064 Engine time: 0.1328159961849451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 17280, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107730 . Total input tokens: 23963882 . Total output tokens: 21546319
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8078579790890217,
    "estimated_duration": 3599.930503929243,
    "input_throughput": 2474.454156900326,
    "output_throughput": 2218.2505999168466,
    "total_throughput": 4692.704756817173,
    "itl": 23.324913399109107,
    "ttft": 4522.798210213306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 36126,
    "finished_requests": 36081,
    "scheduler_time": 5.048108492837643
}
#Debug simulation 
Total elapsed time: 2.8079543048515916. Arrivals time: 0.09479148918762803 Scheduler time: 2.3474747966974974 Scheduler overhead time: 0.14008565619587898 Adapter cache time: 0.02504033036530018 Engine time: 0.13325128518044949 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 17280, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107730 . Total input tokens: 23963882 . Total output tokens: 21546319
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.82411418389529,
    "estimated_duration": 3599.9308409183677,
    "input_throughput": 2474.453925266948,
    "output_throughput": 2218.2503922666556,
    "total_throughput": 4692.704317533604,
    "itl": 23.324909588654,
    "ttft": 4522.783135106505,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 36126,
    "finished_requests": 36081,
    "scheduler_time": 5.04815773939814
}
#Debug simulation 
Total elapsed time: 2.8242063028737903. Arrivals time: 0.09597832523286343 Scheduler time: 2.359230392612517 Scheduler overhead time: 0.14032247848808765 Adapter cache time: 0.024959140457212925 Engine time: 0.13620761083438993 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 17280, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107730 . Total input tokens: 23963882 . Total output tokens: 21546319
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.861292320303619,
    "estimated_duration": 3599.9271964572717,
    "input_throughput": 2474.456430331793,
    "output_throughput": 2218.2526379585306,
    "total_throughput": 4692.709068290324,
    "itl": 23.324920852350274,
    "ttft": 4522.796904803512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 36126,
    "finished_requests": 36081,
    "scheduler_time": 5.0482084036866235
}
#Debug simulation 
Total elapsed time: 2.861386434175074. Arrivals time: 0.09715374978259206 Scheduler time: 2.3931014058180153 Scheduler overhead time: 0.14092960488051176 Adapter cache time: 0.025342067703604698 Engine time: 0.13669320149347186 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_1.6-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 17280, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107730 . Total input tokens: 23963882 . Total output tokens: 21546319
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.8726423610933125,
    "estimated_duration": 3599.9318292640437,
    "input_throughput": 2474.453245916351,
    "output_throughput": 2218.249783255628,
    "total_throughput": 4692.703029171978,
    "itl": 23.324947117676473,
    "ttft": 4522.8304149954,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 36126,
    "finished_requests": 36081,
    "scheduler_time": 5.0481535694681146
}
#Debug simulation 
Total elapsed time: 2.8727355021983385. Arrivals time: 0.09797335183247924 Scheduler time: 2.4064549985341728 Scheduler overhead time: 0.1408556066453457 Adapter cache time: 0.025125876534730196 Engine time: 0.1342989895492792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_1.6-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_1.6-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 17280, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107730 . Total input tokens: 23963882 . Total output tokens: 21546319
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8776663169264793,
    "estimated_duration": 3599.9235997825085,
    "input_throughput": 2474.4589025550913,
    "output_throughput": 2218.2548542092536,
    "total_throughput": 4692.713756764345,
    "itl": 23.324929749950147,
    "ttft": 4522.825603093508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 36126,
    "finished_requests": 36081,
    "scheduler_time": 5.048263488149177
}
#Debug simulation 
Total elapsed time: 2.8777734441682696. Arrivals time: 0.10003579640761018 Scheduler time: 2.4073067596182227 Scheduler overhead time: 0.139904479496181 Adapter cache time: 0.025209311861544847 Engine time: 0.13706780457869172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_1.6-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_1.6-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  1.6  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 17280, 270, 17280, 270, 540, 540, 270, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107730 . Total input tokens: 23963882 . Total output tokens: 21546319
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.870667810086161,
    "estimated_duration": 3599.931872552251,
    "input_throughput": 2474.45321616172,
    "output_throughput": 2218.249756581774,
    "total_throughput": 4692.702972743494,
    "itl": 23.324950441778814,
    "ttft": 4522.83686478986,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 36126,
    "finished_requests": 36081,
    "scheduler_time": 5.04807100533527
}
#Debug simulation 
Total elapsed time: 2.8707697298377752. Arrivals time: 0.09722951101139188 Scheduler time: 2.4041483215987682 Scheduler overhead time: 0.14039330836385489 Adapter cache time: 0.02508195536211133 Engine time: 0.13609990058466792 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 17280, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107055 . Total input tokens: 23818726 . Total output tokens: 21412493
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8277977309189737,
    "estimated_duration": 3599.693444015943,
    "input_throughput": 2459.912528029368,
    "output_throughput": 2207.7529999704057,
    "total_throughput": 4667.665527999774,
    "itl": 23.195356529556943,
    "ttft": 3746.9028390087124,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 35918,
    "finished_requests": 35881,
    "scheduler_time": 4.739526131601537
}
#Debug simulation 
Total elapsed time: 2.8279043417423964. Arrivals time: 0.09577576909214258 Scheduler time: 2.363608821760863 Scheduler overhead time: 0.1407610299065709 Adapter cache time: 0.0249224747531116 Engine time: 0.13455600244924426 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 17280, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107055 . Total input tokens: 23818726 . Total output tokens: 21412493
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8663871390745044,
    "estimated_duration": 3599.698072097779,
    "input_throughput": 2459.909365353982,
    "output_throughput": 2207.7501614930243,
    "total_throughput": 4667.659526847006,
    "itl": 23.195455826822197,
    "ttft": 3746.79566984916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 35918,
    "finished_requests": 35881,
    "scheduler_time": 4.73957279295001
}
#Debug simulation 
Total elapsed time: 2.866482096724212. Arrivals time: 0.09914226178079844 Scheduler time: 2.393018345348537 Scheduler overhead time: 0.142664207611233 Adapter cache time: 0.024849922861903906 Engine time: 0.13794555701315403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 17280, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107055 . Total input tokens: 23818726 . Total output tokens: 21412493
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.858541475608945,
    "estimated_duration": 3599.6981764533984,
    "input_throughput": 2459.9092940409573,
    "output_throughput": 2207.750097490121,
    "total_throughput": 4667.659391531078,
    "itl": 23.19544771612131,
    "ttft": 3746.798854595913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 35918,
    "finished_requests": 35881,
    "scheduler_time": 4.739564828455932
}
#Debug simulation 
Total elapsed time: 2.858637780882418. Arrivals time: 0.0966002568602562 Scheduler time: 2.3910983628593385 Scheduler overhead time: 0.14110434195026755 Adapter cache time: 0.024770415388047695 Engine time: 0.1368213198147714 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 17280, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107055 . Total input tokens: 23818726 . Total output tokens: 21412493
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.817527923732996,
    "estimated_duration": 3599.694421199769,
    "input_throughput": 2459.9118602541475,
    "output_throughput": 2207.752400647166,
    "total_throughput": 4667.664260901313,
    "itl": 23.195421622850077,
    "ttft": 3746.8634357624824,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 35918,
    "finished_requests": 35881,
    "scheduler_time": 4.739583592900128
}
#Debug simulation 
Total elapsed time: 2.8176207351498306. Arrivals time: 0.09723444143310189 Scheduler time: 2.3513373862951994 Scheduler overhead time: 0.14239481324329972 Adapter cache time: 0.02474860893562436 Engine time: 0.1335459053516388 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 17280, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107055 . Total input tokens: 23818726 . Total output tokens: 21412493
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.829357726033777,
    "estimated_duration": 3599.700263928537,
    "input_throughput": 2459.9078675334376,
    "output_throughput": 2207.7488172103467,
    "total_throughput": 4667.656684743784,
    "itl": 23.195414460640407,
    "ttft": 3746.82136435423,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 35918,
    "finished_requests": 35881,
    "scheduler_time": 4.7394302655605705
}
#Debug simulation 
Total elapsed time: 2.8294480089098215. Arrivals time: 0.09668190125375986 Scheduler time: 2.3631692524068058 Scheduler overhead time: 0.14098523650318384 Adapter cache time: 0.02472581621259451 Engine time: 0.13559434469789267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 17280, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107055 . Total input tokens: 23818726 . Total output tokens: 21412493
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8568266490474343,
    "estimated_duration": 3599.693427705001,
    "input_throughput": 2459.912539175731,
    "output_throughput": 2207.753009974183,
    "total_throughput": 4667.665549149914,
    "itl": 23.195359845107667,
    "ttft": 3746.906813707286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 35918,
    "finished_requests": 35881,
    "scheduler_time": 4.739497943067253
}
#Debug simulation 
Total elapsed time: 2.8569257790222764. Arrivals time: 0.096646957565099 Scheduler time: 2.391831972170621 Scheduler overhead time: 0.14091236516833305 Adapter cache time: 0.024853146634995937 Engine time: 0.13424337469041348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   1.6   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 17280, 135, 17280, 135, 540, 540, 135, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 107055 . Total input tokens: 23818726 . Total output tokens: 21412493
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8735283208079636,
    "estimated_duration": 3599.700353985126,
    "input_throughput": 2459.9078059919507,
    "output_throughput": 2207.7487619773246,
    "total_throughput": 4667.656567969276,
    "itl": 23.195423050944054,
    "ttft": 3746.8292656299536,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 35918,
    "finished_requests": 35881,
    "scheduler_time": 4.739422175944485
}
#Debug simulation 
Total elapsed time: 2.873624400701374. Arrivals time: 0.09789342014119029 Scheduler time: 2.403986945748329 Scheduler overhead time: 0.14370414707809687 Adapter cache time: 0.024867022410035133 Engine time: 0.13438563887029886 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 17280, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106710 . Total input tokens: 23745496 . Total output tokens: 21335776
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.825059770140797,
    "estimated_duration": 3599.9586847917217,
    "input_throughput": 2462.0232552787716,
    "output_throughput": 2170.2321287756704,
    "total_throughput": 4632.2553840544415,
    "itl": 23.03853562797856,
    "ttft": 6475.085436468562,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 35793,
    "finished_requests": 35729,
    "scheduler_time": 4.190253182388833
}
#Debug simulation 
Total elapsed time: 2.8251521582715213. Arrivals time: 0.09759883116930723 Scheduler time: 2.35513670835644 Scheduler overhead time: 0.14113016333431005 Adapter cache time: 0.02459601452574134 Engine time: 0.1384472488425672 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 17280, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106710 . Total input tokens: 23745496 . Total output tokens: 21335776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.824722019955516,
    "estimated_duration": 3599.9627457682454,
    "input_throughput": 2462.0204779670753,
    "output_throughput": 2170.2296806220784,
    "total_throughput": 4632.250158589153,
    "itl": 23.038508055828686,
    "ttft": 6475.0944718422525,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 35793,
    "finished_requests": 35729,
    "scheduler_time": 4.190222116530522
}
#Debug simulation 
Total elapsed time: 2.8248158618807793. Arrivals time: 0.09771922091022134 Scheduler time: 2.354915907140821 Scheduler overhead time: 0.1422880901955068 Adapter cache time: 0.024712592363357544 Engine time: 0.13681090530008078 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 17280, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106710 . Total input tokens: 23745496 . Total output tokens: 21335776
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8330036937259138,
    "estimated_duration": 3599.9628994259465,
    "input_throughput": 2462.0203728803235,
    "output_throughput": 2170.229587989873,
    "total_throughput": 4632.249960870196,
    "itl": 23.03851142594116,
    "ttft": 6475.092928696288,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 35793,
    "finished_requests": 35729,
    "scheduler_time": 4.190209148120384
}
#Debug simulation 
Total elapsed time: 2.8330997680313885. Arrivals time: 0.09718794841319323 Scheduler time: 2.363040430471301 Scheduler overhead time: 0.1419859449379146 Adapter cache time: 0.024771653581410646 Engine time: 0.13749212073162198 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 17280, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106710 . Total input tokens: 23745496 . Total output tokens: 21335776
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.830071061849594,
    "estimated_duration": 3599.9597483050065,
    "input_throughput": 2462.0225279388505,
    "output_throughput": 2170.2314876377513,
    "total_throughput": 4632.254015576602,
    "itl": 23.038545792808414,
    "ttft": 6475.096877426442,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 35793,
    "finished_requests": 35729,
    "scheduler_time": 4.1903112274294285
}
#Debug simulation 
Total elapsed time: 2.8301711259409785. Arrivals time: 0.0963905188255012 Scheduler time: 2.360718511044979 Scheduler overhead time: 0.14295566780492663 Adapter cache time: 0.024593709502369165 Engine time: 0.13657000847160816 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 17280, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106710 . Total input tokens: 23745496 . Total output tokens: 21335776
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.795080355834216,
    "estimated_duration": 3599.963360149879,
    "input_throughput": 2462.020057790531,
    "output_throughput": 2170.2293102435156,
    "total_throughput": 4632.249368034047,
    "itl": 23.03843489975309,
    "ttft": 6475.0962003969535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 35793,
    "finished_requests": 35729,
    "scheduler_time": 4.190269695118999
}
#Debug simulation 
Total elapsed time: 2.795183353126049. Arrivals time: 0.09748830553144217 Scheduler time: 2.3271871455945075 Scheduler overhead time: 0.14117116434499621 Adapter cache time: 0.024445087183266878 Engine time: 0.1363341067917645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 17280, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106710 . Total input tokens: 23745496 . Total output tokens: 21335776
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8030659472569823,
    "estimated_duration": 3599.9573831404846,
    "input_throughput": 2462.0241454825364,
    "output_throughput": 2170.2329134753304,
    "total_throughput": 4632.257058957867,
    "itl": 23.03853488772743,
    "ttft": 6475.108480514356,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 35793,
    "finished_requests": 35729,
    "scheduler_time": 4.190204769814331
}
#Debug simulation 
Total elapsed time: 2.8031612168997526. Arrivals time: 0.09482721285894513 Scheduler time: 2.337067517451942 Scheduler overhead time: 0.14233397413045168 Adapter cache time: 0.024850433226674795 Engine time: 0.13492815988138318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    1.6    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 17280, 66, 17280, 66, 540, 540, 66, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106710 . Total input tokens: 23745496 . Total output tokens: 21335776
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.839466862846166,
    "estimated_duration": 3599.9650626299026,
    "input_throughput": 2462.0188934625744,
    "output_throughput": 2170.228283907986,
    "total_throughput": 4632.247177370561,
    "itl": 23.038511602409837,
    "ttft": 6475.054054418478,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 35793,
    "finished_requests": 35729,
    "scheduler_time": 4.19026565031096
}
#Debug simulation 
Total elapsed time: 2.839559788815677. Arrivals time: 0.09973154496401548 Scheduler time: 2.365702932700515 Scheduler overhead time: 0.14174829609692097 Adapter cache time: 0.024769258685410023 Engine time: 0.1384888025932014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 17280, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106545 . Total input tokens: 23705951 . Total output tokens: 21305582
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8240503589622676,
    "estimated_duration": 3599.9070816167086,
    "input_throughput": 2460.433505417644,
    "output_throughput": 2176.870075346677,
    "total_throughput": 4637.303580764321,
    "itl": 23.065250089514688,
    "ttft": 5276.064691762178,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 35739,
    "finished_requests": 35687,
    "scheduler_time": 4.300814340754256
}
#Debug simulation 
Total elapsed time: 2.82414080016315. Arrivals time: 0.09661122830584645 Scheduler time: 2.357090533245355 Scheduler overhead time: 0.1420346898958087 Adapter cache time: 0.024296673480421305 Engine time: 0.13493449380621314 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 17280, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106545 . Total input tokens: 23705951 . Total output tokens: 21305582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8029034077189863,
    "estimated_duration": 3599.887352610603,
    "input_throughput": 2460.4469897028166,
    "output_throughput": 2176.882005576376,
    "total_throughput": 4637.328995279192,
    "itl": 23.065371471461326,
    "ttft": 5276.051993598535,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 35739,
    "finished_requests": 35687,
    "scheduler_time": 4.300866464638813
}
#Debug simulation 
Total elapsed time: 2.802996183745563. Arrivals time: 0.09266388276591897 Scheduler time: 2.34164308803156 Scheduler overhead time: 0.14157619420439005 Adapter cache time: 0.024432980455458164 Engine time: 0.13453613128513098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 17280, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106545 . Total input tokens: 23705951 . Total output tokens: 21305582
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8083488098345697,
    "estimated_duration": 3599.8874208736947,
    "input_throughput": 2460.4469430464355,
    "output_throughput": 2176.881964297114,
    "total_throughput": 4637.32890734355,
    "itl": 23.065372596786037,
    "ttft": 5276.050880209903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 35739,
    "finished_requests": 35687,
    "scheduler_time": 4.30085670705071
}
#Debug simulation 
Total elapsed time: 2.808423412963748. Arrivals time: 0.0904373717494309 Scheduler time: 2.347087385132909 Scheduler overhead time: 0.1412528925575316 Adapter cache time: 0.02453793352469802 Engine time: 0.13657531887292862 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 17280, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106545 . Total input tokens: 23705951 . Total output tokens: 21305582
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.851737244054675,
    "estimated_duration": 3599.8846200573603,
    "input_throughput": 2460.4488573466747,
    "output_throughput": 2176.883657975442,
    "total_throughput": 4637.332515322117,
    "itl": 23.065310364067724,
    "ttft": 5276.057903241948,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 35739,
    "finished_requests": 35687,
    "scheduler_time": 4.3008583750227185
}
#Debug simulation 
Total elapsed time: 2.851830217987299. Arrivals time: 0.0940769906155765 Scheduler time: 2.382646224461496 Scheduler overhead time: 0.1431531310081482 Adapter cache time: 0.0246706735342741 Engine time: 0.13831101078540087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 17280, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106545 . Total input tokens: 23705951 . Total output tokens: 21305582
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.847071235999465,
    "estimated_duration": 3599.8875570642754,
    "input_throughput": 2460.4468499630566,
    "output_throughput": 2176.8818819415364,
    "total_throughput": 4637.328731904593,
    "itl": 23.065413501696824,
    "ttft": 5276.094754052394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 35739,
    "finished_requests": 35687,
    "scheduler_time": 4.300800079738132
}
#Debug simulation 
Total elapsed time: 2.8472006171941757. Arrivals time: 0.09686500253155828 Scheduler time: 2.379559790715575 Scheduler overhead time: 0.14139425661414862 Adapter cache time: 0.024347837548702955 Engine time: 0.1365836844779551 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 17280, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106545 . Total input tokens: 23705951 . Total output tokens: 21305582
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.830441423226148,
    "estimated_duration": 3599.9051596380427,
    "input_throughput": 2460.4348190357805,
    "output_throughput": 2176.8712375711402,
    "total_throughput": 4637.306056606921,
    "itl": 23.06526112926051,
    "ttft": 5276.114025984778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 35739,
    "finished_requests": 35687,
    "scheduler_time": 4.300732151987405
}
#Debug simulation 
Total elapsed time: 2.83053680928424. Arrivals time: 0.09777899039909244 Scheduler time: 2.361188526265323 Scheduler overhead time: 0.14226042246446013 Adapter cache time: 0.024558610282838345 Engine time: 0.13643840746954083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.05-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.05-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     1.6     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 17280, 33, 17280, 33, 540, 540, 33, 540, 17280, 17280, 17280, 17280]
Prompts retrieved: 106545 . Total input tokens: 23705951 . Total output tokens: 21305582
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.829933342989534,
    "estimated_duration": 3599.888379494467,
    "input_throughput": 2460.4462878495797,
    "output_throughput": 2176.881384611288,
    "total_throughput": 4637.327672460868,
    "itl": 23.065437212434794,
    "ttft": 5276.086532860674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 35739,
    "finished_requests": 35687,
    "scheduler_time": 4.300893235445095
}
#Debug simulation 
Total elapsed time: 2.830022438429296. Arrivals time: 0.09784035524353385 Scheduler time: 2.360119282733649 Scheduler overhead time: 0.14171957038342953 Adapter cache time: 0.02427168283611536 Engine time: 0.13750032056123018 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 17280, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105705 . Total input tokens: 23511484 . Total output tokens: 21138728
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.818379062227905,
    "estimated_duration": 3599.96544013159,
    "input_throughput": 2431.7011220196637,
    "output_throughput": 2169.5477720237527,
    "total_throughput": 4601.248894043416,
    "itl": 22.923493655886165,
    "ttft": 6233.307107462173,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 35446,
    "finished_requests": 35385,
    "scheduler_time": 4.12140820491773
}
#Debug simulation 
Total elapsed time: 2.818494531325996. Arrivals time: 0.09580739587545395 Scheduler time: 2.3509769518859684 Scheduler overhead time: 0.14272171165794134 Adapter cache time: 0.0240903296507895 Engine time: 0.1361942458897829 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 17280, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105705 . Total input tokens: 23511484 . Total output tokens: 21138728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8529312419705093,
    "estimated_duration": 3599.968979555917,
    "input_throughput": 2431.698731215144,
    "output_throughput": 2169.5456389636606,
    "total_throughput": 4601.244370178805,
    "itl": 22.923451676305334,
    "ttft": 6233.245290771446,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 35446,
    "finished_requests": 35385,
    "scheduler_time": 4.121331687062942
}
#Debug simulation 
Total elapsed time: 2.853037152905017. Arrivals time: 0.098310521338135 Scheduler time: 2.379985828883946 Scheduler overhead time: 0.14319429686293006 Adapter cache time: 0.02429354190826416 Engine time: 0.13819403015077114 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 17280, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105705 . Total input tokens: 23511484 . Total output tokens: 21138728
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8037623409181833,
    "estimated_duration": 3599.969026177239,
    "input_throughput": 2431.6986997234817,
    "output_throughput": 2169.5456108670064,
    "total_throughput": 4601.244310590488,
    "itl": 22.92345034839077,
    "ttft": 6233.243773109818,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 35446,
    "finished_requests": 35385,
    "scheduler_time": 4.121300287706629
}
#Debug simulation 
Total elapsed time: 2.80387176387012. Arrivals time: 0.09528456814587116 Scheduler time: 2.337475177831948 Scheduler overhead time: 0.14191231643781066 Adapter cache time: 0.024228825233876705 Engine time: 0.13599104806780815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 17280, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105705 . Total input tokens: 23511484 . Total output tokens: 21138728
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.8049160758964717,
    "estimated_duration": 3599.966975750571,
    "input_throughput": 2431.7000847417044,
    "output_throughput": 2169.546846571169,
    "total_throughput": 4601.246931312874,
    "itl": 22.92348607026479,
    "ttft": 6233.284645323931,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 35446,
    "finished_requests": 35385,
    "scheduler_time": 4.121473005100376
}
#Debug simulation 
Total elapsed time: 2.805011731106788. Arrivals time: 0.09511893196031451 Scheduler time: 2.3400509878993034 Scheduler overhead time: 0.1426089545711875 Adapter cache time: 0.0242717987857759 Engine time: 0.13405393483117223 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 17280, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105705 . Total input tokens: 23511484 . Total output tokens: 21138728
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.8255122019909322,
    "estimated_duration": 3599.970165820254,
    "input_throughput": 2431.6979299203135,
    "output_throughput": 2169.5449240536755,
    "total_throughput": 4601.242853973989,
    "itl": 22.92344788877595,
    "ttft": 6233.2261660736995,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 35446,
    "finished_requests": 35385,
    "scheduler_time": 4.121288987268523
}
#Debug simulation 
Total elapsed time: 2.825610062107444. Arrivals time: 0.09823009697720408 Scheduler time: 2.349565356038511 Scheduler overhead time: 0.14448638167232275 Adapter cache time: 0.024192958138883114 Engine time: 0.13920954335480928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 17280, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105705 . Total input tokens: 23511484 . Total output tokens: 21138728
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.828868667129427,
    "estimated_duration": 3599.964504046778,
    "input_throughput": 2431.7017543254783,
    "output_throughput": 2169.548336162848,
    "total_throughput": 4601.250090488326,
    "itl": 22.923507361338437,
    "ttft": 6233.30764379866,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 35446,
    "finished_requests": 35385,
    "scheduler_time": 4.121463622878279
}
#Debug simulation 
Total elapsed time: 2.828960851300508. Arrivals time: 0.0962388115003705 Scheduler time: 2.359117046929896 Scheduler overhead time: 0.14282425865530968 Adapter cache time: 0.024489752482622862 Engine time: 0.13704597018659115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.0125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  1.6   ]. Counts: [5 5 6]
Adapter prompts. [270, 135, 135, 270, 17280, 135, 17280, 135, 270, 270, 135, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105705 . Total input tokens: 23511484 . Total output tokens: 21138728
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8184399399906397,
    "estimated_duration": 3599.9722420346993,
    "input_throughput": 2431.696527485509,
    "output_throughput": 2169.5436728105524,
    "total_throughput": 4601.240200296061,
    "itl": 22.92342967846018,
    "ttft": 6233.150200706469,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 35446,
    "finished_requests": 35385,
    "scheduler_time": 4.121436143208029
}
#Debug simulation 
Total elapsed time: 2.818543376866728. Arrivals time: 0.09697093069553375 Scheduler time: 2.347700735088438 Scheduler overhead time: 0.14273228775709867 Adapter cache time: 0.024295171722769737 Engine time: 0.137904888484627 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 17280, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105360 . Total input tokens: 23440457 . Total output tokens: 21068261
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.806117962114513,
    "estimated_duration": 3599.8795281455414,
    "input_throughput": 2432.735021138723,
    "output_throughput": 2154.5293222619275,
    "total_throughput": 4587.26434340065,
    "itl": 22.85304860392797,
    "ttft": 6762.888171558064,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 35330,
    "finished_requests": 35264,
    "scheduler_time": 3.83503512040655
}
#Debug simulation 
Total elapsed time: 2.806214426178485. Arrivals time: 0.09667660063132644 Scheduler time: 2.3358454685658216 Scheduler overhead time: 0.14325219858437777 Adapter cache time: 0.023908402305096388 Engine time: 0.13752820156514645 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 17280, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105360 . Total input tokens: 23440457 . Total output tokens: 21068261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.83620866201818,
    "estimated_duration": 3599.8830005468267,
    "input_throughput": 2432.732674553511,
    "output_throughput": 2154.5272440303884,
    "total_throughput": 4587.2599185839,
    "itl": 22.85308718868039,
    "ttft": 6762.897715416903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 35330,
    "finished_requests": 35264,
    "scheduler_time": 3.835017273202357
}
#Debug simulation 
Total elapsed time: 2.836315654218197. Arrivals time: 0.09552701376378536 Scheduler time: 2.3592893411405385 Scheduler overhead time: 0.14408207777887583 Adapter cache time: 0.0240862132050097 Engine time: 0.1439714254811406 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 17280, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105360 . Total input tokens: 23440457 . Total output tokens: 21068261
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.81415320886299,
    "estimated_duration": 3599.883050232727,
    "input_throughput": 2432.732640976722,
    "output_throughput": 2154.5272142934155,
    "total_throughput": 4587.259855270137,
    "itl": 22.853092693915762,
    "ttft": 6762.893143488399,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 35330,
    "finished_requests": 35264,
    "scheduler_time": 3.8349938383401176
}
#Debug simulation 
Total elapsed time: 2.814246468245983. Arrivals time: 0.09470878122374415 Scheduler time: 2.3468471565283835 Scheduler overhead time: 0.14356767293065786 Adapter cache time: 0.023881610482931137 Engine time: 0.13654675986617804 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 17280, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105360 . Total input tokens: 23440457 . Total output tokens: 21068261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.808964489027858,
    "estimated_duration": 3599.8798413403792,
    "input_throughput": 2432.7348094872,
    "output_throughput": 2154.5291348147093,
    "total_throughput": 4587.26394430191,
    "itl": 22.85300762220151,
    "ttft": 6762.8724044485025,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 35330,
    "finished_requests": 35264,
    "scheduler_time": 3.834947093737649
}
#Debug simulation 
Total elapsed time: 2.8090640152804554. Arrivals time: 0.09733434580266476 Scheduler time: 2.3368895780295134 Scheduler overhead time: 0.14292116928845644 Adapter cache time: 0.024113496765494347 Engine time: 0.13832953246310353 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 17280, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105360 . Total input tokens: 23440457 . Total output tokens: 21068261
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.800042392220348,
    "estimated_duration": 3599.884129932242,
    "input_throughput": 2432.731911336501,
    "output_throughput": 2154.5265680942866,
    "total_throughput": 4587.258479430788,
    "itl": 22.853122315052186,
    "ttft": 6762.906638050219,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 35330,
    "finished_requests": 35264,
    "scheduler_time": 3.8349981333921805
}
#Debug simulation 
Total elapsed time: 2.8001811713911593. Arrivals time: 0.09466934483498335 Scheduler time: 2.3340335432440042 Scheduler overhead time: 0.14298395533114672 Adapter cache time: 0.02398783713579178 Engine time: 0.13546593952924013 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 17280, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105360 . Total input tokens: 23440457 . Total output tokens: 21068261
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.8266703570261598,
    "estimated_duration": 3599.8790855093675,
    "input_throughput": 2432.7353202644704,
    "output_throughput": 2154.5295871798853,
    "total_throughput": 4587.264907444355,
    "itl": 22.853062045068995,
    "ttft": 6762.854725176664,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 35330,
    "finished_requests": 35264,
    "scheduler_time": 3.835071273434911
}
#Debug simulation 
Total elapsed time: 2.8267752081155777. Arrivals time: 0.09485435765236616 Scheduler time: 2.3584927157498896 Scheduler overhead time: 0.1452229032292962 Adapter cache time: 0.024102729745209217 Engine time: 0.13453558553010225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   1.6    ]. Counts: [5 5 6]
Adapter prompts. [270, 66, 66, 270, 17280, 66, 17280, 66, 270, 270, 66, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105360 . Total input tokens: 23440457 . Total output tokens: 21068261
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.8104060371406376,
    "estimated_duration": 3599.8855187337604,
    "input_throughput": 2432.730972811719,
    "output_throughput": 2154.525736898474,
    "total_throughput": 4587.256709710193,
    "itl": 22.853134402519323,
    "ttft": 6762.904724527571,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 35330,
    "finished_requests": 35264,
    "scheduler_time": 3.834976241379954
}
#Debug simulation 
Total elapsed time: 2.810499511193484. Arrivals time: 0.09801307693123817 Scheduler time: 2.3380512609146535 Scheduler overhead time: 0.1428346331231296 Adapter cache time: 0.02400857675820589 Engine time: 0.13863390451297164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 17280, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105195 . Total input tokens: 23407564 . Total output tokens: 21033433
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.781864320859313,
    "estimated_duration": 3599.983820788216,
    "input_throughput": 2412.0886182479435,
    "output_throughput": 2152.9013422907688,
    "total_throughput": 4564.989960538713,
    "itl": 22.85411754713102,
    "ttft": 5549.146387615651,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 35272,
    "finished_requests": 35218,
    "scheduler_time": 3.902770625995303
}
#Debug simulation 
Total elapsed time: 2.781957241240889. Arrivals time: 0.09481388842687011 Scheduler time: 2.315204091835767 Scheduler overhead time: 0.14195951726287603 Adapter cache time: 0.02381731476634741 Engine time: 0.1377593344077468 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 17280, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105195 . Total input tokens: 23407564 . Total output tokens: 21033433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.7968628578819335,
    "estimated_duration": 3599.9878692674943,
    "input_throughput": 2412.0859056580284,
    "output_throughput": 2152.8989211780345,
    "total_throughput": 4564.984826836063,
    "itl": 22.85427547872936,
    "ttft": 5549.21580221229,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 35272,
    "finished_requests": 35218,
    "scheduler_time": 3.9028230833778363
}
#Debug simulation 
Total elapsed time: 2.7969475057907403. Arrivals time: 0.09393315576016903 Scheduler time: 2.338050247170031 Scheduler overhead time: 0.14154402678832412 Adapter cache time: 0.022851891815662384 Engine time: 0.13252301840111613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 17280, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105195 . Total input tokens: 23407564 . Total output tokens: 21033433
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.7957316003739834,
    "estimated_duration": 3599.987940639573,
    "input_throughput": 2412.0858578368725,
    "output_throughput": 2152.898878495427,
    "total_throughput": 4564.9847363323,
    "itl": 22.854269775491947,
    "ttft": 5549.202570292456,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.052406024020165184,
    "arrivals": 35272,
    "finished_requests": 35218,
    "scheduler_time": 3.902835217801962
}
#Debug simulation 
Total elapsed time: 2.795828258153051. Arrivals time: 0.09526554122567177 Scheduler time: 2.333321795798838 Scheduler overhead time: 0.1403143829666078 Adapter cache time: 0.023052906151860952 Engine time: 0.1362149529159069 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 17280, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105195 . Total input tokens: 23407564 . Total output tokens: 21033433
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7799863959662616,
    "estimated_duration": 3599.9854995643655,
    "input_throughput": 2412.0874934220674,
    "output_throughput": 2152.900338331329,
    "total_throughput": 4564.987831753397,
    "itl": 22.85413463043576,
    "ttft": 5549.130526349284,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 35272,
    "finished_requests": 35218,
    "scheduler_time": 3.902730052792884
}
#Debug simulation 
Total elapsed time: 2.7801120840013027. Arrivals time: 0.09457873646169901 Scheduler time: 2.319736494217068 Scheduler overhead time: 0.14053336437791586 Adapter cache time: 0.02316379500553012 Engine time: 0.13425915641710162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 17280, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105195 . Total input tokens: 23407564 . Total output tokens: 21033433
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.790863063186407,
    "estimated_duration": 3599.9892648137848,
    "input_throughput": 2412.084970605924,
    "output_throughput": 2152.898086600517,
    "total_throughput": 4564.983057206441,
    "itl": 22.854282708247023,
    "ttft": 5549.215763311382,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 35272,
    "finished_requests": 35218,
    "scheduler_time": 3.90281987255581
}
#Debug simulation 
Total elapsed time: 2.790962870232761. Arrivals time: 0.0935328621417284 Scheduler time: 2.3320090705528855 Scheduler overhead time: 0.14029930252581835 Adapter cache time: 0.02296406263485551 Engine time: 0.1348911952227354 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 17280, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105195 . Total input tokens: 23407564 . Total output tokens: 21033433
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.7907272088341415,
    "estimated_duration": 3599.981573920223,
    "input_throughput": 2412.0901237125136,
    "output_throughput": 2152.902685987957,
    "total_throughput": 4564.99280970047,
    "itl": 22.854130437289356,
    "ttft": 5549.1325754789705,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 35272,
    "finished_requests": 35218,
    "scheduler_time": 3.9027931017495314
}
#Debug simulation 
Total elapsed time: 2.790830090176314. Arrivals time: 0.09479904687032104 Scheduler time: 2.3322059833444655 Scheduler overhead time: 0.14069041656330228 Adapter cache time: 0.02282477030530572 Engine time: 0.13269600924104452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.025-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    1.6     ]. Counts: [5 5 6]
Adapter prompts. [270, 33, 33, 270, 17280, 33, 17280, 33, 270, 270, 33, 270, 17280, 17280, 17280, 17280]
Prompts retrieved: 105195 . Total input tokens: 23407564 . Total output tokens: 21033433
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.7670279340818524,
    "estimated_duration": 3599.990696481013,
    "input_throughput": 2412.0840113526106,
    "output_throughput": 2152.8972304222943,
    "total_throughput": 4564.981241774905,
    "itl": 22.854321662119833,
    "ttft": 5549.216849898639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 35272,
    "finished_requests": 35218,
    "scheduler_time": 3.9028413892020217
}
#Debug simulation 
Total elapsed time: 2.7671195790171623. Arrivals time: 0.0936715416610241 Scheduler time: 2.309846947900951 Scheduler overhead time: 0.13860979443416 Adapter cache time: 0.022952258121222258 Engine time: 0.13506630342453718 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-8/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 17280, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104685 . Total input tokens: 23284286 . Total output tokens: 20932660
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.713184631895274,
    "estimated_duration": 3600.007659415958,
    "input_throughput": 2430.0126076451816,
    "output_throughput": 2110.721620306983,
    "total_throughput": 4540.7342279521645,
    "itl": 22.632573968470627,
    "ttft": 5678.289399021867,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 35101,
    "finished_requests": 35046,
    "scheduler_time": 3.2153499285283234
}
#Debug simulation 
Total elapsed time: 2.7133119856007397. Arrivals time: 0.09081635810434818 Scheduler time: 2.2585880304686725 Scheduler overhead time: 0.1410804335027933 Adapter cache time: 0.02271003182977438 Engine time: 0.1325091551989317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-16/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 17280, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104685 . Total input tokens: 23284286 . Total output tokens: 20932660
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.726942513138056,
    "estimated_duration": 3600.0131986413135,
    "input_throughput": 2430.0088686623762,
    "output_throughput": 2110.718372607024,
    "total_throughput": 4540.7272412694,
    "itl": 22.632547122931577,
    "ttft": 5678.274154168078,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 35101,
    "finished_requests": 35046,
    "scheduler_time": 3.2154099750389267
}
#Debug simulation 
Total elapsed time: 2.7270318111404777. Arrivals time: 0.0927960341796279 Scheduler time: 2.271574691403657 Scheduler overhead time: 0.14038492646068335 Adapter cache time: 0.022737618070095778 Engine time: 0.13202420016750693 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-8-32/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 17280, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104685 . Total input tokens: 23284286 . Total output tokens: 20932660
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.731957125943154,
    "estimated_duration": 3600.0132724709324,
    "input_throughput": 2430.0088188273853,
    "output_throughput": 2110.718329320091,
    "total_throughput": 4540.727148147476,
    "itl": 22.63254224155245,
    "ttft": 5678.263887317999,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 35101,
    "finished_requests": 35046,
    "scheduler_time": 3.215410683902933
}
#Debug simulation 
Total elapsed time: 2.732055969070643. Arrivals time: 0.09403749043121934 Scheduler time: 2.269910391420126 Scheduler overhead time: 0.14109052903950214 Adapter cache time: 0.022654997184872627 Engine time: 0.13634724682196975 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-16/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 17280, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104685 . Total input tokens: 23284286 . Total output tokens: 20932660
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.721584205981344,
    "estimated_duration": 3600.009855351907,
    "input_throughput": 2430.0111253847836,
    "output_throughput": 2110.720332807873,
    "total_throughput": 4540.731458192657,
    "itl": 22.632567133997053,
    "ttft": 5678.278487669201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 35101,
    "finished_requests": 35046,
    "scheduler_time": 3.215339795574214
}
#Debug simulation 
Total elapsed time: 2.7217028718441725. Arrivals time: 0.09349710028618574 Scheduler time: 2.264437264762819 Scheduler overhead time: 0.1407741429284215 Adapter cache time: 0.02261608699336648 Engine time: 0.13270573550835252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_8-16-32/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 17280, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104685 . Total input tokens: 23284286 . Total output tokens: 20932660
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.7243129410780966,
    "estimated_duration": 3600.0141135646627,
    "input_throughput": 2430.0082510892826,
    "output_throughput": 2110.717836179815,
    "total_throughput": 4540.726087269098,
    "itl": 22.63252706495597,
    "ttft": 5678.269225139465,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 35101,
    "finished_requests": 35046,
    "scheduler_time": 3.2153869987966837
}
#Debug simulation 
Total elapsed time: 2.7244068970903754. Arrivals time: 0.09282498527318239 Scheduler time: 2.266399522777647 Scheduler overhead time: 0.13933650311082602 Adapter cache time: 0.02278837002813816 Engine time: 0.13576007634401321 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-16/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 17280, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104685 . Total input tokens: 23284286 . Total output tokens: 20932660
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.7266503390856087,
    "estimated_duration": 3600.006151071186,
    "input_throughput": 2430.0136257814456,
    "output_throughput": 2110.72250466545,
    "total_throughput": 4540.736130446896,
    "itl": 22.632561521523424,
    "ttft": 5678.322092680165,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 35101,
    "finished_requests": 35046,
    "scheduler_time": 3.2154434596013073
}
#Debug simulation 
Total elapsed time: 2.7267485223710537. Arrivals time: 0.09274315601214767 Scheduler time: 2.267410491127521 Scheduler overhead time: 0.14113850379362702 Adapter cache time: 0.02256106911227107 Engine time: 0.13510591723024845 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.00625_size_16-16-32/adapters_16_slots_16_rate_1.6-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  1.6    ]. Counts: [5 5 6]
Adapter prompts. [135, 66, 66, 135, 17280, 66, 17280, 66, 135, 135, 66, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104685 . Total input tokens: 23284286 . Total output tokens: 20932660
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.7323224982246757,
    "estimated_duration": 3600.015337329089,
    "input_throughput": 2430.0074250490093,
    "output_throughput": 2110.717118676927,
    "total_throughput": 4540.724543725936,
    "itl": 22.63254385217152,
    "ttft": 5678.270163760067,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 35101,
    "finished_requests": 35046,
    "scheduler_time": 3.2152324621051127
}
#Debug simulation 
Total elapsed time: 2.7324280901812017. Arrivals time: 0.09346622694283724 Scheduler time: 2.275393297895789 Scheduler overhead time: 0.14055694453418255 Adapter cache time: 0.022887437138706446 Engine time: 0.1324024279601872 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 17280, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104520 . Total input tokens: 23248097 . Total output tokens: 20904794
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.7313422658480704,
    "estimated_duration": 3600.0023708129224,
    "input_throughput": 2419.0814624473355,
    "output_throughput": 2121.338880750658,
    "total_throughput": 4540.420343197994,
    "itl": 22.638473507652556,
    "ttft": 4455.741245101336,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 35037,
    "finished_requests": 34993,
    "scheduler_time": 3.3138342920227686
}
#Debug simulation 
Total elapsed time: 2.731425921898335. Arrivals time: 0.08596799056977034 Scheduler time: 2.279388168361038 Scheduler overhead time: 0.14134261291474104 Adapter cache time: 0.02221916476264596 Engine time: 0.1347519988194108 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 17280, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104520 . Total input tokens: 23248097 . Total output tokens: 20904794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.7326553631573915,
    "estimated_duration": 3600.0065970953706,
    "input_throughput": 2419.078622529894,
    "output_throughput": 2121.3363903726445,
    "total_throughput": 4540.415012902538,
    "itl": 22.638493399593266,
    "ttft": 4455.764716119366,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 35037,
    "finished_requests": 34993,
    "scheduler_time": 3.313889042987337
}
#Debug simulation 
Total elapsed time: 2.732736222911626. Arrivals time: 0.08634291728958488 Scheduler time: 2.2803108976222575 Scheduler overhead time: 0.13974241586402059 Adapter cache time: 0.022284261882305145 Engine time: 0.13631072593852878 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 17280, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104520 . Total input tokens: 23248097 . Total output tokens: 20904794
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.707590891048312,
    "estimated_duration": 3600.0066354174564,
    "input_throughput": 2419.078596778792,
    "output_throughput": 2121.3363677910097,
    "total_throughput": 4540.414964569802,
    "itl": 22.638491334256564,
    "ttft": 4455.772863485475,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 35037,
    "finished_requests": 34993,
    "scheduler_time": 3.313868944069133
}
#Debug simulation 
Total elapsed time: 2.7076712329871953. Arrivals time: 0.0851931981742382 Scheduler time: 2.2622104911133647 Scheduler overhead time: 0.1394547433592379 Adapter cache time: 0.022343415766954422 Engine time: 0.13133603846654296 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 17280, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104520 . Total input tokens: 23248097 . Total output tokens: 20904794
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.7195493578910828,
    "estimated_duration": 3600.0042883940964,
    "input_throughput": 2419.080173897462,
    "output_throughput": 2121.337750796587,
    "total_throughput": 4540.417924694049,
    "itl": 22.63846342746277,
    "ttft": 4455.764411354091,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 35037,
    "finished_requests": 34993,
    "scheduler_time": 3.3139818233282825
}
#Debug simulation 
Total elapsed time: 2.719641929026693. Arrivals time: 0.0930771823041141 Scheduler time: 2.264756170101464 Scheduler overhead time: 0.13937055226415396 Adapter cache time: 0.02233751118183136 Engine time: 0.1330113816075027 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 17280, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104520 . Total input tokens: 23248097 . Total output tokens: 20904794
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.724678723141551,
    "estimated_duration": 3600.0074547735335,
    "input_throughput": 2419.0780462002795,
    "output_throughput": 2121.3358849781634,
    "total_throughput": 4540.413931178443,
    "itl": 22.63848475915099,
    "ttft": 4455.758382793387,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 35037,
    "finished_requests": 34993,
    "scheduler_time": 3.313860270711054
}
#Debug simulation 
Total elapsed time: 2.724770501255989. Arrivals time: 0.09317573998123407 Scheduler time: 2.2671817815862596 Scheduler overhead time: 0.13933813013136387 Adapter cache time: 0.022754302248358727 Engine time: 0.13506885431706905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 17280, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104520 . Total input tokens: 23248097 . Total output tokens: 20904794
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.7423980981111526,
    "estimated_duration": 3600.0011358938223,
    "input_throughput": 2419.0822922720467,
    "output_throughput": 2121.3396084398455,
    "total_throughput": 4540.421900711893,
    "itl": 22.638478799441483,
    "ttft": 4455.745885499183,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 35037,
    "finished_requests": 34993,
    "scheduler_time": 3.3138872498933094
}
#Debug simulation 
Total elapsed time: 2.7425205959007144. Arrivals time: 0.09131416585296392 Scheduler time: 2.2810593508183956 Scheduler overhead time: 0.14334947289898992 Adapter cache time: 0.022781684063374996 Engine time: 0.13586122682318091 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.0125-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   1.6     ]. Counts: [5 5 6]
Adapter prompts. [135, 33, 33, 135, 17280, 33, 17280, 33, 135, 135, 33, 135, 17280, 17280, 17280, 17280]
Prompts retrieved: 104520 . Total input tokens: 23248097 . Total output tokens: 20904794
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.70919195888564,
    "estimated_duration": 3600.008320551485,
    "input_throughput": 2419.0774644281696,
    "output_throughput": 2121.3353748110544,
    "total_throughput": 4540.412839239224,
    "itl": 22.638450061597442,
    "ttft": 4455.763618948017,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 35037,
    "finished_requests": 34993,
    "scheduler_time": 3.313818404902633
}
#Debug simulation 
Total elapsed time: 2.709292829968035. Arrivals time: 0.09084765939041972 Scheduler time: 2.2581813875585794 Scheduler overhead time: 0.13958262000232935 Adapter cache time: 0.022316792979836464 Engine time: 0.13126763701438904 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-8/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 17280, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 17280]
Prompts retrieved: 104175 . Total input tokens: 23171129 . Total output tokens: 20834906
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.761075999122113,
    "estimated_duration": 3600.0099802646787,
    "input_throughput": 2391.5747587363635,
    "output_throughput": 2145.208775069065,
    "total_throughput": 4536.783533805428,
    "itl": 22.68319289992635,
    "ttft": 4879.633281114873,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 34944,
    "finished_requests": 34896,
    "scheduler_time": 3.55589889573978
}
#Debug simulation 
Total elapsed time: 2.761166198179126. Arrivals time: 0.09383880626410246 Scheduler time: 2.302059322129935 Scheduler overhead time: 0.14022115338593721 Adapter cache time: 0.022369273472577333 Engine time: 0.13523442391306162 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-16/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 17280, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 17280]
Prompts retrieved: 104175 . Total input tokens: 23171129 . Total output tokens: 20834906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.7487169848755,
    "estimated_duration": 3600.014276400145,
    "input_throughput": 2391.571904711809,
    "output_throughput": 2145.2062150493557,
    "total_throughput": 4536.778119761165,
    "itl": 22.68321929022456,
    "ttft": 4879.6480211875305,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 34944,
    "finished_requests": 34896,
    "scheduler_time": 3.556065691977474
}
#Debug simulation 
Total elapsed time: 2.748801515903324. Arrivals time: 0.09353354247286916 Scheduler time: 2.293953615706414 Scheduler overhead time: 0.140035018324852 Adapter cache time: 0.022133170161396265 Engine time: 0.13178956601768732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-8-32/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 17280, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 17280]
Prompts retrieved: 104175 . Total input tokens: 23171129 . Total output tokens: 20834906
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.745920381974429,
    "estimated_duration": 3600.014528420872,
    "input_throughput": 2391.571737288682,
    "output_throughput": 2145.206064873176,
    "total_throughput": 4536.777802161858,
    "itl": 22.68321762289275,
    "ttft": 4879.653284533092,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0524060240201652,
    "arrivals": 34944,
    "finished_requests": 34896,
    "scheduler_time": 3.556062481155444
}
#Debug simulation 
Total elapsed time: 2.7460328633897007. Arrivals time: 0.09112248895689845 Scheduler time: 2.2915649018250406 Scheduler overhead time: 0.13957200665026903 Adapter cache time: 0.02206352911889553 Engine time: 0.13463026890531182 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-16/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 17280, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 17280]
Prompts retrieved: 104175 . Total input tokens: 23171129 . Total output tokens: 20834906
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.744967603124678,
    "estimated_duration": 3600.0113342599275,
    "input_throughput": 2391.5738592445123,
    "output_throughput": 2145.20796823758,
    "total_throughput": 4536.781827482093,
    "itl": 22.6831401997781,
    "ttft": 4879.654403741294,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 34944,
    "finished_requests": 34896,
    "scheduler_time": 3.5558666623974635
}
#Debug simulation 
Total elapsed time: 2.7450691061094403. Arrivals time: 0.09095893334597349 Scheduler time: 2.288522204849869 Scheduler overhead time: 0.14103553351014853 Adapter cache time: 0.022089605685323477 Engine time: 0.13481517136096954 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_8-16-32/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 17280, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 17280]
Prompts retrieved: 104175 . Total input tokens: 23171129 . Total output tokens: 20834906
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.747938910033554,
    "estimated_duration": 3600.0155198143407,
    "input_throughput": 2391.5710786835766,
    "output_throughput": 2145.2054741137,
    "total_throughput": 4536.776552797277,
    "itl": 22.683211697487952,
    "ttft": 4879.654761814578,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 34944,
    "finished_requests": 34896,
    "scheduler_time": 3.5561185247260076
}
#Debug simulation 
Total elapsed time: 2.748046354390681. Arrivals time: 0.09343041339889169 Scheduler time: 2.2921377797611058 Scheduler overhead time: 0.13928393088281155 Adapter cache time: 0.022175553254783154 Engine time: 0.13360987091436982 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-16/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 17280, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 17280]
Prompts retrieved: 104175 . Total input tokens: 23171129 . Total output tokens: 20834906
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.7489763470366597,
    "estimated_duration": 3600.0089349199516,
    "input_throughput": 2391.575453184658,
    "output_throughput": 2145.209397979375,
    "total_throughput": 4536.784851164032,
    "itl": 22.683197680944744,
    "ttft": 4879.651557441695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 34944,
    "finished_requests": 34896,
    "scheduler_time": 3.5558152473769145
}
#Debug simulation 
Total elapsed time: 2.7490722127258778. Arrivals time: 0.09019948588684201 Scheduler time: 2.294817272108048 Scheduler overhead time: 0.1424851748161018 Adapter cache time: 0.022180960047990084 Engine time: 0.1315814834088087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        1.6,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_1.6-0.00625-0.003125_size_16-16-32/adapters_16_slots_16_rate_1.6-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  1.6     ]. Counts: [5 5 6]
Adapter prompts. [66, 33, 33, 66, 17280, 33, 17280, 33, 66, 66, 33, 66, 17280, 17280, 17280, 17280]
Prompts retrieved: 104175 . Total input tokens: 23171129 . Total output tokens: 20834906
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.751099058892578,
    "estimated_duration": 3600.016191831802,
    "input_throughput": 2391.5706322473834,
    "output_throughput": 2145.2050736667406,
    "total_throughput": 4536.775705914124,
    "itl": 22.683168362774616,
    "ttft": 4879.659160843049,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 34944,
    "finished_requests": 34896,
    "scheduler_time": 3.5560997184138126
}
#Debug simulation 
Total elapsed time: 2.751212968956679. Arrivals time: 0.09129337081685662 Scheduler time: 2.2962601110339165 Scheduler overhead time: 0.14058736013248563 Adapter cache time: 0.021888713352382183 Engine time: 0.13362381421029568 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 78840 . Total input tokens: 17538681 . Total output tokens: 15758818
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.204301227349788,
    "estimated_duration": 3599.965943892783,
    "input_throughput": 1802.4926071893024,
    "output_throughput": 1603.3915570207714,
    "total_throughput": 3405.884164210074,
    "itl": 22.74407275813058,
    "ttft": 5901.658427269869,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 26398,
    "finished_requests": 26355,
    "scheduler_time": 0.2578166080101407
}
#Debug simulation 
Total elapsed time: 2.2043952820822597. Arrivals time: 0.07308681588619947 Scheduler time: 1.762131916359067 Scheduler overhead time: 0.13726171292364597 Adapter cache time: 0.02734602801501751 Engine time: 0.13785017980262637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 78840 . Total input tokens: 17538681 . Total output tokens: 15758818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.194588985759765,
    "estimated_duration": 3599.9715213631716,
    "input_throughput": 1802.4898145702266,
    "output_throughput": 1603.3890728708614,
    "total_throughput": 3405.878887441088,
    "itl": 22.744100015272746,
    "ttft": 5901.664825721892,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 26398,
    "finished_requests": 26355,
    "scheduler_time": 0.25777103089167064
}
#Debug simulation 
Total elapsed time: 2.1946723549626768. Arrivals time: 0.07348775491118431 Scheduler time: 1.759929143358022 Scheduler overhead time: 0.1364957680925727 Adapter cache time: 0.0274541606195271 Engine time: 0.13080990174785256 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 78840 . Total input tokens: 17538681 . Total output tokens: 15758818
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.1912593161687255,
    "estimated_duration": 3599.9719505903977,
    "input_throughput": 1802.489599658079,
    "output_throughput": 1603.3888816976373,
    "total_throughput": 3405.8784813557163,
    "itl": 22.744122183191422,
    "ttft": 5901.631888474299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 26398,
    "finished_requests": 26355,
    "scheduler_time": 0.2578042233420097
}
#Debug simulation 
Total elapsed time: 2.191343393176794. Arrivals time: 0.07510368200019002 Scheduler time: 1.7539992830716074 Scheduler overhead time: 0.1353730191476643 Adapter cache time: 0.027495001442730427 Engine time: 0.13316491292789578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 78840 . Total input tokens: 17538681 . Total output tokens: 15758818
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.1915248557925224,
    "estimated_duration": 3599.968691353531,
    "input_throughput": 1802.4912315446477,
    "output_throughput": 1603.3903333280828,
    "total_throughput": 3405.8815648727305,
    "itl": 22.744121791373118,
    "ttft": 5901.644142267285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 26398,
    "finished_requests": 26355,
    "scheduler_time": 0.25776865405564725
}
#Debug simulation 
Total elapsed time: 2.19161617802456. Arrivals time: 0.07508346252143383 Scheduler time: 1.7566013992764056 Scheduler overhead time: 0.13621785817667842 Adapter cache time: 0.027779588475823402 Engine time: 0.1298345630057156 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 78840 . Total input tokens: 17538681 . Total output tokens: 15758818
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.177745259832591,
    "estimated_duration": 3599.9719329191553,
    "input_throughput": 1802.48960850599,
    "output_throughput": 1603.3888895682192,
    "total_throughput": 3405.878498074209,
    "itl": 22.744118789375054,
    "ttft": 5901.632385183216,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 26398,
    "finished_requests": 26355,
    "scheduler_time": 0.25778721012383565
}
#Debug simulation 
Total elapsed time: 2.1778327599167824. Arrivals time: 0.07265922613441944 Scheduler time: 1.7443661550059915 Scheduler overhead time: 0.13664753315970302 Adapter cache time: 0.027506116777658463 Engine time: 0.13004387822002172 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 78840 . Total input tokens: 17538681 . Total output tokens: 15758818
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.205647717230022,
    "estimated_duration": 3599.9611059739977,
    "input_throughput": 1802.4950295245965,
    "output_throughput": 1603.3937117879773,
    "total_throughput": 3405.8887413125735,
    "itl": 22.744000491334493,
    "ttft": 5901.590061900071,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 26398,
    "finished_requests": 26355,
    "scheduler_time": 0.2578373325383623
}
#Debug simulation 
Total elapsed time: 2.2057599048130214. Arrivals time: 0.07359985914081335 Scheduler time: 1.7644648947753012 Scheduler overhead time: 0.13917592214420438 Adapter cache time: 0.027495728339999914 Engine time: 0.134291285648942 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.1_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.4 0.8]. Counts: [5 5 6]
Adapter prompts. [4320, 1080, 1080, 4320, 8640, 1080, 8640, 1080, 4320, 4320, 1080, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 78840 . Total input tokens: 17538681 . Total output tokens: 15758818
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.2032641037367284,
    "estimated_duration": 3599.972442966921,
    "input_throughput": 1802.4893531274247,
    "output_throughput": 1603.3886623984467,
    "total_throughput": 3405.8780155258714,
    "itl": 22.744082082113145,
    "ttft": 5901.611283601765,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 26398,
    "finished_requests": 26355,
    "scheduler_time": 0.25775581076751836
}
#Debug simulation 
Total elapsed time: 2.2033530296757817. Arrivals time: 0.07497961958870292 Scheduler time: 1.7627821075730026 Scheduler overhead time: 0.13829772546887398 Adapter cache time: 0.02754802629351616 Engine time: 0.13259816588833928 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 8640, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 76140 . Total input tokens: 16948670 . Total output tokens: 15211007
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.1569137098267674,
    "estimated_duration": 3600.0235059915594,
    "input_throughput": 1748.639137917551,
    "output_throughput": 1569.2472536909168,
    "total_throughput": 3317.886391608468,
    "itl": 22.448998666410354,
    "ttft": 5115.056421243953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 25522,
    "finished_requests": 25486,
    "scheduler_time": 0.1846002233571988
}
#Debug simulation 
Total elapsed time: 2.157007670029998. Arrivals time: 0.07221587840467691 Scheduler time: 1.7215145216323435 Scheduler overhead time: 0.13683682307600975 Adapter cache time: 0.02655210718512535 Engine time: 0.13283340586349368 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 8640, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 76140 . Total input tokens: 16948670 . Total output tokens: 15211007
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.1492770141921937,
    "estimated_duration": 3600.00028017143,
    "input_throughput": 1748.650419466142,
    "output_throughput": 1569.2573778719213,
    "total_throughput": 3317.907797338063,
    "itl": 22.448994925320847,
    "ttft": 4974.291179596496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 25522,
    "finished_requests": 25486,
    "scheduler_time": 0.18468349635404718
}
#Debug simulation 
Total elapsed time: 2.1493645161390305. Arrivals time: 0.07248663948848844 Scheduler time: 1.7132426775060594 Scheduler overhead time: 0.13737825118005276 Adapter cache time: 0.026436994317919016 Engine time: 0.13303513312712312 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 8640, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 76140 . Total input tokens: 16948670 . Total output tokens: 15211007
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.1667289691977203,
    "estimated_duration": 3600.000341136638,
    "input_throughput": 1748.6503898531348,
    "output_throughput": 1569.2573512968954,
    "total_throughput": 3317.9077411500302,
    "itl": 22.448996620327726,
    "ttft": 4974.295671979499,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 25522,
    "finished_requests": 25486,
    "scheduler_time": 0.18467624072397382
}
#Debug simulation 
Total elapsed time: 2.166847661137581. Arrivals time: 0.07245427882298827 Scheduler time: 1.7291918797418475 Scheduler overhead time: 0.13801341084763408 Adapter cache time: 0.026707110460847616 Engine time: 0.13362645311281085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 8640, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 76140 . Total input tokens: 16948670 . Total output tokens: 15211007
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.155821941792965,
    "estimated_duration": 3600.0238368594805,
    "input_throughput": 1748.6389772051161,
    "output_throughput": 1569.247109465878,
    "total_throughput": 3317.8860866709942,
    "itl": 22.449022131770505,
    "ttft": 5115.0727987471255,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 25522,
    "finished_requests": 25486,
    "scheduler_time": 0.1846204473974051
}
#Debug simulation 
Total elapsed time: 2.155947190709412. Arrivals time: 0.07208409998565912 Scheduler time: 1.719681988004595 Scheduler overhead time: 0.138161261100322 Adapter cache time: 0.026616312097758055 Engine time: 0.13182054413482547 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 8640, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 76140 . Total input tokens: 16948670 . Total output tokens: 15211007
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.1622257377021015,
    "estimated_duration": 3600.0009394478507,
    "input_throughput": 1748.650099231784,
    "output_throughput": 1569.257090490222,
    "total_throughput": 3317.907189722006,
    "itl": 22.448988417951025,
    "ttft": 4974.290736595742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 25522,
    "finished_requests": 25486,
    "scheduler_time": 0.18473595373657975
}
#Debug simulation 
Total elapsed time: 2.162311452906579. Arrivals time: 0.07335083093494177 Scheduler time: 1.7239613491110504 Scheduler overhead time: 0.13655235851183534 Adapter cache time: 0.026752579025924206 Engine time: 0.13478293316438794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 8640, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 76140 . Total input tokens: 16948670 . Total output tokens: 15211007
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.151351419277489,
    "estimated_duration": 3600.023638925486,
    "input_throughput": 1748.6390733475675,
    "output_throughput": 1569.2471957451307,
    "total_throughput": 3317.8862690926985,
    "itl": 22.449033776139558,
    "ttft": 5115.017404612154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 25522,
    "finished_requests": 25486,
    "scheduler_time": 0.18462661879746167
}
#Debug simulation 
Total elapsed time: 2.1514361700974405. Arrivals time: 0.0720282937400043 Scheduler time: 1.7168131656944752 Scheduler overhead time: 0.13780760066583753 Adapter cache time: 0.026738142129033804 Engine time: 0.13080065371468663 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.05_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.4  0.8 ]. Counts: [5 5 6]
Adapter prompts. [4320, 540, 540, 4320, 8640, 540, 8640, 540, 4320, 4320, 540, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 76140 . Total input tokens: 16948670 . Total output tokens: 15211007
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.1459925319068134,
    "estimated_duration": 3600.00079544799,
    "input_throughput": 1748.6501691777048,
    "output_throughput": 1569.2571532604309,
    "total_throughput": 3317.907322438136,
    "itl": 22.448970175486412,
    "ttft": 4974.324838058012,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 25522,
    "finished_requests": 25486,
    "scheduler_time": 0.18474975613272152
}
#Debug simulation 
Total elapsed time: 2.1460889452137053. Arrivals time: 0.071025718934834 Scheduler time: 1.7115070391446352 Scheduler overhead time: 0.13791659055277705 Adapter cache time: 0.02655432466417551 Engine time: 0.13193737668916583 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 8640, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74790 . Total input tokens: 16638690 . Total output tokens: 14943512
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.1121901110745966,
    "estimated_duration": 3599.9703439618283,
    "input_throughput": 1714.337455682507,
    "output_throughput": 1534.1590269662959,
    "total_throughput": 3248.4964826488026,
    "itl": 22.193072052478467,
    "ttft": 6796.572876859367,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 25030,
    "finished_requests": 24983,
    "scheduler_time": 0.08824857858825555
}
#Debug simulation 
Total elapsed time: 2.112284538336098. Arrivals time: 0.0720894830301404 Scheduler time: 1.6751486491411924 Scheduler overhead time: 0.13878078339621425 Adapter cache time: 0.02579557942226529 Engine time: 0.13262523291632533 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 8640, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74790 . Total input tokens: 16638690 . Total output tokens: 14943512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.1167720179073513,
    "estimated_duration": 3599.9713996904584,
    "input_throughput": 1714.3369529354202,
    "output_throughput": 1534.158577058386,
    "total_throughput": 3248.495529993806,
    "itl": 22.19313192916572,
    "ttft": 6796.6120137226235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 25030,
    "finished_requests": 24983,
    "scheduler_time": 0.08822097379597195
}
#Debug simulation 
Total elapsed time: 2.1168559482321143. Arrivals time: 0.07158070337027311 Scheduler time: 1.6802340662106872 Scheduler overhead time: 0.13729040138423443 Adapter cache time: 0.026072596665471792 Engine time: 0.13443330023437738 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 8640, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74790 . Total input tokens: 16638690 . Total output tokens: 14943512
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.1208087909035385,
    "estimated_duration": 3599.971885075514,
    "input_throughput": 1714.3367217909658,
    "output_throughput": 1534.1583702074245,
    "total_throughput": 3248.4950919983903,
    "itl": 22.193141439519543,
    "ttft": 6796.6044211092685,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 25030,
    "finished_requests": 24983,
    "scheduler_time": 0.08822668657603126
}
#Debug simulation 
Total elapsed time: 2.120904189068824. Arrivals time: 0.07148125488311052 Scheduler time: 1.6850705510005355 Scheduler overhead time: 0.13839447777718306 Adapter cache time: 0.025940238032490015 Engine time: 0.1321426797658205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 8640, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74790 . Total input tokens: 16638690 . Total output tokens: 14943512
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.1183787817135453,
    "estimated_duration": 3599.9707561324103,
    "input_throughput": 1714.3372594032828,
    "output_throughput": 1534.1588513161971,
    "total_throughput": 3248.49611071948,
    "itl": 22.193066583183434,
    "ttft": 6796.59765607334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 25030,
    "finished_requests": 24983,
    "scheduler_time": 0.08820562854981594
}
#Debug simulation 
Total elapsed time: 2.118502933997661. Arrivals time: 0.06960184872150421 Scheduler time: 1.6809306554496288 Scheduler overhead time: 0.13829538878053427 Adapter cache time: 0.02599336253479123 Engine time: 0.13569724652916193 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 8640, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74790 . Total input tokens: 16638690 . Total output tokens: 14943512
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.12434061197564,
    "estimated_duration": 3599.9718852130172,
    "input_throughput": 1714.3367217254856,
    "output_throughput": 1534.1583701488262,
    "total_throughput": 3248.495091874312,
    "itl": 22.193144870885195,
    "ttft": 6796.590176340023,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 25030,
    "finished_requests": 24983,
    "scheduler_time": 0.08823156537008153
}
#Debug simulation 
Total elapsed time: 2.1244299919344485. Arrivals time: 0.07018091296777129 Scheduler time: 1.6866792514920235 Scheduler overhead time: 0.13938740035519004 Adapter cache time: 0.026031963527202606 Engine time: 0.13460827060043812 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 8640, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74790 . Total input tokens: 16638690 . Total output tokens: 14943512
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.129061108920723,
    "estimated_duration": 3599.9700770171726,
    "input_throughput": 1714.337582803903,
    "output_throughput": 1534.1591407271173,
    "total_throughput": 3248.4967235310205,
    "itl": 22.193069910916456,
    "ttft": 6796.566935067909,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 25030,
    "finished_requests": 24983,
    "scheduler_time": 0.08823394220610474
}
#Debug simulation 
Total elapsed time: 2.1291520153172314. Arrivals time: 0.07208199892193079 Scheduler time: 1.6887295097112656 Scheduler overhead time: 0.13910108525305986 Adapter cache time: 0.025884914677590132 Engine time: 0.1353377322666347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.025_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.4   0.8  ]. Counts: [5 5 6]
Adapter prompts. [4320, 270, 270, 4320, 8640, 270, 8640, 270, 4320, 4320, 270, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74790 . Total input tokens: 16638690 . Total output tokens: 14943512
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.121980318799615,
    "estimated_duration": 3599.9748863369136,
    "input_throughput": 1714.3352925663762,
    "output_throughput": 1534.1570911956417,
    "total_throughput": 3248.492383762018,
    "itl": 22.193173880736808,
    "ttft": 6796.615453566994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 25030,
    "finished_requests": 24983,
    "scheduler_time": 0.08824036385016917
}
#Debug simulation 
Total elapsed time: 2.1220688987523317. Arrivals time: 0.06993891438469291 Scheduler time: 1.683341565541923 Scheduler overhead time: 0.13936604326590896 Adapter cache time: 0.025972464587539434 Engine time: 0.13566105999052525 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 8640, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74115 . Total input tokens: 16498677 . Total output tokens: 14806816
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.0777107919566333,
    "estimated_duration": 3599.781701216315,
    "input_throughput": 1699.492221412449,
    "output_throughput": 1496.5896399161304,
    "total_throughput": 3196.081861328579,
    "itl": 22.03396090292716,
    "ttft": 7005.001520229482,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 24797,
    "finished_requests": 24749,
    "scheduler_time": 0.10028996586039945
}
#Debug simulation 
Total elapsed time: 2.077805650886148. Arrivals time: 0.06980917928740382 Scheduler time: 1.6401114892214537 Scheduler overhead time: 0.13837220426648855 Adapter cache time: 0.025709919165819883 Engine time: 0.13646216364577413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 8640, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74115 . Total input tokens: 16498677 . Total output tokens: 14806816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.0765265352092683,
    "estimated_duration": 3599.779348178337,
    "input_throughput": 1699.4933323054659,
    "output_throughput": 1496.5906181794958,
    "total_throughput": 3196.083950484962,
    "itl": 22.03108721226382,
    "ttft": 7004.950851812575,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 24797,
    "finished_requests": 24749,
    "scheduler_time": 0.10029292643842391
}
#Debug simulation 
Total elapsed time: 2.0766153349541128. Arrivals time: 0.06884505832567811 Scheduler time: 1.6398754711262882 Scheduler overhead time: 0.14041257044300437 Adapter cache time: 0.0257896208204329 Engine time: 0.13349608052521944 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 8640, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74115 . Total input tokens: 16498677 . Total output tokens: 14806816
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.086919834371656,
    "estimated_duration": 3599.779440107036,
    "input_throughput": 1699.4932889049705,
    "output_throughput": 1496.590579960591,
    "total_throughput": 3196.0838688655613,
    "itl": 22.031102044739356,
    "ttft": 7004.92531907615,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 24797,
    "finished_requests": 24749,
    "scheduler_time": 0.10028233486431433
}
#Debug simulation 
Total elapsed time: 2.087006422225386. Arrivals time: 0.06781457550823689 Scheduler time: 1.6515291486866772 Scheduler overhead time: 0.1399300624616444 Adapter cache time: 0.02567977085709572 Engine time: 0.1337593924254179 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 8640, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74115 . Total input tokens: 16498677 . Total output tokens: 14806816
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.086519360076636,
    "estimated_duration": 3599.779160299915,
    "input_throughput": 1699.493421004831,
    "output_throughput": 1496.5906962890328,
    "total_throughput": 3196.084117293864,
    "itl": 22.031086844058045,
    "ttft": 7004.931625356386,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 24797,
    "finished_requests": 24749,
    "scheduler_time": 0.1002719935342125
}
#Debug simulation 
Total elapsed time: 2.0866092070937157. Arrivals time: 0.07059889286756516 Scheduler time: 1.6488279504701495 Scheduler overhead time: 0.13913998240604997 Adapter cache time: 0.025750963483005762 Engine time: 0.13420865638181567 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 8640, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74115 . Total input tokens: 16498677 . Total output tokens: 14806816
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.086778039112687,
    "estimated_duration": 3599.7796320449097,
    "input_throughput": 1699.4931982891103,
    "output_throughput": 1496.5905001633691,
    "total_throughput": 3196.0836984524794,
    "itl": 22.0311021101709,
    "ttft": 7004.9813644980395,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 24797,
    "finished_requests": 24749,
    "scheduler_time": 0.10029697124646518
}
#Debug simulation 
Total elapsed time: 2.0868711238726974. Arrivals time: 0.07001312263309956 Scheduler time: 1.6517362110316753 Scheduler overhead time: 0.1387472953647375 Adapter cache time: 0.02566799195483327 Engine time: 0.1325028445571661 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 8640, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74115 . Total input tokens: 16498677 . Total output tokens: 14806816
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.0933332298882306,
    "estimated_duration": 3599.780618417385,
    "input_throughput": 1699.4927326125899,
    "output_throughput": 1496.5900900840245,
    "total_throughput": 3196.082822696614,
    "itl": 22.034000294009402,
    "ttft": 7005.001890155635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 24797,
    "finished_requests": 24749,
    "scheduler_time": 0.10025093550799724
}
#Debug simulation 
Total elapsed time: 2.0934194452129304. Arrivals time: 0.06949874060228467 Scheduler time: 1.6537639340385795 Scheduler overhead time: 0.13961287215352058 Adapter cache time: 0.025547670666128397 Engine time: 0.13676281087100506 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.4    0.8   ]. Counts: [5 5 6]
Adapter prompts. [4320, 135, 135, 4320, 8640, 135, 8640, 135, 4320, 4320, 135, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 74115 . Total input tokens: 16498677 . Total output tokens: 14806816
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.1165567128919065,
    "estimated_duration": 3599.7796077428966,
    "input_throughput": 1699.493209762342,
    "output_throughput": 1496.5905102668103,
    "total_throughput": 3196.0837200291526,
    "itl": 22.03109969277229,
    "ttft": 7004.991378153488,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 24797,
    "finished_requests": 24749,
    "scheduler_time": 0.10030185004051545
}
#Debug simulation 
Total elapsed time: 2.1166456788778305. Arrivals time: 0.06965422863140702 Scheduler time: 1.6761483056470752 Scheduler overhead time: 0.14028789568692446 Adapter cache time: 0.025955865625292063 Engine time: 0.13592129992321134 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 8640, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73770 . Total input tokens: 16422840 . Total output tokens: 14734422
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.1015875921584666,
    "estimated_duration": 3599.6813026231034,
    "input_throughput": 1693.844673292847,
    "output_throughput": 1508.2888021346785,
    "total_throughput": 3202.1334754275254,
    "itl": 22.02667495937279,
    "ttft": 5136.823009745568,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 24704,
    "finished_requests": 24669,
    "scheduler_time": 0.06245303159982364
}
#Debug simulation 
Total elapsed time: 2.1016811770386994. Arrivals time: 0.07021243683993816 Scheduler time: 1.6618287530727684 Scheduler overhead time: 0.140102066565305 Adapter cache time: 0.025368204805999994 Engine time: 0.1360389762558043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 8640, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73770 . Total input tokens: 16422840 . Total output tokens: 14734422
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.084140932187438,
    "estimated_duration": 3599.6688744576004,
    "input_throughput": 1693.8505214368486,
    "output_throughput": 1508.2940096311215,
    "total_throughput": 3202.14453106797,
    "itl": 22.026704469723533,
    "ttft": 5136.841681652813,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 24704,
    "finished_requests": 24669,
    "scheduler_time": 0.062452072491810715
}
#Debug simulation 
Total elapsed time: 2.0842297268100083. Arrivals time: 0.06885208003222942 Scheduler time: 1.6493207486346364 Scheduler overhead time: 0.13905584858730435 Adapter cache time: 0.02528439462184906 Engine time: 0.13298875838518143 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 8640, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73770 . Total input tokens: 16422840 . Total output tokens: 14734422
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.090587231796235,
    "estimated_duration": 3599.6685172843154,
    "input_throughput": 1693.8506895073672,
    "output_throughput": 1508.2941592899924,
    "total_throughput": 3202.14484879736,
    "itl": 22.02671513014594,
    "ttft": 5136.848133921376,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 24704,
    "finished_requests": 24669,
    "scheduler_time": 0.06246099609390224
}
#Debug simulation 
Total elapsed time: 2.0907057616859674. Arrivals time: 0.06769773829728365 Scheduler time: 1.653592157177627 Scheduler overhead time: 0.13979155058041215 Adapter cache time: 0.025009713601320982 Engine time: 0.13616327848285437 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 8640, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73770 . Total input tokens: 16422840 . Total output tokens: 14734422
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.1005015489645302,
    "estimated_duration": 3599.668511522832,
    "input_throughput": 1693.850692218476,
    "output_throughput": 1508.294161704107,
    "total_throughput": 3202.144853922583,
    "itl": 22.02676358751004,
    "ttft": 5136.806361477759,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 24704,
    "finished_requests": 24669,
    "scheduler_time": 0.06246670887396155
}
#Debug simulation 
Total elapsed time: 2.1006026756949723. Arrivals time: 0.0677459379658103 Scheduler time: 1.663931899704039 Scheduler overhead time: 0.14157888386398554 Adapter cache time: 0.025183994323015213 Engine time: 0.13333563739433885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 8640, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73770 . Total input tokens: 16422840 . Total output tokens: 14734422
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.086671895813197,
    "estimated_duration": 3599.6683526145753,
    "input_throughput": 1693.850766993937,
    "output_throughput": 1508.2942282881286,
    "total_throughput": 3202.144995282066,
    "itl": 22.026729753494795,
    "ttft": 5136.857445813282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 24704,
    "finished_requests": 24669,
    "scheduler_time": 0.0624496956557875
}
#Debug simulation 
Total elapsed time: 2.086764550767839. Arrivals time: 0.0692355721257627 Scheduler time: 1.650607471819967 Scheduler overhead time: 0.1387664801441133 Adapter cache time: 0.02506377175450325 Engine time: 0.13573225028812885 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 8640, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73770 . Total input tokens: 16422840 . Total output tokens: 14734422
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.086195519194007,
    "estimated_duration": 3599.6793044224005,
    "input_throughput": 1693.8456135548342,
    "output_throughput": 1508.289639393637,
    "total_throughput": 3202.135252948471,
    "itl": 22.026668744017748,
    "ttft": 5136.851750276184,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 24704,
    "finished_requests": 24669,
    "scheduler_time": 0.06235382961481817
}
#Debug simulation 
Total elapsed time: 2.0862642978318036. Arrivals time: 0.06548812799155712 Scheduler time: 1.6543727302923799 Scheduler overhead time: 0.13830816047266126 Adapter cache time: 0.025054949335753918 Engine time: 0.13523590378463268 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.4     0.8    ]. Counts: [5 5 6]
Adapter prompts. [4320, 66, 66, 4320, 8640, 66, 8640, 66, 4320, 4320, 66, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73770 . Total input tokens: 16422840 . Total output tokens: 14734422
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.074873223900795,
    "estimated_duration": 3599.66873376658,
    "input_throughput": 1693.85058764004,
    "output_throughput": 1508.2940685819415,
    "total_throughput": 3202.144656221981,
    "itl": 22.02672050327157,
    "ttft": 5136.847436051393,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 24704,
    "finished_requests": 24669,
    "scheduler_time": 0.06244898679178234
}
#Debug simulation 
Total elapsed time: 2.0749473022297025. Arrivals time: 0.06423990754410625 Scheduler time: 1.645255250390619 Scheduler overhead time: 0.13863994320854545 Adapter cache time: 0.025085631292313337 Engine time: 0.1340128891170025 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 8640, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73605 . Total input tokens: 16389719 . Total output tokens: 14701664
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.0819544177502394,
    "estimated_duration": 3599.9265157411182,
    "input_throughput": 1677.6803564160089,
    "output_throughput": 1493.842992762558,
    "total_throughput": 3171.5233491785666,
    "itl": 22.017350524618664,
    "ttft": 5437.546117189225,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 24661,
    "finished_requests": 24624,
    "scheduler_time": 0.08163359699566564
}
#Debug simulation 
Total elapsed time: 2.082036606967449. Arrivals time: 0.06552378414198756 Scheduler time: 1.648120007943362 Scheduler overhead time: 0.13933230517432094 Adapter cache time: 0.025047695264220238 Engine time: 0.13612947054207325 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 8640, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73605 . Total input tokens: 16389719 . Total output tokens: 14701664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.0576354498043656,
    "estimated_duration": 3599.913318659429,
    "input_throughput": 1677.6865066987384,
    "output_throughput": 1493.8484691077533,
    "total_throughput": 3171.5349758064917,
    "itl": 22.015294338804473,
    "ttft": 5437.625719240121,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 24661,
    "finished_requests": 24624,
    "scheduler_time": 0.08158827012120265
}
#Debug simulation 
Total elapsed time: 2.0577175808139145. Arrivals time: 0.0643918220885098 Scheduler time: 1.6266367412172258 Scheduler overhead time: 0.13919543102383614 Adapter cache time: 0.025254613254219294 Engine time: 0.13391363807022572 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 8640, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73605 . Total input tokens: 16389719 . Total output tokens: 14701664
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.072778042871505,
    "estimated_duration": 3599.9133390898287,
    "input_throughput": 1677.686497177452,
    "output_throughput": 1493.8484606297934,
    "total_throughput": 3171.5349578072455,
    "itl": 22.01529866501969,
    "ttft": 5437.625712367355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 24661,
    "finished_requests": 24624,
    "scheduler_time": 0.0815923149292439
}
#Debug simulation 
Total elapsed time: 2.072853385936469. Arrivals time: 0.06525526428595185 Scheduler time: 1.6390957133844495 Scheduler overhead time: 0.13954204646870494 Adapter cache time: 0.025235718116164207 Engine time: 0.13536163978278637 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 8640, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73605 . Total input tokens: 16389719 . Total output tokens: 14701664
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 2.0658922800794244,
    "estimated_duration": 3599.9349860714783,
    "input_throughput": 1677.6764089817045,
    "output_throughput": 1493.8394778813995,
    "total_throughput": 3171.515886863104,
    "itl": 22.015320579719752,
    "ttft": 5437.615163545347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 24661,
    "finished_requests": 24624,
    "scheduler_time": 0.08165202794184977
}
#Debug simulation 
Total elapsed time: 2.065989256836474. Arrivals time: 0.0646061822772026 Scheduler time: 1.6364144762046635 Scheduler overhead time: 0.13942250469699502 Adapter cache time: 0.025195087771862745 Engine time: 0.13221854669973254 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 8640, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73605 . Total input tokens: 16389719 . Total output tokens: 14701664
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 2.070694216992706,
    "estimated_duration": 3599.913348231642,
    "input_throughput": 1677.686492917045,
    "output_throughput": 1493.8484568362344,
    "total_throughput": 3171.5349497532793,
    "itl": 22.015300834467688,
    "ttft": 5437.621153613345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 24661,
    "finished_requests": 24624,
    "scheduler_time": 0.0815923149292439
}
#Debug simulation 
Total elapsed time: 2.0707717519253492. Arrivals time: 0.06602646689862013 Scheduler time: 1.6347115319222212 Scheduler overhead time: 0.1389298322610557 Adapter cache time: 0.02518863044679165 Engine time: 0.13765475992113352 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 8640, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73605 . Total input tokens: 16389719 . Total output tokens: 14701664
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 2.0507154064252973,
    "estimated_duration": 3599.9233614568093,
    "input_throughput": 1677.6818264141982,
    "output_throughput": 1493.844301680843,
    "total_throughput": 3171.5261280950413,
    "itl": 22.017352833528687,
    "ttft": 5437.5558537917605,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 24661,
    "finished_requests": 24624,
    "scheduler_time": 0.0816990227883307
}
#Debug simulation 
Total elapsed time: 2.0507934424094856. Arrivals time: 0.0651767267845571 Scheduler time: 1.6209356631152332 Scheduler overhead time: 0.1394944223575294 Adapter cache time: 0.024912510998547077 Engine time: 0.1324580400250852 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.4,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.4-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.4-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.4      0.8     ]. Counts: [5 5 6]
Adapter prompts. [4320, 33, 33, 4320, 8640, 33, 8640, 33, 4320, 4320, 33, 4320, 8640, 8640, 8640, 8640]
Prompts retrieved: 73605 . Total input tokens: 16389719 . Total output tokens: 14701664
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 2.061825746204704,
    "estimated_duration": 3599.913332762774,
    "input_throughput": 1677.6865001260826,
    "output_throughput": 1493.848463255318,
    "total_throughput": 3171.5349633814003,
    "itl": 22.01529867489519,
    "ttft": 5437.625440538306,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 24661,
    "finished_requests": 24624,
    "scheduler_time": 0.08160766017539989
}
#Debug simulation 
Total elapsed time: 2.061899590305984. Arrivals time: 0.06426949286833405 Scheduler time: 1.6316546518355608 Scheduler overhead time: 0.1397502524778247 Adapter cache time: 0.025088700465857983 Engine time: 0.13280938332900405 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 8640, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 59940 . Total input tokens: 13300467 . Total output tokens: 12010419
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.8033651118166745,
    "estimated_duration": 3600.0064743638295,
    "input_throughput": 1376.5411354921841,
    "output_throughput": 1232.3102837707977,
    "total_throughput": 2608.851419262982,
    "itl": 21.105081660965407,
    "ttft": 6470.472994237373,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 20138,
    "finished_requests": 20102,
    "scheduler_time": 1.3927518145683454e-05
}
#Debug simulation 
Total elapsed time: 1.803455124143511. Arrivals time: 0.05663909576833248 Scheduler time: 1.366317552048713 Scheduler overhead time: 0.1428379318676889 Adapter cache time: 0.028452621772885323 Engine time: 0.1391322617419064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 8640, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 59940 . Total input tokens: 13300467 . Total output tokens: 12010419
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.8025615401566029,
    "estimated_duration": 3600.010175208383,
    "input_throughput": 1376.5397203948605,
    "output_throughput": 1232.3090169441557,
    "total_throughput": 2608.848737339016,
    "itl": 21.104976478321433,
    "ttft": 6470.412378375539,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 20138,
    "finished_requests": 20102,
    "scheduler_time": 9.882710104434141e-06
}
#Debug simulation 
Total elapsed time: 1.8026565629988909. Arrivals time: 0.05910655949264765 Scheduler time: 1.3627552520483732 Scheduler overhead time: 0.14369015488773584 Adapter cache time: 0.02841760264709592 Engine time: 0.13828100729733706 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 8640, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 59940 . Total input tokens: 13300467 . Total output tokens: 12010419
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.8111460232175887,
    "estimated_duration": 3600.010622214532,
    "input_throughput": 1376.539549472665,
    "output_throughput": 1232.3088639307994,
    "total_throughput": 2608.8484134034643,
    "itl": 21.104986034982193,
    "ttft": 6470.429946643191,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 20138,
    "finished_requests": 20102,
    "scheduler_time": 9.882710104434141e-06
}
#Debug simulation 
Total elapsed time: 1.8112442293204367. Arrivals time: 0.06088146287947893 Scheduler time: 1.3711605314165354 Scheduler overhead time: 0.14138466631993651 Adapter cache time: 0.028564059641212225 Engine time: 0.1394411688670516 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 8640, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 59940 . Total input tokens: 13300467 . Total output tokens: 12010419
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.8056436921469867,
    "estimated_duration": 3600.0073744693505,
    "input_throughput": 1376.540791317257,
    "output_throughput": 1232.3099756577374,
    "total_throughput": 2608.8507669749943,
    "itl": 21.105056879908478,
    "ttft": 6470.384988987237,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 20138,
    "finished_requests": 20102,
    "scheduler_time": 1.309353213665705e-05
}
#Debug simulation 
Total elapsed time: 1.8057443383149803. Arrivals time: 0.059570937883108854 Scheduler time: 1.3668993483297527 Scheduler overhead time: 0.1427028989419341 Adapter cache time: 0.02836765768006444 Engine time: 0.1376606160774827 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 8640, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 59940 . Total input tokens: 13300467 . Total output tokens: 12010419
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.8206549799069762,
    "estimated_duration": 3600.01123835632,
    "input_throughput": 1376.5393138779727,
    "output_throughput": 1232.3086530211835,
    "total_throughput": 2608.8479668991563,
    "itl": 21.105039763124424,
    "ttft": 6470.401900925949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 20138,
    "finished_requests": 20102,
    "scheduler_time": 1.3927518145683454e-05
}
#Debug simulation 
Total elapsed time: 1.820776792243123. Arrivals time: 0.05758081469684839 Scheduler time: 1.3799922037869692 Scheduler overhead time: 0.14393104426562786 Adapter cache time: 0.02836841018870473 Engine time: 0.14044848456978798 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 8640, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 59940 . Total input tokens: 13300467 . Total output tokens: 12010419
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.8024330753833055,
    "estimated_duration": 3600.0041468348563,
    "input_throughput": 1376.5420254743187,
    "output_throughput": 1232.3110805026272,
    "total_throughput": 2608.8531059769457,
    "itl": 21.1050251123035,
    "ttft": 6470.518812906635,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 20138,
    "finished_requests": 20102,
    "scheduler_time": 1.3927518145683454e-05
}
#Debug simulation 
Total elapsed time: 1.8025327622890472. Arrivals time: 0.058466422371566296 Scheduler time: 1.367213769350201 Scheduler overhead time: 0.14218155993148685 Adapter cache time: 0.02854050789028406 Engine time: 0.13653616700321436 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.05_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.1  0.8 ]. Counts: [5 5 6]
Adapter prompts. [1080, 540, 540, 1080, 8640, 540, 8640, 540, 1080, 1080, 540, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 59940 . Total input tokens: 13300467 . Total output tokens: 12010419
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.809492350090295,
    "estimated_duration": 3600.011245108253,
    "input_throughput": 1376.5393112962304,
    "output_throughput": 1232.3086507099504,
    "total_throughput": 2608.8479620061808,
    "itl": 21.105043722796204,
    "ttft": 6470.403871311099,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 20138,
    "finished_requests": 20102,
    "scheduler_time": 1.3927518145683454e-05
}
#Debug simulation 
Total elapsed time: 1.8095858190208673. Arrivals time: 0.05930331302806735 Scheduler time: 1.3693777318112552 Scheduler overhead time: 0.1427085460163653 Adapter cache time: 0.02833694452419877 Engine time: 0.13993278937414289 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 8640, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 58590 . Total input tokens: 13000283 . Total output tokens: 11732486
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7960056657902896,
    "estimated_duration": 3599.801739150675,
    "input_throughput": 1352.7569996532447,
    "output_throughput": 1212.750122463694,
    "total_throughput": 2565.5071221169387,
    "itl": 20.94809910973785,
    "ttft": 4600.808613335585,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 19710,
    "finished_requests": 19685,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7961025070399046. Arrivals time: 0.058294204995036125 Scheduler time: 1.3492293027229607 Scheduler overhead time: 0.14762358693405986 Adapter cache time: 0.027841117698699236 Engine time: 0.14234293950721622 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 8640, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 58590 . Total input tokens: 13000283 . Total output tokens: 11732486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7908196030184627,
    "estimated_duration": 3599.8033990354993,
    "input_throughput": 1352.7563758911763,
    "output_throughput": 1212.7495632593984,
    "total_throughput": 2565.5059391505747,
    "itl": 20.94807765882118,
    "ttft": 4600.8005721525205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 19710,
    "finished_requests": 19685,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7909138910472393. Arrivals time: 0.05777578707784414 Scheduler time: 1.3503835974261165 Scheduler overhead time: 0.14630161691457033 Adapter cache time: 0.027626177296042442 Engine time: 0.13755153119564056 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 8640, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 58590 . Total input tokens: 13000283 . Total output tokens: 11732486
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.787634639069438,
    "estimated_duration": 3599.8034819560958,
    "input_throughput": 1352.7563447307627,
    "output_throughput": 1212.7495353240076,
    "total_throughput": 2565.5058800547704,
    "itl": 20.94808185124923,
    "ttft": 4600.810196665123,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 19710,
    "finished_requests": 19685,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7877222918905318. Arrivals time: 0.05851246742531657 Scheduler time: 1.346169778611511 Scheduler overhead time: 0.14394325111061335 Adapter cache time: 0.027570215985178947 Engine time: 0.14072627993300557 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 8640, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 58590 . Total input tokens: 13000283 . Total output tokens: 11732486
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7790827518329024,
    "estimated_duration": 3599.801944517177,
    "input_throughput": 1352.7569224792844,
    "output_throughput": 1212.7500532770403,
    "total_throughput": 2565.5069757563247,
    "itl": 20.94808325815227,
    "ttft": 4600.814747866434,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 19710,
    "finished_requests": 19685,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7791735739447176. Arrivals time: 0.057480653282254934 Scheduler time: 1.3401594064198434 Scheduler overhead time: 0.14381359284743667 Adapter cache time: 0.027500362135469913 Engine time: 0.13927543628960848 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 8640, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 58590 . Total input tokens: 13000283 . Total output tokens: 11732486
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.785058369860053,
    "estimated_duration": 3599.803322938236,
    "input_throughput": 1352.756404487477,
    "output_throughput": 1212.7495888960555,
    "total_throughput": 2565.5059933835323,
    "itl": 20.948078428509753,
    "ttft": 4600.800259812879,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 19710,
    "finished_requests": 19685,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7851517917588353. Arrivals time: 0.05789457680657506 Scheduler time: 1.3446904723532498 Scheduler overhead time: 0.14349305164068937 Adapter cache time: 0.027554351836442947 Engine time: 0.14139070874080062 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 8640, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 58590 . Total input tokens: 13000283 . Total output tokens: 11732486
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7888950402848423,
    "estimated_duration": 3599.8008170605526,
    "input_throughput": 1352.75734616238,
    "output_throughput": 1212.750433110023,
    "total_throughput": 2565.507779272403,
    "itl": 20.94811643525802,
    "ttft": 4600.834037545957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 19710,
    "finished_requests": 19685,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7890242110006511. Arrivals time: 0.05816950090229511 Scheduler time: 1.3471445478498936 Scheduler overhead time: 0.14704466192051768 Adapter cache time: 0.027428543660789728 Engine time: 0.13789401948451996 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.025_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.1   0.8  ]. Counts: [5 5 6]
Adapter prompts. [1080, 270, 270, 1080, 8640, 270, 8640, 270, 1080, 1080, 270, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 58590 . Total input tokens: 13000283 . Total output tokens: 11732486
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7823280300945044,
    "estimated_duration": 3599.784277144596,
    "input_throughput": 1352.763561671725,
    "output_throughput": 1212.756005330105,
    "total_throughput": 2565.51956700183,
    "itl": 20.94814884254671,
    "ttft": 4600.830526754905,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 19710,
    "finished_requests": 19685,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7824138919822872. Arrivals time: 0.057688616681843996 Scheduler time: 1.3430449524894357 Scheduler overhead time: 0.14334616670385003 Adapter cache time: 0.02752898121252656 Engine time: 0.1404257956892252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 8640, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57915 . Total input tokens: 12849733 . Total output tokens: 11600581
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7553023002110422,
    "estimated_duration": 3599.9372339393535,
    "input_throughput": 1345.6462391426264,
    "output_throughput": 1181.0278134620457,
    "total_throughput": 2526.674052604672,
    "itl": 20.784670087280738,
    "ttft": 5022.271369027365,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 19487,
    "finished_requests": 19460,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.7553994031623006. Arrivals time: 0.057277265936136246 Scheduler time: 1.3157350234687328 Scheduler overhead time: 0.14600653713569045 Adapter cache time: 0.026955868117511272 Engine time: 0.13814073195680976 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 8640, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57915 . Total input tokens: 12849733 . Total output tokens: 11600581
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7509876410476863,
    "estimated_duration": 3599.9291497383715,
    "input_throughput": 1345.6492610006117,
    "output_throughput": 1181.030465643745,
    "total_throughput": 2526.679726644357,
    "itl": 20.78079030799187,
    "ttft": 5022.306693592359,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 19487,
    "finished_requests": 19460,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.7511032801121473. Arrivals time: 0.05598922725766897 Scheduler time: 1.3119198293425143 Scheduler overhead time: 0.14452910562977195 Adapter cache time: 0.027172487694770098 Engine time: 0.1406893958337605 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 8640, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57915 . Total input tokens: 12849733 . Total output tokens: 11600581
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7580028306692839,
    "estimated_duration": 3599.9291885596963,
    "input_throughput": 1345.6492464892465,
    "output_throughput": 1181.0304529076147,
    "total_throughput": 2526.6796993968615,
    "itl": 20.780797170966473,
    "ttft": 5022.312365459455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.052406024020165184,
    "arrivals": 19487,
    "finished_requests": 19460,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.7580992900766432. Arrivals time: 0.057828811928629875 Scheduler time: 1.3181446534581482 Scheduler overhead time: 0.14427643502131104 Adapter cache time: 0.02710510976612568 Engine time: 0.13928709598258138 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 8640, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57915 . Total input tokens: 12849733 . Total output tokens: 11600581
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7650380656123161,
    "estimated_duration": 3599.9272980586,
    "input_throughput": 1345.6499531566776,
    "output_throughput": 1181.0310731255195,
    "total_throughput": 2526.681026282197,
    "itl": 20.780770156421056,
    "ttft": 5022.318716300371,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 19487,
    "finished_requests": 19460,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.7651355499401689. Arrivals time: 0.05716513888910413 Scheduler time: 1.3267986341379583 Scheduler overhead time: 0.14484660094603896 Adapter cache time: 0.027265929616987705 Engine time: 0.1377892680466175 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 8640, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57915 . Total input tokens: 12849733 . Total output tokens: 11600581
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.7618226991035044,
    "estimated_duration": 3599.9293075399287,
    "input_throughput": 1345.6492020145788,
    "output_throughput": 1181.0304138737156,
    "total_throughput": 2526.6796158882944,
    "itl": 20.780798510206505,
    "ttft": 5022.3224834031835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 19487,
    "finished_requests": 19460,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.761914755217731. Arrivals time: 0.05752086220309138 Scheduler time: 1.3195155332796276 Scheduler overhead time: 0.14420425239950418 Adapter cache time: 0.02716913167387247 Engine time: 0.14229999156668782 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 8640, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57915 . Total input tokens: 12849733 . Total output tokens: 11600581
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.750129968393594,
    "estimated_duration": 3599.9217526907546,
    "input_throughput": 1345.652026013949,
    "output_throughput": 1181.0328924016558,
    "total_throughput": 2526.684918415605,
    "itl": 20.78078806831003,
    "ttft": 5022.260685222292,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 19487,
    "finished_requests": 19460,
    "scheduler_time": 1.6679720180528082e-06
}
#Debug simulation 
Total elapsed time: 1.7502252240665257. Arrivals time: 0.057091225404292345 Scheduler time: 1.3112313887104392 Scheduler overhead time: 0.14414778165519238 Adapter cache time: 0.02725045010447502 Engine time: 0.1395254721865058 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.1    0.8   ]. Counts: [5 5 6]
Adapter prompts. [1080, 135, 135, 1080, 8640, 135, 8640, 135, 1080, 1080, 135, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57915 . Total input tokens: 12849733 . Total output tokens: 11600581
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7481211652047932,
    "estimated_duration": 3599.930439282669,
    "input_throughput": 1345.6487789706503,
    "output_throughput": 1181.0300425824867,
    "total_throughput": 2526.678821553137,
    "itl": 20.780782307629295,
    "ttft": 5022.343252131079,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 19487,
    "finished_requests": 19460,
    "scheduler_time": 2.5019580270792122e-06
}
#Debug simulation 
Total elapsed time: 1.7482186681590974. Arrivals time: 0.05582762509584427 Scheduler time: 1.3079456118866801 Scheduler overhead time: 0.14437081292271614 Adapter cache time: 0.026983574498444796 Engine time: 0.14237910509109497 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 8640, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57570 . Total input tokens: 12773832 . Total output tokens: 11532201
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7448065760545433,
    "estimated_duration": 3599.8755147407796,
    "input_throughput": 1338.8974091641803,
    "output_throughput": 1181.044728516439,
    "total_throughput": 2519.9421376806195,
    "itl": 20.719372850241264,
    "ttft": 8398.170024100833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 19369,
    "finished_requests": 19324,
    "scheduler_time": 6.763612071686889e-05
}
#Debug simulation 
Total elapsed time: 1.7449056482873857. Arrivals time: 0.05652324948459864 Scheduler time: 1.306216998025775 Scheduler overhead time: 0.14527561888098717 Adapter cache time: 0.0269621005281806 Engine time: 0.1387908454053104 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 8640, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57570 . Total input tokens: 12773832 . Total output tokens: 11532201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7483442979864776,
    "estimated_duration": 3599.85542864299,
    "input_throughput": 1338.9048798042725,
    "output_throughput": 1181.0513183866105,
    "total_throughput": 2519.956198190883,
    "itl": 20.71935516397479,
    "ttft": 8398.08808418816,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 19369,
    "finished_requests": 19324,
    "scheduler_time": 6.680213470784248e-05
}
#Debug simulation 
Total elapsed time: 1.7484490210190415. Arrivals time: 0.055747224017977715 Scheduler time: 1.3098937598988414 Scheduler overhead time: 0.1445650369860232 Adapter cache time: 0.026873225811868906 Engine time: 0.1406941949389875 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 8640, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57570 . Total input tokens: 12773832 . Total output tokens: 11532201
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7580302162095904,
    "estimated_duration": 3599.855878983768,
    "input_throughput": 1338.9047123077155,
    "output_throughput": 1181.0511706374818,
    "total_throughput": 2519.955882945197,
    "itl": 20.719340451115414,
    "ttft": 8398.120045751417,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 19369,
    "finished_requests": 19324,
    "scheduler_time": 6.680213470784248e-05
}
#Debug simulation 
Total elapsed time: 1.758160897064954. Arrivals time: 0.057133547496050596 Scheduler time: 1.318598980549723 Scheduler overhead time: 0.14512187615036964 Adapter cache time: 0.026859006378799677 Engine time: 0.1391702750697732 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 8640, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57570 . Total input tokens: 12773832 . Total output tokens: 11532201
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.751611849758774,
    "estimated_duration": 3599.8534312456163,
    "input_throughput": 1338.9056227025992,
    "output_throughput": 1181.0519736990686,
    "total_throughput": 2519.957596401668,
    "itl": 20.719373585412118,
    "ttft": 8398.062468732227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 19369,
    "finished_requests": 19324,
    "scheduler_time": 6.596814869881608e-05
}
#Debug simulation 
Total elapsed time: 1.751708549913019. Arrivals time: 0.05531270895153284 Scheduler time: 1.3105815052986145 Scheduler overhead time: 0.14465593546628952 Adapter cache time: 0.026794887613505125 Engine time: 0.14314228016883135 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 8640, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57570 . Total input tokens: 12773832 . Total output tokens: 11532201
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.7427685027942061,
    "estimated_duration": 3599.8559387580794,
    "input_throughput": 1338.9046900756848,
    "output_throughput": 1181.0511510265524,
    "total_throughput": 2519.955841102237,
    "itl": 20.719326842351382,
    "ttft": 8398.088413161156,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 19369,
    "finished_requests": 19324,
    "scheduler_time": 6.680213470784248e-05
}
#Debug simulation 
Total elapsed time: 1.7428664029575884. Arrivals time: 0.05668588913977146 Scheduler time: 1.306375049520284 Scheduler overhead time: 0.14430092880502343 Adapter cache time: 0.026942006777971983 Engine time: 0.1379366130568087 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 8640, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57570 . Total input tokens: 12773832 . Total output tokens: 11532201
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7546340459957719,
    "estimated_duration": 3599.8754693048586,
    "input_throughput": 1338.8974260631085,
    "output_throughput": 1181.0447434230255,
    "total_throughput": 2519.942169486134,
    "itl": 20.71932088436283,
    "ttft": 8398.167972377632,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 19369,
    "finished_requests": 19324,
    "scheduler_time": 7.572573679936751e-05
}
#Debug simulation 
Total elapsed time: 1.7547520687803626. Arrivals time: 0.05485863145440817 Scheduler time: 1.319011988118291 Scheduler overhead time: 0.14440849050879478 Adapter cache time: 0.027230422012507915 Engine time: 0.13851779140532017 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.1     0.8    ]. Counts: [5 5 6]
Adapter prompts. [1080, 66, 66, 1080, 8640, 66, 8640, 66, 1080, 1080, 66, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57570 . Total input tokens: 12773832 . Total output tokens: 11532201
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7579045817255974,
    "estimated_duration": 3599.855882627715,
    "input_throughput": 1338.9047109524117,
    "output_throughput": 1181.0511694419652,
    "total_throughput": 2519.955880394377,
    "itl": 20.71932186618127,
    "ttft": 8398.096768031803,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 19369,
    "finished_requests": 19324,
    "scheduler_time": 6.680213470784248e-05
}
#Debug simulation 
Total elapsed time: 1.7580227558501065. Arrivals time: 0.05742218950763345 Scheduler time: 1.3160305777564645 Scheduler overhead time: 0.14457663102075458 Adapter cache time: 0.02683459408581257 Engine time: 0.1415794836357236 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 8640, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57405 . Total input tokens: 12735595 . Total output tokens: 11501261
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.743964732158929,
    "estimated_duration": 3600.00285793583,
    "input_throughput": 1338.4450485583166,
    "output_throughput": 1173.814068142977,
    "total_throughput": 2512.2591167012934,
    "itl": 20.72859084641548,
    "ttft": 4698.437220679461,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 19297,
    "finished_requests": 19271,
    "scheduler_time": 1.5011748162475273e-05
}
#Debug simulation 
Total elapsed time: 1.744063374120742. Arrivals time: 0.0547601692378521 Scheduler time: 1.3069915133528411 Scheduler overhead time: 0.1450798767618835 Adapter cache time: 0.026694986037909985 Engine time: 0.13935138238593936 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 8640, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57405 . Total input tokens: 12735595 . Total output tokens: 11501261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.772682337090373,
    "estimated_duration": 3600.005460751354,
    "input_throughput": 1338.4440808582426,
    "output_throughput": 1173.8132194716313,
    "total_throughput": 2512.257300329874,
    "itl": 20.728598350750545,
    "ttft": 4698.505510530496,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 19297,
    "finished_requests": 19271,
    "scheduler_time": 1.417776215344887e-05
}
#Debug simulation 
Total elapsed time: 1.7727932562120259. Arrivals time: 0.05775186698883772 Scheduler time: 1.3283712496049702 Scheduler overhead time: 0.1464234902523458 Adapter cache time: 0.02673297096043825 Engine time: 0.14179840870201588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 8640, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57405 . Total input tokens: 12735595 . Total output tokens: 11501261
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7497672978788614,
    "estimated_duration": 3600.0055036559443,
    "input_throughput": 1338.4440649067683,
    "output_throughput": 1173.8132054822152,
    "total_throughput": 2512.257270388983,
    "itl": 20.728503813941074,
    "ttft": 4698.484260568111,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 19297,
    "finished_requests": 19271,
    "scheduler_time": 1.417776215344887e-05
}
#Debug simulation 
Total elapsed time: 1.7498626937158406. Arrivals time: 0.055845217779278755 Scheduler time: 1.3102021985687315 Scheduler overhead time: 0.14662442030385137 Adapter cache time: 0.02668388932943344 Engine time: 0.13883281080052257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 8640, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57405 . Total input tokens: 12735595 . Total output tokens: 11501261
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7509620282799006,
    "estimated_duration": 3600.004766389648,
    "input_throughput": 1338.444339014655,
    "output_throughput": 1173.813445874373,
    "total_throughput": 2512.2577848890282,
    "itl": 20.72852595337674,
    "ttft": 4698.46177724871,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 19297,
    "finished_requests": 19271,
    "scheduler_time": 1.417776215344887e-05
}
#Debug simulation 
Total elapsed time: 1.7510878192260861. Arrivals time: 0.05839003436267376 Scheduler time: 1.3048270619474351 Scheduler overhead time: 0.1456398726440966 Adapter cache time: 0.026948983781039715 Engine time: 0.14353753067553043 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 8640, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57405 . Total input tokens: 12735595 . Total output tokens: 11501261
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.7412254395894706,
    "estimated_duration": 3600.0059634485483,
    "input_throughput": 1338.443893960751,
    "output_throughput": 1173.8130555628438,
    "total_throughput": 2512.256949523595,
    "itl": 20.72850683869078,
    "ttft": 4698.4798851062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 19297,
    "finished_requests": 19271,
    "scheduler_time": 1.417776215344887e-05
}
#Debug simulation 
Total elapsed time: 1.7413229029625654. Arrivals time: 0.056439556647092104 Scheduler time: 1.3055151752196252 Scheduler overhead time: 0.14431503461673856 Adapter cache time: 0.026725173462182283 Engine time: 0.13756886729970574 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 8640, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57405 . Total input tokens: 12735595 . Total output tokens: 11501261
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7401749431155622,
    "estimated_duration": 3600.002486057314,
    "input_throughput": 1338.4451868190429,
    "output_throughput": 1173.8141893974025,
    "total_throughput": 2512.259376216445,
    "itl": 20.7285684425544,
    "ttft": 4698.487263925853,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 19297,
    "finished_requests": 19271,
    "scheduler_time": 1.5011748162475273e-05
}
#Debug simulation 
Total elapsed time: 1.7402778640389442. Arrivals time: 0.05641318252310157 Scheduler time: 1.300144110340625 Scheduler overhead time: 0.14445106824859977 Adapter cache time: 0.02674936270341277 Engine time: 0.1412141416221857 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.1,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.1-0.003125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.1-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.1      0.8     ]. Counts: [5 5 6]
Adapter prompts. [1080, 33, 33, 1080, 8640, 33, 8640, 33, 1080, 1080, 33, 1080, 8640, 8640, 8640, 8640]
Prompts retrieved: 57405 . Total input tokens: 12735595 . Total output tokens: 11501261
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7469319668598473,
    "estimated_duration": 3600.006584111021,
    "input_throughput": 1338.4436632050906,
    "output_throughput": 1173.8128531905159,
    "total_throughput": 2512.2565163956065,
    "itl": 20.728484970483407,
    "ttft": 4698.458243615835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072867,
    "arrivals": 19297,
    "finished_requests": 19271,
    "scheduler_time": 1.417776215344887e-05
}
#Debug simulation 
Total elapsed time: 1.7470280467532575. Arrivals time: 0.056368038058280945 Scheduler time: 1.307121648453176 Scheduler overhead time: 0.14535659505054355 Adapter cache time: 0.026576122269034386 Engine time: 0.139947144780308 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-8/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 8640, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55890 . Total input tokens: 12389755 . Total output tokens: 11202389
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.718913841061294,
    "estimated_duration": 3599.7800501954775,
    "input_throughput": 1302.2581753975323,
    "output_throughput": 1140.0046510555985,
    "total_throughput": 2442.262826453131,
    "itl": 20.574755537785574,
    "ttft": 2329.5726466864057,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 18819,
    "finished_requests": 18807,
    "scheduler_time": 4.415939046024687e-05
}
#Debug simulation 
Total elapsed time: 1.7190040829591453. Arrivals time: 0.05551249114796519 Scheduler time: 1.2784555056132376 Scheduler overhead time: 0.1463644034229219 Adapter cache time: 0.0267567983828485 Engine time: 0.14018046669662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-16/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 8640, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55890 . Total input tokens: 12389755 . Total output tokens: 11202389
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7205922058783472,
    "estimated_duration": 3599.7886359085314,
    "input_throughput": 1302.2550694332253,
    "output_throughput": 1140.0019320757349,
    "total_throughput": 2442.25700150896,
    "itl": 20.577513981897415,
    "ttft": 2329.5681626223145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 18819,
    "finished_requests": 18807,
    "scheduler_time": 4.415939046024687e-05
}
#Debug simulation 
Total elapsed time: 1.7206923249177635. Arrivals time: 0.05609330115839839 Scheduler time: 1.2791169662959874 Scheduler overhead time: 0.14535842556506395 Adapter cache time: 0.026681152172386646 Engine time: 0.14214138593524694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-8-32/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 8640, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55890 . Total input tokens: 12389755 . Total output tokens: 11202389
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7153586838394403,
    "estimated_duration": 3599.788717195821,
    "input_throughput": 1302.255040026837,
    "output_throughput": 1140.0019063332054,
    "total_throughput": 2442.2569463600425,
    "itl": 20.57751384736467,
    "ttft": 2329.5733544271725,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 18819,
    "finished_requests": 18807,
    "scheduler_time": 4.415939046024687e-05
}
#Debug simulation 
Total elapsed time: 1.715456732083112. Arrivals time: 0.05523412534967065 Scheduler time: 1.2750339452177286 Scheduler overhead time: 0.1464869170449674 Adapter cache time: 0.026729518547654152 Engine time: 0.14044802635908127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-16/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 8640, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55890 . Total input tokens: 12389755 . Total output tokens: 11202389
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7133473209105432,
    "estimated_duration": 3599.7803641059722,
    "input_throughput": 1302.2580618371296,
    "output_throughput": 1140.0045516441378,
    "total_throughput": 2442.262613481267,
    "itl": 20.574764266131716,
    "ttft": 2329.631328400268,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.050292376629076894,
    "arrivals": 18819,
    "finished_requests": 18807,
    "scheduler_time": 4.415939046024687e-05
}
#Debug simulation 
Total elapsed time: 1.7134388401173055. Arrivals time: 0.05523292953148484 Scheduler time: 1.2726044612936676 Scheduler overhead time: 0.14628109149634838 Adapter cache time: 0.02679809695109725 Engine time: 0.1408652332611382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_8-16-32/adapters_16_slots_16_rate_0.8-0.05-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 8640, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55890 . Total input tokens: 12389755 . Total output tokens: 11202389
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.7245418932288885,
    "estimated_duration": 3599.7885606279183,
    "input_throughput": 1302.255096666647,
    "output_throughput": 1140.0019559160364,
    "total_throughput": 2442.257052582683,
    "itl": 20.577512968781097,
    "ttft": 2329.5578199864726,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 18819,
    "finished_requests": 18807,
    "scheduler_time": 4.415939046024687e-05
}
#Debug simulation 
Total elapsed time: 1.7246377621777356. Arrivals time: 0.05627316329628229 Scheduler time: 1.2827662760391831 Scheduler overhead time: 0.1458537862636149 Adapter cache time: 0.02664980385452509 Engine time: 0.14127925969660282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_0.8-0.05-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-16/adapters_16_slots_16_rate_0.8-0.05-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 8640, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55890 . Total input tokens: 12389755 . Total output tokens: 11202389
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7316299290396273,
    "estimated_duration": 3599.7780521817504,
    "input_throughput": 1302.2588982003476,
    "output_throughput": 1140.005283801537,
    "total_throughput": 2442.264182001885,
    "itl": 20.57476272500193,
    "ttft": 2329.5443719246778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 18819,
    "finished_requests": 18807,
    "scheduler_time": 4.415939046024687e-05
}
#Debug simulation 
Total elapsed time: 1.731733142863959. Arrivals time: 0.05654383497312665 Scheduler time: 1.2854501311667264 Scheduler overhead time: 0.1477933037094772 Adapter cache time: 0.026796163525432348 Engine time: 0.14223139407113194 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_0.8-0.05-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.025_size_16-16-32/adapters_16_slots_16_rate_0.8-0.05-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.05  0.8  ]. Counts: [5 5 6]
Adapter prompts. [540, 270, 270, 540, 8640, 270, 8640, 270, 540, 540, 270, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55890 . Total input tokens: 12389755 . Total output tokens: 11202389
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7156544770114124,
    "estimated_duration": 3599.7899425518585,
    "input_throughput": 1302.2545967437284,
    "output_throughput": 1140.001518280502,
    "total_throughput": 2442.2561150242304,
    "itl": 20.577493579029777,
    "ttft": 2329.501359542362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 18819,
    "finished_requests": 18807,
    "scheduler_time": 4.499337646927327e-05
}
#Debug simulation 
Total elapsed time: 1.7157556130550802. Arrivals time: 0.0550987021997571 Scheduler time: 1.2756982338614762 Scheduler overhead time: 0.14708643965423107 Adapter cache time: 0.026712094899266958 Engine time: 0.13914499059319496 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 8640, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55215 . Total input tokens: 12238470 . Total output tokens: 11059090
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7108064950443804,
    "estimated_duration": 3599.849033630047,
    "input_throughput": 1281.4367927391456,
    "output_throughput": 1128.7142771936506,
    "total_throughput": 2410.151069932796,
    "itl": 20.533110496338306,
    "ttft": 5834.993114346246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 18617,
    "finished_requests": 18587,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7108958549797535. Arrivals time: 0.05648652883246541 Scheduler time: 1.2674239086918533 Scheduler overhead time: 0.14709886349737644 Adapter cache time: 0.026361097116023302 Engine time: 0.14172966498881578 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 8640, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55215 . Total input tokens: 12238470 . Total output tokens: 11059090
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6915276828221977,
    "estimated_duration": 3599.850809679613,
    "input_throughput": 1281.4361605198176,
    "output_throughput": 1128.7137203226555,
    "total_throughput": 2410.149880842473,
    "itl": 20.533078549487442,
    "ttft": 5835.0175844574205,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 18617,
    "finished_requests": 18587,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6916307010687888. Arrivals time: 0.05490314960479736 Scheduler time: 1.2537984671071172 Scheduler overhead time: 0.14597101602703333 Adapter cache time: 0.02628339407965541 Engine time: 0.13927390752360225 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 8640, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55215 . Total input tokens: 12238470 . Total output tokens: 11059090
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6968064899556339,
    "estimated_duration": 3599.850860750736,
    "input_throughput": 1281.436142340069,
    "output_throughput": 1128.7137043095818,
    "total_throughput": 2410.149846649651,
    "itl": 20.53308418348165,
    "ttft": 5835.013857830068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 18617,
    "finished_requests": 18587,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6968990718014538. Arrivals time: 0.05465945741161704 Scheduler time: 1.2572200992144644 Scheduler overhead time: 0.1479244283400476 Adapter cache time: 0.02618858264759183 Engine time: 0.13870420726016164 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 8640, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55215 . Total input tokens: 12238470 . Total output tokens: 11059090
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7106050970032811,
    "estimated_duration": 3599.8502283549215,
    "input_throughput": 1281.4363674535603,
    "output_throughput": 1128.713902593893,
    "total_throughput": 2410.150270047453,
    "itl": 20.533095468872027,
    "ttft": 5835.01457561742,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 18617,
    "finished_requests": 18587,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7107184268534184. Arrivals time: 0.05514616286382079 Scheduler time: 1.2682634331285954 Scheduler overhead time: 0.1479224804788828 Adapter cache time: 0.026654118206351995 Engine time: 0.1410707477480173 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 8640, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55215 . Total input tokens: 12238470 . Total output tokens: 11059090
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.693048040382564,
    "estimated_duration": 3599.853029228541,
    "input_throughput": 1281.4353704291575,
    "output_throughput": 1128.713024395542,
    "total_throughput": 2410.1483948246996,
    "itl": 20.53309795734098,
    "ttft": 5835.037107870369,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 18617,
    "finished_requests": 18587,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6931435163132846. Arrivals time: 0.056249423418194056 Scheduler time: 1.2540876222774386 Scheduler overhead time: 0.14481667848303914 Adapter cache time: 0.02654150454327464 Engine time: 0.13979059737175703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 8640, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55215 . Total input tokens: 12238470 . Total output tokens: 11059090
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.6993649923242629,
    "estimated_duration": 3599.8477220701243,
    "input_throughput": 1281.4372596147666,
    "output_throughput": 1128.714688426715,
    "total_throughput": 2410.151948041482,
    "itl": 20.53309288175572,
    "ttft": 5835.025732839772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 18617,
    "finished_requests": 18587,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6994551620446146. Arrivals time: 0.05517884949222207 Scheduler time: 1.2588471015915275 Scheduler overhead time: 0.14555485593155026 Adapter cache time: 0.026316002942621708 Engine time: 0.1422373722307384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.0125_size_16-16-32/adapters_16_slots_16_rate_0.8-0.05-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.05   0.8   ]. Counts: [5 5 6]
Adapter prompts. [540, 135, 135, 540, 8640, 135, 8640, 135, 540, 540, 135, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 55215 . Total input tokens: 12238470 . Total output tokens: 11059090
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7077997396700084,
    "estimated_duration": 3599.853037613774,
    "input_throughput": 1281.4353674442762,
    "output_throughput": 1128.7130217664007,
    "total_throughput": 2410.1483892106767,
    "itl": 20.533107620665007,
    "ttft": 5835.043479297307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 18617,
    "finished_requests": 18587,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.707895701751113. Arrivals time: 0.05462789395824075 Scheduler time: 1.2668484169989824 Scheduler overhead time: 0.1482026008889079 Adapter cache time: 0.026306141167879105 Engine time: 0.139270163141191 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-8/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 8640, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54870 . Total input tokens: 12159118 . Total output tokens: 10993681
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.70231775008142,
    "estimated_duration": 3599.761140684634,
    "input_throughput": 1284.7244078868061,
    "output_throughput": 1118.8897936805802,
    "total_throughput": 2403.6142015673863,
    "itl": 20.477612618505475,
    "ttft": 4699.276139910384,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 18519,
    "finished_requests": 18495,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.702404657844454. Arrivals time: 0.055096912663429976 Scheduler time: 1.2593788378871977 Scheduler overhead time: 0.14579073758795857 Adapter cache time: 0.026458792854100466 Engine time: 0.1439018570818007 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-16/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 8640, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54870 . Total input tokens: 12159118 . Total output tokens: 10993681
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6814838722348213,
    "estimated_duration": 3599.7660373943504,
    "input_throughput": 1284.722660294761,
    "output_throughput": 1118.888271670964,
    "total_throughput": 2403.6109319657253,
    "itl": 20.47765681274294,
    "ttft": 4699.317786734212,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 18519,
    "finished_requests": 18495,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6815721299499273. Arrivals time: 0.053260139655321836 Scheduler time: 1.2452142373658717 Scheduler overhead time: 0.1463624252937734 Adapter cache time: 0.026248539332300425 Engine time: 0.13906554644927382 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-8-32/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 8640, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54870 . Total input tokens: 12159118 . Total output tokens: 10993681
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.694612415973097,
    "estimated_duration": 3599.766088465477,
    "input_throughput": 1284.7226420679563,
    "output_throughput": 1118.8882557969093,
    "total_throughput": 2403.6108978648654,
    "itl": 20.477654806847642,
    "ttft": 4699.332247900769,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 18519,
    "finished_requests": 18495,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.694712249096483. Arrivals time: 0.05500780465081334 Scheduler time: 1.2541682962328196 Scheduler overhead time: 0.14551007049158216 Adapter cache time: 0.02648527966812253 Engine time: 0.14182237442582846 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-16/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 8640, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54870 . Total input tokens: 12159118 . Total output tokens: 10993681
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.6844231518916786,
    "estimated_duration": 3599.763547443329,
    "input_throughput": 1284.7235489354891,
    "output_throughput": 1118.8890456042957,
    "total_throughput": 2403.612594539785,
    "itl": 20.477575560697954,
    "ttft": 4699.271672055663,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 18519,
    "finished_requests": 18495,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6845173970796168. Arrivals time: 0.0540895969606936 Scheduler time: 1.2437978205271065 Scheduler overhead time: 0.14847589936107397 Adapter cache time: 0.02625207556411624 Engine time: 0.14002958638593554 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_8-16-32/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 8640, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54870 . Total input tokens: 12159118 . Total output tokens: 10993681
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.6856430331245065,
    "estimated_duration": 3599.76614660648,
    "input_throughput": 1284.7226213179797,
    "output_throughput": 1118.8882377253783,
    "total_throughput": 2403.610859043358,
    "itl": 20.47763554081065,
    "ttft": 4699.351051346127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05303479295223951,
    "arrivals": 18519,
    "finished_requests": 18495,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6857284270226955. Arrivals time: 0.053190091624855995 Scheduler time: 1.2478188322857022 Scheduler overhead time: 0.14593117963522673 Adapter cache time: 0.02631947072222829 Engine time: 0.14081064518541098 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-16/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 8640, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54870 . Total input tokens: 12159118 . Total output tokens: 10993681
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.6951637561433017,
    "estimated_duration": 3599.7593021182706,
    "input_throughput": 1284.7250640559787,
    "output_throughput": 1118.8903651502164,
    "total_throughput": 2403.615429206195,
    "itl": 20.47752718807824,
    "ttft": 4699.325939076856,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 18519,
    "finished_requests": 18495,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6952480748295784. Arrivals time: 0.055054758209735155 Scheduler time: 1.2546131424605846 Scheduler overhead time: 0.14546422753483057 Adapter cache time: 0.0264056702144444 Engine time: 0.1419328055344522 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.00625_size_16-16-32/adapters_16_slots_16_rate_0.8-0.05-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.05    0.8    ]. Counts: [5 5 6]
Adapter prompts. [540, 66, 66, 540, 8640, 66, 8640, 66, 540, 540, 66, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54870 . Total input tokens: 12159118 . Total output tokens: 10993681
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.6871019317768514,
    "estimated_duration": 3599.768669907834,
    "input_throughput": 1284.7217207761319,
    "output_throughput": 1118.8874534271458,
    "total_throughput": 2403.6091742032777,
    "itl": 20.47765349762927,
    "ttft": 4699.337187514894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05378931567072868,
    "arrivals": 18519,
    "finished_requests": 18495,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.687190219759941. Arrivals time: 0.0543558020144701 Scheduler time: 1.23890027590096 Scheduler overhead time: 0.14828718174248934 Adapter cache time: 0.02659160364419222 Engine time: 0.14629370905458927 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-8/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 8640, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54705 . Total input tokens: 12122728 . Total output tokens: 10961139
Prompts distributed
Adapter sizes. Values: [8]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7035825080238283,
    "estimated_duration": 3599.0279221848486,
    "input_throughput": 1272.8120200909968,
    "output_throughput": 1123.895976206947,
    "total_throughput": 2396.7079962979437,
    "itl": 20.469824533872952,
    "ttft": 7051.709958982299,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.048967803902924066,
    "arrivals": 18467,
    "finished_requests": 18431,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7036690907552838. Arrivals time: 0.0552365742623806 Scheduler time: 1.2606816147454083 Scheduler overhead time: 0.14705358818173409 Adapter cache time: 0.026336850598454475 Engine time: 0.14229479664936662 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-16/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 8640, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54705 . Total input tokens: 12122728 . Total output tokens: 10961139
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.7004198408685625,
    "estimated_duration": 3599.029593093061,
    "input_throughput": 1272.8114291672484,
    "output_throughput": 1123.8954544199019,
    "total_throughput": 2396.7068835871505,
    "itl": 20.469796448328445,
    "ttft": 7051.690693691151,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05233535322127863,
    "arrivals": 18467,
    "finished_requests": 18431,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7005116790533066. Arrivals time: 0.05465547274798155 Scheduler time: 1.2582096219994128 Scheduler overhead time: 0.14774176804348826 Adapter cache time: 0.02601869171485305 Engine time: 0.14067011093720794 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-8-32/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 8640, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54705 . Total input tokens: 12122728 . Total output tokens: 10961139
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [11  5]
---Simulation End---
#Simulation results
{
    "duration": 1.694592087995261,
    "estimated_duration": 3599.0281109205357,
    "input_throughput": 1272.8119533437962,
    "output_throughput": 1123.8959172690134,
    "total_throughput": 2396.7078706128095,
    "itl": 20.469768253399756,
    "ttft": 7051.6780883456795,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05240602402016519,
    "arrivals": 18467,
    "finished_requests": 18431,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6946820761077106. Arrivals time: 0.054082217160612345 Scheduler time: 1.254401118028909 Scheduler overhead time: 0.14554480323567986 Adapter cache time: 0.026035552844405174 Engine time: 0.1430964875034988 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-16/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 8640, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54705 . Total input tokens: 12122728 . Total output tokens: 10961139
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 6 10]
---Simulation End---
#Simulation results
{
    "duration": 1.7092021708376706,
    "estimated_duration": 3599.0281459246175,
    "input_throughput": 1272.8119409644505,
    "output_throughput": 1123.8959063380223,
    "total_throughput": 2396.7078473024726,
    "itl": 20.46978616888241,
    "ttft": 7051.729993544489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.05029237662907689,
    "arrivals": 18467,
    "finished_requests": 18431,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7092911531217396. Arrivals time: 0.05414253892377019 Scheduler time: 1.2694233963266015 Scheduler overhead time: 0.14697282435372472 Adapter cache time: 0.026349776424467564 Engine time: 0.14047337463125587 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_8-16-32/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 8640, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54705 . Total input tokens: 12122728 . Total output tokens: 10961139
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [6 5 5]
---Simulation End---
#Simulation results
{
    "duration": 1.6992918238975108,
    "estimated_duration": 3599.0298827146594,
    "input_throughput": 1272.8113267414026,
    "output_throughput": 1123.8953639776414,
    "total_throughput": 2396.7066907190438,
    "itl": 20.469805194479108,
    "ttft": 7051.686269299355,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.0530347929522395,
    "arrivals": 18467,
    "finished_requests": 18431,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6993768261745572. Arrivals time: 0.055174133740365505 Scheduler time: 1.259045159444213 Scheduler overhead time: 0.1462987819686532 Adapter cache time: 0.026227755937725306 Engine time: 0.14069994864985347 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 16,
    "served_adapters_rates": [
        0.8,
        0.05,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.8-0.05-0.003125_size_16-16-16/adapters_16_slots_16_rate_0.8-0.05-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.05     0.8     ]. Counts: [5 5 6]
Adapter prompts. [540, 33, 33, 540, 8640, 33, 8640, 33, 540, 540, 33, 540, 8640, 8640, 8640, 8640]
Prompts retrieved: 54705 . Total input tokens: 12122728 . Total output tokens: 10961139
Prompts distributed
Adapter sizes. Values: [16]. Counts: [16]
---Simulation End---
#Simulation results
{
    "duration": 1.7075022896751761,
    "estimated_duration": 3599.027538873189,
    "input_throughput": 1272.812155650862,
    "output_throughput": 1123.8960959066233,
    "total_throughput": 2396.7082515574853,
    "itl": 20.469854153302727,
    "ttft": 7051.750236879429,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 16,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.047840804718434805,
    "arrivals": 18467,
    "finished_requests": 18431,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7075936417095363. Arrivals time: 0.0550367240794003 Scheduler time: 1.2641514465212822 Scheduler overhead time: 0.1488799387589097 Adapter cache time: 0.026170481462031603 Engine time: 0.14081544848158956 
