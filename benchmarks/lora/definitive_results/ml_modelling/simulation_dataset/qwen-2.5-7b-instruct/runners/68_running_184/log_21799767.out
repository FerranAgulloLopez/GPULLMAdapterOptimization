INFO 06-01 00:47:10 [__init__.py:243] No platform detected, vLLM is running on UnspecifiedPlatform
WARNING 06-01 00:47:10 [_custom_ops.py:21] Failed to import from vllm._C with ModuleNotFoundError("No module named 'vllm._C'")
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.1-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.7810792060336098,
    "estimated_duration": 3600.0267053412704,
    "input_throughput": 1277.5588562096534,
    "output_throughput": 1132.5007656057126,
    "total_throughput": 2410.059621815366,
    "itl": 24.081795352503747,
    "ttft": 6430.628974363573,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4002960364404136,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.0035440454082770155
}
#Debug simulation 
Total elapsed time: 1.7812030570348725. Arrivals time: 0.058589796302840114 Scheduler time: 1.2866824849043041 Scheduler overhead time: 0.13387381623033434 Adapter cache time: 0.10907586081884801 Engine time: 0.12942886946257204 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_128_rate_0.1-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_8-16-32/adapters_128_slots_128_rate_0.1-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7756225100019947,
    "estimated_duration": 3600.018706658881,
    "input_throughput": 1277.5616947469937,
    "output_throughput": 1132.503281846507,
    "total_throughput": 2410.0649765935004,
    "itl": 24.082279845338448,
    "ttft": 6430.5326247607745,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879447,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.003516565737997297
}
#Debug simulation 
Total elapsed time: 1.7757708090357482. Arrivals time: 0.06195140175987035 Scheduler time: 1.2791994625004008 Scheduler overhead time: 0.13428396545350552 Adapter cache time: 0.1102119543356821 Engine time: 0.1266279845731333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.1-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.799967264989391,
    "estimated_duration": 3600.002374121927,
    "input_throughput": 1277.5674908052797,
    "output_throughput": 1132.5084198019244,
    "total_throughput": 2410.075910607204,
    "itl": 23.948188528564454,
    "ttft": 6237.076841816611,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.003314533711924443
}
#Debug simulation 
Total elapsed time: 1.8001143930014223. Arrivals time: 0.06047316873446107 Scheduler time: 1.2984928216319531 Scheduler overhead time: 0.13790249277371913 Adapter cache time: 0.11208556510973722 Engine time: 0.12692760373465717 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_128_rate_0.1-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.00625_size_16-16-32/adapters_128_slots_128_rate_0.1-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.1    ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 66, 66, 1080, 66, 135, 135, 135, 66, 1080, 135, 66, 1080, 135, 66, 66, 66, 66, 135, 135, 1080, 135, 66, 135, 135, 135, 135, 1080, 135, 66, 135, 66, 1080, 1080, 66, 135, 135, 66, 135, 66, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 66, 135, 1080, 1080, 135, 66, 66, 66, 1080, 135, 135, 135, 135, 1080, 135, 1080, 66, 66, 135, 66, 1080, 1080, 66, 66, 135, 135, 135, 66, 1080, 66, 1080, 135, 66, 1080, 1080, 135, 135, 66, 66, 66, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 66, 1080, 66, 66, 1080, 135, 1080, 1080, 135, 1080, 66, 135, 1080, 66, 1080, 135, 66, 135, 135, 1080, 1080, 66, 66, 1080, 66, 66, 66, 135, 66]
Prompts retrieved: 55017 . Total input tokens: 12180588 . Total output tokens: 11013970
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7729965230682865,
    "estimated_duration": 3600.0241705772796,
    "input_throughput": 1277.5597557342207,
    "output_throughput": 1132.5015629954034,
    "total_throughput": 2410.061318729624,
    "itl": 24.082157332427638,
    "ttft": 6430.5896123969915,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378315,
    "arrivals": 18589,
    "finished_requests": 18556,
    "scheduler_time": 0.003509310107923825
}
#Debug simulation 
Total elapsed time: 1.7731167000019923. Arrivals time: 0.05775269551668316 Scheduler time: 1.2818288098787889 Scheduler overhead time: 0.13300348550546914 Adapter cache time: 0.10997854126617312 Engine time: 0.12717684672679752 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8005032179644331,
    "estimated_duration": 3599.819589976351,
    "input_throughput": 1234.6940975531497,
    "output_throughput": 1119.060802718301,
    "total_throughput": 2353.7549002714504,
    "itl": 23.83237388735219,
    "ttft": 5806.553231428101,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.00180223412449456
}
#Debug simulation 
Total elapsed time: 1.8006410850211978. Arrivals time: 0.06188139203004539 Scheduler time: 1.2999427595641464 Scheduler overhead time: 0.13535356614738703 Adapter cache time: 0.10745287465397269 Engine time: 0.1319183319574222 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8008327099960297,
    "estimated_duration": 3599.8197170259905,
    "input_throughput": 1234.6940539766786,
    "output_throughput": 1119.0607632229141,
    "total_throughput": 2353.7548171995927,
    "itl": 23.83258802331996,
    "ttft": 5806.551522140316,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0017973553304442842
}
#Debug simulation 
Total elapsed time: 1.8009796839905903. Arrivals time: 0.059250506456010044 Scheduler time: 1.3025685884058475 Scheduler overhead time: 0.1362896526698023 Adapter cache time: 0.10717073560226709 Engine time: 0.13163628824986517 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.856533141923137,
    "estimated_duration": 3599.819716516595,
    "input_throughput": 1234.694054151395,
    "output_throughput": 1119.0607633812679,
    "total_throughput": 2353.754817532663,
    "itl": 23.832596981692607,
    "ttft": 5806.559315513521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41857369717210635,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0017973553304442842
}
#Debug simulation 
Total elapsed time: 1.856639830977656. Arrivals time: 0.061199315008707345 Scheduler time: 1.356870521325618 Scheduler overhead time: 0.13579454272985458 Adapter cache time: 0.1082243851851672 Engine time: 0.13059577520471066 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.8438089990522712,
    "estimated_duration": 3599.827772539749,
    "input_throughput": 1234.6912910403473,
    "output_throughput": 1119.0582590449524,
    "total_throughput": 2353.7495500852997,
    "itl": 23.83218211760012,
    "ttft": 5806.575715649687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0018014001384855335
}
#Debug simulation 
Total elapsed time: 1.8440090720541775. Arrivals time: 0.06288773484993726 Scheduler time: 1.3411545736016706 Scheduler overhead time: 0.13543822546489537 Adapter cache time: 0.10823843686375767 Engine time: 0.1312976173358038 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8559052349301055,
    "estimated_duration": 3599.8317822292947,
    "input_throughput": 1234.6899157736511,
    "output_throughput": 1119.0570125766521,
    "total_throughput": 2353.7469283503033,
    "itl": 23.832484054344036,
    "ttft": 5806.595676183949,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42398110998794464,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0017981893164533106
}
#Debug simulation 
Total elapsed time: 1.8560123689239845. Arrivals time: 0.06286756007466465 Scheduler time: 1.3528077823575586 Scheduler overhead time: 0.13511937949806452 Adapter cache time: 0.10966469848062843 Engine time: 0.13164610543753952 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.8458968919003382,
    "estimated_duration": 3599.831822262434,
    "input_throughput": 1234.689902042867,
    "output_throughput": 1119.0570001318026,
    "total_throughput": 2353.7469021746697,
    "itl": 23.832044186115656,
    "ttft": 5806.611939330834,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.001793310522403035
}
#Debug simulation 
Total elapsed time: 1.8460052359150723. Arrivals time: 0.05820500187110156 Scheduler time: 1.3486139883752912 Scheduler overhead time: 0.1347542272415012 Adapter cache time: 0.10857466387096792 Engine time: 0.13117644097656012 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.0125-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.1-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 135, 1080, 1080, 33, 33, 1080, 33, 135, 135, 135, 33, 1080, 135, 33, 1080, 135, 33, 33, 33, 33, 135, 135, 1080, 135, 33, 135, 135, 135, 135, 1080, 135, 33, 135, 33, 1080, 1080, 33, 135, 135, 33, 135, 33, 135, 135, 1080, 1080, 1080, 1080, 135, 135, 33, 135, 1080, 1080, 135, 33, 33, 33, 1080, 135, 135, 135, 135, 1080, 135, 1080, 33, 33, 135, 33, 1080, 1080, 33, 33, 135, 135, 135, 33, 1080, 33, 1080, 135, 33, 1080, 1080, 135, 135, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 135, 1080, 1080, 135, 1080, 33, 135, 1080, 33, 1080, 135, 33, 135, 135, 1080, 1080, 33, 33, 1080, 33, 33, 33, 135, 33]
Prompts retrieved: 53631 . Total input tokens: 11885169 . Total output tokens: 10748452
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.8477339440723881,
    "estimated_duration": 3599.8197316038063,
    "input_throughput": 1234.6940489766664,
    "output_throughput": 1119.0607586911701,
    "total_throughput": 2353.7548076678363,
    "itl": 23.832626782830687,
    "ttft": 5806.561832195481,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378326,
    "arrivals": 18102,
    "finished_requests": 18073,
    "scheduler_time": 0.0018184133566595572
}
#Debug simulation 
Total elapsed time: 1.8478333150269464. Arrivals time: 0.06018153880722821 Scheduler time: 1.3449550147634 Scheduler overhead time: 0.13723297615069896 Adapter cache time: 0.1090630586259067 Engine time: 0.13149150041863322 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.7116724119987339,
    "estimated_duration": 3600.007338502528,
    "input_throughput": 1192.6439577164726,
    "output_throughput": 1037.6251070515357,
    "total_throughput": 2230.2690647680083,
    "itl": 23.07126047792549,
    "ttft": 4654.306659788372,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7117791830096394. Arrivals time: 0.06078792642802 Scheduler time: 1.2116516535170376 Scheduler overhead time: 0.1389128059381619 Adapter cache time: 0.10128167842049152 Engine time: 0.13344239175785333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7251640650210902,
    "estimated_duration": 3600.0035079935647,
    "input_throughput": 1192.6452267245054,
    "output_throughput": 1037.6262111149802,
    "total_throughput": 2230.2714378394858,
    "itl": 23.071824005805123,
    "ttft": 4444.725727178939,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7252701440593228. Arrivals time: 0.05688676633872092 Scheduler time: 1.2283185285050422 Scheduler overhead time: 0.13898022775538266 Adapter cache time: 0.10164236754644662 Engine time: 0.13377801049500704 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7390080379555002,
    "estimated_duration": 3600.0123874411042,
    "input_throughput": 1192.6422850594265,
    "output_throughput": 1037.6236518050348,
    "total_throughput": 2230.2659368644613,
    "itl": 23.071567308347397,
    "ttft": 4654.3250486135485,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41857369717210635,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7391091519966722. Arrivals time: 0.056653976906090975 Scheduler time: 1.2413271364057437 Scheduler overhead time: 0.13871712237596512 Adapter cache time: 0.10176220932044089 Engine time: 0.13481484400108457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.7511341279605404,
    "estimated_duration": 3600.0026961056665,
    "input_throughput": 1192.6454956949226,
    "output_throughput": 1037.6264451248505,
    "total_throughput": 2230.271940819773,
    "itl": 23.071460740985184,
    "ttft": 4444.733877987716,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7512457919074222. Arrivals time: 0.05846424971241504 Scheduler time: 1.2459633266553283 Scheduler overhead time: 0.13836666813585907 Adapter cache time: 0.10139379359316081 Engine time: 0.14148705243133008 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.7210231570061296,
    "estimated_duration": 3600.007312015879,
    "input_throughput": 1192.6439664912164,
    "output_throughput": 1037.6251146857458,
    "total_throughput": 2230.269081176962,
    "itl": 23.07152367206753,
    "ttft": 4654.367619479748,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879448,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.721131406025961. Arrivals time: 0.060266429209150374 Scheduler time: 1.2222042653011158 Scheduler overhead time: 0.13869278121273965 Adapter cache time: 0.10100004309788346 Engine time: 0.1331958449445665 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.6962427499238402,
    "estimated_duration": 3600.002683651076,
    "input_throughput": 1192.6454998210058,
    "output_throughput": 1037.626448714629,
    "total_throughput": 2230.2719485356347,
    "itl": 23.071533769129957,
    "ttft": 4444.742651410512,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.6963507829932496. Arrivals time: 0.05949385219719261 Scheduler time: 1.1979909728979692 Scheduler overhead time: 0.13909249927382916 Adapter cache time: 0.10114654584322125 Engine time: 0.13289328734390438 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.1,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.1-0.00625-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.1-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.1     ]. Counts: [42 43 43]
Adapter prompts. [1080, 66, 1080, 1080, 33, 33, 1080, 33, 66, 66, 66, 33, 1080, 66, 33, 1080, 66, 33, 33, 33, 33, 66, 66, 1080, 66, 33, 66, 66, 66, 66, 1080, 66, 33, 66, 33, 1080, 1080, 33, 66, 66, 33, 66, 33, 66, 66, 1080, 1080, 1080, 1080, 66, 66, 33, 66, 1080, 1080, 66, 33, 33, 33, 1080, 66, 66, 66, 66, 1080, 66, 1080, 33, 33, 66, 33, 1080, 1080, 33, 33, 66, 66, 66, 33, 1080, 33, 1080, 66, 33, 1080, 1080, 66, 66, 33, 33, 33, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 1080, 33, 1080, 33, 33, 1080, 66, 1080, 1080, 66, 1080, 33, 66, 1080, 33, 1080, 66, 33, 66, 66, 1080, 1080, 33, 33, 1080, 33, 33, 33, 66, 33]
Prompts retrieved: 50664 . Total input tokens: 11220806 . Total output tokens: 10144425
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.728221874916926,
    "estimated_duration": 3600.0072790347413,
    "input_throughput": 1192.643977417515,
    "output_throughput": 1037.6251241918535,
    "total_throughput": 2230.2691016093686,
    "itl": 23.07139334023136,
    "ttft": 4654.2971879823845,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4293885228037832,
    "arrivals": 17157,
    "finished_requests": 17135,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.7283328749472275. Arrivals time: 0.06138249905779958 Scheduler time: 1.2275119861587882 Scheduler overhead time: 0.138958758325316 Adapter cache time: 0.10112760402262211 Engine time: 0.1335457224631682 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-8/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.5041323819896206,
    "estimated_duration": 3599.533014304904,
    "input_throughput": 922.9066622803316,
    "output_throughput": 839.2699797430176,
    "total_throughput": 1762.1766420233491,
    "itl": 22.261247538709625,
    "ttft": 5537.306452552955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.504237930988893. Arrivals time: 0.050375602091662586 Scheduler time: 0.9969223047373816 Scheduler overhead time: 0.14261202490888536 Adapter cache time: 0.11286398652009666 Engine time: 0.13402232702355832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-16/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4927852170076221,
    "estimated_duration": 3599.53602802097,
    "input_throughput": 922.9058895755679,
    "output_throughput": 839.2692770631717,
    "total_throughput": 1762.1751666387395,
    "itl": 22.26118548165278,
    "ttft": 5537.346354685201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4928848940180615. Arrivals time: 0.049646696425043046 Scheduler time: 0.9843926826724783 Scheduler overhead time: 0.14243125566281378 Adapter cache time: 0.11258561979047954 Engine time: 0.13695201964583248 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-8-32/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4857341629685834,
    "estimated_duration": 3599.5386532798907,
    "input_throughput": 922.9052164707196,
    "output_throughput": 839.2686649571857,
    "total_throughput": 1762.1738814279054,
    "itl": 22.2611990850326,
    "ttft": 5537.248087573602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4185736971721064,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.485842191032134. Arrivals time: 0.04959807253908366 Scheduler time: 0.9824282131157815 Scheduler overhead time: 0.14099535590503365 Adapter cache time: 0.11291457258630544 Engine time: 0.13301471050363034 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-16/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.502153237001039,
    "estimated_duration": 3599.5250913153345,
    "input_throughput": 922.9086937093878,
    "output_throughput": 839.2718270776318,
    "total_throughput": 1762.1805207870195,
    "itl": 22.26127789086623,
    "ttft": 5537.314124018894,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5022689020261168. Arrivals time: 0.05171663698274642 Scheduler time: 0.992774206562899 Scheduler overhead time: 0.1413551870500669 Adapter cache time: 0.11247523373458534 Engine time: 0.136385427438654 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_8-16-32/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.5167797530302778,
    "estimated_duration": 3599.532906978377,
    "input_throughput": 922.9066897984484,
    "output_throughput": 839.2700047673568,
    "total_throughput": 1762.176694565805,
    "itl": 22.2615870185427,
    "ttft": 5537.29603485695,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879447,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.516973095946014. Arrivals time: 0.05277922656387091 Scheduler time: 1.0068486909149215 Scheduler overhead time: 0.1410517527256161 Adapter cache time: 0.11283213691785932 Engine time: 0.13638772605918348 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-16/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.503118383930996,
    "estimated_duration": 3599.5263934406053,
    "input_throughput": 922.90835984804,
    "output_throughput": 839.2715234718415,
    "total_throughput": 1762.1798833198816,
    "itl": 22.261058813967427,
    "ttft": 5537.301781849942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.5032419830095023. Arrivals time: 0.04751320998184383 Scheduler time: 1.000568979070522 Scheduler overhead time: 0.14089287747628987 Adapter cache time: 0.11288984271232039 Engine time: 0.13470321567729115 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.0125_size_16-16-32/adapters_128_slots_128_rate_0.05-0.025-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.025  0.05  ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 135, 135, 540, 135, 270, 270, 270, 135, 540, 270, 135, 540, 270, 135, 135, 135, 135, 270, 270, 540, 270, 135, 270, 270, 270, 270, 540, 270, 135, 270, 135, 540, 540, 135, 270, 270, 135, 270, 135, 270, 270, 540, 540, 540, 540, 270, 270, 135, 270, 540, 540, 270, 135, 135, 135, 540, 270, 270, 270, 270, 540, 270, 540, 135, 135, 270, 135, 540, 540, 135, 135, 270, 270, 270, 135, 540, 135, 540, 270, 135, 540, 540, 270, 270, 135, 135, 135, 540, 540, 540, 540, 540, 540, 540, 540, 135, 540, 135, 135, 540, 270, 540, 540, 270, 540, 135, 270, 540, 135, 540, 270, 135, 270, 270, 540, 540, 135, 135, 540, 135, 135, 135, 270, 135]
Prompts retrieved: 40500 . Total input tokens: 8939661 . Total output tokens: 8106807
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4828421989222988,
    "estimated_duration": 3599.5330172551544,
    "input_throughput": 922.9066615238985,
    "output_throughput": 839.269979055135,
    "total_throughput": 1762.1766405790333,
    "itl": 22.261354488180082,
    "ttft": 5537.282737818042,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378303,
    "arrivals": 13744,
    "finished_requests": 13723,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4829509869450703. Arrivals time: 0.04941112152300775 Scheduler time: 0.9798149868147448 Scheduler overhead time: 0.14060723362490535 Adapter cache time: 0.11189185443799943 Engine time: 0.1349395946599543 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.4157346159918234,
    "estimated_duration": 3599.9216976248395,
    "input_throughput": 863.83212225192,
    "output_throughput": 768.6800526316276,
    "total_throughput": 1632.5121748835477,
    "itl": 21.703446571002797,
    "ttft": 5692.6122709198235,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4159205260220915. Arrivals time: 0.04747254273388535 Scheduler time: 0.9152749382192269 Scheduler overhead time: 0.14547731971833855 Adapter cache time: 0.10382002731785178 Engine time: 0.135554545908235 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.418708570068702,
    "estimated_duration": 3599.924845062266,
    "input_throughput": 863.8313669979443,
    "output_throughput": 768.6793805697179,
    "total_throughput": 1632.510747567662,
    "itl": 21.70353209583701,
    "ttft": 5692.571523692592,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.418840612983331. Arrivals time: 0.048227555118501186 Scheduler time: 0.9166219512699172 Scheduler overhead time: 0.1435946914134547 Adapter cache time: 0.10446404595859349 Engine time: 0.1374533635098487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-8-32/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.418209397001192,
    "estimated_duration": 3599.9241213525593,
    "input_throughput": 863.8315406580339,
    "output_throughput": 768.6795351009553,
    "total_throughput": 1632.5110757589891,
    "itl": 21.70358067573585,
    "ttft": 5692.53120470812,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4185736971721064,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4183201140258461. Arrivals time: 0.04649589222390205 Scheduler time: 0.9214835964376107 Scheduler overhead time: 0.14396699494682252 Adapter cache time: 0.10350814298726618 Engine time: 0.13510109344497323 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.404148177942261,
    "estimated_duration": 3599.9262730910086,
    "input_throughput": 863.8310243309207,
    "output_throughput": 768.6790756478483,
    "total_throughput": 1632.5100999787692,
    "itl": 21.703564702487757,
    "ttft": 5692.539365943285,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4042599219828844. Arrivals time: 0.04551452212035656 Scheduler time: 0.9089349197456613 Scheduler overhead time: 0.14343800256028771 Adapter cache time: 0.10444760567042977 Engine time: 0.13403996464330703 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_8-16-32/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4131525999400765,
    "estimated_duration": 3599.9346485528395,
    "input_throughput": 863.8290145767228,
    "output_throughput": 768.6772872703118,
    "total_throughput": 1632.5063018470346,
    "itl": 21.703538678126357,
    "ttft": 5692.5841819473835,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42398110998794475,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.4132638829760253. Arrivals time: 0.04371282027568668 Scheduler time: 0.9200559173477814 Scheduler overhead time: 0.14289728505536914 Adapter cache time: 0.10306670726276934 Engine time: 0.13586793467402458 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.3971551889553666,
    "estimated_duration": 3599.9285814563527,
    "input_throughput": 863.8304704205988,
    "output_throughput": 768.6785827513647,
    "total_throughput": 1632.5090531719634,
    "itl": 21.703182801864017,
    "ttft": 5692.509628215112,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3972621539141983. Arrivals time: 0.04693004093132913 Scheduler time: 0.9045444985385984 Scheduler overhead time: 0.14357494236901402 Adapter cache time: 0.1030778696294874 Engine time: 0.13142007659189403 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.00625_size_16-16-32/adapters_128_slots_128_rate_0.05-0.025-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.025   0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 66, 66, 540, 66, 270, 270, 270, 66, 540, 270, 66, 540, 270, 66, 66, 66, 66, 270, 270, 540, 270, 66, 270, 270, 270, 270, 540, 270, 66, 270, 66, 540, 540, 66, 270, 270, 66, 270, 66, 270, 270, 540, 540, 540, 540, 270, 270, 66, 270, 540, 540, 270, 66, 66, 66, 540, 270, 270, 270, 270, 540, 270, 540, 66, 66, 270, 66, 540, 540, 66, 66, 270, 270, 270, 66, 540, 66, 540, 270, 66, 540, 540, 270, 270, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 270, 540, 540, 270, 540, 66, 270, 540, 66, 540, 270, 66, 270, 270, 540, 540, 66, 66, 540, 66, 66, 66, 270, 66]
Prompts retrieved: 37602 . Total input tokens: 8311855 . Total output tokens: 7507822
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.4415831780061126,
    "estimated_duration": 3599.920877462427,
    "input_throughput": 863.8323190569781,
    "output_throughput": 768.6802277583895,
    "total_throughput": 1632.5125468153676,
    "itl": 21.703716105140106,
    "ttft": 5692.501804496883,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378326,
    "arrivals": 12728,
    "finished_requests": 12708,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.441684919060208. Arrivals time: 0.04792472254484892 Scheduler time: 0.9395763803040609 Scheduler overhead time: 0.14357649849262089 Adapter cache time: 0.10409500694368035 Engine time: 0.13869698613416404 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.376004559919238,
    "estimated_duration": 3599.9511777403136,
    "input_throughput": 839.4961072491539,
    "output_throughput": 733.1427204678572,
    "total_throughput": 1572.638827717011,
    "itl": 21.348964611565744,
    "ttft": 6490.572520167617,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3761086699087173. Arrivals time: 0.044614481390453875 Scheduler time: 0.8801175963599235 Scheduler overhead time: 0.14646729826927185 Adapter cache time: 0.09933621133677661 Engine time: 0.13656500249635428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3754113529575989,
    "estimated_duration": 3599.935400234103,
    "input_throughput": 839.4997865249112,
    "output_throughput": 733.145933626578,
    "total_throughput": 1572.645720151489,
    "itl": 21.349394833705915,
    "ttft": 6490.630324662506,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41786563513334846,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3755110669881105. Arrivals time: 0.04435228859074414 Scheduler time: 0.880913044558838 Scheduler overhead time: 0.1450950496364385 Adapter cache time: 0.10058065794873983 Engine time: 0.1359173166565597 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3733197839464992,
    "estimated_duration": 3599.939549210561,
    "input_throughput": 839.4988189906503,
    "output_throughput": 733.1450886664953,
    "total_throughput": 1572.6439076571457,
    "itl": 21.349453260042555,
    "ttft": 6490.545909777899,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41857369717210635,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3734208929818124. Arrivals time: 0.042805328383110464 Scheduler time: 0.8758022100664675 Scheduler overhead time: 0.1446576036978513 Adapter cache time: 0.09950926632154733 Engine time: 0.14246696420013905 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.3627768839942291,
    "estimated_duration": 3599.943385825016,
    "input_throughput": 839.4979243006626,
    "output_throughput": 733.1443073222509,
    "total_throughput": 1572.6422316229134,
    "itl": 21.349074188647652,
    "ttft": 6490.703696554572,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4002960364404137,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3628797880373895. Arrivals time: 0.04236885218415409 Scheduler time: 0.8708164962008595 Scheduler overhead time: 0.1439170811790973 Adapter cache time: 0.09955928369890898 Engine time: 0.1375480213901028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3865224240580574,
    "estimated_duration": 3599.9451066818447,
    "input_throughput": 839.4975230012835,
    "output_throughput": 733.1439568623549,
    "total_throughput": 1572.6414798636386,
    "itl": 21.34955301326682,
    "ttft": 6490.564010042738,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879448,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3866230030544102. Arrivals time: 0.044274001964367926 Scheduler time: 0.8935786766232923 Scheduler overhead time: 0.14468632510397583 Adapter cache time: 0.09920880349818617 Engine time: 0.13623129983898252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.373906149994582,
    "estimated_duration": 3599.946102923847,
    "input_throughput": 839.4972906803906,
    "output_throughput": 733.1437539735387,
    "total_throughput": 1572.6410446539292,
    "itl": 21.34906900645398,
    "ttft": 6490.598632235077,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3740444659488276. Arrivals time: 0.04478065867442638 Scheduler time: 0.8783000380499288 Scheduler overhead time: 0.1450879214098677 Adapter cache time: 0.10017479863017797 Engine time: 0.1365558577235788 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.025,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.025-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.05-0.025-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.025    0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 270, 540, 540, 33, 33, 540, 33, 270, 270, 270, 33, 540, 270, 33, 540, 270, 33, 33, 33, 33, 270, 270, 540, 270, 33, 270, 270, 270, 270, 540, 270, 33, 270, 33, 540, 540, 33, 270, 270, 33, 270, 33, 270, 270, 540, 540, 540, 540, 270, 270, 33, 270, 540, 540, 270, 33, 33, 33, 540, 270, 270, 270, 270, 540, 270, 540, 33, 33, 270, 33, 540, 540, 33, 33, 270, 270, 270, 33, 540, 33, 540, 270, 33, 540, 540, 270, 270, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 270, 540, 540, 270, 540, 33, 270, 540, 33, 540, 270, 33, 270, 270, 540, 540, 33, 33, 540, 33, 33, 33, 270, 33]
Prompts retrieved: 36216 . Total input tokens: 7995821 . Total output tokens: 7231656
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3918203000212088,
    "estimated_duration": 3599.9353984411805,
    "input_throughput": 839.4997869430181,
    "output_throughput": 733.1459339917161,
    "total_throughput": 1572.6457209347343,
    "itl": 21.34900970445181,
    "ttft": 6490.599035448783,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4293885228037832,
    "arrivals": 12269,
    "finished_requests": 12247,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3919151179725304. Arrivals time: 0.044329067110084 Scheduler time: 0.8954069351311773 Scheduler overhead time: 0.14549483626615256 Adapter cache time: 0.09930915664881468 Engine time: 0.13876437407452613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.291863261954859,
    "estimated_duration": 3600.011577211205,
    "input_throughput": 728.1684916221055,
    "output_throughput": 658.6498262977364,
    "total_throughput": 1386.8183179198418,
    "itl": 21.014496612141606,
    "ttft": 5387.294064228774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2919881580164656. Arrivals time: 0.04131191817577928 Scheduler time: 0.8023965865140781 Scheduler overhead time: 0.14905231480952352 Adapter cache time: 0.09006135852541775 Engine time: 0.13859653566032648 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.3086173520423472,
    "estimated_duration": 3600.0027037770196,
    "input_throughput": 728.1702864416426,
    "output_throughput": 658.6514497648184,
    "total_throughput": 1386.8217362064609,
    "itl": 20.854378837466644,
    "ttft": 5387.178065089903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.3087093440117314. Arrivals time: 0.040062180836685 Scheduler time: 0.8187733631348237 Scheduler overhead time: 0.14789569156710058 Adapter cache time: 0.09022149606607854 Engine time: 0.1411964917788282 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-8-32/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2912573660723865,
    "estimated_duration": 3600.0026991843615,
    "input_throughput": 728.1702873705966,
    "output_throughput": 658.6514506050847,
    "total_throughput": 1386.8217379756813,
    "itl": 20.854462029193883,
    "ttft": 5387.164832221602,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4185736971721064,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2913713400484994. Arrivals time: 0.04090275277849287 Scheduler time: 0.8049983943346888 Scheduler overhead time: 0.1470121843740344 Adapter cache time: 0.09077465534210205 Engine time: 0.13781882100738585 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.2793381720548496,
    "estimated_duration": 3600.0124027773486,
    "input_throughput": 728.1683246362214,
    "output_throughput": 658.6496752540909,
    "total_throughput": 1386.8179998903124,
    "itl": 21.008882079281918,
    "ttft": 5387.478814607916,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2794353161007166. Arrivals time: 0.03966171876527369 Scheduler time: 0.7982380314497277 Scheduler overhead time: 0.14531160553451627 Adapter cache time: 0.08911869814619422 Engine time: 0.13830046053044498 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_8-16-32/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2811734389979392,
    "estimated_duration": 3600.0091954397603,
    "input_throughput": 728.1689733794639,
    "output_throughput": 658.6502620614423,
    "total_throughput": 1386.8192354409061,
    "itl": 20.854399638758487,
    "ttft": 5387.16660155013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42398110998794475,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2812745840055868. Arrivals time: 0.04068298637866974 Scheduler time: 0.7978652422316372 Scheduler overhead time: 0.14685135590843856 Adapter cache time: 0.08965723402798176 Engine time: 0.13628864311613142 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2778821809915826,
    "estimated_duration": 3599.9999588517007,
    "input_throughput": 728.1708416563865,
    "output_throughput": 658.651951972891,
    "total_throughput": 1386.8227936292776,
    "itl": 21.01447742729185,
    "ttft": 5387.501743932953,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2779793299268931. Arrivals time: 0.04035512323025614 Scheduler time: 0.7975181144429371 Scheduler overhead time: 0.14497805491555482 Adapter cache time: 0.08925767953041941 Engine time: 0.13688411586917937 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.00625_size_16-16-32/adapters_128_slots_128_rate_0.05-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.05   ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 66, 66, 540, 66, 135, 135, 135, 66, 540, 135, 66, 540, 135, 66, 66, 66, 66, 135, 135, 540, 135, 66, 135, 135, 135, 135, 540, 135, 66, 135, 66, 540, 540, 66, 135, 135, 66, 135, 66, 135, 135, 540, 540, 540, 540, 135, 135, 66, 135, 540, 540, 135, 66, 66, 66, 540, 135, 135, 135, 135, 540, 135, 540, 66, 66, 135, 66, 540, 540, 66, 66, 135, 135, 135, 66, 540, 66, 540, 135, 66, 540, 540, 135, 135, 66, 66, 66, 540, 540, 540, 540, 540, 540, 540, 540, 66, 540, 66, 66, 540, 135, 540, 540, 135, 540, 66, 135, 540, 66, 540, 135, 66, 135, 135, 540, 540, 66, 66, 540, 66, 66, 66, 135, 66]
Prompts retrieved: 31797 . Total input tokens: 7021629 . Total output tokens: 6368784
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2847433130955324,
    "estimated_duration": 3600.0133284268827,
    "input_throughput": 728.1681374067284,
    "output_throughput": 658.6495058995054,
    "total_throughput": 1386.8176433062338,
    "itl": 20.854481879802513,
    "ttft": 5387.122946945303,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4293885228037832,
    "arrivals": 10761,
    "finished_requests": 10745,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2848512220662087. Arrivals time: 0.04138962144497782 Scheduler time: 0.7973593561910093 Scheduler overhead time: 0.1483150478452444 Adapter cache time: 0.0905652844812721 Engine time: 0.13719314569607377 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.244961480027996,
    "estimated_duration": 3600.017237961007,
    "input_throughput": 705.6077324337283,
    "output_throughput": 630.8028128460303,
    "total_throughput": 1336.4105452797585,
    "itl": 20.601913585234584,
    "ttft": 4594.26486702875,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.24506075901445. Arrivals time: 0.036807154305279255 Scheduler time: 0.7676592629868537 Scheduler overhead time: 0.1473843230633065 Adapter cache time: 0.08505980530753732 Engine time: 0.13787561061326414 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2405448809731752,
    "estimated_duration": 3600.021754571386,
    "input_throughput": 705.6068471737425,
    "output_throughput": 630.8020214367762,
    "total_throughput": 1336.4088686105188,
    "itl": 20.6021197903412,
    "ttft": 4594.101438755859,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2406943009700626. Arrivals time: 0.03715439245570451 Scheduler time: 0.7638987113023177 Scheduler overhead time: 0.14841004472691566 Adapter cache time: 0.08498230890836567 Engine time: 0.13558534637559205 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2490629359381273,
    "estimated_duration": 3600.0020638561145,
    "input_throughput": 705.6107065891747,
    "output_throughput": 630.8054716967417,
    "total_throughput": 1336.4161782859164,
    "itl": 20.602151363801003,
    "ttft": 4243.778166321772,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41857369717210635,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2491791360080242. Arrivals time: 0.03961284109391272 Scheduler time: 0.7671170477988198 Scheduler overhead time: 0.14800249272957444 Adapter cache time: 0.08503795193973929 Engine time: 0.1391542195342481 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.2671354879857972,
    "estimated_duration": 3600.0021462322006,
    "input_throughput": 705.6106904432264,
    "output_throughput": 630.8054572625042,
    "total_throughput": 1336.4161477057307,
    "itl": 20.602004275317153,
    "ttft": 4243.755303840687,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2672319709090516. Arrivals time: 0.03911241132300347 Scheduler time: 0.7823219153797254 Scheduler overhead time: 0.14914983708877116 Adapter cache time: 0.08561405865475535 Engine time: 0.139468492125161 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2339852390578017,
    "estimated_duration": 3600.012890568131,
    "input_throughput": 705.6085845290187,
    "output_throughput": 630.8035746065401,
    "total_throughput": 1336.4121591355588,
    "itl": 20.602294646886243,
    "ttft": 4594.302352681013,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879447,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2341206980636343. Arrivals time: 0.03845061268657446 Scheduler time: 0.7577706830343232 Scheduler overhead time: 0.14692265237681568 Adapter cache time: 0.08479548513423651 Engine time: 0.13604639761615545 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2632653990294784,
    "estimated_duration": 3600.005569791374,
    "input_throughput": 705.6100194165001,
    "output_throughput": 630.8048573745963,
    "total_throughput": 1336.4148767910965,
    "itl": 20.601788830761546,
    "ttft": 4243.674972560874,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2633777860319242. Arrivals time: 0.04045558732468635 Scheduler time: 0.7800290958257392 Scheduler overhead time: 0.14810756244696677 Adapter cache time: 0.08551386184990406 Engine time: 0.138374085072428 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.0125-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.05-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 135, 540, 540, 33, 33, 540, 33, 135, 135, 135, 33, 540, 135, 33, 540, 135, 33, 33, 33, 33, 135, 135, 540, 135, 33, 135, 135, 135, 135, 540, 135, 33, 135, 33, 540, 540, 33, 135, 135, 33, 135, 33, 135, 135, 540, 540, 540, 540, 135, 135, 33, 135, 540, 540, 135, 33, 33, 33, 540, 135, 135, 135, 135, 540, 135, 540, 33, 33, 135, 33, 540, 540, 33, 33, 135, 135, 135, 33, 540, 33, 540, 135, 33, 540, 540, 135, 135, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 135, 540, 540, 135, 540, 33, 135, 540, 33, 540, 135, 33, 135, 135, 540, 540, 33, 33, 540, 33, 33, 33, 135, 33]
Prompts retrieved: 30411 . Total input tokens: 6723561 . Total output tokens: 6097076
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2403098880313337,
    "estimated_duration": 3600.0163084350875,
    "input_throughput": 705.6079146219797,
    "output_throughput": 630.8029757196159,
    "total_throughput": 1336.4108903415956,
    "itl": 20.60221947747674,
    "ttft": 4594.197882703246,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378315,
    "arrivals": 10263,
    "finished_requests": 10250,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2403912789886817. Arrivals time: 0.039355547400191426 Scheduler time: 0.7595908710500225 Scheduler overhead time: 0.14737610169686377 Adapter cache time: 0.0850551180774346 Engine time: 0.13897263526450843 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.2125553849618882,
    "estimated_duration": 3599.9223798518424,
    "input_throughput": 644.115554540215,
    "output_throughput": 556.9817313901422,
    "total_throughput": 1201.0972859303572,
    "itl": 20.078475907156037,
    "ttft": 3126.482150260147,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.212636383017525. Arrivals time: 0.037751105381175876 Scheduler time: 0.7207281165756285 Scheduler overhead time: 0.15849531558342278 Adapter cache time: 0.07947588083334267 Engine time: 0.1434605154208839 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1731868319911882,
    "estimated_duration": 3599.9330415494014,
    "input_throughput": 644.1136469032795,
    "output_throughput": 556.9800818120257,
    "total_throughput": 1201.0937287153051,
    "itl": 20.07862631225901,
    "ttft": 3126.4443314524287,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41786563513334835,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.17329177306965. Arrivals time: 0.037117815227247775 Scheduler time: 0.6943838414736092 Scheduler overhead time: 0.15011592931114137 Adapter cache time: 0.07962314726319164 Engine time: 0.1404904966475442 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.2055301459040493,
    "estimated_duration": 3599.9360957512235,
    "input_throughput": 644.1131004343918,
    "output_throughput": 556.9796092676428,
    "total_throughput": 1201.0927097020347,
    "itl": 20.078652743553512,
    "ttft": 3126.452101257211,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41857369717210635,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.2056388169294223. Arrivals time: 0.03747794299852103 Scheduler time: 0.7209800528362393 Scheduler overhead time: 0.149717602529563 Adapter cache time: 0.07986489380709827 Engine time: 0.14621168212033808 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.1897391150705516,
    "estimated_duration": 3599.9360769331965,
    "input_throughput": 644.1131038013787,
    "output_throughput": 556.9796121791549,
    "total_throughput": 1201.0927159805335,
    "itl": 20.0787039568073,
    "ttft": 3126.4423333387044,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1898469970328733. Arrivals time: 0.037119372049346566 Scheduler time: 0.7090656241634861 Scheduler overhead time: 0.15135291393380612 Adapter cache time: 0.07909111911430955 Engine time: 0.1410916963359341 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.1806977989617735,
    "estimated_duration": 3599.9377525380823,
    "input_throughput": 644.1128039964549,
    "output_throughput": 556.9793529308502,
    "total_throughput": 1201.092156927305,
    "itl": 20.078623167792323,
    "ttft": 3126.430624426492,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42398110998794475,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1808079229667783. Arrivals time: 0.03584446187596768 Scheduler time: 0.7000281711807474 Scheduler overhead time: 0.15071955497842282 Adapter cache time: 0.07953617675229907 Engine time: 0.14314482896588743 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.183447233051993,
    "estimated_duration": 3599.935997173439,
    "input_throughput": 644.1131180722728,
    "output_throughput": 556.9796245195295,
    "total_throughput": 1201.092742591802,
    "itl": 20.078365404403115,
    "ttft": 3126.448261032556,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1835293980548158. Arrivals time: 0.035833501257002354 Scheduler time: 0.7017853581346571 Scheduler overhead time: 0.1522875182563439 Adapter cache time: 0.07893482025247067 Engine time: 0.14239107840694487 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.05,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.05-0.00625-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.05-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.05    ]. Counts: [42 43 43]
Adapter prompts. [540, 66, 540, 540, 33, 33, 540, 33, 66, 66, 66, 33, 540, 66, 33, 540, 66, 33, 33, 33, 33, 66, 66, 540, 66, 33, 66, 66, 66, 66, 540, 66, 33, 66, 33, 540, 540, 33, 66, 66, 33, 66, 33, 66, 66, 540, 540, 540, 540, 66, 66, 33, 66, 540, 540, 66, 33, 33, 33, 540, 66, 66, 66, 66, 540, 66, 540, 33, 33, 66, 33, 540, 540, 33, 33, 66, 66, 66, 33, 540, 33, 540, 66, 33, 540, 540, 66, 66, 33, 33, 33, 540, 540, 540, 540, 540, 540, 540, 540, 33, 540, 33, 33, 540, 66, 540, 540, 66, 540, 33, 66, 540, 33, 540, 66, 33, 66, 66, 540, 540, 33, 33, 540, 33, 33, 33, 66, 33]
Prompts retrieved: 27444 . Total input tokens: 6052346 . Total output tokens: 5499823
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.176022614003159,
    "estimated_duration": 3599.923685471751,
    "input_throughput": 644.1153209324597,
    "output_throughput": 556.9815293840718,
    "total_throughput": 1201.0968503165313,
    "itl": 20.07862155671825,
    "ttft": 3126.628482917027,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4293885228037831,
    "arrivals": 9311,
    "finished_requests": 9303,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.1761068319901824. Arrivals time: 0.03663391328882426 Scheduler time: 0.6974904742091894 Scheduler overhead time: 0.14972845697775483 Adapter cache time: 0.0794499508338049 Engine time: 0.1409985894570127 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-8/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0190166679676622,
    "estimated_duration": 3598.5613136926495,
    "input_throughput": 458.97675654862184,
    "output_throughput": 415.035307114837,
    "total_throughput": 874.0120636634588,
    "itl": 19.52900892251067,
    "ttft": 3196.4848491096136,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.019144288962707. Arrivals time: 0.030083208461292088 Scheduler time: 0.5490526088979095 Scheduler overhead time: 0.15266299049835652 Adapter cache time: 0.06993288942612708 Engine time: 0.14402008440811187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-16/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0295709690544754,
    "estimated_duration": 3598.5622864466163,
    "input_throughput": 458.9766324792227,
    "output_throughput": 415.0351949235758,
    "total_throughput": 874.0118274027985,
    "itl": 19.529415217217075,
    "ttft": 3196.4609879373606,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.02970005501993. Arrivals time: 0.030545792425982654 Scheduler time: 0.5542345099383965 Scheduler overhead time: 0.15505414665676653 Adapter cache time: 0.07092864764854312 Engine time: 0.14443553623277694 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-8-32/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0239303220296279,
    "estimated_duration": 3598.5622371960126,
    "input_throughput": 458.97663876086375,
    "output_throughput": 415.035200603826,
    "total_throughput": 874.0118393646898,
    "itl": 19.529424469632467,
    "ttft": 3196.4759425396583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4185736971721064,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0239999589975923. Arrivals time: 0.030316574731841683 Scheduler time: 0.5502543248003349 Scheduler overhead time: 0.1529245610581711 Adapter cache time: 0.07064830418676138 Engine time: 0.14687955880071968 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-16/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 1.0220293900929391,
    "estimated_duration": 3598.561866752704,
    "input_throughput": 458.9766860088564,
    "output_throughput": 415.03524332839726,
    "total_throughput": 874.0119293372536,
    "itl": 19.529214602615507,
    "ttft": 3196.482717413842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0221472301054746. Arrivals time: 0.030572822550311685 Scheduler time: 0.5498525169678032 Scheduler overhead time: 0.15316311735659838 Adapter cache time: 0.07146149256732315 Engine time: 0.1435031193541363 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_8-16-32/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0157363850157708,
    "estimated_duration": 3598.5624038317333,
    "input_throughput": 458.97661750740355,
    "output_throughput": 415.0351813851264,
    "total_throughput": 874.0117988925299,
    "itl": 19.529448694785952,
    "ttft": 3196.488474979383,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879448,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0158341759815812. Arrivals time: 0.030374057590961456 Scheduler time: 0.5460729988990352 Scheduler overhead time: 0.15305875428020954 Adapter cache time: 0.07014046248514205 Engine time: 0.14263564685825258 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-16/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 1.0353408459341154,
    "estimated_duration": 3598.559662969917,
    "input_throughput": 458.9769670893483,
    "output_throughput": 415.03549749884627,
    "total_throughput": 874.0124645881946,
    "itl": 19.529106665500283,
    "ttft": 3196.429868293643,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.035411129007116. Arrivals time: 0.030152935185469687 Scheduler time: 0.5574752684915438 Scheduler overhead time: 0.1607038201764226 Adapter cache time: 0.07066876033786684 Engine time: 0.14139006251934916 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.00625_size_16-16-32/adapters_128_slots_128_rate_0.025-0.0125-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.0125  0.025  ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 66, 66, 270, 66, 135, 135, 135, 66, 270, 135, 66, 270, 135, 66, 66, 66, 66, 135, 135, 270, 135, 66, 135, 135, 135, 135, 270, 135, 66, 135, 66, 270, 270, 66, 135, 135, 66, 135, 66, 135, 135, 270, 270, 270, 270, 135, 135, 66, 135, 270, 270, 135, 66, 66, 66, 270, 135, 135, 135, 135, 270, 135, 270, 66, 66, 135, 66, 270, 270, 66, 66, 135, 135, 135, 66, 270, 66, 270, 135, 66, 270, 270, 135, 135, 66, 66, 66, 270, 270, 270, 270, 270, 270, 270, 270, 66, 270, 66, 66, 270, 135, 270, 270, 135, 270, 66, 135, 270, 66, 270, 135, 66, 135, 135, 270, 270, 66, 66, 270, 66, 66, 66, 135, 66]
Prompts retrieved: 20187 . Total input tokens: 4469012 . Total output tokens: 4045314
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 1.0120473690330982,
    "estimated_duration": 3598.5627386872084,
    "input_throughput": 458.9765747984543,
    "output_throughput": 415.0351427650403,
    "total_throughput": 874.0117175634946,
    "itl": 19.529077843774477,
    "ttft": 3196.476402355747,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378315,
    "arrivals": 6826,
    "finished_requests": 6820,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 1.0122029010672122. Arrivals time: 0.030026664375327528 Scheduler time: 0.5460979724302888 Scheduler overhead time: 0.15175673668272793 Adapter cache time: 0.0700754577992484 Engine time: 0.14127729937899858 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9826252359198406,
    "estimated_duration": 3599.997400792389,
    "input_throughput": 426.8136414936849,
    "output_throughput": 387.73027994208184,
    "total_throughput": 814.5439214357667,
    "itl": 19.188002562216315,
    "ttft": 5716.361357041957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9827021890087053. Arrivals time: 0.02903413015883416 Scheduler time: 0.5165930662769824 Scheduler overhead time: 0.15229841228574514 Adapter cache time: 0.06690136902034283 Engine time: 0.1444766242057085 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9944754170719534,
    "estimated_duration": 3600.006694821184,
    "input_throughput": 426.812539601769,
    "output_throughput": 387.7292789505027,
    "total_throughput": 814.5418185522717,
    "itl": 19.188510681445244,
    "ttft": 5716.365498914778,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4178656351333484,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9945617960765958. Arrivals time: 0.029424513690173626 Scheduler time: 0.5269867925671861 Scheduler overhead time: 0.15198140568099916 Adapter cache time: 0.06621801562141627 Engine time: 0.14642158255446702 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9913792309816927,
    "estimated_duration": 3600.006690228522,
    "input_throughput": 426.81254014626955,
    "output_throughput": 387.7292794451433,
    "total_throughput": 814.5418195914128,
    "itl": 19.18851956331274,
    "ttft": 5716.358285586646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41857369717210635,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9914783069398254. Arrivals time: 0.0300364081049338 Scheduler time: 0.523367230896838 Scheduler overhead time: 0.15294922422617674 Adapter cache time: 0.06640811928082258 Engine time: 0.1448629820952192 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9945119310868904,
    "estimated_duration": 3600.0067415717876,
    "input_throughput": 426.81253405907273,
    "output_throughput": 387.7292739153516,
    "total_throughput": 814.5418079744243,
    "itl": 19.188029505812175,
    "ttft": 5716.353121179639,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9945756270317361. Arrivals time: 0.029080557636916637 Scheduler time: 0.5224427612265572 Scheduler overhead time: 0.15760741918347776 Adapter cache time: 0.06624235631898046 Engine time: 0.14497661648783833 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9880154860438779,
    "estimated_duration": 3600.0099992834766,
    "input_throughput": 426.81214782898405,
    "output_throughput": 387.7289230523851,
    "total_throughput": 814.5410708813691,
    "itl": 19.188176399515022,
    "ttft": 5716.189200841345,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42398110998794464,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9881520400522277. Arrivals time: 0.028372558997943997 Scheduler time: 0.520288321073167 Scheduler overhead time: 0.15320709941443056 Adapter cache time: 0.06659860222134739 Engine time: 0.14573038602247834 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9898723990190774,
    "estimated_duration": 3600.0075557637315,
    "input_throughput": 426.81243752946233,
    "output_throughput": 387.7291862249659,
    "total_throughput": 814.5416237544282,
    "itl": 19.187719355155085,
    "ttft": 5716.434189940187,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9899659999646246. Arrivals time: 0.029243468889035285 Scheduler time: 0.5242562260245904 Scheduler overhead time: 0.15304294985253364 Adapter cache time: 0.06655677210073918 Engine time: 0.1431437279097736 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.0125,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.0125-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.025-0.0125-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.0125   0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 135, 270, 270, 33, 33, 270, 33, 135, 135, 135, 33, 270, 135, 33, 270, 135, 33, 33, 33, 33, 135, 135, 270, 135, 33, 135, 135, 135, 135, 270, 135, 33, 135, 33, 270, 270, 33, 135, 135, 33, 135, 33, 135, 135, 270, 270, 270, 270, 135, 135, 33, 135, 270, 270, 135, 33, 33, 33, 270, 135, 135, 135, 135, 270, 135, 270, 33, 33, 135, 33, 270, 270, 33, 33, 135, 135, 135, 33, 270, 33, 270, 135, 33, 270, 270, 135, 135, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 135, 270, 270, 135, 270, 33, 135, 270, 33, 270, 135, 33, 135, 135, 270, 270, 33, 33, 270, 33, 33, 33, 135, 33]
Prompts retrieved: 18801 . Total input tokens: 4147914 . Total output tokens: 3764709
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9934423809172586,
    "estimated_duration": 3599.9977438617266,
    "input_throughput": 426.8136008195834,
    "output_throughput": 387.73024299251136,
    "total_throughput": 814.5438438120948,
    "itl": 19.18830094440947,
    "ttft": 5716.366448573314,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4293885228037831,
    "arrivals": 6333,
    "finished_requests": 6323,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9935148309450597. Arrivals time: 0.02964372222777456 Scheduler time: 0.5243041394278407 Scheduler overhead time: 0.15301745501346886 Adapter cache time: 0.06674355105496943 Engine time: 0.1459147579735145 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9283501020399854,
    "estimated_duration": 3599.430161474897,
    "input_throughput": 359.52913154168033,
    "output_throughput": 326.2880365259702,
    "total_throughput": 685.8171680676505,
    "itl": 18.922527154893753,
    "ttft": 6748.924624875334,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.928440900053829. Arrivals time: 0.026854017982259393 Scheduler time: 0.4626649901038036 Scheduler overhead time: 0.15791991620790213 Adapter cache time: 0.059774674591608346 Engine time: 0.1458584211068228 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9204565400723368,
    "estimated_duration": 3599.430161474897,
    "input_throughput": 359.52913154168033,
    "output_throughput": 326.2880365259702,
    "total_throughput": 685.8171680676505,
    "itl": 18.922803685284848,
    "ttft": 6748.874668057762,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41786563513334846,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9206656680908054. Arrivals time: 0.02733039075974375 Scheduler time: 0.45941333193331957 Scheduler overhead time: 0.15435218752827495 Adapter cache time: 0.05950078344903886 Engine time: 0.14543041947763413 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9250015950528905,
    "estimated_duration": 3599.430161474897,
    "input_throughput": 359.52913154168033,
    "output_throughput": 326.2880365259702,
    "total_throughput": 685.8171680676505,
    "itl": 18.92277088263413,
    "ttft": 6748.90849664631,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41857369717210635,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.925092003075406. Arrivals time: 0.026968449936248362 Scheduler time: 0.46292422886472195 Scheduler overhead time: 0.15345328068360686 Adapter cache time: 0.059240546193905175 Engine time: 0.14781220187433064 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.9193285360233858,
    "estimated_duration": 3599.430161474897,
    "input_throughput": 359.52913154168033,
    "output_throughput": 326.2880365259702,
    "total_throughput": 685.8171680676505,
    "itl": 18.92268128000306,
    "ttft": 6748.936461434932,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.40029603644041367,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9193913330091164. Arrivals time: 0.0262297042645514 Scheduler time: 0.4613209250383079 Scheduler overhead time: 0.15264045516960323 Adapter cache time: 0.05899741605389863 Engine time: 0.14586224465165287 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9232495239702985,
    "estimated_duration": 3599.430161474897,
    "input_throughput": 359.52913154168033,
    "output_throughput": 326.2880365259702,
    "total_throughput": 685.8171680676505,
    "itl": 18.922771153638827,
    "ttft": 6748.909100174774,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879447,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9234519460005686. Arrivals time: 0.02712134155444801 Scheduler time: 0.46049695112742484 Scheduler overhead time: 0.15460414602421224 Adapter cache time: 0.05980516807176173 Engine time: 0.14659114927053452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.9215691830031574,
    "estimated_duration": 3599.430161474897,
    "input_throughput": 359.52913154168033,
    "output_throughput": 326.2880365259702,
    "total_throughput": 685.8171680676505,
    "itl": 18.922547403766135,
    "ttft": 6748.897325865558,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9216408879728988. Arrivals time: 0.026966784498654306 Scheduler time: 0.46052939910441637 Scheduler overhead time: 0.1532895261188969 Adapter cache time: 0.05979931680485606 Engine time: 0.14650333381723613 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.025,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.025-0.00625-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.025-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.025   ]. Counts: [42 43 43]
Adapter prompts. [270, 66, 270, 270, 33, 33, 270, 33, 66, 66, 66, 33, 270, 66, 33, 270, 66, 33, 33, 33, 33, 66, 66, 270, 66, 33, 66, 66, 66, 66, 270, 66, 33, 66, 33, 270, 270, 33, 66, 66, 33, 66, 33, 66, 66, 270, 270, 270, 270, 66, 66, 33, 66, 270, 270, 66, 33, 33, 33, 270, 66, 66, 66, 66, 270, 66, 270, 33, 33, 66, 33, 270, 270, 33, 33, 66, 66, 66, 33, 270, 33, 270, 66, 33, 270, 270, 66, 66, 33, 33, 33, 270, 270, 270, 270, 270, 270, 270, 270, 33, 270, 33, 33, 270, 66, 270, 270, 66, 270, 33, 66, 270, 33, 270, 66, 33, 66, 66, 270, 270, 33, 33, 270, 33, 33, 33, 66, 33]
Prompts retrieved: 15834 . Total input tokens: 3478100 . Total output tokens: 3189536
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.9318080879747868,
    "estimated_duration": 3599.430161474897,
    "input_throughput": 359.52913154168033,
    "output_throughput": 326.2880365259702,
    "total_throughput": 685.8171680676505,
    "itl": 18.92278903199503,
    "ttft": 6748.8709731270155,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378326,
    "arrivals": 5359,
    "finished_requests": 5349,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.9319016940426081. Arrivals time: 0.027654662495478988 Scheduler time: 0.4682065821252763 Scheduler overhead time: 0.1544988084351644 Adapter cache time: 0.059849804383702576 Engine time: 0.14723317162133753 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 601664,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-8/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [8]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.7689661330077797,
    "estimated_duration": 3598.3583796595913,
    "input_throughput": 219.70685423356585,
    "output_throughput": 202.52985475808637,
    "total_throughput": 422.2367089916522,
    "itl": 18.366308165538392,
    "ttft": 3305.8944536445674,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.39174243122339203,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7690589169505984. Arrivals time: 0.021400354569777846 Scheduler time: 0.32725526590365916 Scheduler overhead time: 0.154512366396375 Adapter cache time: 0.046011218219064176 Engine time: 0.1449944336200133 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-16/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7677466840250418,
    "estimated_duration": 3598.3583796595913,
    "input_throughput": 219.70685423356585,
    "output_throughput": 202.52985475808637,
    "total_throughput": 422.2367089916522,
    "itl": 18.366945411342133,
    "ttft": 3305.8463276420307,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.41786563513334835,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.767831331002526. Arrivals time: 0.021592933451756835 Scheduler time: 0.3265716094756499 Scheduler overhead time: 0.15380110929254442 Adapter cache time: 0.046215053531341255 Engine time: 0.14498984802048653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-8-32/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7720766690326855,
    "estimated_duration": 3598.3583796595913,
    "input_throughput": 219.70685423356585,
    "output_throughput": 202.52985475808637,
    "total_throughput": 422.2367089916522,
    "itl": 18.366949771579456,
    "ttft": 3305.864251836102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4185736971721064,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7721688280580565. Arrivals time: 0.021771658794023097 Scheduler time: 0.3287392359925434 Scheduler overhead time: 0.15405417629517615 Adapter cache time: 0.046538911876268685 Engine time: 0.1459141100058332 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-16/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [43 85]
---Simulation End---
#Simulation results
{
    "duration": 0.7670933840563521,
    "estimated_duration": 3598.3583796595913,
    "input_throughput": 219.70685423356585,
    "output_throughput": 202.52985475808637,
    "total_throughput": 422.2367089916522,
    "itl": 18.36630103506265,
    "ttft": 3305.889102396105,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4002960364404136,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7671891649952158. Arrivals time: 0.021664693602360785 Scheduler time: 0.3264004176016897 Scheduler overhead time: 0.15217772161122411 Adapter cache time: 0.046167073771357536 Engine time: 0.1461150289978832 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_8-16-32/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [43 43 42]
---Simulation End---
#Simulation results
{
    "duration": 0.7703986420528963,
    "estimated_duration": 3598.3583796595913,
    "input_throughput": 219.70685423356585,
    "output_throughput": 202.52985475808637,
    "total_throughput": 422.2367089916522,
    "itl": 18.36702060260149,
    "ttft": 3305.8274255174806,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.4239811099879448,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7704832559684291. Arrivals time: 0.022021632874384522 Scheduler time: 0.32779214228503406 Scheduler overhead time: 0.15328836371190846 Adapter cache time: 0.046124159009195864 Engine time: 0.1464586325455457 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 526992,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-16/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [16]. Counts: [128]
---Simulation End---
#Simulation results
{
    "duration": 0.769770059036091,
    "estimated_duration": 3598.3583796595913,
    "input_throughput": 219.70685423356585,
    "output_throughput": 202.52985475808637,
    "total_throughput": 422.2367089916522,
    "itl": 18.366213848018656,
    "ttft": 3305.9176495115994,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.38272643774747894,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7698832199675962. Arrivals time: 0.021694869617931545 Scheduler time: 0.3277464781422168 Scheduler overhead time: 0.1534542265580967 Adapter cache time: 0.046369101386517286 Engine time: 0.14614791853819042 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 128,
    "served_adapters": 128,
    "served_adapters_rates": [
        0.0125,
        0.00625,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 346768,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_0.0125-0.00625-0.003125_size_16-16-32/adapters_128_slots_128_rate_0.0125-0.00625-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.003125 0.00625  0.0125  ]. Counts: [42 43 43]
Adapter prompts. [135, 66, 135, 135, 33, 33, 135, 33, 66, 66, 66, 33, 135, 66, 33, 135, 66, 33, 33, 33, 33, 66, 66, 135, 66, 33, 66, 66, 66, 66, 135, 66, 33, 66, 33, 135, 135, 33, 66, 66, 33, 66, 33, 66, 66, 135, 135, 135, 135, 66, 66, 33, 66, 135, 135, 66, 33, 33, 33, 135, 66, 66, 66, 66, 135, 66, 135, 33, 33, 66, 33, 135, 135, 33, 33, 66, 66, 66, 33, 135, 33, 135, 66, 33, 135, 135, 66, 66, 33, 33, 33, 135, 135, 135, 135, 135, 135, 135, 135, 33, 135, 33, 33, 135, 66, 135, 135, 66, 135, 33, 66, 135, 33, 135, 66, 33, 66, 66, 135, 135, 33, 33, 135, 33, 33, 33, 66, 33]
Prompts retrieved: 10029 . Total input tokens: 2205085 . Total output tokens: 2017823
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [86 42]
---Simulation End---
#Simulation results
{
    "duration": 0.770801851991564,
    "estimated_duration": 3598.3583796595913,
    "input_throughput": 219.70685423356585,
    "output_throughput": 202.52985475808637,
    "total_throughput": 422.2367089916522,
    "itl": 18.367539593904137,
    "ttft": 3305.897479296484,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 128,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.42938852280378326,
    "arrivals": 3297,
    "finished_requests": 3294,
    "scheduler_time": 0.0
}
#Debug simulation 
Total elapsed time: 0.7709319969872013. Arrivals time: 0.02181756973732263 Scheduler time: 0.3287804687861353 Scheduler overhead time: 0.15324289724230766 Adapter cache time: 0.045995921711437404 Engine time: 0.14654189755674452 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 152.42057588801254,
    "estimated_duration": 3600.1263727206833,
    "input_throughput": 7907.235205881652,
    "output_throughput": 7028.134676527667,
    "total_throughput": 14935.369882409319,
    "itl": 104.3056752007281,
    "ttft": 1960305.800384201,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.089533636840062,
    "arrivals": 1078565,
    "finished_requests": 115060,
    "scheduler_time": 274.0975231176865
}
#Debug simulation 
Total elapsed time: 152.42073385394178. Arrivals time: 1.0236947018420324 Scheduler time: 151.058102798881 Scheduler overhead time: 0.1377832005964592 Adapter cache time: 0.02959510695654899 Engine time: 0.13132897368632257 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 153.14226573088672,
    "estimated_duration": 3600.0084234680066,
    "input_throughput": 7792.9895433338625,
    "output_throughput": 6927.267680106201,
    "total_throughput": 14720.257223440063,
    "itl": 101.4772240726834,
    "ttft": 1974759.822253424,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.125135679664096,
    "arrivals": 1078565,
    "finished_requests": 113333,
    "scheduler_time": 279.5828090802954
}
#Debug simulation 
Total elapsed time: 153.1424271329306. Arrivals time: 1.0107172796269879 Scheduler time: 151.80108836945146 Scheduler overhead time: 0.13508462021127343 Adapter cache time: 0.028416578890755773 Engine time: 0.1269237856613472 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 153.87349469598848,
    "estimated_duration": 3600.0106762354417,
    "input_throughput": 7792.98466673914,
    "output_throughput": 6927.263345251545,
    "total_throughput": 14720.248011990685,
    "itl": 101.47726474546815,
    "ttft": 1974760.7700374702,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.127243679072714,
    "arrivals": 1078565,
    "finished_requests": 113333,
    "scheduler_time": 279.5828538097259
}
#Debug simulation 
Total elapsed time: 153.87368758802768. Arrivals time: 1.0326344020431861 Scheduler time: 152.51317276933696 Scheduler overhead time: 0.13518750329967588 Adapter cache time: 0.02777628682088107 Engine time: 0.12565830489620566 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 152.3429197249934,
    "estimated_duration": 3600.020797682342,
    "input_throughput": 7906.903487425821,
    "output_throughput": 7028.14828633458,
    "total_throughput": 14935.051773760402,
    "itl": 104.30611916825356,
    "ttft": 1960276.8613690247,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1138979385164585,
    "arrivals": 1078565,
    "finished_requests": 115054,
    "scheduler_time": 274.08892189276514
}
#Debug simulation 
Total elapsed time: 152.3431595839793. Arrivals time: 1.0354430205188692 Scheduler time: 150.9685098885093 Scheduler overhead time: 0.14021213084924966 Adapter cache time: 0.029885113588534296 Engine time: 0.12938844237942249 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.8_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 155.42757955100387,
    "estimated_duration": 3600.024882352791,
    "input_throughput": 7792.9539147142805,
    "output_throughput": 6927.236009463819,
    "total_throughput": 14720.1899241781,
    "itl": 101.47758289380653,
    "ttft": 1974767.1515270162,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1410765955783482,
    "arrivals": 1078565,
    "finished_requests": 113333,
    "scheduler_time": 279.5830269334214
}
#Debug simulation 
Total elapsed time: 155.42773695499636. Arrivals time: 0.9931789964903146 Scheduler time: 154.10923152568284 Scheduler overhead time: 0.13276809558738023 Adapter cache time: 0.028054938302375376 Engine time: 0.12512834439985454 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.8_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.8_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 150.5603835210204,
    "estimated_duration": 3600.100878287495,
    "input_throughput": 7907.291201668014,
    "output_throughput": 7028.184446885777,
    "total_throughput": 14935.475648553791,
    "itl": 104.3049142802459,
    "ttft": 1960294.8836266946,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0644579049851737,
    "arrivals": 1078565,
    "finished_requests": 115060,
    "scheduler_time": 274.0972044548803
}
#Debug simulation 
Total elapsed time: 150.56055595597718. Arrivals time: 1.0079356821952388 Scheduler time: 149.22617918101605 Scheduler overhead time: 0.13495654659345746 Adapter cache time: 0.028315691044554114 Engine time: 0.12437252420932055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.8_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.8
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.8_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.8_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.8 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [8640, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 34560, 17280, 8640, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 8640, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 17280, 34560, 8640, 8640, 34560, 8640, 34560, 8640, 8640, 17280, 8640, 17280, 34560, 8640, 8640, 17280, 8640, 8640, 8640, 8640, 8640, 34560, 17280, 17280, 34560, 17280, 8640, 34560, 34560, 34560, 17280, 17280, 8640, 8640, 8640, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 8640, 8640, 34560, 17280, 34560, 34560, 8640, 34560, 8640, 17280, 8640, 8640, 17280, 17280, 34560, 34560, 34560, 8640, 34560, 17280, 17280, 8640, 8640, 8640, 8640, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 8640, 17280, 17280, 34560, 17280, 34560, 8640, 8640, 8640, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 8640, 17280, 17280, 8640, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 8640, 34560, 8640, 34560, 17280, 8640, 17280, 8640, 8640, 17280, 17280, 17280, 34560, 17280, 8640, 8640]
Prompts retrieved: 3240000 . Total input tokens: 721625136 . Total output tokens: 648199760
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 156.3854084329214,
    "estimated_duration": 3600.0398904403078,
    "input_throughput": 7792.921426925832,
    "output_throughput": 6927.207130738181,
    "total_throughput": 14720.128557664013,
    "itl": 101.47789680928568,
    "ttft": 1974773.3308580394,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.156041296161715,
    "arrivals": 1078565,
    "finished_requests": 113333,
    "scheduler_time": 279.5831703589509
}
#Debug simulation 
Total elapsed time: 156.38556142500602. Arrivals time: 1.0271070132730529 Scheduler time: 155.0288933988195 Scheduler overhead time: 0.13541645754594356 Adapter cache time: 0.028331504319794476 Engine time: 0.1263142244424671 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 108.87563587899785,
    "estimated_duration": 3600.0724780335813,
    "input_throughput": 7972.226719078927,
    "output_throughput": 7081.106604254929,
    "total_throughput": 15053.333323333856,
    "itl": 104.47939744902176,
    "ttft": 1953036.0983674342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.089533636840062,
    "arrivals": 1002554,
    "finished_requests": 115876,
    "scheduler_time": 271.3354224213625
}
#Debug simulation 
Total elapsed time: 108.87575647502672. Arrivals time: 0.5738498751306906 Scheduler time: 108.08659545902628 Scheduler overhead time: 0.08756439120043069 Adapter cache time: 0.017703436547890306 Engine time: 0.07872478850185871 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 108.77332581102382,
    "estimated_duration": 3600.1048629409634,
    "input_throughput": 7888.669658583142,
    "output_throughput": 7002.61546809655,
    "total_throughput": 14891.285126679692,
    "itl": 102.50993236642235,
    "ttft": 1951643.385253347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1293515159143188,
    "arrivals": 1002554,
    "finished_requests": 114677,
    "scheduler_time": 275.4872100778884
}
#Debug simulation 
Total elapsed time: 108.77345189102925. Arrivals time: 0.5636807701084763 Scheduler time: 107.99442677455954 Scheduler overhead time: 0.0870992416748777 Adapter cache time: 0.01750723854638636 Engine time: 0.07962954719550908 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 108.55078922398388,
    "estimated_duration": 3600.106807760052,
    "input_throughput": 7888.665397033095,
    "output_throughput": 7002.611685203164,
    "total_throughput": 14891.277082236258,
    "itl": 102.50997805904571,
    "ttft": 1951644.1847221842,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1312989404052558,
    "arrivals": 1002554,
    "finished_requests": 114677,
    "scheduler_time": 275.4872074724692
}
#Debug simulation 
Total elapsed time: 108.5509085750673. Arrivals time: 0.5719671647530049 Scheduler time: 107.76041226717643 Scheduler overhead time: 0.08924227091483772 Adapter cache time: 0.01764324400573969 Engine time: 0.08021999488119036 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 108.56585787597578,
    "estimated_duration": 3600.0966817219723,
    "input_throughput": 7972.173121270771,
    "output_throughput": 7081.058997506315,
    "total_throughput": 15053.232118777085,
    "itl": 104.47989497236809,
    "ttft": 1953046.1152935093,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.113489343198018,
    "arrivals": 1002554,
    "finished_requests": 115876,
    "scheduler_time": 271.335870480518
}
#Debug simulation 
Total elapsed time: 108.56598106399179. Arrivals time: 0.6730741830542684 Scheduler time: 107.67649427836295 Scheduler overhead time: 0.08805561391636729 Adapter cache time: 0.017521097790449858 Engine time: 0.07887398055754602 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 108.71700468205381,
    "estimated_duration": 3600.1215305521723,
    "input_throughput": 7888.633136127522,
    "output_throughput": 7002.5830478376565,
    "total_throughput": 14891.21618396518,
    "itl": 102.51026647504453,
    "ttft": 1951650.3536145266,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.145760625842964,
    "arrivals": 1002554,
    "finished_requests": 114677,
    "scheduler_time": 275.4874685791659
}
#Debug simulation 
Total elapsed time: 108.71718849905301. Arrivals time: 0.5668899841839448 Scheduler time: 107.93169028311968 Scheduler overhead time: 0.08741433662362397 Adapter cache time: 0.017954437993466854 Engine time: 0.08162349823396653 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 108.96113116294146,
    "estimated_duration": 3600.0463926075267,
    "input_throughput": 7972.284484704114,
    "output_throughput": 7081.157912950031,
    "total_throughput": 15053.442397654144,
    "itl": 104.47884998930968,
    "ttft": 1953025.0175537297,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 356,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0644579049851737,
    "arrivals": 1002554,
    "finished_requests": 115876,
    "scheduler_time": 271.33510067936174
}
#Debug simulation 
Total elapsed time: 108.96125616098288. Arrivals time: 0.5714068392990157 Scheduler time: 108.17732710856944 Scheduler overhead time: 0.0861912511754781 Adapter cache time: 0.017226513475179672 Engine time: 0.07818636612500995 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.4_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 34560, 17280, 4320, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 4320, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 17280, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 17280, 4320, 17280, 34560, 4320, 4320, 17280, 4320, 4320, 4320, 4320, 4320, 34560, 17280, 17280, 34560, 17280, 4320, 34560, 34560, 34560, 17280, 17280, 4320, 4320, 4320, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 17280, 34560, 34560, 4320, 34560, 4320, 17280, 4320, 4320, 17280, 17280, 34560, 34560, 34560, 4320, 34560, 17280, 17280, 4320, 4320, 4320, 4320, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 4320, 17280, 17280, 34560, 17280, 34560, 4320, 4320, 4320, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 4320, 17280, 17280, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 4320, 34560, 4320, 34560, 17280, 4320, 17280, 4320, 4320, 17280, 17280, 17280, 34560, 17280, 4320, 4320]
Prompts retrieved: 3011040 . Total input tokens: 670651597 . Total output tokens: 602378110
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 108.67267489491496,
    "estimated_duration": 3600.0073518228814,
    "input_throughput": 7888.687778823523,
    "output_throughput": 7002.611255011762,
    "total_throughput": 14891.299033835287,
    "itl": 102.50988037021304,
    "ttft": 1951607.7977120033,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 346,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1604738188535013,
    "arrivals": 1002554,
    "finished_requests": 114674,
    "scheduler_time": 275.4787143090516
}
#Debug simulation 
Total elapsed time: 108.67279722390231. Arrivals time: 0.5679152171360329 Scheduler time: 107.88676967681386 Scheduler overhead time: 0.08921100432053208 Adapter cache time: 0.01788780279457569 Engine time: 0.07953265483956784 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 109.69793187093455,
    "estimated_duration": 3600.045179927991,
    "input_throughput": 7906.89049090472,
    "output_throughput": 7019.194131476274,
    "total_throughput": 14926.084622380993,
    "itl": 105.2671545385276,
    "ttft": 1933372.606370021,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0619892471446664,
    "arrivals": 945185,
    "finished_requests": 115079,
    "scheduler_time": 274.96037876454164
}
#Debug simulation 
Total elapsed time: 109.69805448292755. Arrivals time: 0.5595006472431123 Scheduler time: 108.92255341424607 Scheduler overhead time: 0.0873856182442978 Adapter cache time: 0.017765708500519395 Engine time: 0.07948121393565089 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 107.985670465976,
    "estimated_duration": 3600.0126645434616,
    "input_throughput": 7952.216469113587,
    "output_throughput": 7049.134368314285,
    "total_throughput": 15001.350837427872,
    "itl": 105.63879061926885,
    "ttft": 1937181.1721584045,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1519162492523958,
    "arrivals": 945185,
    "finished_requests": 115565,
    "scheduler_time": 273.4450818657128
}
#Debug simulation 
Total elapsed time: 107.9857967729913. Arrivals time: 0.5717885573394597 Scheduler time: 107.20004733244423 Scheduler overhead time: 0.08615180046763271 Adapter cache time: 0.017432500259019434 Engine time: 0.0787040563300252 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 107.87356160802301,
    "estimated_duration": 3600.014496698109,
    "input_throughput": 7952.212421993672,
    "output_throughput": 7049.130780799762,
    "total_throughput": 15001.343202793434,
    "itl": 105.6388264264324,
    "ttft": 1937181.702087957,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.153952562324709,
    "arrivals": 945185,
    "finished_requests": 115565,
    "scheduler_time": 273.44507778443386
}
#Debug simulation 
Total elapsed time: 107.87368163000792. Arrivals time: 0.548617459833622 Scheduler time: 107.11205925920513 Scheduler overhead time: 0.0864870494697243 Adapter cache time: 0.017096937401220202 Engine time: 0.07890143350232393 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 109.12608399800956,
    "estimated_duration": 3600.068450276026,
    "input_throughput": 7906.839381850506,
    "output_throughput": 7019.148760369412,
    "total_throughput": 14925.988142219918,
    "itl": 105.26761490388911,
    "ttft": 1933381.7292284968,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0849445092701377,
    "arrivals": 945185,
    "finished_requests": 115079,
    "scheduler_time": 274.9605938118316
}
#Debug simulation 
Total elapsed time: 109.12620653701015. Arrivals time: 0.5553361258935183 Scheduler time: 108.35393829015084 Scheduler overhead time: 0.08837871113792062 Adapter cache time: 0.017915874137543142 Engine time: 0.0791795743862167 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 108.39914758002851,
    "estimated_duration": 3600.028366072187,
    "input_throughput": 7952.181785510396,
    "output_throughput": 7049.103623504934,
    "total_throughput": 15001.28540901533,
    "itl": 105.63904609737362,
    "ttft": 1937187.2177185942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1685400015488316,
    "arrivals": 945185,
    "finished_requests": 115565,
    "scheduler_time": 273.44516002794217
}
#Debug simulation 
Total elapsed time: 108.39927509101108. Arrivals time: 0.555188917554915 Scheduler time: 107.62532293924596 Scheduler overhead time: 0.08802498818840832 Adapter cache time: 0.0177076623076573 Engine time: 0.08173926407471299 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 109.06615287996829,
    "estimated_duration": 3600.0193314715407,
    "input_throughput": 7906.947263076114,
    "output_throughput": 7019.244529909482,
    "total_throughput": 14926.191792985595,
    "itl": 105.26730013199176,
    "ttft": 1933361.8571629776,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.037547452331055,
    "arrivals": 945185,
    "finished_requests": 115079,
    "scheduler_time": 274.960072527235
}
#Debug simulation 
Total elapsed time: 109.06634322600439. Arrivals time: 0.562412757310085 Scheduler time: 108.28732075903099 Scheduler overhead time: 0.0872209487715736 Adapter cache time: 0.017312734737060964 Engine time: 0.08007655711844563 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.1_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 1.6 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 34560, 17280, 1080, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 1080, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 17280, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 17280, 1080, 17280, 34560, 1080, 1080, 17280, 1080, 1080, 1080, 1080, 1080, 34560, 17280, 17280, 34560, 17280, 1080, 34560, 34560, 34560, 17280, 17280, 1080, 1080, 1080, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 17280, 34560, 34560, 1080, 34560, 1080, 17280, 1080, 1080, 17280, 17280, 34560, 34560, 34560, 1080, 34560, 17280, 17280, 1080, 1080, 1080, 1080, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 1080, 17280, 17280, 34560, 17280, 34560, 1080, 1080, 1080, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 1080, 17280, 17280, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 1080, 34560, 1080, 34560, 17280, 1080, 17280, 1080, 1080, 17280, 17280, 17280, 34560, 17280, 1080, 1080]
Prompts retrieved: 2839320 . Total input tokens: 632348578 . Total output tokens: 567998722
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 107.72647525393404,
    "estimated_duration": 3600.044370258967,
    "input_throughput": 7952.14643366761,
    "output_throughput": 7049.07228634366,
    "total_throughput": 15001.218720011271,
    "itl": 105.6393317604523,
    "ttft": 1937193.864729275,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 353,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1836304559186135,
    "arrivals": 945185,
    "finished_requests": 115565,
    "scheduler_time": 273.44537349030554
}
#Debug simulation 
Total elapsed time: 107.72659947897773. Arrivals time: 0.5586140914820135 Scheduler time: 106.95261629659217 Scheduler overhead time: 0.08685182360932231 Adapter cache time: 0.01740474021062255 Engine time: 0.07980761199723929 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 115.39524501597043,
    "estimated_duration": 3600.0873014184763,
    "input_throughput": 7952.056048396436,
    "output_throughput": 7030.476452620312,
    "total_throughput": 14982.532501016749,
    "itl": 106.51096476857248,
    "ttft": 1924255.0421563743,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0069004677538749,
    "arrivals": 935737,
    "finished_requests": 115794,
    "scheduler_time": 274.12788854860906
}
#Debug simulation 
Total elapsed time: 115.39536951796617. Arrivals time: 0.5570737596135587 Scheduler time: 114.61861817515455 Scheduler overhead time: 0.08977596508339047 Adapter cache time: 0.017915281583555043 Engine time: 0.08007090783212334 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 113.42484743206296,
    "estimated_duration": 3600.0375650903707,
    "input_throughput": 7798.40251452911,
    "output_throughput": 6882.4231836530935,
    "total_throughput": 14680.825698182203,
    "itl": 103.4811438474146,
    "ttft": 1931453.5064661857,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0684546071267746,
    "arrivals": 935737,
    "finished_requests": 113422,
    "scheduler_time": 282.1510468725373
}
#Debug simulation 
Total elapsed time: 113.42496698501054. Arrivals time: 0.5452087767189369 Scheduler time: 112.65794606984127 Scheduler overhead time: 0.09035830211360008 Adapter cache time: 0.017739531816914678 Engine time: 0.08093243767507374 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 113.87322121707257,
    "estimated_duration": 3600.0392191093515,
    "input_throughput": 7798.398931594315,
    "output_throughput": 6882.420021560159,
    "total_throughput": 14680.818953154474,
    "itl": 103.4811629686545,
    "ttft": 1931454.2397535145,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0700996073335467,
    "arrivals": 935737,
    "finished_requests": 113422,
    "scheduler_time": 282.1510558912959
}
#Debug simulation 
Total elapsed time: 113.87333780503832. Arrivals time: 0.5731892985058948 Scheduler time: 113.0808572723763 Scheduler overhead time: 0.08914704457856715 Adapter cache time: 0.017574225435964763 Engine time: 0.08023704844526947 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 114.00106300995685,
    "estimated_duration": 3600.075205906449,
    "input_throughput": 7896.7383662869925,
    "output_throughput": 6980.515006678179,
    "total_throughput": 14877.253372965171,
    "itl": 105.51838098757408,
    "ttft": 1926822.336841669,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 331,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0350607279595019,
    "arrivals": 935737,
    "finished_requests": 115025,
    "scheduler_time": 276.6750845685596
}
#Debug simulation 
Total elapsed time: 114.00118355103768. Arrivals time: 0.5664820856181905 Scheduler time: 113.21525626839139 Scheduler overhead time: 0.08931074268184602 Adapter cache time: 0.017940430087037385 Engine time: 0.08030382986180484 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 113.28886931703892,
    "estimated_duration": 3600.053508576149,
    "input_throughput": 7798.367977898116,
    "output_throughput": 6882.392703601648,
    "total_throughput": 14680.760681499763,
    "itl": 103.48141328257242,
    "ttft": 1931459.776268508,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.083932523839181,
    "arrivals": 935737,
    "finished_requests": 113422,
    "scheduler_time": 282.1512123258587
}
#Debug simulation 
Total elapsed time: 113.28899092203937. Arrivals time: 0.5542729462031275 Scheduler time: 112.51434702356346 Scheduler overhead time: 0.09027489239815623 Adapter cache time: 0.017790379468351603 Engine time: 0.08057306287810206 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 115.28569582907949,
    "estimated_duration": 3600.0640750920898,
    "input_throughput": 7952.107352219195,
    "output_throughput": 7030.521810740983,
    "total_throughput": 14982.629162960176,
    "itl": 106.51054718300735,
    "ttft": 1924245.7115459489,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 329,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9837265470228171,
    "arrivals": 935737,
    "finished_requests": 115794,
    "scheduler_time": 274.1277361043209
}
#Debug simulation 
Total elapsed time: 115.28581725107506. Arrivals time: 0.5633776456816122 Scheduler time: 114.50250784866512 Scheduler overhead time: 0.08999513369053602 Adapter cache time: 0.017605843720957637 Engine time: 0.08051628188695759 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.05_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 1.6  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 17280, 540, 540, 540, 34560, 540, 17280, 34560, 17280, 540, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 540, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 540, 17280, 17280, 17280, 34560, 540, 540, 34560, 540, 34560, 540, 540, 17280, 540, 17280, 34560, 540, 540, 17280, 540, 540, 540, 540, 540, 34560, 17280, 17280, 34560, 17280, 540, 34560, 34560, 34560, 17280, 17280, 540, 540, 540, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 540, 540, 34560, 17280, 34560, 34560, 540, 34560, 540, 17280, 540, 540, 17280, 17280, 34560, 34560, 34560, 540, 34560, 17280, 17280, 540, 540, 540, 540, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 540, 17280, 17280, 34560, 17280, 34560, 540, 540, 540, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 540, 17280, 17280, 540, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 540, 34560, 540, 34560, 17280, 540, 17280, 540, 540, 17280, 17280, 17280, 34560, 17280, 540, 540]
Prompts retrieved: 2810700 . Total input tokens: 625934726 . Total output tokens: 562216680
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 113.61124277103227,
    "estimated_duration": 3600.0683687482338,
    "input_throughput": 7798.335788206626,
    "output_throughput": 6882.364294824521,
    "total_throughput": 14680.700083031146,
    "itl": 103.48162995330662,
    "ttft": 1931465.5228474934,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0980169479176447,
    "arrivals": 935737,
    "finished_requests": 113422,
    "scheduler_time": 282.15148788097747
}
#Debug simulation 
Total elapsed time: 113.61141967203002. Arrivals time: 0.5476024163654074 Scheduler time: 112.84366238629445 Scheduler overhead time: 0.08885456656571478 Adapter cache time: 0.01751419948413968 Engine time: 0.0812875124393031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 116.54807274590712,
    "estimated_duration": 3600.0549142067553,
    "input_throughput": 7985.660687160541,
    "output_throughput": 7051.133275724844,
    "total_throughput": 15036.793962885386,
    "itl": 106.52342598192236,
    "ttft": 1933109.1487351696,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9426302251312869,
    "arrivals": 931056,
    "finished_requests": 116209,
    "scheduler_time": 272.75139102438203
}
#Debug simulation 
Total elapsed time: 116.54819772194605. Arrivals time: 0.5643655902240425 Scheduler time: 115.76541460107546 Scheduler overhead time: 0.08892868657130748 Adapter cache time: 0.017368622589856386 Engine time: 0.08003281836863607 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 110.15979801095091,
    "estimated_duration": 3600.1005463669203,
    "input_throughput": 8039.488794058295,
    "output_throughput": 7122.711065911028,
    "total_throughput": 15162.199859969322,
    "itl": 107.98188849008189,
    "ttft": 1924007.4506650756,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1459361486625912,
    "arrivals": 931056,
    "finished_requests": 117101,
    "scheduler_time": 270.0040860851947
}
#Debug simulation 
Total elapsed time: 110.15992011502385. Arrivals time: 0.5534847256494686 Scheduler time: 109.38883335038554 Scheduler overhead time: 0.08896182966418564 Adapter cache time: 0.017401094315573573 Engine time: 0.07966138527262956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 110.38971459702589,
    "estimated_duration": 3600.102465722059,
    "input_throughput": 8039.484507893032,
    "output_throughput": 7122.707268515755,
    "total_throughput": 15162.191776408787,
    "itl": 107.98192781332263,
    "ttft": 1924008.1337003203,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1478655246272746,
    "arrivals": 931056,
    "finished_requests": 117101,
    "scheduler_time": 270.00407606435175
}
#Debug simulation 
Total elapsed time: 110.38983065902721. Arrivals time: 0.5541588708292693 Scheduler time: 109.61920176714193 Scheduler overhead time: 0.08818479883484542 Adapter cache time: 0.017573088756762445 Engine time: 0.07945693260990083 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 116.21407382993493,
    "estimated_duration": 3600.079138366011,
    "input_throughput": 7985.606953365029,
    "output_throughput": 7051.085830163554,
    "total_throughput": 15036.692783528582,
    "itl": 106.52390910131766,
    "ttft": 1933119.2163491521,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9654723805398715,
    "arrivals": 931056,
    "finished_requests": 116209,
    "scheduler_time": 272.7518726809739
}
#Debug simulation 
Total elapsed time: 116.21419782098383. Arrivals time: 0.5602246298221871 Scheduler time: 115.43500226945616 Scheduler overhead time: 0.09046056610532105 Adapter cache time: 0.016853130771778524 Engine time: 0.07998316432349384 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 110.19543219800107,
    "estimated_duration": 3600.0015168890627,
    "input_throughput": 8039.709390181321,
    "output_throughput": 7122.793109864732,
    "total_throughput": 15162.502500046054,
    "itl": 107.98290492410871,
    "ttft": 1923997.943254491,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 351,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1623272100649826,
    "arrivals": 931056,
    "finished_requests": 117099,
    "scheduler_time": 269.9959982598192
}
#Debug simulation 
Total elapsed time: 110.19555729907006. Arrivals time: 0.5676710125990212 Scheduler time: 109.40954314370174 Scheduler overhead time: 0.08935729810036719 Adapter cache time: 0.017726187710650265 Engine time: 0.07965240406338125 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 116.56294527894352,
    "estimated_duration": 3600.0329492136666,
    "input_throughput": 7985.7094103206555,
    "output_throughput": 7051.176297023774,
    "total_throughput": 15036.88570734443,
    "itl": 106.52317492136086,
    "ttft": 1933099.8134459588,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 308,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9209354908298714,
    "arrivals": 931056,
    "finished_requests": 116209,
    "scheduler_time": 272.7510207269679
}
#Debug simulation 
Total elapsed time: 116.56307023600675. Arrivals time: 0.5583820169558749 Scheduler time: 115.78727985324804 Scheduler overhead time: 0.08883315394632518 Adapter cache time: 0.016538055147975683 Engine time: 0.08027059014420956 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.025_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 1.6   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 17280, 270, 270, 270, 34560, 270, 17280, 34560, 17280, 270, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 270, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 270, 17280, 17280, 17280, 34560, 270, 270, 34560, 270, 34560, 270, 270, 17280, 270, 17280, 34560, 270, 270, 17280, 270, 270, 270, 270, 270, 34560, 17280, 17280, 34560, 17280, 270, 34560, 34560, 34560, 17280, 17280, 270, 270, 270, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 270, 270, 34560, 17280, 34560, 34560, 270, 34560, 270, 17280, 270, 270, 17280, 17280, 34560, 34560, 34560, 270, 34560, 17280, 17280, 270, 270, 270, 270, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 270, 17280, 17280, 34560, 17280, 34560, 270, 270, 270, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 270, 17280, 17280, 270, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 270, 34560, 270, 34560, 17280, 270, 17280, 270, 270, 17280, 17280, 17280, 34560, 17280, 270, 270]
Prompts retrieved: 2796390 . Total input tokens: 622717176 . Total output tokens: 559314112
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 112.94392907200381,
    "estimated_duration": 3600.004421821535,
    "input_throughput": 8060.8173212512165,
    "output_throughput": 7132.37846163759,
    "total_throughput": 15193.195782888806,
    "itl": 107.69802624034145,
    "ttft": 1922667.5423087068,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0994059517607133,
    "arrivals": 931056,
    "finished_requests": 117331,
    "scheduler_time": 268.79574162515115
}
#Debug simulation 
Total elapsed time: 112.94404982600827. Arrivals time: 0.5657176987733692 Scheduler time: 112.16043286118656 Scheduler overhead time: 0.08895451587159187 Adapter cache time: 0.017541857552714646 Engine time: 0.08023759722709656 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 114.87321735499427,
    "estimated_duration": 3600.0343164317283,
    "input_throughput": 8040.358356553163,
    "output_throughput": 7111.131380929293,
    "total_throughput": 15151.489737482456,
    "itl": 106.9012096803502,
    "ttft": 1918166.805955158,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9365092496434214,
    "arrivals": 928543,
    "finished_requests": 116894,
    "scheduler_time": 271.26316826856987
}
#Debug simulation 
Total elapsed time: 114.87338692101184. Arrivals time: 0.6621996767353266 Scheduler time: 113.99231703288388 Scheduler overhead time: 0.08910503843799233 Adapter cache time: 0.01718616613652557 Engine time: 0.08022466814145446 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 113.17111270595342,
    "estimated_duration": 3600.0659906234887,
    "input_throughput": 8096.741025280977,
    "output_throughput": 7148.186190760127,
    "total_throughput": 15244.927216041104,
    "itl": 108.54004105505378,
    "ttft": 1918380.200319579,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0718532527401174,
    "arrivals": 928543,
    "finished_requests": 117715,
    "scheduler_time": 268.2761052739288
}
#Debug simulation 
Total elapsed time: 113.1712307559792. Arrivals time: 0.6623332615708932 Scheduler time: 112.29135251929983 Scheduler overhead time: 0.08937777439132333 Adapter cache time: 0.01743119116872549 Engine time: 0.0794239939423278 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 113.06758335302584,
    "estimated_duration": 3600.06785116374,
    "input_throughput": 8096.73684082857,
    "output_throughput": 7148.1824965274955,
    "total_throughput": 15244.919337356065,
    "itl": 108.54005172306177,
    "ttft": 1918381.0599740362,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.073480373676872,
    "arrivals": 928543,
    "finished_requests": 117715,
    "scheduler_time": 268.27613861606915
}
#Debug simulation 
Total elapsed time: 113.06770584103651. Arrivals time: 0.5654272586107254 Scheduler time: 112.28722604573704 Scheduler overhead time: 0.08785228431224823 Adapter cache time: 0.016809334512799978 Engine time: 0.07912822510115802 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 115.24636167602148,
    "estimated_duration": 3600.014534312988,
    "input_throughput": 8040.361983017334,
    "output_throughput": 7111.053234924058,
    "total_throughput": 15151.415217941392,
    "itl": 106.9017144577652,
    "ttft": 1918179.5106438322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 306,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9574493033578652,
    "arrivals": 928543,
    "finished_requests": 116893,
    "scheduler_time": 271.2579511092817
}
#Debug simulation 
Total elapsed time: 115.24648521398194. Arrivals time: 0.9930579394567758 Scheduler time: 114.03806872910354 Scheduler overhead time: 0.08797536278143525 Adapter cache time: 0.01727361953817308 Engine time: 0.07907529943622649 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 113.74145583901554,
    "estimated_duration": 3600.081812669725,
    "input_throughput": 8096.705440808864,
    "output_throughput": 7148.154775103956,
    "total_throughput": 15244.86021591282,
    "itl": 108.54027244269288,
    "ttft": 1918387.0018046286,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0874390439689212,
    "arrivals": 928543,
    "finished_requests": 117715,
    "scheduler_time": 268.27634152893495
}
#Debug simulation 
Total elapsed time: 113.74157475691754. Arrivals time: 0.5611753328703344 Scheduler time: 112.96676540072076 Scheduler overhead time: 0.08609201537910849 Adapter cache time: 0.017250236123800278 Engine time: 0.07898917235434055 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 114.16649580490775,
    "estimated_duration": 3600.0221293103677,
    "input_throughput": 8091.25526280584,
    "output_throughput": 7158.959049214803,
    "total_throughput": 15250.214312020644,
    "itl": 107.65126748808173,
    "ttft": 1920094.704745062,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 327,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9777464464330128,
    "arrivals": 928543,
    "finished_requests": 117646,
    "scheduler_time": 269.21559414111937
}
#Debug simulation 
Total elapsed time: 114.16661296295933. Arrivals time: 0.5807465980760753 Scheduler time: 113.37099613063037 Scheduler overhead time: 0.08703449124004692 Adapter cache time: 0.01722259761299938 Engine time: 0.07866063539404422 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.0125_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 1.6    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 17280, 135, 135, 135, 34560, 135, 17280, 34560, 17280, 135, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 135, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 135, 17280, 17280, 17280, 34560, 135, 135, 34560, 135, 34560, 135, 135, 17280, 135, 17280, 34560, 135, 135, 17280, 135, 135, 135, 135, 135, 34560, 17280, 17280, 34560, 17280, 135, 34560, 34560, 34560, 17280, 17280, 135, 135, 135, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 135, 135, 34560, 17280, 34560, 34560, 135, 34560, 135, 17280, 135, 135, 17280, 17280, 34560, 34560, 34560, 135, 34560, 17280, 17280, 135, 135, 135, 135, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 135, 17280, 17280, 34560, 17280, 34560, 135, 135, 135, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 135, 17280, 17280, 135, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 135, 34560, 135, 34560, 17280, 135, 17280, 135, 135, 17280, 17280, 17280, 34560, 17280, 135, 135]
Prompts retrieved: 2789235 . Total input tokens: 621133368 . Total output tokens: 557879875
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 113.72160621394869,
    "estimated_duration": 3600.0961474814876,
    "input_throughput": 8096.673201462014,
    "output_throughput": 7148.126312682689,
    "total_throughput": 15244.799514144703,
    "itl": 108.54048391743196,
    "ttft": 1918392.9940501414,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 328,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1015234680473849,
    "arrivals": 928543,
    "finished_requests": 117715,
    "scheduler_time": 268.27649187805025
}
#Debug simulation 
Total elapsed time: 113.72172117198352. Arrivals time: 0.5634004212915897 Scheduler time: 112.94323732762132 Scheduler overhead time: 0.0877259379485622 Adapter cache time: 0.017256973776966333 Engine time: 0.07889784045983106 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 120.43713924102485,
    "estimated_duration": 3600.0399434068936,
    "input_throughput": 7817.052433414984,
    "output_throughput": 6902.79007751312,
    "total_throughput": 14719.842510928105,
    "itl": 103.38016338433533,
    "ttft": 1940372.3054491798,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8293921786057752,
    "arrivals": 927414,
    "finished_requests": 114033,
    "scheduler_time": 281.1192290134021
}
#Debug simulation 
Total elapsed time: 120.43727104307618. Arrivals time: 0.6572960207704455 Scheduler time: 119.55927457974758 Scheduler overhead time: 0.09046241466421634 Adapter cache time: 0.017244425835087895 Engine time: 0.08073959418106824 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 115.80101728392765,
    "estimated_duration": 3600.0158692501054,
    "input_throughput": 8067.954991001225,
    "output_throughput": 7132.423559385188,
    "total_throughput": 15200.378550386413,
    "itl": 106.94548893080356,
    "ttft": 1926469.5707086455,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.936056257393216,
    "arrivals": 927414,
    "finished_requests": 117691,
    "scheduler_time": 268.40239337178184
}
#Debug simulation 
Total elapsed time: 115.80119201692287. Arrivals time: 0.567001573741436 Scheduler time: 115.01817314315122 Scheduler overhead time: 0.08794715674594045 Adapter cache time: 0.01708934037014842 Engine time: 0.07973897072952241 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 116.1734485499328,
    "estimated_duration": 3600.0170381953117,
    "input_throughput": 8067.952371292148,
    "output_throughput": 7132.421243448281,
    "total_throughput": 15200.373614740429,
    "itl": 106.9455198733828,
    "ttft": 1926470.030696502,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9372213946655441,
    "arrivals": 927414,
    "finished_requests": 117691,
    "scheduler_time": 268.4023971797022
}
#Debug simulation 
Total elapsed time: 116.17357168602757. Arrivals time: 0.5684387617511675 Scheduler time: 115.38790364097804 Scheduler overhead time: 0.08942693285644054 Adapter cache time: 0.016760929254814982 Engine time: 0.07983906101435423 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 120.0241408799775,
    "estimated_duration": 3600.058127420217,
    "input_throughput": 7817.012949223184,
    "output_throughput": 6902.755211290883,
    "total_throughput": 14719.768160514066,
    "itl": 103.3805238818811,
    "ttft": 1940378.9830720448,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8474858038965639,
    "arrivals": 927414,
    "finished_requests": 114033,
    "scheduler_time": 281.11931940140556
}
#Debug simulation 
Total elapsed time: 120.0242704260163. Arrivals time: 0.5524869905784726 Scheduler time: 119.25042931188364 Scheduler overhead time: 0.09086632658727467 Adapter cache time: 0.017631580936722457 Engine time: 0.08055323490407318 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 116.18769503501244,
    "estimated_duration": 3600.030153623134,
    "input_throughput": 8067.922978580841,
    "output_throughput": 7132.395259011477,
    "total_throughput": 15200.318237592319,
    "itl": 106.94563796257152,
    "ttft": 1926475.767458882,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9502997884526897,
    "arrivals": 927414,
    "finished_requests": 117691,
    "scheduler_time": 268.40263429090925
}
#Debug simulation 
Total elapsed time: 116.18781418295112. Arrivals time: 0.5695808484451845 Scheduler time: 115.40196836844552 Scheduler overhead time: 0.0883555969921872 Adapter cache time: 0.017297177342697978 Engine time: 0.07982686860486865 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 120.28718150197528,
    "estimated_duration": 3600.0206082121313,
    "input_throughput": 7817.094417683331,
    "output_throughput": 6902.827151409378,
    "total_throughput": 14719.921569092709,
    "itl": 103.37987881777495,
    "ttft": 1940364.3069415598,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 271,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8103036299184907,
    "arrivals": 927414,
    "finished_requests": 114033,
    "scheduler_time": 281.1188823287065
}
#Debug simulation 
Total elapsed time: 120.28730036201887. Arrivals time: 0.6489882544847205 Scheduler time: 119.41867963282857 Scheduler overhead time: 0.09036383987404406 Adapter cache time: 0.01699118607211858 Engine time: 0.07992141041904688 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.00625
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.00625_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.00625_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 1.6     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 17280, 66, 66, 66, 34560, 66, 17280, 34560, 17280, 66, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 66, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 66, 17280, 17280, 17280, 34560, 66, 66, 34560, 66, 34560, 66, 66, 17280, 66, 17280, 34560, 66, 66, 17280, 66, 66, 66, 66, 66, 34560, 17280, 17280, 34560, 17280, 66, 34560, 34560, 34560, 17280, 17280, 66, 66, 66, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 66, 66, 34560, 17280, 34560, 34560, 66, 34560, 66, 17280, 66, 66, 17280, 17280, 34560, 34560, 34560, 66, 34560, 17280, 17280, 66, 66, 66, 66, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 66, 17280, 17280, 34560, 17280, 34560, 66, 66, 66, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 66, 17280, 17280, 66, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 66, 34560, 66, 34560, 17280, 66, 17280, 66, 66, 17280, 17280, 17280, 34560, 17280, 66, 66]
Prompts retrieved: 2785578 . Total input tokens: 620302199 . Total output tokens: 557146111
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 116.38636258407496,
    "estimated_duration": 3600.0425140689676,
    "input_throughput": 8067.895278039924,
    "output_throughput": 7132.370770526989,
    "total_throughput": 15200.266048566913,
    "itl": 106.94588800125554,
    "ttft": 1926481.0427952227,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 286,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9621206443756868,
    "arrivals": 927414,
    "finished_requests": 117691,
    "scheduler_time": 268.4027737265098
}
#Debug simulation 
Total elapsed time: 116.38648566103075. Arrivals time: 0.5697991761844605 Scheduler time: 115.59882800513878 Scheduler overhead time: 0.08867088577244431 Adapter cache time: 0.017059294739738107 Engine time: 0.08014658594038337 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-8/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 17280, 33, 33, 33, 34560, 33, 17280, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 33, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 33, 17280, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 33, 33, 17280, 33, 17280, 34560, 33, 33, 17280, 33, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 33, 34560, 34560, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 33, 17280, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 34560, 17280, 34560, 33, 33, 33, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 2783829 . Total input tokens: 619926946 . Total output tokens: 556795169
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 111.20790452510118,
    "estimated_duration": 3600.100714556456,
    "input_throughput": 8049.621468317828,
    "output_throughput": 7148.07196808395,
    "total_throughput": 15197.693436401778,
    "itl": 107.14360465366735,
    "ttft": 1923834.863870282,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8477551050693717,
    "arrivals": 926784,
    "finished_requests": 117574,
    "scheduler_time": 267.4224016668803
}
#Debug simulation 
Total elapsed time: 111.20802608702797. Arrivals time: 0.5672472603619099 Scheduler time: 110.43111660249997 Scheduler overhead time: 0.08469596167560667 Adapter cache time: 0.016358511289581656 Engine time: 0.0776147892465815 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-16/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 17280, 33, 33, 33, 34560, 33, 17280, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 33, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 33, 17280, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 33, 33, 17280, 33, 17280, 34560, 33, 33, 17280, 33, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 33, 34560, 34560, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 33, 17280, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 34560, 17280, 34560, 33, 33, 33, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 2783829 . Total input tokens: 619926946 . Total output tokens: 556795169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 114.16035643301439,
    "estimated_duration": 3600.030375258245,
    "input_throughput": 8139.470489300531,
    "output_throughput": 7245.383311003013,
    "total_throughput": 15384.853800303543,
    "itl": 108.62379374572238,
    "ttft": 1912511.93467942,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.903704182533552,
    "arrivals": 926784,
    "finished_requests": 118767,
    "scheduler_time": 264.15650090972207
}
#Debug simulation 
Total elapsed time: 114.16048350906931. Arrivals time: 0.573481292463839 Scheduler time: 113.37378979567438 Scheduler overhead time: 0.08684474916663021 Adapter cache time: 0.016821947530843318 Engine time: 0.07817364216316491 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-8-32/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 17280, 33, 33, 33, 34560, 33, 17280, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 33, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 33, 17280, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 33, 33, 17280, 33, 17280, 34560, 33, 33, 17280, 33, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 33, 34560, 34560, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 33, 17280, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 34560, 17280, 34560, 33, 33, 33, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 2783829 . Total input tokens: 619926946 . Total output tokens: 556795169
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 113.6463500490645,
    "estimated_duration": 3600.0314374044383,
    "input_throughput": 8139.468087847169,
    "output_throughput": 7245.381173339373,
    "total_throughput": 15384.849261186542,
    "itl": 108.62382523012943,
    "ttft": 1912512.3388477555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9047627212107228,
    "arrivals": 926784,
    "finished_requests": 118767,
    "scheduler_time": 264.1565045172255
}
#Debug simulation 
Total elapsed time: 113.6465176610509. Arrivals time: 0.5729208788834512 Scheduler time: 112.86195461987518 Scheduler overhead time: 0.08618852368090302 Adapter cache time: 0.016776831937022507 Engine time: 0.07808106567244977 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-16/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 17280, 33, 33, 33, 34560, 33, 17280, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 33, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 33, 17280, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 33, 33, 17280, 33, 17280, 34560, 33, 33, 17280, 33, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 33, 34560, 34560, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 33, 17280, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 34560, 17280, 34560, 33, 33, 33, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 2783829 . Total input tokens: 619926946 . Total output tokens: 556795169
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 113.65204733400606,
    "estimated_duration": 3600.050286088196,
    "input_throughput": 8139.425472259121,
    "output_throughput": 7245.343238897466,
    "total_throughput": 15384.768711156587,
    "itl": 108.62289368533422,
    "ttft": 1912493.488426833,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.864479031963277,
    "arrivals": 926784,
    "finished_requests": 118767,
    "scheduler_time": 264.162325009733
}
#Debug simulation 
Total elapsed time: 113.65216391393915. Arrivals time: 0.5636867753928527 Scheduler time: 112.8744830598589 Scheduler overhead time: 0.08800898445770144 Adapter cache time: 0.016316188615746796 Engine time: 0.07892252563033253 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_8-16-32/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 17280, 33, 33, 33, 34560, 33, 17280, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 33, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 33, 17280, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 33, 33, 17280, 33, 17280, 34560, 33, 33, 17280, 33, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 33, 34560, 34560, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 33, 17280, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 34560, 17280, 34560, 33, 33, 33, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 2783829 . Total input tokens: 619926946 . Total output tokens: 556795169
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 114.00378029502463,
    "estimated_duration": 3600.0436209992827,
    "input_throughput": 8139.440541519438,
    "output_throughput": 7245.356652861845,
    "total_throughput": 15384.797194381283,
    "itl": 108.62414110518237,
    "ttft": 1912517.9675768218,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9168350847065494,
    "arrivals": 926784,
    "finished_requests": 118767,
    "scheduler_time": 264.1566157485824
}
#Debug simulation 
Total elapsed time: 114.00390523497481. Arrivals time: 0.6799211346078664 Scheduler time: 113.11153813113924 Scheduler overhead time: 0.0861643748357892 Adapter cache time: 0.016685605281963944 Engine time: 0.07895348686724901 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-16/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 17280, 33, 33, 33, 34560, 33, 17280, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 33, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 33, 17280, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 33, 33, 17280, 33, 17280, 34560, 33, 33, 17280, 33, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 33, 34560, 34560, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 33, 17280, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 34560, 17280, 34560, 33, 33, 33, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 2783829 . Total input tokens: 619926946 . Total output tokens: 556795169
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 111.41183509200346,
    "estimated_duration": 3600.0811164692363,
    "input_throughput": 8049.665288770345,
    "output_throughput": 7148.110880689902,
    "total_throughput": 15197.776169460247,
    "itl": 107.14319526738362,
    "ttft": 1923826.5788571236,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 277,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8282439316879038,
    "arrivals": 926784,
    "finished_requests": 117574,
    "scheduler_time": 267.42221471442156
}
#Debug simulation 
Total elapsed time: 111.41195070801768. Arrivals time: 0.561275975429453 Scheduler time: 110.64104111480992 Scheduler overhead time: 0.0840535945026204 Adapter cache time: 0.016565112629905343 Engine time: 0.07800565101206303 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        1.6,
        0.003125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-1.6-0.003125_size_16-16-32/adapters_160_slots_16_rate_3.2-1.6-0.003125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [3.125e-03 1.600e+00 3.200e+00]. Counts: [53 53 54]
Adapter prompts. [33, 34560, 33, 33, 17280, 33, 33, 33, 34560, 33, 17280, 34560, 17280, 33, 17280, 17280, 17280, 17280, 34560, 34560, 34560, 17280, 17280, 17280, 34560, 34560, 33, 34560, 17280, 34560, 34560, 34560, 17280, 34560, 33, 17280, 17280, 17280, 34560, 33, 33, 34560, 33, 34560, 33, 33, 17280, 33, 17280, 34560, 33, 33, 17280, 33, 33, 33, 33, 33, 34560, 17280, 17280, 34560, 17280, 33, 34560, 34560, 34560, 17280, 17280, 33, 33, 33, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 33, 33, 34560, 17280, 34560, 34560, 33, 34560, 33, 17280, 33, 33, 17280, 17280, 34560, 34560, 34560, 33, 34560, 17280, 17280, 33, 33, 33, 33, 34560, 17280, 34560, 17280, 34560, 34560, 34560, 33, 17280, 17280, 34560, 17280, 34560, 33, 33, 33, 17280, 17280, 17280, 34560, 34560, 17280, 34560, 33, 17280, 17280, 33, 34560, 34560, 34560, 34560, 34560, 34560, 17280, 17280, 17280, 17280, 17280, 34560, 33, 34560, 33, 34560, 17280, 33, 17280, 33, 33, 17280, 17280, 17280, 34560, 17280, 33, 33]
Prompts retrieved: 2783829 . Total input tokens: 619926946 . Total output tokens: 556795169
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 113.924043871928,
    "estimated_duration": 3600.054978030525,
    "input_throughput": 8139.4148641669835,
    "output_throughput": 7245.333796060388,
    "total_throughput": 15384.748660227371,
    "itl": 108.6243206302203,
    "ttft": 1912522.296749322,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 276,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9289074482023764,
    "arrivals": 926784,
    "finished_requests": 118767,
    "scheduler_time": 264.156700724985
}
#Debug simulation 
Total elapsed time: 113.9241631559562. Arrivals time: 0.6611758591607213 Scheduler time: 113.04924840549938 Scheduler overhead time: 0.08754199254326522 Adapter cache time: 0.016670368728227913 Engine time: 0.07847171381581575 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 8640, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 4320, 34560, 34560, 34560, 8640, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 8640, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 2553120 . Total input tokens: 568776188 . Total output tokens: 510562220
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 108.16750148299616,
    "estimated_duration": 3600.0561213512583,
    "input_throughput": 7989.103789083337,
    "output_throughput": 7063.1171134231945,
    "total_throughput": 15052.220902506531,
    "itl": 103.88711719158346,
    "ttft": 1915938.6015597563,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1078965633036593,
    "arrivals": 850231,
    "finished_requests": 116379,
    "scheduler_time": 272.2660682054989
}
#Debug simulation 
Total elapsed time: 108.16761784395203. Arrivals time: 0.5565088239964098 Scheduler time: 107.39488314115442 Scheduler overhead time: 0.08836006897035986 Adapter cache time: 0.017473527463153005 Engine time: 0.07887184235733002 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 8640, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 4320, 34560, 34560, 34560, 8640, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 8640, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 2553120 . Total input tokens: 568776188 . Total output tokens: 510562220
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 110.27902678900864,
    "estimated_duration": 3600.047316802249,
    "input_throughput": 7987.744734850546,
    "output_throughput": 7065.237415432881,
    "total_throughput": 15052.982150283427,
    "itl": 104.30493261986244,
    "ttft": 1912694.2821688245,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1369659977778852,
    "arrivals": 850231,
    "finished_requests": 116514,
    "scheduler_time": 271.9742720222841
}
#Debug simulation 
Total elapsed time: 110.27914621995296. Arrivals time: 0.5781587329693139 Scheduler time: 109.4855819317745 Scheduler overhead time: 0.08790977008175105 Adapter cache time: 0.017236125306226313 Engine time: 0.0791842092294246 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 8640, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 4320, 34560, 34560, 34560, 8640, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 8640, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 2553120 . Total input tokens: 568776188 . Total output tokens: 510562220
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 110.3751288469648,
    "estimated_duration": 3600.049209496808,
    "input_throughput": 7987.740535363228,
    "output_throughput": 7065.233700945762,
    "total_throughput": 15052.97423630899,
    "itl": 104.30495822029997,
    "ttft": 1912695.0461440347,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.138734968081123,
    "arrivals": 850231,
    "finished_requests": 116514,
    "scheduler_time": 271.97429570794435
}
#Debug simulation 
Total elapsed time: 110.37525297992397. Arrivals time: 0.5636674254201353 Scheduler time: 109.592110794154 Scheduler overhead time: 0.08938234171364456 Adapter cache time: 0.01775644044391811 Engine time: 0.08023555169347674 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 8640, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 4320, 34560, 34560, 34560, 8640, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 8640, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 2553120 . Total input tokens: 568776188 . Total output tokens: 510562220
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 108.29524983896408,
    "estimated_duration": 3600.0815444791106,
    "input_throughput": 7989.047371470418,
    "output_throughput": 7063.067234961501,
    "total_throughput": 15052.114606431918,
    "itl": 103.88758666514691,
    "ttft": 1915949.252968278,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1330640262411922,
    "arrivals": 850231,
    "finished_requests": 116379,
    "scheduler_time": 272.2664239089532
}
#Debug simulation 
Total elapsed time: 108.29541769390926. Arrivals time: 0.5616239602677524 Scheduler time: 107.51829314033967 Scheduler overhead time: 0.08828914840705693 Adapter cache time: 0.017671108129434288 Engine time: 0.07773080037441105 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.4_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 8640, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 4320, 34560, 34560, 34560, 8640, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 8640, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 2553120 . Total input tokens: 568776188 . Total output tokens: 510562220
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 110.31464794406202,
    "estimated_duration": 3600.0640874741252,
    "input_throughput": 7987.7075244446405,
    "output_throughput": 7065.204502469239,
    "total_throughput": 15052.912026913878,
    "itl": 104.30526369157509,
    "ttft": 1912701.1187528293,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1533224073052455,
    "arrivals": 850231,
    "finished_requests": 116514,
    "scheduler_time": 271.97438616888957
}
#Debug simulation 
Total elapsed time: 110.31477547308896. Arrivals time: 0.5615364861441776 Scheduler time: 109.53780844516587 Scheduler overhead time: 0.08814962452743202 Adapter cache time: 0.01762291823979467 Engine time: 0.07871149876154959 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.4_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.4_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 8640, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 4320, 34560, 34560, 34560, 8640, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 8640, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 2553120 . Total input tokens: 568776188 . Total output tokens: 510562220
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 108.52937309700064,
    "estimated_duration": 3600.0298081939213,
    "input_throughput": 7989.162182640109,
    "output_throughput": 7063.168738804593,
    "total_throughput": 15052.330921444702,
    "itl": 103.88658464535536,
    "ttft": 1915927.9730304056,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 362,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.082398206754586,
    "arrivals": 850231,
    "finished_requests": 116379,
    "scheduler_time": 272.2658536361367
}
#Debug simulation 
Total elapsed time: 108.52949313202407. Arrivals time: 0.8497173613868654 Scheduler time: 107.46575565449893 Scheduler overhead time: 0.08698195836041123 Adapter cache time: 0.017627370194531977 Engine time: 0.07808305171784014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.4_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.4
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.4_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.4_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.4 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [4320, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 34560, 8640, 4320, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 4320, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 8640, 34560, 4320, 4320, 34560, 4320, 34560, 4320, 4320, 8640, 4320, 8640, 34560, 4320, 4320, 8640, 4320, 4320, 4320, 4320, 4320, 34560, 8640, 8640, 34560, 8640, 4320, 34560, 34560, 34560, 8640, 8640, 4320, 4320, 4320, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 4320, 4320, 34560, 8640, 34560, 34560, 4320, 34560, 4320, 8640, 4320, 4320, 8640, 8640, 34560, 34560, 34560, 4320, 34560, 8640, 8640, 4320, 4320, 4320, 4320, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 4320, 8640, 8640, 34560, 8640, 34560, 4320, 4320, 4320, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 4320, 8640, 8640, 4320, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 4320, 34560, 4320, 34560, 8640, 4320, 8640, 4320, 4320, 8640, 8640, 8640, 34560, 8640, 4320, 4320]
Prompts retrieved: 2553120 . Total input tokens: 568776188 . Total output tokens: 510562220
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 110.38459122704808,
    "estimated_duration": 3600.0527777043603,
    "input_throughput": 7987.732618280379,
    "output_throughput": 7065.226698209468,
    "total_throughput": 15052.959316489847,
    "itl": 104.30648681177007,
    "ttft": 1912686.7811117761,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 348,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1684128616750276,
    "arrivals": 850231,
    "finished_requests": 116514,
    "scheduler_time": 271.96968563387946
}
#Debug simulation 
Total elapsed time: 110.38471081503667. Arrivals time: 0.6521510086022317 Scheduler time: 109.5149917540839 Scheduler overhead time: 0.08869809156749398 Adapter cache time: 0.01744970097206533 Engine time: 0.08001422649249434 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 8640, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 1080, 34560, 34560, 34560, 8640, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 8640, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2381400 . Total input tokens: 530601632 . Total output tokens: 476239805
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 118.95600031397771,
    "estimated_duration": 3600.0467027507475,
    "input_throughput": 7834.269477240366,
    "output_throughput": 6902.572397467168,
    "total_throughput": 14736.841874707534,
    "itl": 101.42708601465863,
    "ttft": 1879456.5153591689,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9303882741555559,
    "arrivals": 793158,
    "finished_requests": 113653,
    "scheduler_time": 282.3682222528457
}
#Debug simulation 
Total elapsed time: 118.95611910091247. Arrivals time: 0.5478623154340312 Scheduler time: 118.18662079214118 Scheduler overhead time: 0.09168235003016889 Adapter cache time: 0.017163346288725734 Engine time: 0.08074177464004606 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 8640, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 1080, 34560, 34560, 34560, 8640, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 8640, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2381400 . Total input tokens: 530601632 . Total output tokens: 476239805
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 109.60742302704602,
    "estimated_duration": 3600.0281709820715,
    "input_throughput": 7981.2583778092585,
    "output_throughput": 7018.4150789874,
    "total_throughput": 14999.673456796658,
    "itl": 104.09961770538494,
    "ttft": 1884438.710865903,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1311157802538998,
    "arrivals": 793158,
    "finished_requests": 115871,
    "scheduler_time": 274.2442291370019
}
#Debug simulation 
Total elapsed time: 109.60754357709084. Arrivals time: 0.5434902826091275 Scheduler time: 108.84586703556124 Scheduler overhead time: 0.08938334102276713 Adapter cache time: 0.017726438702084124 Engine time: 0.08005190163385123 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 8640, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 1080, 34560, 34560, 34560, 8640, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 8640, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2381400 . Total input tokens: 530601632 . Total output tokens: 476239805
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 109.16469432599843,
    "estimated_duration": 3600.030395939445,
    "input_throughput": 7981.2534450843295,
    "output_throughput": 7018.410741336696,
    "total_throughput": 14999.664186421027,
    "itl": 104.09965507161235,
    "ttft": 1884439.427995039,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1333307167701485,
    "arrivals": 793158,
    "finished_requests": 115871,
    "scheduler_time": 274.2442391578449
}
#Debug simulation 
Total elapsed time: 109.16481656196993. Arrivals time: 0.5468617314472795 Scheduler time: 108.40316604846157 Scheduler overhead time: 0.08688675065059215 Adapter cache time: 0.0174197512678802 Engine time: 0.07880438503343612 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 8640, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 1080, 34560, 34560, 34560, 8640, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 8640, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2381400 . Total input tokens: 530601632 . Total output tokens: 476239805
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 109.74847398302518,
    "estimated_duration": 3600.1093599735345,
    "input_throughput": 7981.3408779924475,
    "output_throughput": 7018.502904641138,
    "total_throughput": 14999.843782633587,
    "itl": 104.09954176918494,
    "ttft": 1884492.7257044413,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0845359139516972,
    "arrivals": 793158,
    "finished_requests": 115874,
    "scheduler_time": 274.252460574064
}
#Debug simulation 
Total elapsed time: 109.74859405995812. Arrivals time: 0.5494128330610693 Scheduler time: 108.98153479758184 Scheduler overhead time: 0.08894693083129823 Adapter cache time: 0.017103700549341738 Engine time: 0.08034939190838486 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.1_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 8640, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 1080, 34560, 34560, 34560, 8640, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 8640, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2381400 . Total input tokens: 530601632 . Total output tokens: 476239805
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 109.3100032149814,
    "estimated_duration": 3600.046152155218,
    "input_throughput": 7981.218513767868,
    "output_throughput": 7018.380024065486,
    "total_throughput": 14999.598537833353,
    "itl": 104.09989534330963,
    "ttft": 1884446.3392241127,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 347,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1476666484214422,
    "arrivals": 793158,
    "finished_requests": 115871,
    "scheduler_time": 274.2444589790143
}
#Debug simulation 
Total elapsed time: 109.31017071998212. Arrivals time: 0.5583484582602978 Scheduler time: 108.53319875698071 Scheduler overhead time: 0.08989230124279857 Adapter cache time: 0.01758921949658543 Engine time: 0.0795500377425924 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.1_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.1_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 8640, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 1080, 34560, 34560, 34560, 8640, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 8640, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2381400 . Total input tokens: 530601632 . Total output tokens: 476239805
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 119.08263632201124,
    "estimated_duration": 3600.024325328399,
    "input_throughput": 7834.318174343785,
    "output_throughput": 6902.615303226649,
    "total_throughput": 14736.933477570436,
    "itl": 101.42676281427829,
    "ttft": 1879447.2408142006,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 304,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9089752896502626,
    "arrivals": 793158,
    "finished_requests": 113653,
    "scheduler_time": 282.367958085017
}
#Debug simulation 
Total elapsed time: 119.08275863598101. Arrivals time: 0.5428102085134014 Scheduler time: 118.31876090576407 Scheduler overhead time: 0.09106067602988333 Adapter cache time: 0.01728728087618947 Engine time: 0.08039145672228187 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.1_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.1
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.1_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.1_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.1 0.8 3.2]. Counts: [53 53 54]
Adapter prompts. [1080, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 34560, 8640, 1080, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 1080, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 8640, 34560, 1080, 1080, 34560, 1080, 34560, 1080, 1080, 8640, 1080, 8640, 34560, 1080, 1080, 8640, 1080, 1080, 1080, 1080, 1080, 34560, 8640, 8640, 34560, 8640, 1080, 34560, 34560, 34560, 8640, 8640, 1080, 1080, 1080, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 1080, 1080, 34560, 8640, 34560, 34560, 1080, 34560, 1080, 8640, 1080, 1080, 8640, 8640, 34560, 34560, 34560, 1080, 34560, 8640, 8640, 1080, 1080, 1080, 1080, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 1080, 8640, 8640, 34560, 8640, 34560, 1080, 1080, 1080, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 1080, 8640, 8640, 1080, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 1080, 34560, 1080, 34560, 8640, 1080, 8640, 1080, 1080, 8640, 8640, 8640, 34560, 8640, 1080, 1080]
Prompts retrieved: 2381400 . Total input tokens: 530601632 . Total output tokens: 476239805
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 106.7059893719852,
    "estimated_duration": 3600.002761536787,
    "input_throughput": 8027.209120157421,
    "output_throughput": 7052.345423524633,
    "total_throughput": 15079.554543682054,
    "itl": 104.61797858335446,
    "ttft": 1884468.0171397002,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 350,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1735738968104161,
    "arrivals": 793158,
    "finished_requests": 116472,
    "scheduler_time": 272.4611162032399
}
#Debug simulation 
Total elapsed time: 106.70611579099204. Arrivals time: 0.5556730430107564 Scheduler time: 105.93649028567597 Scheduler overhead time: 0.08608241402544081 Adapter cache time: 0.017237548134289682 Engine time: 0.07943818939384073 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 8640, 540, 540, 540, 34560, 540, 8640, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 540, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 540, 8640, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 540, 540, 8640, 540, 8640, 34560, 540, 540, 8640, 540, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 540, 34560, 34560, 34560, 8640, 8640, 540, 540, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 8640, 540, 540, 8640, 8640, 34560, 34560, 34560, 540, 34560, 8640, 8640, 540, 540, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 34560, 8640, 34560, 540, 540, 540, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2352780 . Total input tokens: 524176632 . Total output tokens: 470532189
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 112.6230040260125,
    "estimated_duration": 3600.024469120562,
    "input_throughput": 7964.005868827844,
    "output_throughput": 7028.42889459056,
    "total_throughput": 14992.434763418403,
    "itl": 104.97802429879714,
    "ttft": 1878073.5228626912,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.028323881961405,
    "arrivals": 783512,
    "finished_requests": 116037,
    "scheduler_time": 273.46240805687074
}
#Debug simulation 
Total elapsed time: 112.62312397698406. Arrivals time: 0.5440047802403569 Scheduler time: 111.863492337754 Scheduler overhead time: 0.08733404066879302 Adapter cache time: 0.017192868748679757 Engine time: 0.07976024528034031 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 8640, 540, 540, 540, 34560, 540, 8640, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 540, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 540, 8640, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 540, 540, 8640, 540, 8640, 34560, 540, 540, 8640, 540, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 540, 34560, 34560, 34560, 8640, 8640, 540, 540, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 8640, 540, 540, 8640, 8640, 34560, 34560, 34560, 540, 34560, 8640, 8640, 540, 540, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 34560, 8640, 34560, 540, 540, 540, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2352780 . Total input tokens: 524176632 . Total output tokens: 470532189
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 109.33652190095745,
    "estimated_duration": 3600.0817314175356,
    "input_throughput": 8010.608411560889,
    "output_throughput": 7061.21218808843,
    "total_throughput": 15071.82059964932,
    "itl": 105.40781269356624,
    "ttft": 1884007.0286747154,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.104205327599781,
    "arrivals": 783512,
    "finished_requests": 116592,
    "scheduler_time": 271.77523876879627
}
#Debug simulation 
Total elapsed time: 109.336645510979. Arrivals time: 0.5529469896573573 Scheduler time: 108.56561466422863 Scheduler overhead time: 0.08875653380528092 Adapter cache time: 0.017533802310936153 Engine time: 0.07982344238553196 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 8640, 540, 540, 540, 34560, 540, 8640, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 540, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 540, 8640, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 540, 540, 8640, 540, 8640, 34560, 540, 540, 8640, 540, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 540, 34560, 34560, 34560, 8640, 8640, 540, 540, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 8640, 540, 540, 8640, 8640, 34560, 34560, 34560, 540, 34560, 8640, 8640, 540, 540, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 34560, 8640, 34560, 540, 540, 540, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2352780 . Total input tokens: 524176632 . Total output tokens: 470532189
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 109.59818800899666,
    "estimated_duration": 3600.0832333211156,
    "input_throughput": 8010.605069648864,
    "output_throughput": 7061.209242251021,
    "total_throughput": 15071.814311899885,
    "itl": 105.40785105898503,
    "ttft": 1884007.4245873133,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1059390471316934,
    "arrivals": 783512,
    "finished_requests": 116592,
    "scheduler_time": 271.77520702999084
}
#Debug simulation 
Total elapsed time: 109.59831453789957. Arrivals time: 0.639401716995053 Scheduler time: 108.73952038958669 Scheduler overhead time: 0.08967263414524496 Adapter cache time: 0.017235180363059044 Engine time: 0.08004939812235534 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 8640, 540, 540, 540, 34560, 540, 8640, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 540, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 540, 8640, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 540, 540, 8640, 540, 8640, 34560, 540, 540, 8640, 540, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 540, 34560, 34560, 34560, 8640, 8640, 540, 540, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 8640, 540, 540, 8640, 8640, 34560, 34560, 34560, 540, 34560, 8640, 8640, 540, 540, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 34560, 8640, 34560, 540, 540, 540, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2352780 . Total input tokens: 524176632 . Total output tokens: 470532189
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 112.54984196205623,
    "estimated_duration": 3600.0478896292425,
    "input_throughput": 7963.954058109126,
    "output_throughput": 7028.383170371055,
    "total_throughput": 14992.33722848018,
    "itl": 104.97847508931072,
    "ttft": 1878082.234706338,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0516453607077738,
    "arrivals": 783512,
    "finished_requests": 116037,
    "scheduler_time": 273.46260712534536
}
#Debug simulation 
Total elapsed time: 112.54996442096308. Arrivals time: 0.567127495072782 Scheduler time: 111.76466489466839 Scheduler overhead time: 0.08872114727273583 Adapter cache time: 0.017440184601582587 Engine time: 0.07985313679091632 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.05_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 8640, 540, 540, 540, 34560, 540, 8640, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 540, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 540, 8640, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 540, 540, 8640, 540, 8640, 34560, 540, 540, 8640, 540, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 540, 34560, 34560, 34560, 8640, 8640, 540, 540, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 8640, 540, 540, 8640, 8640, 34560, 34560, 34560, 540, 34560, 8640, 8640, 540, 540, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 34560, 8640, 34560, 540, 540, 540, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2352780 . Total input tokens: 524176632 . Total output tokens: 470532189
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 109.79315868695267,
    "estimated_duration": 3600.096628339659,
    "input_throughput": 8010.5752642812495,
    "output_throughput": 7061.182969337123,
    "total_throughput": 15071.758233618373,
    "itl": 105.40801863570319,
    "ttft": 1884012.56283917,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1200234712101573,
    "arrivals": 783512,
    "finished_requests": 116592,
    "scheduler_time": 271.77531793311
}
#Debug simulation 
Total elapsed time: 109.79328364902176. Arrivals time: 0.5573510613758117 Scheduler time: 109.01841487362981 Scheduler overhead time: 0.08882256958168 Adapter cache time: 0.01720041234511882 Engine time: 0.08047431847080588 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.05_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.05_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 8640, 540, 540, 540, 34560, 540, 8640, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 540, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 540, 8640, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 540, 540, 8640, 540, 8640, 34560, 540, 540, 8640, 540, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 540, 34560, 34560, 34560, 8640, 8640, 540, 540, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 8640, 540, 540, 8640, 8640, 34560, 34560, 34560, 540, 34560, 8640, 8640, 540, 540, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 34560, 8640, 34560, 540, 540, 540, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2352780 . Total input tokens: 524176632 . Total output tokens: 470532189
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 112.56126602098811,
    "estimated_duration": 3600.0001271389656,
    "input_throughput": 7964.059718738246,
    "output_throughput": 7028.476418446327,
    "total_throughput": 14992.536137184574,
    "itl": 104.97763395074577,
    "ttft": 1878064.337495913,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 336,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0046568990871323,
    "arrivals": 783512,
    "finished_requests": 116037,
    "scheduler_time": 273.46213321241504
}
#Debug simulation 
Total elapsed time: 112.5613960409537. Arrivals time: 0.5578801325755194 Scheduler time: 111.78564228687901 Scheduler overhead time: 0.08904290327336639 Adapter cache time: 0.017541621578857303 Engine time: 0.07924981915857643 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.05_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.05
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.05_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.05_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.05 0.8  3.2 ]. Counts: [53 53 54]
Adapter prompts. [540, 34560, 540, 540, 8640, 540, 540, 540, 34560, 540, 8640, 34560, 8640, 540, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 540, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 540, 8640, 8640, 8640, 34560, 540, 540, 34560, 540, 34560, 540, 540, 8640, 540, 8640, 34560, 540, 540, 8640, 540, 540, 540, 540, 540, 34560, 8640, 8640, 34560, 8640, 540, 34560, 34560, 34560, 8640, 8640, 540, 540, 540, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 540, 540, 34560, 8640, 34560, 34560, 540, 34560, 540, 8640, 540, 540, 8640, 8640, 34560, 34560, 34560, 540, 34560, 8640, 8640, 540, 540, 540, 540, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 540, 8640, 8640, 34560, 8640, 34560, 540, 540, 540, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 540, 8640, 8640, 540, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 540, 34560, 540, 34560, 8640, 540, 8640, 540, 540, 8640, 8640, 8640, 34560, 8640, 540, 540]
Prompts retrieved: 2352780 . Total input tokens: 524176632 . Total output tokens: 470532189
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 109.51217177102808,
    "estimated_duration": 3600.1112850814416,
    "input_throughput": 8010.542651696837,
    "output_throughput": 7061.154221910373,
    "total_throughput": 15071.69687360721,
    "itl": 105.40821328764623,
    "ttft": 1884018.1013461838,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 338,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1347366642206949,
    "arrivals": 783512,
    "finished_requests": 116592,
    "scheduler_time": 271.77546155905634
}
#Debug simulation 
Total elapsed time: 109.51229203201365. Arrivals time: 0.6350074094953015 Scheduler time: 108.65247913892381 Scheduler overhead time: 0.0923613429768011 Adapter cache time: 0.01744949840940535 Engine time: 0.0826169754145667 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 8640, 270, 270, 270, 34560, 270, 8640, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 270, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 270, 8640, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 270, 270, 8640, 270, 8640, 34560, 270, 270, 8640, 270, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 270, 34560, 34560, 34560, 8640, 8640, 270, 270, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 8640, 270, 270, 8640, 8640, 34560, 34560, 34560, 270, 34560, 8640, 8640, 270, 270, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 34560, 8640, 34560, 270, 270, 270, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2338470 . Total input tokens: 520978248 . Total output tokens: 467723721
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 121.56555080600083,
    "estimated_duration": 3600.1059813125107,
    "input_throughput": 7864.943461935856,
    "output_throughput": 6969.618152977902,
    "total_throughput": 14834.561614913759,
    "itl": 104.24246650486003,
    "ttft": 1892580.9490870947,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8875414457404974,
    "arrivals": 778725,
    "finished_requests": 114860,
    "scheduler_time": 277.7536397420389
}
#Debug simulation 
Total elapsed time: 121.5656762040453. Arrivals time: 0.5649445235030726 Scheduler time: 120.78173701674677 Scheduler overhead time: 0.08935757330618799 Adapter cache time: 0.017801587702706456 Engine time: 0.08016016683541238 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 8640, 270, 270, 270, 34560, 270, 8640, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 270, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 270, 8640, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 270, 270, 8640, 270, 8640, 34560, 270, 270, 8640, 270, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 270, 34560, 34560, 34560, 8640, 8640, 270, 270, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 8640, 270, 270, 8640, 8640, 34560, 34560, 34560, 270, 34560, 8640, 8640, 270, 270, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 34560, 8640, 34560, 270, 270, 270, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2338470 . Total input tokens: 520978248 . Total output tokens: 467723721
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 107.60221037408337,
    "estimated_duration": 3600.0253258512494,
    "input_throughput": 8037.300680144036,
    "output_throughput": 7125.990702283186,
    "total_throughput": 15163.291382427222,
    "itl": 107.52044957893236,
    "ttft": 1884145.0964109646,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.126361465619417,
    "arrivals": 778725,
    "finished_requests": 117465,
    "scheduler_time": 268.3753431134885
}
#Debug simulation 
Total elapsed time: 107.60232803004328. Arrivals time: 0.5511905354214832 Scheduler time: 106.83683483419009 Scheduler overhead time: 0.08760791225358844 Adapter cache time: 0.017239053267985582 Engine time: 0.07846959494054317 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 8640, 270, 270, 270, 34560, 270, 8640, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 270, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 270, 8640, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 270, 270, 8640, 270, 8640, 34560, 270, 270, 8640, 270, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 270, 34560, 34560, 34560, 8640, 8640, 270, 270, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 8640, 270, 270, 8640, 8640, 34560, 34560, 34560, 270, 34560, 8640, 8640, 270, 270, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 34560, 8640, 34560, 270, 270, 270, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2338470 . Total input tokens: 520978248 . Total output tokens: 467723721
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 107.60369981708936,
    "estimated_duration": 3600.027223414705,
    "input_throughput": 8037.296443707168,
    "output_throughput": 7125.98694619505,
    "total_throughput": 15163.283389902219,
    "itl": 107.52049603124027,
    "ttft": 1884145.7486003102,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.1282554215565386,
    "arrivals": 778725,
    "finished_requests": 117465,
    "scheduler_time": 268.37534672099196
}
#Debug simulation 
Total elapsed time: 107.60381611506455. Arrivals time: 0.5530237391358241 Scheduler time: 106.8376569263637 Scheduler overhead time: 0.08690988679882139 Adapter cache time: 0.017299672355875373 Engine time: 0.07769601617474109 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 8640, 270, 270, 270, 34560, 270, 8640, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 270, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 270, 8640, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 270, 270, 8640, 270, 8640, 34560, 270, 270, 8640, 270, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 270, 34560, 34560, 34560, 8640, 8640, 270, 270, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 8640, 270, 270, 8640, 8640, 34560, 34560, 34560, 270, 34560, 8640, 8640, 270, 270, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 34560, 8640, 34560, 270, 270, 270, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2338470 . Total input tokens: 520978248 . Total output tokens: 467723721
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 108.09837491891813,
    "estimated_duration": 3600.0033723165348,
    "input_throughput": 8037.349693197982,
    "output_throughput": 7126.034157988106,
    "total_throughput": 15163.383851186089,
    "itl": 107.51837843989752,
    "ttft": 1884146.2307648177,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0801901946356545,
    "arrivals": 778725,
    "finished_requests": 117465,
    "scheduler_time": 268.3783613535346
}
#Debug simulation 
Total elapsed time: 108.09849648899399. Arrivals time: 0.5512624204857275 Scheduler time: 107.33337564615067 Scheduler overhead time: 0.08666604349855334 Adapter cache time: 0.01704088447149843 Engine time: 0.07923376455437392 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.025_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 8640, 270, 270, 270, 34560, 270, 8640, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 270, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 270, 8640, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 270, 270, 8640, 270, 8640, 34560, 270, 270, 8640, 270, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 270, 34560, 34560, 34560, 8640, 8640, 270, 270, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 8640, 270, 270, 8640, 8640, 34560, 34560, 34560, 270, 34560, 8640, 8640, 270, 270, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 34560, 8640, 34560, 270, 270, 270, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2338470 . Total input tokens: 520978248 . Total output tokens: 467723721
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 107.51438981108367,
    "estimated_duration": 3600.04129232854,
    "input_throughput": 8037.2650340587925,
    "output_throughput": 7125.959097932157,
    "total_throughput": 15163.22413199095,
    "itl": 107.52075219801893,
    "ttft": 1884151.203438342,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.142465599421417,
    "arrivals": 778725,
    "finished_requests": 117465,
    "scheduler_time": 268.375405534136
}
#Debug simulation 
Total elapsed time: 107.51451332401484. Arrivals time: 0.5533574330620468 Scheduler time: 106.7476321614813 Scheduler overhead time: 0.08643236488569528 Adapter cache time: 0.017256310675293207 Engine time: 0.07856523315422237 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.025_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.025_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 8640, 270, 270, 270, 34560, 270, 8640, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 270, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 270, 8640, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 270, 270, 8640, 270, 8640, 34560, 270, 270, 8640, 270, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 270, 34560, 34560, 34560, 8640, 8640, 270, 270, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 8640, 270, 270, 8640, 8640, 34560, 34560, 34560, 270, 34560, 8640, 8640, 270, 270, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 34560, 8640, 34560, 270, 270, 270, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2338470 . Total input tokens: 520978248 . Total output tokens: 467723721
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 121.97786505694967,
    "estimated_duration": 3600.084736057899,
    "input_throughput": 7864.989875489593,
    "output_throughput": 6969.6592829298515,
    "total_throughput": 14834.649158419445,
    "itl": 104.24213320683863,
    "ttft": 1892572.0668147528,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 290,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.8671145855216321,
    "arrivals": 778725,
    "finished_requests": 114860,
    "scheduler_time": 277.75342157908347
}
#Debug simulation 
Total elapsed time: 121.97798376402352. Arrivals time: 0.5573285036953166 Scheduler time: 121.201170057524 Scheduler overhead time: 0.09069874021224678 Adapter cache time: 0.017386588151566684 Engine time: 0.08014263375662267 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.025_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.025
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.025_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.025_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.025 0.8   3.2  ]. Counts: [53 53 54]
Adapter prompts. [270, 34560, 270, 270, 8640, 270, 270, 270, 34560, 270, 8640, 34560, 8640, 270, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 270, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 270, 8640, 8640, 8640, 34560, 270, 270, 34560, 270, 34560, 270, 270, 8640, 270, 8640, 34560, 270, 270, 8640, 270, 270, 270, 270, 270, 34560, 8640, 8640, 34560, 8640, 270, 34560, 34560, 34560, 8640, 8640, 270, 270, 270, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 270, 270, 34560, 8640, 34560, 34560, 270, 34560, 270, 8640, 270, 270, 8640, 8640, 34560, 34560, 34560, 270, 34560, 8640, 8640, 270, 270, 270, 270, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 270, 8640, 8640, 34560, 8640, 34560, 270, 270, 270, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 270, 8640, 8640, 270, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 270, 34560, 270, 34560, 8640, 270, 8640, 270, 270, 8640, 8640, 8640, 34560, 8640, 270, 270]
Prompts retrieved: 2338470 . Total input tokens: 520978248 . Total output tokens: 467723721
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 107.32741496607196,
    "estimated_duration": 3600.0553311980316,
    "input_throughput": 8037.233691730827,
    "output_throughput": 7125.931309356545,
    "total_throughput": 15163.165001087373,
    "itl": 107.52095976488003,
    "ttft": 1884156.163338583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 345,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.157430300004784,
    "arrivals": 778725,
    "finished_requests": 117465,
    "scheduler_time": 268.37548008886193
}
#Debug simulation 
Total elapsed time: 107.32769684505183. Arrivals time: 0.5490261267405003 Scheduler time: 106.56550446315669 Scheduler overhead time: 0.08627597230952233 Adapter cache time: 0.017113554407842457 Engine time: 0.07791949470993131 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 8640, 135, 135, 135, 34560, 135, 8640, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 135, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 135, 8640, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 135, 135, 8640, 135, 8640, 34560, 135, 135, 8640, 135, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 135, 34560, 34560, 34560, 8640, 8640, 135, 135, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 8640, 135, 135, 8640, 8640, 34560, 34560, 34560, 135, 34560, 8640, 8640, 135, 135, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 34560, 8640, 34560, 135, 135, 135, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2331315 . Total input tokens: 519399039 . Total output tokens: 466309476
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 109.80768237402663,
    "estimated_duration": 3600.063520860953,
    "input_throughput": 7984.050790616636,
    "output_throughput": 7109.9287142241,
    "total_throughput": 15093.979504840736,
    "itl": 107.37962330741345,
    "ttft": 1883779.6260977401,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9640536393388162,
    "arrivals": 776317,
    "finished_requests": 116689,
    "scheduler_time": 269.257931703052
}
#Debug simulation 
Total elapsed time: 109.80780903401319. Arrivals time: 0.5400529224425554 Scheduler time: 109.05458725488279 Scheduler overhead time: 0.08671884122304618 Adapter cache time: 0.01689973403699696 Engine time: 0.078273557825014 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 8640, 135, 135, 135, 34560, 135, 8640, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 135, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 135, 8640, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 135, 135, 8640, 135, 8640, 34560, 135, 135, 8640, 135, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 135, 34560, 34560, 34560, 8640, 8640, 135, 135, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 8640, 135, 135, 8640, 8640, 34560, 34560, 34560, 135, 34560, 8640, 8640, 135, 135, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 34560, 8640, 34560, 135, 135, 135, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2331315 . Total input tokens: 519399039 . Total output tokens: 466309476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 116.52337890898343,
    "estimated_duration": 3600.0090469724078,
    "input_throughput": 7923.566754363945,
    "output_throughput": 7047.513122595344,
    "total_throughput": 14971.07987695929,
    "itl": 105.6378561125628,
    "ttft": 1878987.5140577564,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9851228480669726,
    "arrivals": 776317,
    "finished_requests": 115765,
    "scheduler_time": 272.7048926542356
}
#Debug simulation 
Total elapsed time: 116.52349578600843. Arrivals time: 0.5582894398830831 Scheduler time: 115.74980718048755 Scheduler overhead time: 0.08743267832323909 Adapter cache time: 0.01738979120273143 Engine time: 0.07885282579809427 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 8640, 135, 135, 135, 34560, 135, 8640, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 135, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 135, 8640, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 135, 135, 8640, 135, 8640, 34560, 135, 135, 8640, 135, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 135, 34560, 34560, 34560, 8640, 8640, 135, 135, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 8640, 135, 135, 8640, 8640, 34560, 34560, 34560, 135, 34560, 8640, 8640, 135, 135, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 34560, 8640, 34560, 135, 135, 135, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2331315 . Total input tokens: 519399039 . Total output tokens: 466309476
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 162.54155521502253,
    "estimated_duration": 3600.0108655880927,
    "input_throughput": 7923.562751619698,
    "output_throughput": 7047.509562406671,
    "total_throughput": 14971.072314026369,
    "itl": 105.63788118834142,
    "ttft": 1878988.1947101422,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9869294387288443,
    "arrivals": 776317,
    "finished_requests": 115765,
    "scheduler_time": 272.7049046792472
}
#Debug simulation 
Total elapsed time: 162.5416894700611. Arrivals time: 1.0386112517444417 Scheduler time: 161.16193893074524 Scheduler overhead time: 0.13925344869494438 Adapter cache time: 0.029278248315677047 Engine time: 0.13114248518832028 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 8640, 135, 135, 135, 34560, 135, 8640, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 135, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 135, 8640, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 135, 135, 8640, 135, 8640, 34560, 135, 135, 8640, 135, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 135, 34560, 34560, 34560, 8640, 8640, 135, 135, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 8640, 135, 135, 8640, 8640, 34560, 34560, 34560, 135, 34560, 8640, 8640, 135, 135, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 34560, 8640, 34560, 135, 135, 135, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2331315 . Total input tokens: 519399039 . Total output tokens: 466309476
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 147.3871140369447,
    "estimated_duration": 3600.068458157209,
    "input_throughput": 7964.889371764232,
    "output_throughput": 7088.204931820124,
    "total_throughput": 15053.094303584356,
    "itl": 106.85418755603932,
    "ttft": 1883787.2514657779,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 316,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9893927828990892,
    "arrivals": 776317,
    "finished_requests": 116444,
    "scheduler_time": 270.27794332236834
}
#Debug simulation 
Total elapsed time: 147.3872717448976. Arrivals time: 0.9947897701058537 Scheduler time: 146.06812869757414 Scheduler overhead time: 0.13244910910725594 Adapter cache time: 0.028042580699548125 Engine time: 0.12379034166224301 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 8640, 135, 135, 135, 34560, 135, 8640, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 135, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 135, 8640, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 135, 135, 8640, 135, 8640, 34560, 135, 135, 8640, 135, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 135, 34560, 34560, 34560, 8640, 8640, 135, 135, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 8640, 135, 135, 8640, 8640, 34560, 34560, 34560, 135, 34560, 8640, 8640, 135, 135, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 34560, 8640, 34560, 135, 135, 135, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2331315 . Total input tokens: 519399039 . Total output tokens: 466309476
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 162.6092700670706,
    "estimated_duration": 3600.0234510024375,
    "input_throughput": 7923.535051433388,
    "output_throughput": 7047.48492483718,
    "total_throughput": 14971.019976270569,
    "itl": 105.63810519769929,
    "ttft": 1878993.3375545773,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9991275560110862,
    "arrivals": 776317,
    "finished_requests": 115765,
    "scheduler_time": 272.70499186058095
}
#Debug simulation 
Total elapsed time: 162.60942001501098. Arrivals time: 0.9850454188417643 Scheduler time: 161.28744999878109 Scheduler overhead time: 0.13943069579545408 Adapter cache time: 0.028857318102382123 Engine time: 0.1285711107775569 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_16-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-16/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_16-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 8640, 135, 135, 135, 34560, 135, 8640, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 135, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 135, 8640, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 135, 135, 8640, 135, 8640, 34560, 135, 135, 8640, 135, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 135, 34560, 34560, 34560, 8640, 8640, 135, 135, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 8640, 135, 135, 8640, 8640, 34560, 34560, 34560, 135, 34560, 8640, 8640, 135, 135, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 34560, 8640, 34560, 135, 135, 135, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2331315 . Total input tokens: 519399039 . Total output tokens: 466309476
Prompts distributed
Adapter sizes. Values: [16]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 151.7139782360755,
    "estimated_duration": 3600.0407356576716,
    "input_throughput": 7984.101322883805,
    "output_throughput": 7109.973714040203,
    "total_throughput": 15094.075036924007,
    "itl": 107.37908170105275,
    "ttft": 1883770.3271070318,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 315,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9418658428941866,
    "arrivals": 776317,
    "finished_requests": 116689,
    "scheduler_time": 269.25763441190804
}
#Debug simulation 
Total elapsed time: 151.7141350239981. Arrivals time: 0.9563926707487553 Scheduler time: 150.4430504613556 Scheduler overhead time: 0.12964619032572955 Adapter cache time: 0.027148061199113727 Engine time: 0.1207122434861958 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_16-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.0125
    ],
    "served_adapters_sizes": [
        16,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.0125_size_16-16-32/adapters_160_slots_16_rate_3.2-0.8-0.0125_size_16-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.0125 0.8    3.2   ]. Counts: [53 53 54]
Adapter prompts. [135, 34560, 135, 135, 8640, 135, 135, 135, 34560, 135, 8640, 34560, 8640, 135, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 135, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 135, 8640, 8640, 8640, 34560, 135, 135, 34560, 135, 34560, 135, 135, 8640, 135, 8640, 34560, 135, 135, 8640, 135, 135, 135, 135, 135, 34560, 8640, 8640, 34560, 8640, 135, 34560, 34560, 34560, 8640, 8640, 135, 135, 135, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 135, 135, 34560, 8640, 34560, 34560, 135, 34560, 135, 8640, 135, 135, 8640, 8640, 34560, 34560, 34560, 135, 34560, 8640, 8640, 135, 135, 135, 135, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 135, 8640, 8640, 34560, 8640, 34560, 135, 135, 135, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 135, 8640, 8640, 135, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 135, 34560, 135, 34560, 8640, 135, 8640, 135, 135, 8640, 8640, 8640, 34560, 8640, 135, 135]
Prompts retrieved: 2331315 . Total input tokens: 519399039 . Total output tokens: 466309476
Prompts distributed
Adapter sizes. Values: [16 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 165.28643668396398,
    "estimated_duration": 3600.0368800229085,
    "input_throughput": 7923.5054947044,
    "output_throughput": 7047.458635990016,
    "total_throughput": 14970.964130694416,
    "itl": 105.63827215133453,
    "ttft": 1878998.6185940586,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 302,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0122059497982319,
    "arrivals": 776317,
    "finished_requests": 115765,
    "scheduler_time": 272.70514241011307
}
#Debug simulation 
Total elapsed time: 165.28657756000757. Arrivals time: 0.9911123460624367 Scheduler time: 163.95990360644646 Scheduler overhead time: 0.13668101641815156 Adapter cache time: 0.029390326468273997 Engine time: 0.12985607818700373 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-8-8
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        8
    ],
    "available_gpu_memory": 694848,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-8/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-8-8",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 8640, 66, 66, 66, 34560, 66, 8640, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 66, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 66, 8640, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 66, 66, 8640, 66, 8640, 34560, 66, 66, 8640, 66, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 66, 34560, 34560, 34560, 8640, 8640, 66, 66, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 8640, 66, 66, 8640, 8640, 34560, 34560, 34560, 66, 34560, 8640, 8640, 66, 66, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 34560, 8640, 34560, 66, 66, 66, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2327658 . Total input tokens: 518585562 . Total output tokens: 465577310
Prompts distributed
Adapter sizes. Values: [8]. Counts: [160]
---Simulation End---
#Simulation results
{
    "duration": 150.7883921529865,
    "estimated_duration": 3600.092699255897,
    "input_throughput": 8112.971648212527,
    "output_throughput": 7146.919301638551,
    "total_throughput": 15259.890949851077,
    "itl": 107.21537882942788,
    "ttft": 1879595.7619521955,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9518116883630852,
    "arrivals": 775108,
    "finished_requests": 117767,
    "scheduler_time": 267.35007661487094
}
#Debug simulation 
Total elapsed time: 150.7885806140257. Arrivals time: 0.7780729836085811 Scheduler time: 149.7133057442261 Scheduler overhead time: 0.1186441380996257 Adapter cache time: 0.0244450910249725 Engine time: 0.1173565856879577 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-8-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-16/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-8-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 8640, 66, 66, 66, 34560, 66, 8640, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 66, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 66, 8640, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 66, 66, 8640, 66, 8640, 34560, 66, 66, 8640, 66, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 66, 34560, 34560, 34560, 8640, 8640, 66, 66, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 8640, 66, 66, 8640, 8640, 34560, 34560, 34560, 66, 34560, 8640, 8640, 66, 66, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 34560, 8640, 34560, 66, 66, 66, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2327658 . Total input tokens: 518585562 . Total output tokens: 465577310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 149.04372954904102,
    "estimated_duration": 3600.025689617703,
    "input_throughput": 8112.845162252583,
    "output_throughput": 7146.852333359938,
    "total_throughput": 15259.697495612521,
    "itl": 107.21663779150684,
    "ttft": 1879566.9637663555,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0132590866764128,
    "arrivals": 775108,
    "finished_requests": 117763,
    "scheduler_time": 267.3423017267229
}
#Debug simulation 
Total elapsed time: 149.0438728040317. Arrivals time: 0.7847612701589242 Scheduler time: 147.96369701181538 Scheduler overhead time: 0.11756732081994414 Adapter cache time: 0.023659729631617665 Engine time: 0.11766183946747333 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-8-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        8,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-8-32/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-8-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 8640, 66, 66, 66, 34560, 66, 8640, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 66, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 66, 8640, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 66, 66, 8640, 66, 8640, 34560, 66, 66, 8640, 66, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 66, 34560, 34560, 34560, 8640, 8640, 66, 66, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 8640, 66, 66, 8640, 8640, 34560, 34560, 34560, 66, 34560, 8640, 8640, 66, 66, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 34560, 8640, 34560, 66, 66, 66, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2327658 . Total input tokens: 518585562 . Total output tokens: 465577310
Prompts distributed
Adapter sizes. Values: [ 8 32]. Counts: [107  53]
---Simulation End---
#Simulation results
{
    "duration": 149.53222271194682,
    "estimated_duration": 3600.027663908087,
    "input_throughput": 8112.840713088941,
    "output_throughput": 7146.848413956212,
    "total_throughput": 15259.689127045152,
    "itl": 107.21667849874946,
    "ttft": 1879567.4759664182,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.015332850851124,
    "arrivals": 775108,
    "finished_requests": 117763,
    "scheduler_time": 267.3423022915026
}
#Debug simulation 
Total elapsed time: 149.53235977701843. Arrivals time: 0.761214398429729 Scheduler time: 148.47458154079504 Scheduler overhead time: 0.11844746756833047 Adapter cache time: 0.024040274671278894 Engine time: 0.11696919414680451 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-16-16
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        16
    ],
    "available_gpu_memory": 683472,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-16/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-16-16",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 8640, 66, 66, 66, 34560, 66, 8640, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 66, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 66, 8640, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 66, 66, 8640, 66, 8640, 34560, 66, 66, 8640, 66, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 66, 34560, 34560, 34560, 8640, 8640, 66, 66, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 8640, 66, 66, 8640, 8640, 34560, 34560, 34560, 66, 34560, 8640, 8640, 66, 66, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 34560, 8640, 34560, 66, 66, 66, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2327658 . Total input tokens: 518585562 . Total output tokens: 465577310
Prompts distributed
Adapter sizes. Values: [ 8 16]. Counts: [ 54 106]
---Simulation End---
#Simulation results
{
    "duration": 149.73556548496708,
    "estimated_duration": 3600.1146441545166,
    "input_throughput": 8112.92219469287,
    "output_throughput": 7146.875736798255,
    "total_throughput": 15259.797931491124,
    "itl": 107.21614597755674,
    "ttft": 1879604.4998637836,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 0.9740339361061378,
    "arrivals": 775108,
    "finished_requests": 117767,
    "scheduler_time": 267.3508996900953
}
#Debug simulation 
Total elapsed time: 149.73570345097687. Arrivals time: 0.7731005802052096 Scheduler time: 148.66483015404083 Scheduler overhead time: 0.11874685215298086 Adapter cache time: 0.02353171946015209 Engine time: 0.11809555266518146 
------------>Running benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-16-32
With arguments {
    "total_time": 3600.0,
    "model": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/models/qwen/qwen-2.5-7b-instruct",
    "adapter_slots": 16,
    "served_adapters": 160,
    "served_adapters_rates": [
        3.2,
        0.8,
        0.00625
    ],
    "served_adapters_sizes": [
        8,
        16,
        32
    ],
    "available_gpu_memory": 657616,
    "max_num_batched_tokens": 2048,
    "dataset_path": "/gpfs/scratch/bsc98/bsc098069/llm_benchmarking/data/ShareGPT_V3_unfiltered_cleaned_split.json",
    "output_path": "benchmarks/lora/definitive_results/finding_maximum/simulation_dataset/with_offloading/qwen-2.5-7b-instruct/results/rate_3.2-0.8-0.00625_size_8-16-32/adapters_160_slots_16_rate_3.2-0.8-0.00625_size_8-16-32",
    "print_outcome": true,
    "mean_version": true,
    "include_computation_overhead": true,
    "include_preemption": true,
    "without_offloading": false,
    "include_network_collapse": 25500
}
Adapter rates. Values: [0.00625 0.8     3.2    ]. Counts: [53 53 54]
Adapter prompts. [66, 34560, 66, 66, 8640, 66, 66, 66, 34560, 66, 8640, 34560, 8640, 66, 8640, 8640, 8640, 8640, 34560, 34560, 34560, 8640, 8640, 8640, 34560, 34560, 66, 34560, 8640, 34560, 34560, 34560, 8640, 34560, 66, 8640, 8640, 8640, 34560, 66, 66, 34560, 66, 34560, 66, 66, 8640, 66, 8640, 34560, 66, 66, 8640, 66, 66, 66, 66, 66, 34560, 8640, 8640, 34560, 8640, 66, 34560, 34560, 34560, 8640, 8640, 66, 66, 66, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 66, 66, 34560, 8640, 34560, 34560, 66, 34560, 66, 8640, 66, 66, 8640, 8640, 34560, 34560, 34560, 66, 34560, 8640, 8640, 66, 66, 66, 66, 34560, 8640, 34560, 8640, 34560, 34560, 34560, 66, 8640, 8640, 34560, 8640, 34560, 66, 66, 66, 8640, 8640, 8640, 34560, 34560, 8640, 34560, 66, 8640, 8640, 66, 34560, 34560, 34560, 34560, 34560, 34560, 8640, 8640, 8640, 8640, 8640, 34560, 66, 34560, 66, 34560, 8640, 66, 8640, 66, 66, 8640, 8640, 8640, 34560, 8640, 66, 66]
Prompts retrieved: 2327658 . Total input tokens: 518585562 . Total output tokens: 465577310
Prompts distributed
Adapter sizes. Values: [ 8 16 32]. Counts: [54 53 53]
---Simulation End---
#Simulation results
{
    "duration": 149.24584035598673,
    "estimated_duration": 3600.0394903593883,
    "input_throughput": 8112.814061682515,
    "output_throughput": 7146.824935920777,
    "total_throughput": 15259.638997603292,
    "itl": 107.21693106541655,
    "ttft": 1879572.3415588583,
    "total_loads_from_disk": 0,
    "total_loads_from_memory": 311,
    "loading_time_from_disk": 0,
    "loading_time_from_memory": 1.0274052143469505,
    "arrivals": 775108,
    "finished_requests": 117763,
    "scheduler_time": 267.3423564950589
}
#Debug simulation 
Total elapsed time: 149.2459798560012. Arrivals time: 0.7754783279960975 Scheduler time: 148.1720220814459 Scheduler overhead time: 0.11975047353189439 Adapter cache time: 0.02361809986177832 Engine time: 0.11798411456402391 
